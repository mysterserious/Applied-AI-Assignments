{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDFassignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgf8xWsj5M6F"
      },
      "source": [
        "# **TASK 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ynsvPYJE_o"
      },
      "source": [
        "## SkLearn# Collection of string documents\n",
        "\n",
        "corpus = [\n",
        "     'this is the first document',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document',\n",
        "]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV9EJF_MPtny"
      },
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrL6RibwPyey",
        "outputId": "3b79cc14-532b-4352-9ed6-99201c8d0c57"
      },
      "source": [
        "def idf(unique_words,dataset):\n",
        "    idf_values={}\n",
        "    counts=[]\n",
        "    for i in unique_words:\n",
        "        count=0  \n",
        "        for j in dataset:\n",
        "            if i in j.split():\n",
        "                count+=1          \n",
        "        idf_values[i]=((1+math.log((len(dataset)+1)/(1+count))))\n",
        "    return idf_values\n",
        "def fit(dataset):\n",
        "    unique_words=set()\n",
        "    for i in dataset:\n",
        "        for j in i.split():  \n",
        "            unique_words.add(j)\n",
        "    unique_words=sorted(list(unique_words))\n",
        "    vocab={j:i for i,j in enumerate(unique_words)}\n",
        "    idf_dict=idf(unique_words,dataset)\n",
        "    return vocab,idf_dict\n",
        "def transform(dataset,vocab,idf_values):\n",
        "    rows=[]\n",
        "    columns=[]\n",
        "    values=[]\n",
        "    for i,row in enumerate(dataset):\n",
        "        word_freq=dict(Counter(row.split()))\n",
        "        for word,freq in word_freq.items():\n",
        "            col_ind=vocab.get(word,-1)\n",
        "            if col_ind!=-1:\n",
        "                columns.append(col_ind)\n",
        "                rows.append(i)\n",
        "                values.append(idf_values[word]*(freq/len(row.split())))\n",
        "    matrix=csr_matrix((values,(rows,columns)),shape=(len(dataset),len(vocab)))             \n",
        "    nor_matrix=normalize(matrix)\n",
        "    return nor_matrix    \n",
        "             \n",
        "vocabulary,idf_dict=fit(corpus) \n",
        "matrix=transform(corpus,vocabulary,idf_dict)\n",
        "print(matrix)\n",
        "print('value of row and column (0,8) using sklearn\\'s TfidfVectorizer is 0.38408524091481483')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t0.4697913855799205\n",
            "  (0, 2)\t0.580285823684436\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n",
            "  (1, 1)\t0.6876235979836937\n",
            "  (1, 3)\t0.2810886740337529\n",
            "  (1, 5)\t0.5386476208856762\n",
            "  (1, 6)\t0.2810886740337529\n",
            "  (1, 8)\t0.2810886740337529\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.4697913855799205\n",
            "  (3, 2)\t0.580285823684436\n",
            "  (3, 3)\t0.3840852409148149\n",
            "  (3, 6)\t0.3840852409148149\n",
            "  (3, 8)\t0.3840852409148149\n",
            "value of row and column (0,8) using sklearn's TfidfVectorizer is 0.38408524091481483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYIzWU7ZrlGg"
      },
      "source": [
        "# **TASK 2**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB02_e4uX_2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a213348-bd62-4701-c64a-8b7a508f5cc0"
      },
      "source": [
        "import pickle\n",
        "with open('cleaned_strings', 'rb') as f:\n",
        "    corpus = pickle.load(f)\n",
        "    \n",
        "# printing the length of the corpus loaded\n",
        "print(\"Number of documents in corpus = \",len(corpus))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in corpus =  746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrpmLdISsszu",
        "outputId": "6bc5d452-32c3-4d5d-8c5f-48966a243a2d"
      },
      "source": [
        "def idf(unique_words,dataset):\n",
        "    idf_values={}\n",
        "    for i in unique_words:\n",
        "        count=0  \n",
        "        for j in dataset:\n",
        "            if i in j.split():\n",
        "                count+=1          \n",
        "        idf_values[i]=((1+math.log((len(dataset)+1)/(1+count))))\n",
        "    idf_sorted=sorted(idf_values.items(),key=lambda idf:(idf[1],idf[0]),reverse=True)\n",
        "    idf_sorted=idf_sorted[0:50]\n",
        "    return dict(idf_sorted)\n",
        "def fit(dataset):\n",
        "    unique_words=set()\n",
        "    for i in dataset:\n",
        "        for j in i.split():  \n",
        "            unique_words.add(j)\n",
        "    unique_words=sorted(list(unique_words))\n",
        "    idf_dict=idf(unique_words,dataset)\n",
        "    count=0\n",
        "    vocab=[]\n",
        "    for i,j in idf_dict.items():\n",
        "        vocab.append((i,count))\n",
        "        count+=1    \n",
        "    return dict(vocab),idf_dict\n",
        "def transform(dataset,vocab,idf_values):\n",
        "    rows=[]\n",
        "    columns=[]\n",
        "    values=[]\n",
        "    for i,row in enumerate(dataset):\n",
        "        word_freq=dict(Counter(row.split()))\n",
        "        for word,freq in word_freq.items():\n",
        "            col_ind=vocab.get(word,-1)\n",
        "            if col_ind!=-1:\n",
        "                columns.append(col_ind)\n",
        "                rows.append(i)\n",
        "                values.append(idf_values[word]*(freq/len(row.split())))\n",
        "    matrix=csr_matrix((values,(rows,columns)),shape=(len(dataset),len(vocab)))             \n",
        "    nor_matrix=normalize(matrix)\n",
        "    return nor_matrix\n",
        "vocabulary,idf_values=fit(corpus)\n",
        "print(idf_values)\n",
        "print(vocabulary)\n",
        "print(len(vocabulary))\n",
        "matrix=transform(corpus,vocabulary,idf_values)\n",
        "print(matrix)       \n",
        "print(matrix.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'zombiez': 6.922918004572872, 'zillion': 6.922918004572872, 'z': 6.922918004572872, 'yun': 6.922918004572872, 'youtube': 6.922918004572872, 'youthful': 6.922918004572872, 'younger': 6.922918004572872, 'yelps': 6.922918004572872, 'yawn': 6.922918004572872, 'yardley': 6.922918004572872, 'x': 6.922918004572872, 'wrote': 6.922918004572872, 'writers': 6.922918004572872, 'wrap': 6.922918004572872, 'wow': 6.922918004572872, 'woven': 6.922918004572872, 'wouldnt': 6.922918004572872, 'worthy': 6.922918004572872, 'worthwhile': 6.922918004572872, 'worthless': 6.922918004572872, 'worry': 6.922918004572872, 'worked': 6.922918004572872, 'woo': 6.922918004572872, 'wont': 6.922918004572872, 'wong': 6.922918004572872, 'wondered': 6.922918004572872, 'woa': 6.922918004572872, 'witticisms': 6.922918004572872, 'within': 6.922918004572872, 'wise': 6.922918004572872, 'win': 6.922918004572872, 'wily': 6.922918004572872, 'willie': 6.922918004572872, 'william': 6.922918004572872, 'wild': 6.922918004572872, 'wih': 6.922918004572872, 'wife': 6.922918004572872, 'widmark': 6.922918004572872, 'wide': 6.922918004572872, 'whoever': 6.922918004572872, 'whites': 6.922918004572872, 'whine': 6.922918004572872, 'whenever': 6.922918004572872, 'went': 6.922918004572872, 'welsh': 6.922918004572872, 'weight': 6.922918004572872, 'wedding': 6.922918004572872, 'website': 6.922918004572872, 'weaving': 6.922918004572872, 'weariness': 6.922918004572872}\n",
            "{'zombiez': 0, 'zillion': 1, 'z': 2, 'yun': 3, 'youtube': 4, 'youthful': 5, 'younger': 6, 'yelps': 7, 'yawn': 8, 'yardley': 9, 'x': 10, 'wrote': 11, 'writers': 12, 'wrap': 13, 'wow': 14, 'woven': 15, 'wouldnt': 16, 'worthy': 17, 'worthwhile': 18, 'worthless': 19, 'worry': 20, 'worked': 21, 'woo': 22, 'wont': 23, 'wong': 24, 'wondered': 25, 'woa': 26, 'witticisms': 27, 'within': 28, 'wise': 29, 'win': 30, 'wily': 31, 'willie': 32, 'william': 33, 'wild': 34, 'wih': 35, 'wife': 36, 'widmark': 37, 'wide': 38, 'whoever': 39, 'whites': 40, 'whine': 41, 'whenever': 42, 'went': 43, 'welsh': 44, 'weight': 45, 'wedding': 46, 'website': 47, 'weaving': 48, 'weariness': 49}\n",
            "50\n",
            "  (19, 5)\t0.5773502691896258\n",
            "  (19, 20)\t0.5773502691896258\n",
            "  (19, 39)\t0.5773502691896258\n",
            "  (68, 36)\t1.0\n",
            "  (70, 46)\t1.0\n",
            "  (80, 41)\t1.0\n",
            "  (109, 0)\t1.0\n",
            "  (135, 13)\t0.37796447300922725\n",
            "  (135, 26)\t0.37796447300922725\n",
            "  (135, 27)\t0.37796447300922725\n",
            "  (135, 29)\t0.37796447300922725\n",
            "  (135, 35)\t0.37796447300922725\n",
            "  (135, 47)\t0.37796447300922725\n",
            "  (135, 49)\t0.37796447300922725\n",
            "  (148, 8)\t0.7071067811865476\n",
            "  (148, 38)\t0.7071067811865476\n",
            "  (155, 12)\t1.0\n",
            "  (191, 31)\t1.0\n",
            "  (222, 7)\t1.0\n",
            "  (251, 14)\t1.0\n",
            "  (270, 3)\t0.7071067811865476\n",
            "  (270, 22)\t0.7071067811865476\n",
            "  (321, 1)\t1.0\n",
            "  (323, 2)\t1.0\n",
            "  (326, 37)\t1.0\n",
            "  (337, 40)\t1.0\n",
            "  (340, 16)\t1.0\n",
            "  (341, 32)\t1.0\n",
            "  (350, 24)\t0.7071067811865476\n",
            "  (350, 33)\t0.7071067811865476\n",
            "  (361, 11)\t1.0\n",
            "  (366, 21)\t1.0\n",
            "  (378, 45)\t1.0\n",
            "  (421, 44)\t1.0\n",
            "  (452, 15)\t1.0\n",
            "  (464, 43)\t1.0\n",
            "  (495, 23)\t1.0\n",
            "  (514, 9)\t1.0\n",
            "  (518, 4)\t1.0\n",
            "  (535, 42)\t1.0\n",
            "  (555, 17)\t1.0\n",
            "  (562, 34)\t1.0\n",
            "  (633, 28)\t1.0\n",
            "  (634, 25)\t1.0\n",
            "  (644, 6)\t0.7071067811865475\n",
            "  (644, 10)\t0.7071067811865475\n",
            "  (663, 30)\t1.0\n",
            "  (680, 18)\t1.0\n",
            "  (720, 19)\t1.0\n",
            "  (734, 48)\t1.0\n",
            "(746, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_87uBVmv4ApB",
        "outputId": "aa923438-886d-4d3a-bfbb-2c1aa8e5bf53"
      },
      "source": [
        ""
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "746\n"
          ]
        }
      ]
    }
  ]
}