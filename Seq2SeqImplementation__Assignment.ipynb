{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYHE_1ck2az"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**\n",
        "\n",
        "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
        " so do read the references completly and after that only please check the internet.\n",
        " The best things is to read the research papers and try to implement it on your own. \n",
        "\n",
        "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
        "\n",
        "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
        " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
        "with out learning much and didn't spend your time productively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfZo8fmLOec"
      },
      "source": [
        "## Task -1: Simple Encoder and Decoder\n",
        "Implement simple Encoder-Decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNSZXNkkOkO"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data this way only: \n",
        "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
        "    \n",
        "3. You have to implement a simple Encoder and Decoder architecture  \n",
        "\n",
        "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "6.  a. Check the reference notebook <br>\n",
        "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGrKqlHZuEK5",
        "outputId": "5f164199-0344-4e08-d7aa-49c6798b9293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fU80Ao-AGaob"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "f=zipfile.ZipFile('/content/drive/MyDrive/ita-eng.zip','r')\n",
        "f.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FPTX8SH-jmSQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "tmFXRV6gwHiV",
        "outputId": "fc9bbca5-0d6d-4b5b-da47-9fe8809826af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(354238, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1     Hi.     Ciao.\n",
              "2    Run!    Corri!\n",
              "3    Run!    Corra!\n",
              "4    Run!  Correte!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c47e5733-de2b-4b23-ad50-78502eb59dff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c47e5733-de2b-4b23-ad50-78502eb59dff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c47e5733-de2b-4b23-ad50-78502eb59dff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c47e5733-de2b-4b23-ad50-78502eb59dff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])\n",
        "data = pd.DataFrame(data=list(zip(eng,ita)), columns=['english','italian'])\n",
        "print(data.shape)\n",
        "data.head() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fuqO0fsCxmSb"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9QqElB_nKZos",
        "outputId": "a15f639d-8a78-42ab-d088-c0c4c9b2f35f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06e9392e-b668-40bb-9cac-ea35fb6fb2a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06e9392e-b668-40bb-9cac-ea35fb6fb2a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06e9392e-b668-40bb-9cac-ea35fb6fb2a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06e9392e-b668-40bb-9cac-ea35fb6fb2a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['english'] = data['english'].apply(preprocess)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gcvrGsaMxyIH"
      },
      "outputs": [],
      "source": [
        "ita_lengths = data['italian'].str.split().apply(len)\n",
        "eng_lengths = data['english'].str.split().apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UGFTl52xx-OT"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92bCe3u5x75Q",
        "outputId": "03d149f7-f977-4708-b3e7-be936cf7dcd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 3.0\n",
            "20 4.0\n",
            "30 4.0\n",
            "40 5.0\n",
            "50 5.0\n",
            "60 6.0\n",
            "70 6.0\n",
            "80 7.0\n",
            "90 8.0\n",
            "100 92.0\n",
            "90 8.0\n",
            "91 8.0\n",
            "92 8.0\n",
            "93 9.0\n",
            "94 9.0\n",
            "95 9.0\n",
            "96 9.0\n",
            "97 10.0\n",
            "98 11.0\n",
            "99 12.0\n",
            "100 92.0\n",
            "99.1 12.0\n",
            "99.2 12.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 13.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 22.0\n",
            "100 92.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(ita_lengths, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ8JbFOsyHxR",
        "outputId": "2b1d4da4-6ae9-44d7-9737-578f9ee1c877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 4.0\n",
            "20 4.0\n",
            "30 5.0\n",
            "40 5.0\n",
            "50 6.0\n",
            "60 6.0\n",
            "70 7.0\n",
            "80 7.0\n",
            "90 8.0\n",
            "100 101.0\n",
            "90 8.0\n",
            "91 9.0\n",
            "92 9.0\n",
            "93 9.0\n",
            "94 9.0\n",
            "95 9.0\n",
            "96 10.0\n",
            "97 10.0\n",
            "98 11.0\n",
            "99 12.0\n",
            "100 101.0\n",
            "99.1 12.0\n",
            "99.2 13.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 14.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 25.0\n",
            "100 101.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(eng_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(eng_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(eng_lengths, i))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aypsO2JHZvse",
        "outputId": "16a25016-42e4-4e3d-b9c8-3557b1cd08c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ab1bc7d-bf2a-44f5-92d3-7aa2ab3d9d7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ab1bc7d-bf2a-44f5-92d3-7aa2ab3d9d7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ab1bc7d-bf2a-44f5-92d3-7aa2ab3d9d7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ab1bc7d-bf2a-44f5-92d3-7aa2ab3d9d7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1skZ1EryyTFS",
        "outputId": "63880dbc-87c7-4de3-bdab-e22d0fe6420e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english  italian  italian_len  english_len  english_inp english_out\n",
              "0      hi     ciao            1            1   <start> hi    hi <end>\n",
              "1      hi     ciao            1            1   <start> hi    hi <end>\n",
              "2     run    corri            1            1  <start> run   run <end>\n",
              "3     run    corra            1            1  <start> run   run <end>\n",
              "4     run  correte            1            1  <start> run   run <end>"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee1b2754-4e87-45fe-9dc3-8758c498b68e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "      <th>italian_len</th>\n",
              "      <th>english_len</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee1b2754-4e87-45fe-9dc3-8758c498b68e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee1b2754-4e87-45fe-9dc3-8758c498b68e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee1b2754-4e87-45fe-9dc3-8758c498b68e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 22]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 25]\n",
        "\n",
        "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
        "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
        "# data = data.drop(['english','italian_len','english_len','italian'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OTUCge0JZ8oF",
        "outputId": "d1fe1261-ff31-4af1-9f2d-637a6b1f43e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   italian  english_inp english_out\n",
              "0     ciao   <start> hi    hi <end>\n",
              "1     ciao   <start> hi    hi <end>\n",
              "2    corri  <start> run   run <end>\n",
              "3    corra  <start> run   run <end>\n",
              "4  correte  <start> run   run <end>"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e9058c9-cb0e-4f0d-9f52-926bbff86155\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e9058c9-cb0e-4f0d-9f52-926bbff86155')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e9058c9-cb0e-4f0d-9f52-926bbff86155 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e9058c9-cb0e-4f0d-9f52-926bbff86155');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EkOVyUxdzRMa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data, test_size=0.2,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "707hyioJzYHf",
        "outputId": "4a7fda22-699d-40ff-fa4a-d6a760607d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(283068, 3) (70767, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train.shape, validation.shape)\n",
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LW3sLMycbRSd",
        "outputId": "abd0a995-3fa7-460b-8eb0-76b2bbae674f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   italian  \\\n",
              "122627    ci vedremo la settimana prossima   \n",
              "130538        chi le ha dato questo elenco   \n",
              "161415  dobbiamo andarcene da questo posto   \n",
              "207536       tom sta guardando un film ora   \n",
              "102547              non si scordi la borsa   \n",
              "\n",
              "                                   english_inp  \\\n",
              "122627  <start> i will see you next week <end>   \n",
              "130538          <start> who gave you this list   \n",
              "161415        <start> we must leave this place   \n",
              "207536     <start> tom is watching a movie now   \n",
              "102547          <start> do not forget your bag   \n",
              "\n",
              "                              english_out  \n",
              "122627     i will see you next week <end>  \n",
              "130538       who gave you this list <end>  \n",
              "161415     we must leave this place <end>  \n",
              "207536  tom is watching a movie now <end>  \n",
              "102547       do not forget your bag <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41f7e7a4-ebab-48f3-8ad4-453331b7e4bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122627</th>\n",
              "      <td>ci vedremo la settimana prossima</td>\n",
              "      <td>&lt;start&gt; i will see you next week &lt;end&gt;</td>\n",
              "      <td>i will see you next week &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130538</th>\n",
              "      <td>chi le ha dato questo elenco</td>\n",
              "      <td>&lt;start&gt; who gave you this list</td>\n",
              "      <td>who gave you this list &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161415</th>\n",
              "      <td>dobbiamo andarcene da questo posto</td>\n",
              "      <td>&lt;start&gt; we must leave this place</td>\n",
              "      <td>we must leave this place &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207536</th>\n",
              "      <td>tom sta guardando un film ora</td>\n",
              "      <td>&lt;start&gt; tom is watching a movie now</td>\n",
              "      <td>tom is watching a movie now &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102547</th>\n",
              "      <td>non si scordi la borsa</td>\n",
              "      <td>&lt;start&gt; do not forget your bag</td>\n",
              "      <td>do not forget your bag &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41f7e7a4-ebab-48f3-8ad4-453331b7e4bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41f7e7a4-ebab-48f3-8ad4-453331b7e4bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41f7e7a4-ebab-48f3-8ad4-453331b7e4bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1oubpe_5z9T6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k5miZI23zrsb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JuuvFID7zncC"
      },
      "outputs": [],
      "source": [
        "tknizer_ita = Tokenizer()\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5SwGhLvzoTK",
        "outputId": "ab1696a4-43be-4a97-bc85-a286fff9d828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13086\n",
            "26775\n"
          ]
        }
      ],
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(vocab_size_ita)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SE3ojlp0N5Y",
        "outputId": "04e146fb-858b-40f3-a5b0-4968dcb04229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 10327\n"
          ]
        }
      ],
      "source": [
        "print(tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMQBPEgT0VeJ"
      },
      "outputs": [],
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/drive/MyDrive/Kaggle/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
        "for word, i in tknizer_eng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwHEE6cLSN5H"
      },
      "outputs": [],
      "source": [
        "np.save('/content/drive/MyDrive/Kaggle/seq2seqEmbedding.npy',embedding_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66ZqpaMUSlpz"
      },
      "outputs": [],
      "source": [
        "embedding_matrix=np.load('/content/drive/MyDrive/Kaggle/seq2seqEmbedding.npy',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrnAzmoH8sV4",
        "outputId": "8a57b98a-f283-4184-c63b-15432023da4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13052, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K_JHGUTxhNSu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hwDVcwXMmFlG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LSTM,Embedding,Dense,Input,TimeDistributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "9cex2XfCLOew"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.inp_vocab_size=inp_vocab_size\n",
        "        self.embedding_size=embedding_size\n",
        "        self.input_length=input_length\n",
        "        self.lstm_size=lstm_size\n",
        "        self.encoder_output = 0\n",
        "        self.encoder_state_h=0\n",
        "        self.encoder_state_c=0\n",
        "        self.embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True,return_sequences=True, name=\"Encoder_LSTM\")\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        print(\"ENCODER ==> INPUT SQUENCES SHAPE :\",input_sequence.shape)\n",
        "        input_embedd                           = self.embedding(input_sequence)\n",
        "\n",
        "        self.encoder_output, self.encoder_state_h,self.encoder_state_c = self.lstm(input_embedd,states)\n",
        "        return self.encoder_output, self.encoder_state_h,self.encoder_state_c\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      self.initial_hidden_state=tf.zeros(shape=(batch_size,self.lstm_size))\n",
        "      self.initial_cell_state=tf.zeros(shape=(batch_size,self.lstm_size))\n",
        "      return [self.initial_hidden_state,self.initial_cell_state]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziSqOgmhLOe1",
        "outputId": "5b16a302-07b7-4761-d6da-f0d97e9ebd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (16, 10)\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "x1ES1-sJLOe4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Decoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.out_vocab_size=out_vocab_size\n",
        "        self.embedding_size=embedding_size\n",
        "        self.lstm_size=lstm_size\n",
        "        self.input_length=input_length\n",
        "        self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,mask_zero=True, name=\"embedding_layer_decoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
        "    def call(self,input_sequence,initial_states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "        \n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "\n",
        "        print(\"DECODER ==> INPUT SQUENCES SHAPE :\",input_sequence.shape)\n",
        "        target_embedd           = self.embedding(input_sequence)\n",
        "        print(\"WE ARE INITIALIZING DECODER WITH ENCODER STATES :\",initial_states)\n",
        "        decoder_output, decoder_final_state_h,decoder_final_state_c= self.lstm(target_embedd, initial_state=initial_states)\n",
        "        return decoder_output,decoder_final_state_h,decoder_final_state_c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B0gokgKLOe8",
        "outputId": "d08e0eea-f2ba-47a4-d586-1fc8bd315175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 5 1 7 7 9 6 2 0 8], shape=(10,), dtype=int32)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (32, 10)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor: shape=(32, 16), dtype=float32, numpy=\n",
            "array([[0.92179024, 0.16340113, 0.6480031 , 0.43840408, 0.32647872,\n",
            "        0.13078666, 0.5185168 , 0.2949556 , 0.1530428 , 0.23431706,\n",
            "        0.75380135, 0.05600166, 0.36792672, 0.9631493 , 0.01799679,\n",
            "        0.20237362],\n",
            "       [0.20225394, 0.27778184, 0.5098262 , 0.15119994, 0.08031154,\n",
            "        0.4902991 , 0.6168529 , 0.05001652, 0.17247474, 0.4787799 ,\n",
            "        0.21444106, 0.79419625, 0.5458056 , 0.3933618 , 0.37510586,\n",
            "        0.8311132 ],\n",
            "       [0.81137526, 0.9975141 , 0.15676665, 0.7474166 , 0.11488032,\n",
            "        0.14572072, 0.84651685, 0.9564847 , 0.31727183, 0.4812311 ,\n",
            "        0.9795867 , 0.18806267, 0.55223703, 0.04798007, 0.6617298 ,\n",
            "        0.82730174],\n",
            "       [0.82166517, 0.41886282, 0.891657  , 0.7594162 , 0.82484484,\n",
            "        0.39074683, 0.86574507, 0.52426493, 0.7308217 , 0.42016816,\n",
            "        0.8182888 , 0.8576454 , 0.36012137, 0.13513732, 0.46002197,\n",
            "        0.25287116],\n",
            "       [0.432204  , 0.05112505, 0.18332016, 0.21284223, 0.17086518,\n",
            "        0.2983439 , 0.00872958, 0.03769159, 0.11568356, 0.6700022 ,\n",
            "        0.34743834, 0.9800117 , 0.0120821 , 0.85935426, 0.04645455,\n",
            "        0.3579452 ],\n",
            "       [0.49056458, 0.8528241 , 0.09786093, 0.1948967 , 0.12130594,\n",
            "        0.7885177 , 0.68867433, 0.6772176 , 0.5757816 , 0.05313969,\n",
            "        0.15766835, 0.8915329 , 0.4814607 , 0.1222142 , 0.29000127,\n",
            "        0.5445663 ],\n",
            "       [0.26345766, 0.12648928, 0.7989625 , 0.5856571 , 0.6888759 ,\n",
            "        0.5912224 , 0.5466701 , 0.66983986, 0.12479365, 0.80091107,\n",
            "        0.66343343, 0.31655014, 0.9773462 , 0.32426214, 0.7828202 ,\n",
            "        0.4568404 ],\n",
            "       [0.041394  , 0.2625742 , 0.10813284, 0.4097153 , 0.44121397,\n",
            "        0.85989976, 0.9074266 , 0.3230753 , 0.28920746, 0.9698905 ,\n",
            "        0.7058356 , 0.41400433, 0.14248335, 0.27503133, 0.11826015,\n",
            "        0.52657723],\n",
            "       [0.61140764, 0.39856708, 0.3080498 , 0.28458893, 0.82053006,\n",
            "        0.80701625, 0.95468974, 0.579041  , 0.61185884, 0.40506494,\n",
            "        0.76036143, 0.970999  , 0.36922252, 0.52216005, 0.13009763,\n",
            "        0.26003385],\n",
            "       [0.8496393 , 0.8221735 , 0.8318523 , 0.03114104, 0.42544496,\n",
            "        0.9325324 , 0.7422162 , 0.21419191, 0.49736166, 0.5089712 ,\n",
            "        0.00323498, 0.17508316, 0.51863074, 0.27489305, 0.34625947,\n",
            "        0.50767124],\n",
            "       [0.9314209 , 0.79692006, 0.90803254, 0.27471125, 0.6775664 ,\n",
            "        0.0771178 , 0.27114117, 0.4570769 , 0.38921392, 0.28381956,\n",
            "        0.57250285, 0.44863582, 0.83880675, 0.88388085, 0.4354899 ,\n",
            "        0.27454722],\n",
            "       [0.43996072, 0.75673735, 0.5149553 , 0.97970545, 0.21200669,\n",
            "        0.6251513 , 0.8637941 , 0.05611014, 0.11837316, 0.43629658,\n",
            "        0.2800138 , 0.10227966, 0.34144545, 0.0567584 , 0.3841902 ,\n",
            "        0.04608738],\n",
            "       [0.071293  , 0.94806945, 0.6694287 , 0.01740026, 0.40561807,\n",
            "        0.38090742, 0.42590153, 0.96200085, 0.07901442, 0.86477745,\n",
            "        0.1097132 , 0.21993458, 0.11547506, 0.8810668 , 0.4478413 ,\n",
            "        0.31897783],\n",
            "       [0.06359208, 0.668157  , 0.8692827 , 0.94629776, 0.383543  ,\n",
            "        0.49354386, 0.10296535, 0.65908   , 0.8710879 , 0.5152836 ,\n",
            "        0.45830178, 0.52142036, 0.5998814 , 0.48109925, 0.39359188,\n",
            "        0.15024817],\n",
            "       [0.12781441, 0.93277395, 0.9252111 , 0.83046496, 0.23614061,\n",
            "        0.22878265, 0.83936644, 0.6029254 , 0.40703845, 0.67711186,\n",
            "        0.07754862, 0.25411308, 0.24277091, 0.93519604, 0.45742035,\n",
            "        0.90526533],\n",
            "       [0.22382545, 0.92435753, 0.8228333 , 0.18777168, 0.01765084,\n",
            "        0.6930419 , 0.5675558 , 0.4400754 , 0.11092293, 0.7025808 ,\n",
            "        0.25916576, 0.6814879 , 0.11067724, 0.08871818, 0.96115327,\n",
            "        0.24058068],\n",
            "       [0.74001384, 0.90521324, 0.7593169 , 0.8267236 , 0.00136936,\n",
            "        0.50965154, 0.6059886 , 0.23579264, 0.6124418 , 0.8806164 ,\n",
            "        0.7957667 , 0.6402035 , 0.17641795, 0.22028232, 0.6908555 ,\n",
            "        0.3191694 ],\n",
            "       [0.00688088, 0.61941504, 0.37051547, 0.74196744, 0.91694057,\n",
            "        0.48893893, 0.7126061 , 0.76882184, 0.05712605, 0.48819947,\n",
            "        0.18588519, 0.10900915, 0.15082586, 0.88550913, 0.4507966 ,\n",
            "        0.63082147],\n",
            "       [0.4445064 , 0.7545265 , 0.8560653 , 0.19548655, 0.06090379,\n",
            "        0.9764086 , 0.50814867, 0.8337413 , 0.57347775, 0.71418595,\n",
            "        0.9052937 , 0.06725979, 0.9810184 , 0.82977855, 0.7691932 ,\n",
            "        0.3056544 ],\n",
            "       [0.99092364, 0.20517945, 0.5120616 , 0.5942197 , 0.24157989,\n",
            "        0.4873551 , 0.0431484 , 0.1938076 , 0.6332474 , 0.9887936 ,\n",
            "        0.52700686, 0.80888176, 0.54093194, 0.27537918, 0.9904535 ,\n",
            "        0.97636175],\n",
            "       [0.4013276 , 0.99717426, 0.62602854, 0.9845406 , 0.6267674 ,\n",
            "        0.59423625, 0.09674716, 0.3748734 , 0.7087009 , 0.99045205,\n",
            "        0.8714775 , 0.6166111 , 0.4162326 , 0.16259134, 0.02602768,\n",
            "        0.4062662 ],\n",
            "       [0.8989724 , 0.9166597 , 0.10254669, 0.807865  , 0.70050824,\n",
            "        0.6939553 , 0.25199866, 0.75382864, 0.62377286, 0.7698505 ,\n",
            "        0.30977678, 0.11620736, 0.65705466, 0.01524329, 0.17278337,\n",
            "        0.01887679],\n",
            "       [0.34854782, 0.24486697, 0.29177737, 0.29752505, 0.68177044,\n",
            "        0.09436905, 0.06273365, 0.43347204, 0.5123898 , 0.18206096,\n",
            "        0.69631565, 0.828666  , 0.14970458, 0.43462002, 0.4868312 ,\n",
            "        0.64103174],\n",
            "       [0.94099915, 0.40436852, 0.9058715 , 0.48099756, 0.61639106,\n",
            "        0.2524612 , 0.19015396, 0.29442358, 0.6332296 , 0.985842  ,\n",
            "        0.38905907, 0.892436  , 0.5969293 , 0.6549661 , 0.30537152,\n",
            "        0.9196255 ],\n",
            "       [0.40347648, 0.30641115, 0.1934005 , 0.896816  , 0.45317614,\n",
            "        0.20179605, 0.06463778, 0.02096283, 0.10120225, 0.61627495,\n",
            "        0.04298306, 0.26649594, 0.4788586 , 0.18308425, 0.05401862,\n",
            "        0.78160715],\n",
            "       [0.6336237 , 0.2371701 , 0.03920007, 0.549024  , 0.5239309 ,\n",
            "        0.6772108 , 0.34006333, 0.8995905 , 0.44696903, 0.00794017,\n",
            "        0.6398169 , 0.9459101 , 0.9787605 , 0.06092   , 0.5697663 ,\n",
            "        0.68304646],\n",
            "       [0.78544164, 0.47315192, 0.34102118, 0.3058952 , 0.69808066,\n",
            "        0.6149068 , 0.03196836, 0.22548437, 0.74037373, 0.73431623,\n",
            "        0.7726728 , 0.6278231 , 0.9647633 , 0.09600711, 0.3695941 ,\n",
            "        0.7244834 ],\n",
            "       [0.59259534, 0.06748641, 0.15215302, 0.03608394, 0.45950782,\n",
            "        0.45657122, 0.7095206 , 0.5485071 , 0.64960706, 0.7762325 ,\n",
            "        0.29492128, 0.3290887 , 0.5100299 , 0.5225024 , 0.4221964 ,\n",
            "        0.24660623],\n",
            "       [0.963833  , 0.06509066, 0.58874476, 0.9502369 , 0.397403  ,\n",
            "        0.6293137 , 0.421759  , 0.35180962, 0.64584804, 0.9810107 ,\n",
            "        0.4802258 , 0.06309819, 0.6123539 , 0.08083534, 0.7927196 ,\n",
            "        0.6941315 ],\n",
            "       [0.8630065 , 0.78840697, 0.42302024, 0.83852553, 0.44976234,\n",
            "        0.08185768, 0.14764798, 0.32151043, 0.7449913 , 0.5538324 ,\n",
            "        0.89691925, 0.05252564, 0.66560936, 0.649425  , 0.30478036,\n",
            "        0.3059131 ],\n",
            "       [0.8216461 , 0.1668477 , 0.9177449 , 0.702448  , 0.54704344,\n",
            "        0.09561813, 0.61157036, 0.1788975 , 0.27737486, 0.02966905,\n",
            "        0.9117557 , 0.90030503, 0.5574324 , 0.03249145, 0.18888366,\n",
            "        0.9647579 ],\n",
            "       [0.745677  , 0.734812  , 0.49283826, 0.73396504, 0.5371971 ,\n",
            "        0.7356279 , 0.86514866, 0.12706912, 0.69185424, 0.93835306,\n",
            "        0.12509334, 0.9443824 , 0.65050364, 0.27017474, 0.5942559 ,\n",
            "        0.03661704]], dtype=float32)>, <tf.Tensor: shape=(32, 16), dtype=float32, numpy=\n",
            "array([[0.06772792, 0.29332638, 0.95610523, 0.5307592 , 0.8692416 ,\n",
            "        0.9698168 , 0.27160203, 0.2898066 , 0.95507574, 0.21192718,\n",
            "        0.6485486 , 0.6943902 , 0.06403422, 0.18963099, 0.46766222,\n",
            "        0.730747  ],\n",
            "       [0.8809978 , 0.98606515, 0.02431333, 0.05933988, 0.14767838,\n",
            "        0.33945346, 0.17474294, 0.1840198 , 0.7899661 , 0.9713007 ,\n",
            "        0.6869632 , 0.65223897, 0.38115406, 0.55522573, 0.01169205,\n",
            "        0.3077315 ],\n",
            "       [0.35698438, 0.30142498, 0.24667966, 0.5578021 , 0.15916896,\n",
            "        0.7703885 , 0.62286496, 0.7355951 , 0.6216018 , 0.922084  ,\n",
            "        0.26463807, 0.08690798, 0.34764588, 0.9579325 , 0.56532085,\n",
            "        0.09930825],\n",
            "       [0.1950345 , 0.5053147 , 0.10063362, 0.68929327, 0.2469194 ,\n",
            "        0.6916585 , 0.08181322, 0.07196844, 0.3203349 , 0.8053405 ,\n",
            "        0.25353837, 0.7763196 , 0.9186295 , 0.1300149 , 0.38209558,\n",
            "        0.39684844],\n",
            "       [0.50754786, 0.55923116, 0.9591348 , 0.6708363 , 0.69799006,\n",
            "        0.5622246 , 0.43139744, 0.8537489 , 0.9253236 , 0.6932671 ,\n",
            "        0.17942858, 0.00931239, 0.5642648 , 0.27346134, 0.59781075,\n",
            "        0.2853377 ],\n",
            "       [0.44578218, 0.3160019 , 0.17867064, 0.24473834, 0.07259107,\n",
            "        0.42631304, 0.9213524 , 0.61955667, 0.0855521 , 0.79166317,\n",
            "        0.7253243 , 0.7464733 , 0.22830868, 0.8010684 , 0.5669658 ,\n",
            "        0.19458926],\n",
            "       [0.8885132 , 0.35901546, 0.14757836, 0.52223   , 0.73155046,\n",
            "        0.1828978 , 0.02596688, 0.7793186 , 0.57457626, 0.27700722,\n",
            "        0.47268045, 0.51188576, 0.7722273 , 0.49665117, 0.34260178,\n",
            "        0.76440394],\n",
            "       [0.5240623 , 0.6759441 , 0.5668267 , 0.5666605 , 0.08118129,\n",
            "        0.3218813 , 0.94386935, 0.6858059 , 0.44877517, 0.8371073 ,\n",
            "        0.37704027, 0.7331259 , 0.81973565, 0.5899285 , 0.02736437,\n",
            "        0.88072586],\n",
            "       [0.07705271, 0.67660487, 0.1819005 , 0.83932066, 0.0830574 ,\n",
            "        0.7228403 , 0.9258096 , 0.05586565, 0.31253445, 0.1800822 ,\n",
            "        0.7656225 , 0.1554743 , 0.1398493 , 0.31136465, 0.6359757 ,\n",
            "        0.7429863 ],\n",
            "       [0.51070476, 0.7722359 , 0.01807511, 0.9930923 , 0.4313258 ,\n",
            "        0.08868015, 0.5368105 , 0.2734636 , 0.99313056, 0.9430374 ,\n",
            "        0.22198248, 0.5158309 , 0.11303902, 0.4341483 , 0.44110906,\n",
            "        0.58811855],\n",
            "       [0.90285933, 0.55334806, 0.12794662, 0.03977454, 0.8806393 ,\n",
            "        0.4815023 , 0.63241637, 0.5003693 , 0.91361105, 0.1726296 ,\n",
            "        0.27210152, 0.04124451, 0.18184066, 0.47392702, 0.85750794,\n",
            "        0.41440916],\n",
            "       [0.39666855, 0.5330136 , 0.19263124, 0.26412654, 0.89260256,\n",
            "        0.8015443 , 0.66307104, 0.73616266, 0.99306715, 0.43331528,\n",
            "        0.08693385, 0.99923074, 0.52871287, 0.41350663, 0.80189097,\n",
            "        0.9444066 ],\n",
            "       [0.9496089 , 0.47976077, 0.04420912, 0.21518493, 0.4858538 ,\n",
            "        0.5651088 , 0.2902676 , 0.33152854, 0.08701217, 0.02804124,\n",
            "        0.85999095, 0.62599564, 0.7697352 , 0.9270457 , 0.178738  ,\n",
            "        0.5373188 ],\n",
            "       [0.9926497 , 0.45001948, 0.4435805 , 0.34302938, 0.69586146,\n",
            "        0.05358577, 0.08586419, 0.94885087, 0.29903352, 0.48187435,\n",
            "        0.36093366, 0.89427173, 0.20418394, 0.8738967 , 0.31519163,\n",
            "        0.65958035],\n",
            "       [0.71045494, 0.10700428, 0.10148609, 0.39919055, 0.5888226 ,\n",
            "        0.2906505 , 0.07415867, 0.9380778 , 0.2572955 , 0.21055317,\n",
            "        0.37678707, 0.5287392 , 0.9287821 , 0.4587201 , 0.9473957 ,\n",
            "        0.0434624 ],\n",
            "       [0.12770855, 0.31798363, 0.10060143, 0.07963872, 0.5086304 ,\n",
            "        0.73077846, 0.5674012 , 0.42253435, 0.93777597, 0.7448429 ,\n",
            "        0.51820076, 0.04114485, 0.85075665, 0.07341266, 0.0326556 ,\n",
            "        0.67908883],\n",
            "       [0.36703074, 0.54163826, 0.52401865, 0.5168935 , 0.13432217,\n",
            "        0.09490967, 0.21055877, 0.8416629 , 0.8684411 , 0.7326802 ,\n",
            "        0.02394772, 0.20228565, 0.29763198, 0.68822086, 0.9701264 ,\n",
            "        0.8076103 ],\n",
            "       [0.5899401 , 0.3214172 , 0.42722118, 0.5595466 , 0.01686263,\n",
            "        0.7685579 , 0.0623703 , 0.17195511, 0.19349873, 0.5440109 ,\n",
            "        0.66672194, 0.2890575 , 0.29352164, 0.6163012 , 0.6771685 ,\n",
            "        0.06266797],\n",
            "       [0.85181034, 0.4229107 , 0.06527472, 0.6383822 , 0.93300915,\n",
            "        0.29212427, 0.99315464, 0.8555654 , 0.8866861 , 0.6267189 ,\n",
            "        0.52867997, 0.20737731, 0.25864887, 0.5203699 , 0.56702936,\n",
            "        0.4730065 ],\n",
            "       [0.02449226, 0.52729297, 0.21214736, 0.91792977, 0.25392103,\n",
            "        0.71237206, 0.8427708 , 0.53079784, 0.92730296, 0.5122708 ,\n",
            "        0.04978848, 0.14989829, 0.7775277 , 0.42230153, 0.4736365 ,\n",
            "        0.5554224 ],\n",
            "       [0.63010025, 0.6249546 , 0.01727533, 0.5003309 , 0.98431134,\n",
            "        0.37020493, 0.01241136, 0.6265309 , 0.7717618 , 0.9591565 ,\n",
            "        0.6036179 , 0.17515433, 0.1751219 , 0.22984242, 0.9914197 ,\n",
            "        0.6384461 ],\n",
            "       [0.90753603, 0.23093987, 0.6430632 , 0.96701   , 0.8651922 ,\n",
            "        0.7325102 , 0.20402169, 0.98210704, 0.42444205, 0.77657855,\n",
            "        0.9731034 , 0.4413674 , 0.725477  , 0.25809085, 0.02171791,\n",
            "        0.47473454],\n",
            "       [0.51382005, 0.7618803 , 0.43585467, 0.87295866, 0.12287784,\n",
            "        0.24291408, 0.59144616, 0.6352891 , 0.7536044 , 0.56936085,\n",
            "        0.05829203, 0.12069702, 0.91547847, 0.33510125, 0.31046867,\n",
            "        0.6488961 ],\n",
            "       [0.6304647 , 0.00573862, 0.7788166 , 0.34312987, 0.6691332 ,\n",
            "        0.4297037 , 0.07133698, 0.34134805, 0.999022  , 0.5271466 ,\n",
            "        0.09805691, 0.7545532 , 0.1039784 , 0.94746983, 0.30519485,\n",
            "        0.52224827],\n",
            "       [0.9549918 , 0.6337478 , 0.41952074, 0.09341681, 0.96367407,\n",
            "        0.6392355 , 0.9534111 , 0.58862865, 0.01416981, 0.96992767,\n",
            "        0.53008366, 0.46052766, 0.9365915 , 0.18021393, 0.42049408,\n",
            "        0.713029  ],\n",
            "       [0.2612865 , 0.6632787 , 0.8368646 , 0.8961873 , 0.61575687,\n",
            "        0.85001814, 0.4361143 , 0.73603094, 0.46223915, 0.7855183 ,\n",
            "        0.09105682, 0.8447726 , 0.9987745 , 0.8738524 , 0.79524624,\n",
            "        0.62992   ],\n",
            "       [0.37245607, 0.7448207 , 0.40501904, 0.15912855, 0.32048285,\n",
            "        0.7932234 , 0.09823072, 0.85758436, 0.07543457, 0.75692785,\n",
            "        0.38240457, 0.11856079, 0.07989085, 0.96757424, 0.15252817,\n",
            "        0.2636118 ],\n",
            "       [0.93346024, 0.6263406 , 0.7183305 , 0.21669638, 0.5201318 ,\n",
            "        0.6908233 , 0.05004525, 0.7257011 , 0.66719925, 0.30620253,\n",
            "        0.9602978 , 0.972497  , 0.41790915, 0.10974538, 0.07777321,\n",
            "        0.06283164],\n",
            "       [0.16399896, 0.50780034, 0.2182231 , 0.27594614, 0.52847373,\n",
            "        0.76149464, 0.9984274 , 0.00358343, 0.8647351 , 0.8847172 ,\n",
            "        0.71838033, 0.582746  , 0.32844734, 0.6712122 , 0.37599194,\n",
            "        0.9601811 ],\n",
            "       [0.02705908, 0.88881993, 0.969466  , 0.6674485 , 0.9224224 ,\n",
            "        0.23208058, 0.5569254 , 0.03717816, 0.1149869 , 0.6068928 ,\n",
            "        0.35492647, 0.08125532, 0.42620456, 0.7017062 , 0.43472862,\n",
            "        0.33798957],\n",
            "       [0.81979215, 0.7606282 , 0.8481355 , 0.04007232, 0.5795866 ,\n",
            "        0.2689662 , 0.06968856, 0.92995644, 0.13914704, 0.04470432,\n",
            "        0.8760328 , 0.2729056 , 0.7328155 , 0.09501839, 0.19813347,\n",
            "        0.2506354 ],\n",
            "       [0.5727302 , 0.43564868, 0.51857674, 0.51632416, 0.02169549,\n",
            "        0.8100773 , 0.7924142 , 0.3156854 , 0.06647468, 0.09116328,\n",
            "        0.08484089, 0.6877036 , 0.62768364, 0.36517465, 0.6620157 ,\n",
            "        0.04133725]], dtype=float32)>]\n",
            "(32, 10, 16)\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=100\n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    print(target_sentences[0])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    print(output.shape)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "BXrIj4scLOe_"
      },
      "outputs": [],
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,encoder_inputs_length,decoder_inputs_length,output_vocab_size,batch_size,encoder_size,decoder_size):\n",
        "         \n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
        "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita, embedding_size=100, input_length=encoder_inputs_length, lstm_size=encoder_size)\n",
        "        self.decoder = Decoder(out_vocab_size=vocab_size_eng, embedding_size=100, input_length=decoder_inputs_length, lstm_size=decoder_size)\n",
        "        # self.dense   = Dense(output_vocab_size, activation='softmax')\n",
        "        self.td=TimeDistributed(Dense(output_vocab_size, activation='softmax'))\n",
        "        self.batch_size=batch_size\n",
        "        self.initial_states = self.encoder.initialize_states(self.batch_size)\n",
        "    def call(self,data):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer \n",
        "        \n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        input_sequence= data[0]\n",
        "        output_sequence=data[1]\n",
        "        encoder_output,encoder_final_state_h,encoder_final_state_c=self.encoder(input_sequence,self.initial_states)\n",
        "        states=[encoder_final_state_h,encoder_final_state_c]\n",
        "        decoder_output,decoder_final_state_h,decoder_final_state_c=self.decoder(output_sequence,states)\n",
        "        output=self.td(decoder_output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XBw7nLwUrb3x"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(data['english_out'].str.split().apply(len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOCq1FLYjK9D",
        "outputId": "b98efb22-6fcc-4cb7-cfad-7a0983ab70b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QQ1-RcNbinlw"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['italian'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "class Dataloader(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0], batch[1]], batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCAjUBkTtz-E",
        "outputId": "53d152ad-6e2f-4037-e0b1-4c8c1540881a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024, 25) (1024, 25) (1024, 25)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 25)\n",
        "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 25)\n",
        "\n",
        "train_dataloader = Dataloader(train_dataset, batch_size=1024)\n",
        "test_dataloader = Dataloader(test_dataset, batch_size=1024)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "kcL61dJXLOfB"
      },
      "outputs": [],
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model\n",
        "model  = Encoder_decoder(encoder_inputs_length=25,decoder_inputs_length=25,output_vocab_size=vocab_size_eng,batch_size=1024,encoder_size=256,decoder_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch,lr):\n",
        "  if epoch%2==1:\n",
        "    lr=0.9*lr\n",
        "  return lr\n",
        "callbacks=[ModelCheckpoint(filepath='best_vanilla_model.h5',save_best_only=True,mode='min',save_weights_only=True),\n",
        "           LearningRateScheduler(scheduler)]"
      ],
      "metadata": {
        "id": "FAxSPReqe1ea"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "model.fit(train_dataloader, batch_size=1024,steps_per_epoch=train_steps, epochs=30, validation_data=test_dataloader, validation_steps=valid_steps,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jxH1cJbvkl4U",
        "outputId": "85be21f0-6f4e-4c2e-dd41-b65debc853b7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (1024, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1024, 25)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor: shape=(1024, 256), dtype=float32, numpy=\n",
            "array([[-0.00535074,  0.00554437, -0.00375006, ..., -0.00108819,\n",
            "        -0.00389561,  0.00183007],\n",
            "       [-0.00456535, -0.00222861, -0.00568424, ...,  0.0024075 ,\n",
            "        -0.0033401 , -0.00502326],\n",
            "       [ 0.00093474,  0.00078609, -0.00268965, ...,  0.00862669,\n",
            "        -0.0015534 , -0.00375482],\n",
            "       ...,\n",
            "       [ 0.00115088,  0.00062637, -0.00173641, ...,  0.00379096,\n",
            "        -0.01029191, -0.00115002],\n",
            "       [ 0.00700191,  0.00326212, -0.00610604, ...,  0.00084154,\n",
            "        -0.00656535,  0.00270223],\n",
            "       [-0.00085911, -0.00214373, -0.00536723, ...,  0.0049578 ,\n",
            "         0.00786184,  0.00523582]], dtype=float32)>, <tf.Tensor: shape=(1024, 256), dtype=float32, numpy=\n",
            "array([[-0.0106191 ,  0.01104696, -0.00752795, ..., -0.00219365,\n",
            "        -0.00787075,  0.00366351],\n",
            "       [-0.00911385, -0.00446567, -0.01131759, ...,  0.00478476,\n",
            "        -0.00672175, -0.0100179 ],\n",
            "       [ 0.00186166,  0.00157983, -0.00538192, ...,  0.01737333,\n",
            "        -0.00308274, -0.00750504],\n",
            "       ...,\n",
            "       [ 0.00228893,  0.00124334, -0.00347533, ...,  0.00762136,\n",
            "        -0.02063723, -0.00233296],\n",
            "       [ 0.01390066,  0.00646513, -0.01239366, ...,  0.00168271,\n",
            "        -0.01298298,  0.00540612],\n",
            "       [-0.00170712, -0.00425014, -0.01077111, ...,  0.00988004,\n",
            "         0.01571528,  0.01034471]], dtype=float32)>]\n",
            "Epoch 1/30\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'encoder_decoder_10/encoder_11/Encoder_LSTM/PartitionedCall:2' shape=(1024, 256) dtype=float32>, <tf.Tensor 'encoder_decoder_10/encoder_11/Encoder_LSTM/PartitionedCall:3' shape=(1024, 256) dtype=float32>]\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'encoder_decoder_10/encoder_11/Encoder_LSTM/PartitionedCall:2' shape=(1024, 256) dtype=float32>, <tf.Tensor 'encoder_decoder_10/encoder_11/Encoder_LSTM/PartitionedCall:3' shape=(1024, 256) dtype=float32>]\n",
            "276/276 [==============================] - ETA: 0s - loss: 1.2507ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'encoder_decoder_10/encoder_11/Encoder_LSTM/PartitionedCall:2' shape=(1024, 256) dtype=float32>, <tf.Tensor 'encoder_decoder_10/encoder_11/Encoder_LSTM/PartitionedCall:3' shape=(1024, 256) dtype=float32>]\n",
            "276/276 [==============================] - 100s 324ms/step - loss: 1.2507 - val_loss: 0.9474 - lr: 0.0100\n",
            "Epoch 2/30\n",
            "276/276 [==============================] - 77s 278ms/step - loss: 0.7126 - val_loss: 0.5033 - lr: 0.0090\n",
            "Epoch 3/30\n",
            "276/276 [==============================] - 75s 273ms/step - loss: 0.3869 - val_loss: 0.3247 - lr: 0.0090\n",
            "Epoch 4/30\n",
            "276/276 [==============================] - 76s 274ms/step - loss: 0.2467 - val_loss: 0.2553 - lr: 0.0081\n",
            "Epoch 5/30\n",
            "276/276 [==============================] - 75s 273ms/step - loss: 0.1812 - val_loss: 0.2210 - lr: 0.0081\n",
            "Epoch 6/30\n",
            "276/276 [==============================] - 75s 273ms/step - loss: 0.1399 - val_loss: 0.2005 - lr: 0.0073\n",
            "Epoch 7/30\n",
            "276/276 [==============================] - 76s 273ms/step - loss: 0.1155 - val_loss: 0.1897 - lr: 0.0073\n",
            "Epoch 8/30\n",
            "276/276 [==============================] - 76s 273ms/step - loss: 0.0959 - val_loss: 0.1807 - lr: 0.0066\n",
            "Epoch 9/30\n",
            "276/276 [==============================] - 76s 276ms/step - loss: 0.0830 - val_loss: 0.1768 - lr: 0.0066\n",
            "Epoch 10/30\n",
            "276/276 [==============================] - 76s 274ms/step - loss: 0.0710 - val_loss: 0.1716 - lr: 0.0059\n",
            "Epoch 11/30\n",
            "276/276 [==============================] - 76s 274ms/step - loss: 0.0631 - val_loss: 0.1721 - lr: 0.0059\n",
            "Epoch 12/30\n",
            " 55/276 [====>.........................] - ETA: 52s - loss: 0.0527"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-6905e1375fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/best_vanilla_model.h5')"
      ],
      "metadata": {
        "id": "d_ulCARAq3LK"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkpEY2KSibvD",
        "outputId": "0b4fd733-a30d-45c6-a1b1-7e430ef98c18"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 14s 197ms/step - loss: 0.1716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1715967357158661"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "ZJtSmwRT4v54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5cf647-9bdb-43c0-808e-3e2fcf6838a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'encoder_decoder_10/encoder_11/Encoder_LSTM/PartitionedCall:2' shape=(1024, 256) dtype=float32>, <tf.Tensor 'encoder_decoder_10/encoder_11/Encoder_LSTM/PartitionedCall:3' shape=(1024, 256) dtype=float32>]\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'initial_states:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'initial_states_1:0' shape=(None, 256) dtype=float32>]\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'initial_states:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'initial_states_1:0' shape=(None, 256) dtype=float32>]\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'encoder_11/Encoder_LSTM/PartitionedCall:2' shape=(1024, 256) dtype=float32>, <tf.Tensor 'encoder_11/Encoder_LSTM/PartitionedCall:3' shape=(1024, 256) dtype=float32>]\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'encoder_11/Encoder_LSTM/PartitionedCall:2' shape=(1024, 256) dtype=float32>, <tf.Tensor 'encoder_11/Encoder_LSTM/PartitionedCall:3' shape=(1024, 256) dtype=float32>]\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'initial_states/0:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'initial_states/1:0' shape=(None, 256) dtype=float32>]\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (None, 25)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : [<tf.Tensor 'initial_states/0:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'initial_states/1:0' shape=(None, 256) dtype=float32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_28_layer_call_fn, lstm_cell_28_layer_call_and_return_conditional_losses, lstm_cell_29_layer_call_fn, lstm_cell_29_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Kaggle/seq2seqmodel1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Kaggle/seq2seqmodel1/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f40c653a690> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f40c64c3890> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/Kaggle/seq2seqmodel1',save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KvUnTp6jFAL"
      },
      "outputs": [],
      "source": [
        "model=tf.keras.models.load_model('/content/drive/MyDrive/Kaggle/seq2seqmodel1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "\n",
        "  final_sentence =[]\n",
        "  enc_ita_data = np.array(tknizer_ita.texts_to_sequences(np.array(['<start> '+input_sentence+' <end>'])))\n",
        "  enc_ita_data=pad_sequences(enc_ita_data,maxlen=25,padding='post')\n",
        "  initial_state = model.encoder.initialize_states(batch_size = 1)\n",
        "  #print(enc_ita_data)\n",
        "  #print(type(enc_ita_data))\n",
        "  encoder_output, encoder_h, encoder_c = model.layers[0](enc_ita_data,initial_state)\n",
        "\n",
        "  decoder_input = np.array(tknizer_eng.texts_to_sequences(np.array(['<start>'])))\n",
        "\n",
        "  states =(encoder_h, encoder_c)\n",
        "  #print(decoder_input)\n",
        "  max_length = 25 # in data preprocessing we have remove all datapoints which are greater then 20\n",
        "  for i in range(max_length):\n",
        "\n",
        "    predicted_out,state_h,state_c  =   model.layers[1](decoder_input,states)\n",
        "\n",
        "    states = (state_h,state_c)\n",
        "\n",
        "    output = model.layers[2](predicted_out)\n",
        "\n",
        "    #print(output.shape)\n",
        "    #print(np.argmax(output))\n",
        "    #print(output)\n",
        "    vec = np.argmax(output)\n",
        "    word = tknizer_eng.index_word[vec]\n",
        "    decoder_input = np.array([np.array([vec])])\n",
        "    #print(decoder_input)\n",
        "    #break\n",
        "    final_sentence.append(word)\n",
        "    if vec == tknizer_eng.word_index['<end>']:\n",
        "      return ' '.join(final_sentence)\n",
        "      \n",
        "\n",
        "  return ' '.join(final_sentence)"
      ],
      "metadata": {
        "id": "3Dj_KL2Ps547"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=data.sample(1000,ignore_index=True)\n",
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tUMaioAKymxl",
        "outputId": "8f2a16b4-57f9-4dc0-de2d-bf0bcdebc127"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             italian  \\\n",
              "0              sognai di baciare tom   \n",
              "1         ti incontri spesso con tom   \n",
              "2  non ho mai visto quel tizio prima   \n",
              "3                 tom è fiero di lei   \n",
              "4   penso di sapere cosa succede ora   \n",
              "\n",
              "                                 english_inp  \\\n",
              "0        <start> i dreamed about kissing tom   \n",
              "1              <start> do you meet tom often   \n",
              "2  <start> i have never seen that guy before   \n",
              "3                <start> tom is proud of you   \n",
              "4    <start> i think i know what happens now   \n",
              "\n",
              "                               english_out  \n",
              "0        i dreamed about kissing tom <end>  \n",
              "1              do you meet tom often <end>  \n",
              "2  i have never seen that guy before <end>  \n",
              "3                tom is proud of you <end>  \n",
              "4    i think i know what happens now <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9059fa8-6a01-4ba1-a62f-df41a28ab5b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sognai di baciare tom</td>\n",
              "      <td>&lt;start&gt; i dreamed about kissing tom</td>\n",
              "      <td>i dreamed about kissing tom &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ti incontri spesso con tom</td>\n",
              "      <td>&lt;start&gt; do you meet tom often</td>\n",
              "      <td>do you meet tom often &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>non ho mai visto quel tizio prima</td>\n",
              "      <td>&lt;start&gt; i have never seen that guy before</td>\n",
              "      <td>i have never seen that guy before &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tom è fiero di lei</td>\n",
              "      <td>&lt;start&gt; tom is proud of you</td>\n",
              "      <td>tom is proud of you &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>penso di sapere cosa succede ora</td>\n",
              "      <td>&lt;start&gt; i think i know what happens now</td>\n",
              "      <td>i think i know what happens now &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9059fa8-6a01-4ba1-a62f-df41a28ab5b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9059fa8-6a01-4ba1-a62f-df41a28ab5b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9059fa8-6a01-4ba1-a62f-df41a28ab5b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores=[]\n",
        "import statistics\n",
        "import nltk.translate.bleu_score as bleu\n",
        "for i in range(len(test)):\n",
        "  prediction=predict(test['italian'].values[i])\n",
        "  reference = [test['english_out'].values[i].split()] # the original\n",
        "  translation = prediction.split() # trasilated using model\n",
        "  scores.append(bleu.sentence_bleu(reference, translation,weights=(1,0,0,0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWxKT5Lezzc_",
        "outputId": "315f36f2-a000-4960-a691-19b05e31ac7c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.04501776e-01,  9.55773238e-03,  2.77299464e-01,\n",
            "        -6.60737697e-03,  6.05429590e-01, -2.78411865e-01,\n",
            "        -2.73142666e-01, -7.10660475e-04,  2.46547479e-05,\n",
            "         4.45908960e-03,  2.07295548e-02,  7.73746241e-03,\n",
            "         4.90181483e-02,  6.14089407e-02, -9.50584292e-01,\n",
            "        -6.25617325e-01, -8.56492400e-01, -8.38192463e-01,\n",
            "        -3.53519567e-07, -7.86382139e-01, -2.18489822e-06,\n",
            "        -5.04865408e-01,  4.61510941e-02, -3.82231921e-01,\n",
            "        -3.26053463e-02, -1.55686185e-01, -7.18144059e-01,\n",
            "         2.82400823e-03,  7.03314781e-01, -2.33646140e-01,\n",
            "        -3.81724123e-04,  4.61119771e-06,  6.72833502e-01,\n",
            "        -2.15425454e-02, -1.56354174e-01, -1.05657809e-05,\n",
            "        -1.40949094e-03, -7.86135495e-02,  1.31333708e-08,\n",
            "         5.36561885e-04,  4.00801420e-01,  3.84647647e-05,\n",
            "        -6.74123913e-02, -3.82510843e-05, -5.84675744e-03,\n",
            "        -1.63742453e-01,  6.08315645e-03,  2.91917496e-03,\n",
            "         6.92276582e-02,  4.29887950e-01,  2.17204139e-01,\n",
            "         7.98553050e-01,  2.01110631e-01, -6.65124357e-02,\n",
            "         4.02327366e-02,  3.09012622e-01,  2.75202822e-02,\n",
            "        -1.04658082e-01, -1.31154477e-04,  1.10544750e-06,\n",
            "        -6.02336586e-01,  2.55022803e-03, -2.68883280e-08,\n",
            "         4.23938334e-01,  1.51084391e-02,  4.48081749e-07,\n",
            "        -1.34293782e-02,  1.97462272e-02,  6.08305540e-03,\n",
            "        -9.03380942e-03,  6.30364299e-01,  2.32560620e-01,\n",
            "         4.62686084e-02,  7.47401834e-01, -2.66466266e-03,\n",
            "        -1.64108172e-01,  3.06473374e-01,  7.18247235e-01,\n",
            "        -6.70766294e-01, -1.61157679e-02, -3.60869206e-02,\n",
            "        -9.95102301e-02,  4.77611815e-04,  3.48872729e-02,\n",
            "        -2.53013289e-03,  7.40434527e-02, -1.31607577e-01,\n",
            "         1.88628808e-02,  2.13831966e-03, -8.05707693e-01,\n",
            "         2.76142103e-03, -8.26240338e-08,  1.68618432e-03,\n",
            "        -2.62466282e-01, -6.02026060e-02, -4.04327273e-01,\n",
            "         2.13144869e-01, -7.62729542e-06, -5.47960177e-02,\n",
            "         2.03169249e-02,  5.04519880e-01,  2.16011286e-01,\n",
            "        -6.92451060e-01, -5.12347758e-01, -9.74040540e-06,\n",
            "         4.76026558e-04,  5.74103979e-05,  3.02904814e-01,\n",
            "         2.11057395e-01,  5.50342491e-03,  2.43038114e-04,\n",
            "         1.54460943e-03,  9.95802344e-04, -5.73992550e-01,\n",
            "         7.00376272e-01,  7.16072559e-01,  5.04638553e-02,\n",
            "        -6.66182209e-03,  6.98661059e-03, -6.78342651e-04,\n",
            "        -2.08531972e-04, -2.93834269e-01,  4.55240905e-02,\n",
            "        -9.99609903e-02,  1.79448747e-03,  2.55414218e-01,\n",
            "         7.74160400e-03, -2.33265346e-05,  1.14890654e-05,\n",
            "         1.18851743e-03, -5.78720530e-04, -3.52118760e-01,\n",
            "        -2.67283190e-02,  7.59754300e-01,  4.45168734e-01,\n",
            "         5.42716742e-01, -7.59185180e-02, -2.98635244e-01,\n",
            "        -5.79644041e-03,  3.77489999e-02,  6.54016197e-01,\n",
            "        -2.56209493e-01,  6.07991457e-01, -8.93384404e-03,\n",
            "         3.96576354e-07, -3.93675230e-02, -7.03499198e-01,\n",
            "         2.73799121e-01,  8.76262505e-03,  7.30768085e-01,\n",
            "         9.53804934e-04,  5.54824760e-03, -3.78269935e-03,\n",
            "        -9.95059405e-03, -3.55412317e-06, -1.28604239e-04,\n",
            "         2.55763414e-04, -9.66886804e-02, -2.34990530e-02,\n",
            "        -1.55267388e-01,  9.66343343e-01,  1.90546196e-02,\n",
            "         2.60509610e-01,  6.97089434e-01,  3.57102975e-02,\n",
            "        -7.83536255e-01,  9.17375028e-01, -4.69048977e-01,\n",
            "         7.34470785e-01,  6.50452762e-07, -1.29626202e-03,\n",
            "        -3.97802532e-01, -3.18887502e-01,  2.58209417e-03,\n",
            "         5.84577084e-01, -2.18032878e-02,  1.18407710e-02,\n",
            "         1.41900709e-05, -2.91038683e-04,  2.50271052e-01,\n",
            "         7.11105585e-01,  9.89463995e-04, -4.27782629e-03,\n",
            "        -7.10750818e-01, -4.71664488e-01,  3.36809113e-04,\n",
            "        -7.76556075e-01, -1.79978626e-04, -1.50443271e-01,\n",
            "         7.51677027e-04, -6.73397906e-08,  5.18444227e-03,\n",
            "         2.88745528e-03, -8.07790399e-01,  1.95845664e-02,\n",
            "        -2.79028900e-02,  3.12186748e-01,  6.35952890e-01,\n",
            "        -3.86839446e-07, -2.38738913e-08,  1.24340889e-03,\n",
            "        -3.05449236e-02,  6.79017365e-01,  2.26274892e-07,\n",
            "         1.48801208e-01,  5.83871687e-03,  3.62947285e-02,\n",
            "        -5.30631542e-01,  2.51188432e-03, -4.01459903e-01,\n",
            "         1.30404555e-03, -7.33668387e-01,  4.91252095e-01,\n",
            "         6.41762512e-04, -7.31564537e-02,  3.56415217e-03,\n",
            "        -1.95872679e-04, -1.33143857e-01,  1.05606450e-04,\n",
            "        -2.95188818e-02,  3.28282088e-01, -3.86178382e-02,\n",
            "         5.97536936e-02,  2.21867055e-01,  2.63128575e-04,\n",
            "         2.45291486e-01, -1.59651339e-01, -2.69206357e-04,\n",
            "         5.26964338e-03,  1.00811929e-01, -6.06243532e-07,\n",
            "         1.21493638e-02,  1.46176562e-01,  6.99510157e-01,\n",
            "        -5.37602425e-01,  5.57013787e-04, -8.59822854e-02,\n",
            "        -2.74367072e-02,  3.15383368e-05, -5.19713342e-01,\n",
            "        -1.79273158e-01, -7.03055561e-01,  9.63654295e-02,\n",
            "         1.37223110e-01, -4.27518025e-05, -2.02365918e-03,\n",
            "        -2.68830656e-04, -3.97761767e-07,  1.01602454e-04,\n",
            "         1.42660245e-01, -2.56444901e-01,  5.87070473e-02,\n",
            "         3.38160375e-04,  1.58551857e-02, -1.82966143e-01,\n",
            "        -2.02678098e-06]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.66474056e+00,  1.39033526e-01,  1.00947690e+00,\n",
            "        -1.88054722e-02,  9.87398148e-01, -7.30424047e-01,\n",
            "        -9.53824043e-01, -1.49556577e+00,  7.48527110e-01,\n",
            "         1.86253059e+00,  1.12816298e+00,  7.70875096e-01,\n",
            "         4.92363758e-02,  7.64916837e-02, -1.89632154e+00,\n",
            "        -1.00057113e+00, -1.39517343e+00, -1.49027956e+00,\n",
            "        -6.77476883e-01, -1.18729329e+00, -6.69526458e-02,\n",
            "        -1.27058482e+00,  4.81500961e-02, -4.25518453e-01,\n",
            "        -1.65685809e+00, -1.23759401e+00, -9.03828859e-01,\n",
            "         1.04315817e+00,  8.75777423e-01, -1.04790437e+00,\n",
            "        -1.20299983e+00,  1.67274070e+00,  9.03798223e-01,\n",
            "        -2.00844765e-01, -1.57920197e-01, -2.69408989e+00,\n",
            "        -5.19625425e-01, -1.53581011e+00,  4.24422175e-02,\n",
            "         1.16593850e+00,  5.54043531e-01,  1.08359732e-01,\n",
            "        -1.11758244e+00, -1.89185619e+00, -2.54404426e-01,\n",
            "        -1.97560632e+00,  3.24053839e-02,  2.91928602e-03,\n",
            "         5.57394505e-01,  1.92476583e+00,  1.28205037e+00,\n",
            "         1.09588540e+00,  4.18041259e-01, -1.54398751e+00,\n",
            "         1.26411080e-01,  1.36006224e+00,  2.77908351e-02,\n",
            "        -1.59117162e+00, -1.05966735e+00,  1.46850204e+00,\n",
            "        -7.00165212e-01,  6.39457226e-01, -2.39525398e-05,\n",
            "         5.32898247e-01,  1.87266171e+00,  5.44160366e-01,\n",
            "        -6.73505440e-02,  2.86239348e-02,  1.06973387e-02,\n",
            "        -9.04585328e-03,  7.42033541e-01,  6.76544607e-01,\n",
            "         1.96177661e-01,  9.67093885e-01, -1.78752542e-01,\n",
            "        -1.69602185e-01,  3.16697121e-01,  2.32755828e+00,\n",
            "        -8.12135160e-01, -1.91943967e+00, -4.77409288e-02,\n",
            "        -1.00388415e-01,  4.79539915e-04,  4.35725868e-01,\n",
            "        -1.71091408e-01,  1.42219496e+00, -1.41614050e-01,\n",
            "         1.26075312e-01,  1.74493885e+00, -1.11520016e+00,\n",
            "         1.86380893e-02, -5.77875257e-01,  1.52017213e-02,\n",
            "        -2.99052954e-01, -1.56684607e-01, -1.00643265e+00,\n",
            "         9.80913341e-01, -3.87422703e-02, -1.75946876e-01,\n",
            "         3.74315493e-02,  2.02969623e+00,  2.23923981e-01,\n",
            "        -1.11924255e+00, -1.03121507e+00, -1.45013928e+00,\n",
            "         4.52506512e-01,  5.15982583e-02,  8.49686563e-01,\n",
            "         2.16949105e-01,  7.42635876e-02,  8.30455334e-04,\n",
            "         8.97886097e-01,  2.51707844e-02, -6.53535545e-01,\n",
            "         8.70731056e-01,  1.01509261e+00,  3.91516447e-01,\n",
            "        -1.38042843e+00,  1.72892177e+00, -1.74288114e-03,\n",
            "        -1.14893329e+00, -5.24923682e-01,  4.73734513e-02,\n",
            "        -9.38065171e-01,  1.64659489e-02,  2.00718617e+00,\n",
            "         1.70864892e+00, -8.02290857e-01,  2.18835402e+00,\n",
            "         8.93628132e-03, -7.50374002e-03, -1.26770437e+00,\n",
            "        -2.68268138e-02,  1.00034606e+00,  6.27817392e-01,\n",
            "         6.10726416e-01, -8.69310573e-02, -4.28114086e-01,\n",
            "        -9.67526436e-01,  1.68810928e+00,  7.92815208e-01,\n",
            "        -2.64654517e-01,  1.10797477e+00, -8.93828645e-03,\n",
            "         4.26296681e-01, -1.28482628e+00, -9.95221019e-01,\n",
            "         2.30566430e+00,  8.19491386e-01,  9.61743295e-01,\n",
            "         1.08021164e+00,  5.54941827e-03, -1.82772267e+00,\n",
            "        -1.74513769e+00, -1.45387100e-02, -9.91764784e-01,\n",
            "         3.98348004e-01, -9.97814983e-02, -4.89068061e-01,\n",
            "        -1.68165833e-01,  2.12227774e+00,  2.05471203e-01,\n",
            "         2.70602107e-01,  8.61762941e-01,  6.35147318e-02,\n",
            "        -1.75601363e+00,  1.69880331e+00, -5.09836197e-01,\n",
            "         9.45684552e-01,  1.51327416e-01, -8.59464586e-01,\n",
            "        -1.03699386e+00, -4.78682309e-01,  2.65602970e+00,\n",
            "         6.93056941e-01, -6.22146904e-01,  1.22476825e-02,\n",
            "         1.63704288e+00, -8.52641941e-04,  7.28349268e-01,\n",
            "         9.22068715e-01,  6.05784655e-01, -1.55915701e+00,\n",
            "        -9.54824328e-01, -6.75146282e-01,  1.64756775e-02,\n",
            "        -1.04987490e+00, -9.15147901e-01, -3.19576681e-01,\n",
            "         1.36897242e+00, -5.16201437e-01,  5.27212858e-01,\n",
            "         1.02113867e+00, -1.13900757e+00,  1.53138661e+00,\n",
            "        -1.89059293e+00,  3.23238492e-01,  8.80837083e-01,\n",
            "        -1.30492735e+00, -5.35094841e-06,  1.20922589e+00,\n",
            "        -5.31504266e-02,  9.98695493e-01,  1.22429192e+00,\n",
            "         3.28456044e-01,  2.57755518e+00,  2.33485723e+00,\n",
            "        -1.18595779e+00,  1.85850370e+00, -9.20612574e-01,\n",
            "         4.31532890e-01, -9.91962612e-01,  6.05067134e-01,\n",
            "         4.46314132e-03, -1.28949320e+00,  1.67529023e+00,\n",
            "        -1.96015884e-04, -1.36337385e-01,  7.54778981e-02,\n",
            "        -9.60062742e-01,  3.44126642e-01, -6.53761327e-02,\n",
            "         2.73782754e+00,  2.47806236e-01,  1.55650282e+00,\n",
            "         3.00981879e-01, -1.96979666e+00, -7.44318843e-01,\n",
            "         6.51998520e-02,  1.73984900e-01, -1.37421284e-02,\n",
            "         1.51598501e+00,  5.31570673e-01,  1.97477376e+00,\n",
            "        -7.27524102e-01,  3.31620015e-02, -8.77567947e-01,\n",
            "        -1.03398621e+00,  6.52062241e-03, -9.16056275e-01,\n",
            "        -1.81232572e-01, -8.73532951e-01,  1.81752348e+00,\n",
            "         1.38124049e-01, -2.28142500e+00, -1.57361960e+00,\n",
            "        -7.80721486e-01, -2.62893140e-01,  2.02558732e+00,\n",
            "         1.50895029e-01, -2.62299865e-01,  1.29769397e+00,\n",
            "         1.40001014e-01,  1.58698298e-02, -2.00024903e-01,\n",
            "        -2.95170605e-01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 5.81091791e-02,  1.88528770e-03,  6.33402228e-01,\n",
            "        -1.97599251e-02,  4.34915930e-01, -4.11849529e-01,\n",
            "        -6.02449298e-01, -5.70822880e-03, -1.32946357e-01,\n",
            "         6.31137118e-02,  7.87246406e-01,  3.35749099e-03,\n",
            "         2.89636012e-03, -1.06029913e-01, -3.76356370e-03,\n",
            "        -5.04207378e-03, -9.62593183e-02, -1.79843754e-01,\n",
            "        -1.28308274e-02, -8.18847060e-01, -5.41155860e-02,\n",
            "        -4.41165529e-02, -7.16662824e-01, -9.77882557e-03,\n",
            "        -1.18957301e-04, -8.63810420e-01, -9.45856646e-02,\n",
            "         4.81282856e-04,  1.51251480e-01, -5.52440099e-02,\n",
            "        -4.71185029e-01,  3.90774995e-01,  1.87415034e-01,\n",
            "        -1.01032835e-02, -2.15027742e-02, -5.95753044e-02,\n",
            "        -2.32367553e-02, -6.45394325e-01,  2.19736699e-04,\n",
            "         8.19008145e-03,  5.05729914e-01,  5.12774646e-01,\n",
            "        -5.11484817e-02, -6.39319711e-04, -7.91766718e-02,\n",
            "        -9.28037524e-01,  7.79627450e-03,  3.23780417e-03,\n",
            "         6.94417208e-02,  6.67506814e-01,  8.87414336e-01,\n",
            "         6.47670567e-01,  5.41416788e-03, -5.00878394e-01,\n",
            "         7.50751048e-02,  6.86938688e-02,  1.83083722e-03,\n",
            "        -2.55689502e-01, -9.50519741e-01,  5.99206076e-04,\n",
            "        -7.09215283e-01,  1.08076267e-01, -2.25376658e-04,\n",
            "         1.08621100e-06,  6.71032176e-04,  8.25375259e-01,\n",
            "        -6.79606199e-01,  1.70178916e-02,  1.06103364e-02,\n",
            "        -1.15100080e-02,  4.29283887e-01,  3.79302986e-02,\n",
            "        -6.48130536e-01,  9.46064740e-02, -1.38529181e-01,\n",
            "        -3.44402313e-01,  4.48538834e-04,  9.36798155e-01,\n",
            "        -9.09406006e-01, -2.72281170e-01, -8.70893523e-02,\n",
            "        -4.86682728e-03,  3.24776000e-03,  2.06785619e-01,\n",
            "        -6.40475610e-03,  3.04099079e-03, -2.44428567e-03,\n",
            "         1.11070031e-03,  7.88237751e-01, -8.88226926e-01,\n",
            "         1.92271476e-03, -5.34171283e-01, -6.93524837e-01,\n",
            "        -1.90968551e-02, -6.98792860e-02, -3.60686891e-03,\n",
            "         1.01777226e-01, -3.74715924e-02, -2.37994827e-03,\n",
            "         4.03469913e-02,  9.13701117e-01,  6.23781756e-02,\n",
            "        -3.16082209e-01, -2.27220818e-01, -6.37481064e-02,\n",
            "         3.75245929e-01,  7.22576980e-04,  3.36280435e-01,\n",
            "         1.53429608e-03,  7.27581561e-01,  1.71173317e-03,\n",
            "        -8.76392722e-02,  9.09720361e-02, -8.68774474e-01,\n",
            "         5.19037247e-02,  8.23790848e-01, -3.61380130e-01,\n",
            "        -6.67168498e-02,  7.49302357e-02, -3.93670313e-02,\n",
            "        -1.63152590e-01, -2.62311250e-01,  2.48743102e-01,\n",
            "        -4.47543859e-01,  3.07484530e-04,  6.52108155e-03,\n",
            "         3.38073820e-01, -7.83136129e-05,  2.16434360e-03,\n",
            "         1.24556748e-02, -1.03092694e-03,  6.33014321e-01,\n",
            "        -1.18877672e-01,  4.55773503e-01,  9.75836962e-02,\n",
            "         5.57600975e-01, -1.71495567e-03, -1.29582741e-05,\n",
            "        -9.15849864e-01,  9.81317684e-02,  3.34926397e-01,\n",
            "         3.58822197e-02,  1.59247145e-01, -4.44321521e-03,\n",
            "         2.29879934e-02, -5.97576378e-04, -8.58336926e-01,\n",
            "         8.45479488e-01,  1.98821247e-01,  7.34363735e-01,\n",
            "         1.84881210e-01,  3.63598794e-01, -7.97149301e-01,\n",
            "        -4.07600343e-01, -6.11143351e-01, -1.66344699e-02,\n",
            "         7.67682723e-05,  1.53609246e-01, -1.69861279e-02,\n",
            "        -1.73852697e-03,  3.23190868e-01,  1.82173739e-04,\n",
            "         3.51521224e-01,  5.48649132e-01,  1.17584698e-01,\n",
            "        -8.83654654e-01,  1.57014153e-03, -7.07287312e-01,\n",
            "         3.58889878e-01, -5.69651136e-04, -6.51189883e-04,\n",
            "        -7.71505415e-01, -4.28638421e-03,  3.77179560e-04,\n",
            "         4.22820508e-01,  3.01533248e-02, -5.41206479e-01,\n",
            "         3.51699352e-01, -6.09201903e-04,  4.03837897e-02,\n",
            "         2.49218382e-02,  4.61439103e-01, -5.80411144e-02,\n",
            "        -3.19770351e-02, -5.11278920e-02,  6.45351829e-04,\n",
            "        -7.86891103e-01, -1.82353109e-01, -7.97665417e-02,\n",
            "         7.22999573e-01, -1.31901016e-03,  1.29858847e-03,\n",
            "         9.04849827e-01, -8.74214768e-01,  4.93452817e-01,\n",
            "        -7.21081734e-01,  6.92441583e-01,  6.99182570e-01,\n",
            "        -1.15092756e-04, -2.99785490e-04,  2.33342707e-01,\n",
            "        -1.09340705e-04,  1.22930575e-02,  9.75929737e-01,\n",
            "        -1.05717918e-03,  8.43793213e-01,  9.64678347e-01,\n",
            "        -3.90745044e-01,  1.10508734e-02, -2.26102322e-01,\n",
            "         5.93867479e-03, -7.73342729e-01,  8.80881250e-01,\n",
            "         2.06653099e-03, -8.23663082e-03,  2.01272196e-03,\n",
            "        -1.67936305e-04,  3.49977165e-01, -2.24115606e-02,\n",
            "        -7.44689941e-01,  1.84256993e-02,  7.72788897e-02,\n",
            "         2.81351781e-03,  1.46101476e-04,  1.54778350e-03,\n",
            "        -2.55440857e-04, -9.17621076e-01, -6.09682560e-01,\n",
            "         9.85765830e-04, -1.18745320e-01, -2.59933379e-02,\n",
            "         1.01650581e-01,  7.38101482e-01,  6.86012626e-01,\n",
            "        -6.11250103e-01,  6.53153956e-02, -7.08160043e-01,\n",
            "        -1.11644469e-04,  4.46597114e-02, -7.88738251e-01,\n",
            "         4.30473924e-01, -8.69415164e-01,  1.53177470e-01,\n",
            "         3.03300451e-02, -9.88208592e-01, -3.72351348e-01,\n",
            "        -1.98151404e-03, -5.98637700e-01,  3.49212289e-01,\n",
            "        -7.31123000e-05, -1.59839634e-03,  5.08403838e-01,\n",
            "         3.37112229e-03,  1.65218730e-02, -1.63651288e-01,\n",
            "        -8.47778720e-05]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.54512072e+00,  9.10130858e-01,  7.49179184e-01,\n",
            "        -1.76409781e-01,  1.51276970e+00, -7.12368786e-01,\n",
            "        -1.04136097e+00, -2.45999837e+00, -1.83348671e-01,\n",
            "         2.41096926e+00,  1.13170505e+00,  1.76101041e+00,\n",
            "         5.81205547e-01, -9.63009179e-01, -2.86596704e+00,\n",
            "        -1.87008905e+00, -2.23900294e+00, -4.87975180e-01,\n",
            "        -1.64546359e+00, -1.16983807e+00, -6.84470832e-02,\n",
            "        -2.20218086e+00, -9.00851071e-01, -1.21954203e+00,\n",
            "        -2.43734193e+00, -1.30886137e+00, -9.54275802e-02,\n",
            "         2.03396702e+00,  1.84869134e+00, -1.96398818e+00,\n",
            "        -5.29299557e-01,  1.77654338e+00,  1.25527644e+00,\n",
            "        -1.18842816e+00, -2.38646455e-02, -3.40967917e+00,\n",
            "        -1.45510340e+00, -1.66780806e+00,  1.01597738e+00,\n",
            "         1.01018941e+00,  5.58380306e-01,  9.24731672e-01,\n",
            "        -1.18325651e+00, -2.86815763e+00, -1.04602611e+00,\n",
            "        -1.70183504e+00,  1.03145289e+00,  7.91506588e-01,\n",
            "         1.42290390e+00,  2.55597663e+00,  1.71166348e+00,\n",
            "         7.85146832e-01,  1.33070016e+00, -5.58911800e-01,\n",
            "         1.86940044e-01,  2.33391404e+00,  9.17311609e-02,\n",
            "        -2.43689680e+00, -1.83719170e+00,  1.94873559e+00,\n",
            "        -8.86815608e-01,  2.97582000e-01, -2.35029683e-01,\n",
            "         1.52861750e+00,  2.60552168e+00,  1.50270033e+00,\n",
            "        -8.28651249e-01,  9.45207000e-01,  1.00033498e+00,\n",
            "        -1.15504935e-02,  8.21835577e-01,  1.21859848e+00,\n",
            "        -7.72212088e-01,  1.03086814e-01, -1.93332776e-01,\n",
            "        -3.61039281e-01,  1.15364850e+00,  1.89190292e+00,\n",
            "        -1.72433794e+00, -2.09843326e+00, -8.99742767e-02,\n",
            "        -1.09930587e+00,  9.54170883e-01,  4.36709344e-01,\n",
            "        -9.28127408e-01,  2.40905881e+00, -1.49567738e-01,\n",
            "         1.11552072e+00,  1.19366479e+00, -1.41348743e+00,\n",
            "         9.72573340e-01, -5.96731842e-01, -8.70508611e-01,\n",
            "        -5.34402430e-01, -9.85199869e-01, -1.96951985e+00,\n",
            "         1.93540585e+00, -8.64554286e-01, -5.99302769e-01,\n",
            "         7.10656822e-01,  1.62056100e+00,  6.50646016e-02,\n",
            "        -3.63405466e-01, -2.73325652e-01, -2.02749753e+00,\n",
            "         5.03976643e-01,  7.37620533e-01,  8.45946729e-01,\n",
            "         1.12926280e+00,  9.39123571e-01,  9.70083058e-01,\n",
            "        -8.80414546e-02,  9.64855373e-01, -1.34023058e+00,\n",
            "         1.72894144e+00,  1.20118499e+00, -3.79327059e-01,\n",
            "        -1.78843045e+00,  2.16207123e+00, -7.98282847e-02,\n",
            "        -1.54477024e+00, -1.51230145e+00,  2.96382278e-01,\n",
            "        -9.77214694e-01,  7.42469192e-01,  2.96695375e+00,\n",
            "         2.17134547e+00, -9.15947735e-01,  2.59363341e+00,\n",
            "         1.39769744e-02, -9.98674452e-01,  7.49926925e-01,\n",
            "        -1.45190150e-01,  1.16776156e+00,  1.61647797e+00,\n",
            "         6.65157318e-01, -5.91535047e-02, -1.40534079e+00,\n",
            "        -1.71789706e+00,  2.21444654e+00,  8.97288442e-01,\n",
            "         4.32796657e-01,  1.63221896e+00, -8.08359385e-02,\n",
            "         4.29863036e-01, -2.05678248e+00, -1.45221257e+00,\n",
            "         1.24083257e+00,  1.67185259e+00,  9.38303888e-01,\n",
            "         1.82907438e+00,  8.61524224e-01, -1.11498535e+00,\n",
            "        -1.73159742e+00, -1.01449490e+00, -1.98401248e+00,\n",
            "         1.38799727e+00,  1.54948041e-01, -1.17275596e+00,\n",
            "        -1.15839958e+00,  1.40653706e+00,  5.91576397e-01,\n",
            "         3.71360302e-01,  1.77236950e+00,  1.69859752e-01,\n",
            "        -1.75123703e+00,  2.68157697e+00, -8.86695921e-01,\n",
            "         3.84815931e-01, -7.99073935e-01, -9.27488804e-01,\n",
            "        -1.02518749e+00, -4.69604462e-01,  3.59143782e+00,\n",
            "         9.11206007e-01,  2.31909081e-01, -9.82597947e-01,\n",
            "         2.49335504e+00, -9.55319405e-01,  1.64768839e+00,\n",
            "         1.00903928e+00,  6.01920068e-01, -2.48531365e+00,\n",
            "        -1.93575919e+00, -1.65574539e+00,  5.27530834e-02,\n",
            "        -1.06715071e+00, -1.13029110e+00, -1.31336606e+00,\n",
            "         9.17327225e-01, -6.28102720e-01,  1.48169744e+00,\n",
            "         1.80827701e+00, -1.36341786e+00,  5.92809141e-01,\n",
            "        -9.84700382e-01,  1.17958152e+00,  8.73958230e-01,\n",
            "        -2.29824114e+00, -9.86979008e-01,  2.65722603e-01,\n",
            "        -1.04833889e+00,  1.97714210e+00,  2.20419192e+00,\n",
            "        -3.76290947e-01,  1.23421645e+00,  2.02806497e+00,\n",
            "        -1.43668258e+00,  2.24294329e+00, -1.91313601e+00,\n",
            "         1.04195869e+00, -1.08240879e+00,  1.39908373e+00,\n",
            "         9.61390972e-01, -1.30088329e+00,  2.66281700e+00,\n",
            "        -1.90221966e-04,  3.66581053e-01, -6.22601390e-01,\n",
            "        -9.61113572e-01,  1.33672380e+00,  9.12982166e-01,\n",
            "         2.74769258e+00,  1.08128119e+00,  2.43425679e+00,\n",
            "        -3.12330909e-02, -1.59359658e+00, -7.21139908e-01,\n",
            "         8.18961710e-02, -1.23476692e-01, -1.00780964e+00,\n",
            "         2.51575494e+00,  9.52581644e-01,  2.26462865e+00,\n",
            "        -7.20052004e-01,  8.26782644e-01, -8.84055257e-01,\n",
            "        -1.78422081e+00,  6.59821391e-01, -1.07297766e+00,\n",
            "         9.60456192e-01, -1.77622867e+00,  2.62223506e+00,\n",
            "         1.00933361e+00, -2.70337558e+00, -1.20733213e+00,\n",
            "        -1.69231129e+00, -1.23897016e+00,  3.67407531e-01,\n",
            "        -8.40687037e-01, -1.20022170e-01,  5.61961412e-01,\n",
            "         1.02649128e+00,  1.69640519e-02, -7.90777147e-01,\n",
            "        -1.28617346e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.49135458e-05,  1.06622613e-08, -1.43715456e-01,\n",
            "        -7.46512842e-06,  9.19529617e-01, -7.12015666e-04,\n",
            "        -4.65269715e-01, -4.08031592e-05, -8.09157670e-01,\n",
            "         4.30041254e-02,  2.17658132e-01,  4.51261662e-02,\n",
            "         3.86395113e-05, -1.60993531e-03, -1.09897310e-05,\n",
            "        -2.87966308e-04, -6.88028052e-08,  4.34964001e-01,\n",
            "        -4.19450862e-06, -8.23927045e-01, -5.92831493e-05,\n",
            "        -1.03974016e-03, -8.70357811e-01, -1.23086313e-04,\n",
            "        -4.03500871e-06,  7.59931386e-01, -3.84302251e-02,\n",
            "         5.73253232e-08,  7.61523144e-04, -2.00237700e-05,\n",
            "         4.35900718e-01,  4.89472955e-01,  2.75511784e-03,\n",
            "        -9.74971116e-01, -6.27006928e-04, -8.78658087e-04,\n",
            "        -6.18223639e-05, -4.42218602e-01,  1.19284006e-04,\n",
            "         2.49329751e-04,  8.03499699e-01,  9.57739353e-01,\n",
            "        -1.62620336e-06, -1.80012390e-01, -6.50500536e-01,\n",
            "        -6.14134908e-01,  3.10779825e-07,  1.76635454e-04,\n",
            "         9.28995132e-01,  1.93360865e-01,  4.77904500e-03,\n",
            "         5.36070466e-01,  7.82989900e-06,  4.09418494e-01,\n",
            "         2.04582815e-03,  9.73009765e-01,  1.73216835e-02,\n",
            "        -2.41985072e-05, -6.75309956e-01,  3.52341100e-04,\n",
            "        -8.16051960e-01, -6.00099921e-01, -6.64872550e-06,\n",
            "         2.24351879e-05,  2.43442506e-03,  4.41265732e-01,\n",
            "        -7.65073180e-01,  9.97105017e-05,  4.28418643e-05,\n",
            "        -7.91492835e-02,  3.02363856e-04,  7.78455706e-03,\n",
            "        -9.40381169e-01, -6.94890380e-01, -2.43483543e-01,\n",
            "        -3.35409969e-01,  9.67486529e-04,  7.39032805e-01,\n",
            "        -6.47020638e-02, -4.90323349e-04, -3.10918950e-02,\n",
            "        -1.96874869e-04,  1.58076901e-02,  2.75164783e-01,\n",
            "        -2.65938288e-04,  2.06778864e-07, -7.81956351e-06,\n",
            "         3.71726288e-04,  2.13132471e-01, -8.92841935e-01,\n",
            "         1.25922007e-03, -4.69660133e-01, -9.11562324e-01,\n",
            "        -7.43892160e-04, -1.72761109e-04, -1.14291038e-06,\n",
            "         7.24031985e-01, -8.35152715e-02, -1.16897574e-07,\n",
            "         7.65481234e-10,  5.60061634e-01,  1.76819656e-02,\n",
            "         5.10237277e-01,  1.09694950e-01, -9.55384877e-03,\n",
            "         1.18925199e-01,  2.83122831e-03,  2.83901423e-01,\n",
            "         1.32188043e-05,  2.46702626e-01,  7.60082639e-06,\n",
            "        -7.76440144e-01,  1.13816668e-05, -2.75234804e-02,\n",
            "         7.12367473e-03,  6.74144924e-01, -8.56166661e-01,\n",
            "        -9.30993795e-01,  6.40778977e-04, -9.14567802e-03,\n",
            "        -2.17396067e-03, -3.00913125e-05,  2.32398454e-02,\n",
            "        -1.99896959e-03,  2.11900333e-04,  1.18806653e-04,\n",
            "         4.44930425e-04, -7.12734472e-04,  4.70539927e-01,\n",
            "         8.58497970e-07, -2.21976464e-07,  8.94641221e-01,\n",
            "        -2.20230315e-02,  1.16453975e-01,  8.42220962e-01,\n",
            "         8.44280366e-05, -4.93204221e-04, -1.99117944e-10,\n",
            "         2.76002020e-01,  3.09221541e-05,  3.59476078e-03,\n",
            "         6.72183692e-01,  1.17152638e-03, -1.56637100e-06,\n",
            "         2.10347376e-03, -6.59427524e-01, -1.71011627e-01,\n",
            "         4.31180567e-01,  8.62895162e-04,  7.26541042e-01,\n",
            "         2.34753434e-02,  6.70516267e-02, -1.55753151e-01,\n",
            "        -1.66834696e-04, -5.74319661e-01, -4.76237894e-09,\n",
            "         1.49932563e-01,  6.99668288e-01, -3.81669315e-06,\n",
            "        -8.07859806e-08,  3.81192535e-01,  2.76045824e-07,\n",
            "         3.35507095e-01,  6.74806118e-01,  9.45028570e-03,\n",
            "        -9.27659035e-01,  5.33452141e-04, -9.41041275e-04,\n",
            "        -5.10070026e-01, -2.41286424e-03, -3.70685143e-06,\n",
            "        -6.77797437e-01, -1.17011543e-03,  1.62380684e-06,\n",
            "         1.27381808e-03,  1.60884333e-03, -1.30333665e-05,\n",
            "         2.99367011e-01, -5.71113160e-05,  1.04789929e-02,\n",
            "         3.13010810e-06,  6.20049599e-04, -2.15439289e-03,\n",
            "        -4.52554077e-02, -7.66967150e-06,  1.97168742e-06,\n",
            "        -3.62600596e-03, -1.08683098e-05, -2.51844351e-04,\n",
            "        -5.79185486e-01, -5.56560993e-01,  3.06789160e-01,\n",
            "         5.66179872e-01, -9.01935399e-01, -3.54023546e-01,\n",
            "         1.14913667e-02,  2.49553710e-01,  4.96102214e-01,\n",
            "        -7.93282879e-07, -2.31727914e-04, -4.79642093e-01,\n",
            "        -1.07021315e-03,  1.68278385e-02,  9.96626318e-01,\n",
            "        -7.72998668e-04, -1.11110806e-01,  7.76741445e-01,\n",
            "        -9.49028671e-01,  1.93185336e-03, -3.65176261e-03,\n",
            "         4.87274374e-05, -1.20215409e-04,  3.28294814e-01,\n",
            "         1.80193160e-06, -5.67484065e-04,  2.16599703e-01,\n",
            "        -1.87040656e-04,  7.94060886e-01, -9.40962955e-02,\n",
            "        -7.47555315e-01,  5.07355966e-02,  1.49355343e-04,\n",
            "         1.17395899e-07,  9.37136701e-06,  1.15343093e-04,\n",
            "        -9.40166321e-03, -5.32701075e-01, -6.16352022e-01,\n",
            "         2.72357633e-04, -7.31047750e-01, -9.81692137e-05,\n",
            "         5.90067655e-02,  9.58318889e-01,  7.50851585e-04,\n",
            "        -6.16673648e-01,  1.36342191e-03, -8.73792975e-04,\n",
            "        -1.61145710e-08,  4.34335927e-03, -5.02680719e-01,\n",
            "        -8.72401074e-02, -2.04067468e-03,  2.32782872e-06,\n",
            "         6.46252139e-03, -9.46419716e-01, -8.29463065e-01,\n",
            "        -8.52124049e-06, -9.73081291e-01,  7.20414281e-01,\n",
            "        -2.27929490e-06, -4.79018390e-01, -3.21254402e-01,\n",
            "         4.45982296e-05,  1.67148217e-04, -7.46688283e-06,\n",
            "        -5.37655251e-05]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.46782064e+00,  1.89873159e+00, -1.44717336e-01,\n",
            "        -7.06847429e-01,  1.73852277e+00, -9.08485889e-01,\n",
            "        -1.94092643e+00, -3.44165373e+00, -1.14780283e+00,\n",
            "         3.35980511e+00,  1.13214922e+00,  2.75862646e+00,\n",
            "         1.57694340e+00, -1.96282399e+00, -3.72541213e+00,\n",
            "        -2.83305693e+00, -3.11791825e+00,  5.05327344e-01,\n",
            "        -2.64511943e+00, -1.16962612e+00, -6.92256689e-02,\n",
            "        -2.98730779e+00, -1.33455420e+00, -2.19261694e+00,\n",
            "        -3.36614728e+00,  9.96145070e-01, -3.84494029e-02,\n",
            "         2.64709783e+00,  2.84318686e+00, -2.96081471e+00,\n",
            "         4.67161208e-01,  2.63605189e+00,  2.25196648e+00,\n",
            "        -2.18580198e+00, -3.23486105e-02, -3.41283822e+00,\n",
            "        -2.39218569e+00, -2.55614734e+00,  2.01267219e+00,\n",
            "         4.30194616e-01,  1.40902257e+00,  1.92123032e+00,\n",
            "        -1.34061909e+00, -3.85470104e+00, -2.03499961e+00,\n",
            "        -7.16150403e-01,  2.02777243e+00,  1.77024364e+00,\n",
            "         2.36547470e+00,  3.43226218e+00,  1.71751750e+00,\n",
            "         5.98645210e-01,  2.28138995e+00,  4.34912950e-01,\n",
            "         1.17829001e+00,  3.32314944e+00,  1.06949615e+00,\n",
            "        -3.41915393e+00, -8.20442140e-01,  2.91597271e+00,\n",
            "        -1.14491105e+00, -6.93499088e-01, -1.20360863e+00,\n",
            "         2.52832747e+00,  2.61462116e+00,  2.48318911e+00,\n",
            "        -1.00834417e+00,  1.94258273e+00,  1.98365092e+00,\n",
            "        -1.01040637e+00,  1.80373955e+00,  2.15017486e+00,\n",
            "        -1.76751053e+00, -8.57677937e-01, -2.48493806e-01,\n",
            "        -1.16291416e+00,  1.91691935e+00,  9.48768020e-01,\n",
            "        -2.69247651e+00, -3.09770250e+00, -9.17639062e-02,\n",
            "        -2.09902215e+00,  1.86474371e+00,  4.36731696e-01,\n",
            "        -1.92716050e+00,  3.39769578e+00, -1.47155970e-01,\n",
            "         2.11219573e+00,  2.17868179e-01, -1.43611872e+00,\n",
            "         1.94573569e+00, -8.19056332e-01, -1.85357189e+00,\n",
            "        -5.56253433e-01, -1.96237016e+00, -2.95884132e+00,\n",
            "         2.52490139e+00, -1.86448371e+00, -7.25298822e-01,\n",
            "         9.25839365e-01,  6.33018553e-01,  1.76840834e-02,\n",
            "         5.63724756e-01,  1.10143304e-01, -3.01860499e+00,\n",
            "         1.20518172e+00,  6.18336141e-01,  9.53533828e-01,\n",
            "         2.12676740e+00,  1.14726889e+00,  1.96984482e+00,\n",
            "        -1.03702402e+00,  9.86992717e-01, -2.33981395e+00,\n",
            "         1.79358947e+00,  1.26827228e+00, -1.27880871e+00,\n",
            "        -2.76726413e+00,  2.38366914e+00, -1.71580359e-01,\n",
            "        -2.48060536e+00, -2.29360890e+00,  1.25012684e+00,\n",
            "        -1.52753425e+00,  1.74173963e+00,  3.93059826e+00,\n",
            "         3.04516578e+00, -9.12973702e-01,  2.81140924e+00,\n",
            "         1.00636518e+00, -1.99683332e+00,  1.44508982e+00,\n",
            "        -5.10102272e-01,  1.16737938e+00,  2.29176402e+00,\n",
            "         8.07138443e-01, -4.77226853e-01, -2.39857435e+00,\n",
            "         2.83366919e-01,  3.07400560e+00,  1.69683492e+00,\n",
            "         1.21508801e+00,  2.58791828e+00, -1.07617378e+00,\n",
            "         9.38811719e-01, -2.45123100e+00, -2.44532871e+00,\n",
            "         4.62341726e-01,  2.12802434e+00,  9.21766758e-01,\n",
            "         2.82209110e+00,  1.19439268e+00, -1.57032996e-01,\n",
            "        -1.71093643e+00, -1.31161332e+00, -2.97472119e+00,\n",
            "         2.38188791e+00,  8.70739043e-01, -1.79921043e+00,\n",
            "        -1.75687671e+00,  4.08231854e-01,  1.29361594e+00,\n",
            "         3.70665401e-01,  2.76953292e+00,  1.13470411e+00,\n",
            "        -1.74531722e+00,  3.68032146e+00, -9.12492454e-01,\n",
            "        -5.98552585e-01, -1.78324485e+00, -1.75509655e+00,\n",
            "        -8.25028300e-01, -4.43083435e-01,  4.48995495e+00,\n",
            "         1.76450181e+00,  2.28761628e-01, -1.98133421e+00,\n",
            "         3.48913240e+00, -1.94241858e+00,  2.64165068e+00,\n",
            "         9.61893439e-01,  1.54718018e+00, -3.41323376e+00,\n",
            "        -2.93527532e+00, -2.51024032e+00,  1.05165648e+00,\n",
            "        -1.06824875e+00, -2.08969140e+00, -2.31040239e+00,\n",
            "        -6.84564412e-01, -6.28382981e-01,  2.37965059e+00,\n",
            "         6.41950846e-01, -1.48286414e+00, -3.70071173e-01,\n",
            "         1.14941383e-02,  2.17876840e+00,  8.88905764e-01,\n",
            "        -3.29266214e+00, -1.98476470e+00, -5.28398037e-01,\n",
            "        -2.04737782e+00,  2.94246936e+00,  3.19434309e+00,\n",
            "        -1.36700928e+00, -1.11571476e-01,  1.03773808e+00,\n",
            "        -2.33341765e+00,  1.80182898e+00, -2.90588999e+00,\n",
            "         1.55230415e+00, -2.07127309e+00,  2.33295083e+00,\n",
            "         1.93589830e+00, -1.30090690e+00,  3.65658855e+00,\n",
            "        -1.87302037e-04,  1.18360686e+00, -1.59293544e+00,\n",
            "        -9.67492819e-01,  2.33609009e+00,  1.89753509e+00,\n",
            "         2.74759007e+00,  2.04616547e+00,  3.33297014e+00,\n",
            "        -2.21519284e-02, -5.96183717e-01, -7.19100773e-01,\n",
            "         1.59234315e-01, -9.35736656e-01, -2.00582862e+00,\n",
            "         3.51549292e+00,  1.93299079e+00,  3.25603914e+00,\n",
            "        -7.19896674e-01,  1.82475162e+00, -8.75544851e-04,\n",
            "        -2.66702342e+00,  7.77974486e-01, -1.84448326e+00,\n",
            "        -6.68854892e-01, -2.72222900e+00,  3.59786463e+00,\n",
            "         1.98674107e+00, -2.35362363e+00, -1.18768561e+00,\n",
            "        -2.65734005e+00, -2.14738083e+00,  9.10049736e-01,\n",
            "        -1.83949769e+00, -1.05750191e+00, -3.33198220e-01,\n",
            "         1.95819819e+00,  2.54762471e-02, -1.52768540e+00,\n",
            "        -2.28575277e+00]], dtype=float32)>)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.71896250e-03,  2.10811958e-01,  6.90949500e-01,\n",
            "        -2.59653091e-01,  5.79901457e-01, -5.37954986e-01,\n",
            "        -3.75354051e-04, -9.57904011e-02,  3.22395022e-06,\n",
            "         5.75815327e-03,  8.96051824e-02,  1.36633599e-02,\n",
            "         5.26538379e-02,  5.85381947e-02, -9.31134820e-01,\n",
            "        -8.87519956e-01, -5.32491446e-01, -9.89828467e-01,\n",
            "        -1.09142935e-08, -7.27366269e-01, -1.65667700e-06,\n",
            "        -9.94464397e-01,  2.91802466e-01, -8.20615888e-01,\n",
            "        -6.25789613e-02, -4.83873338e-01, -9.82744694e-01,\n",
            "         1.34662303e-04,  9.24669206e-01, -6.34672993e-04,\n",
            "        -2.18958929e-04,  1.18109404e-06,  2.81923294e-01,\n",
            "        -5.32462239e-01, -2.59232847e-03, -1.33415244e-06,\n",
            "        -5.13593912e-01, -1.19507387e-02,  5.47599200e-07,\n",
            "         4.96986846e-04,  8.91753435e-01,  2.72253565e-05,\n",
            "        -1.02714794e-02, -1.04694152e-07, -9.48802769e-01,\n",
            "        -6.48191708e-05,  1.16453401e-03,  2.37966537e-01,\n",
            "         7.61641711e-02,  9.38382149e-01,  9.23494160e-01,\n",
            "         9.98885453e-01,  7.40984082e-01, -2.40567043e-01,\n",
            "         6.48806896e-03,  9.82394040e-01,  5.37501834e-03,\n",
            "        -2.31786087e-01, -1.62194006e-03,  1.16578356e-08,\n",
            "         1.76293775e-01,  8.39359302e-04, -1.11438112e-05,\n",
            "         1.57384664e-01,  1.28059037e-04,  3.05385441e-08,\n",
            "         2.26058632e-01,  1.22945683e-04,  6.24837935e-01,\n",
            "        -7.24997884e-03,  1.05245575e-01,  1.03168704e-01,\n",
            "         6.12113066e-02,  9.96568918e-01, -1.35856852e-01,\n",
            "        -8.27613533e-01,  7.04010762e-03,  2.22786944e-02,\n",
            "        -7.34263778e-01, -4.96836379e-04, -1.12423971e-01,\n",
            "        -1.17697798e-01,  6.54395495e-04,  2.43775621e-01,\n",
            "        -3.07846945e-02,  9.00539085e-02, -8.17856472e-03,\n",
            "         7.11737157e-05,  2.16838089e-04, -8.97685409e-01,\n",
            "         1.33274300e-02, -2.52726329e-09,  8.34178063e-04,\n",
            "        -8.19943666e-01, -5.04009783e-01, -4.92637455e-01,\n",
            "         5.73663592e-01, -5.18554180e-06, -3.65267717e-03,\n",
            "         5.41066565e-02,  1.45978509e-02,  8.54914542e-04,\n",
            "        -1.61556285e-02, -4.14648950e-02, -7.09477533e-03,\n",
            "         2.37067486e-03,  6.52055070e-02,  8.07334721e-01,\n",
            "         4.49560396e-03,  3.63334045e-02,  1.14841862e-02,\n",
            "         7.86820710e-01,  1.73847768e-02, -2.97966897e-01,\n",
            "         1.87297821e-01,  8.37382138e-01,  5.73092513e-02,\n",
            "        -2.41883172e-04,  2.68265218e-01, -1.20977219e-02,\n",
            "        -1.00694262e-04, -5.83385932e-04,  4.80834931e-01,\n",
            "        -1.74980417e-01,  2.68005151e-02,  5.82743399e-02,\n",
            "         2.78408934e-05, -3.36677949e-05,  8.17116648e-02,\n",
            "         1.01344529e-04, -4.72075753e-02, -1.42352745e-01,\n",
            "        -5.32630324e-01,  1.55636594e-02,  9.25535142e-01,\n",
            "         8.45366776e-01, -7.16285646e-01, -4.58838195e-01,\n",
            "        -4.31367342e-04,  3.66596668e-03,  1.53061956e-01,\n",
            "         1.12917060e-02,  9.07853484e-01, -1.94748133e-01,\n",
            "         4.37777192e-09, -4.51748371e-01, -8.64526987e-01,\n",
            "         7.64689267e-01,  8.06923863e-03,  9.00943398e-01,\n",
            "         3.50638060e-03,  1.33435195e-03, -1.71292648e-01,\n",
            "        -1.93261821e-02, -2.07717693e-03, -3.69749992e-04,\n",
            "         5.37591457e-01, -7.11679459e-02, -9.55907285e-01,\n",
            "        -7.18326390e-01,  9.49080646e-01,  8.15319180e-01,\n",
            "         9.75061297e-01,  2.90125281e-01,  8.43683258e-03,\n",
            "        -8.95160139e-02,  7.22597480e-01, -6.44817114e-01,\n",
            "         7.36852348e-01, -1.79276383e-03, -3.94622612e-06,\n",
            "        -1.22708298e-04,  2.48139441e-01,  8.99852312e-05,\n",
            "         1.15721464e-01,  7.11091906e-02, -2.51226338e-05,\n",
            "         2.04544471e-04, -7.98402380e-06,  1.73563114e-03,\n",
            "         1.96266398e-01,  9.88932559e-04, -1.52719812e-02,\n",
            "        -7.33041048e-01, -8.31897497e-01,  1.59192324e-01,\n",
            "        -7.73207426e-01, -1.03463815e-03, -6.75504506e-01,\n",
            "        -2.35753462e-01, -5.70987993e-07,  9.07731414e-01,\n",
            "         1.68856219e-04,  7.84919918e-01,  8.92605167e-03,\n",
            "        -5.25822956e-03, -1.41838998e-01,  4.02472690e-02,\n",
            "        -8.93517971e-09, -4.04697431e-08,  3.06874141e-03,\n",
            "        -5.28125986e-02,  4.61229049e-02,  1.50475588e-09,\n",
            "        -9.78920639e-01,  2.48602917e-03,  8.25754106e-01,\n",
            "        -8.30455916e-04,  7.39224209e-03, -3.37850451e-02,\n",
            "         2.88482435e-04, -7.85183549e-01,  5.24561405e-01,\n",
            "         4.07262356e-04, -3.60342348e-03,  1.54100405e-03,\n",
            "         1.40733672e-02, -7.93976724e-01, -1.14790969e-01,\n",
            "        -5.65928780e-03,  3.82497050e-02,  4.95807603e-02,\n",
            "         3.57244074e-01,  5.98826766e-01,  1.54569198e-03,\n",
            "         5.69559395e-01, -5.13320230e-03, -1.58252747e-04,\n",
            "         6.80282891e-01, -1.73757002e-02, -1.18833235e-07,\n",
            "         3.92425526e-03,  3.84854257e-01,  8.78005549e-02,\n",
            "        -9.08905745e-01,  4.02714610e-01, -5.22080474e-02,\n",
            "        -1.30358785e-01,  1.17417075e-01, -3.05840999e-01,\n",
            "        -2.49607954e-03, -1.52125899e-02,  2.07599238e-01,\n",
            "         4.75778952e-02, -1.57713821e-05, -2.21777130e-02,\n",
            "        -1.36694389e-05, -2.95440515e-07,  6.16605439e-06,\n",
            "        -1.60855998e-04,  3.43332551e-02, -2.82785343e-03,\n",
            "         5.93414232e-02,  5.78599647e-02, -9.72259790e-03,\n",
            "        -2.90886464e-06]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.50734115e+00,  2.02533269e+00,  2.62670398e+00,\n",
            "        -3.11387032e-01,  7.84676731e-01, -8.88282359e-01,\n",
            "        -1.31859541e+00, -3.85781169e+00,  9.98266697e-01,\n",
            "         3.81692886e+00,  1.44067073e+00,  1.83241117e+00,\n",
            "         5.27038947e-02,  5.86201511e-02, -3.86033821e+00,\n",
            "        -1.41624665e+00, -2.57062936e+00, -2.76914930e+00,\n",
            "        -3.32884550e-01, -9.37234223e-01, -1.44055784e-01,\n",
            "        -3.23579741e+00,  3.00574273e-01, -2.80405807e+00,\n",
            "        -2.57908916e+00, -2.60505128e+00, -2.37206149e+00,\n",
            "         3.97858667e+00,  1.62036586e+00, -3.34860268e-03,\n",
            "        -2.90649915e+00,  3.73724985e+00,  3.29115301e-01,\n",
            "        -9.70429063e-01, -2.59236107e-03, -3.92509484e+00,\n",
            "        -2.28151631e+00, -3.00281763e+00,  2.20946884e+00,\n",
            "         2.37765789e+00,  1.48163080e+00,  1.64736509e-02,\n",
            "        -2.90398479e-01, -3.02173448e+00, -2.55809593e+00,\n",
            "        -6.53016865e-01,  5.28291473e-03,  2.42621079e-01,\n",
            "         5.44977427e-01,  2.96972418e+00,  1.70774448e+00,\n",
            "         3.75072956e+00,  1.03730738e+00, -3.82543015e+00,\n",
            "         8.30233749e-03,  3.49773884e+00,  5.38016716e-03,\n",
            "        -4.08061600e+00, -4.21552706e+00,  2.01725554e+00,\n",
            "         1.78295359e-01,  2.96553898e+00, -1.31747423e-04,\n",
            "         1.59782422e+00,  2.70993090e+00,  3.34585238e+00,\n",
            "         5.54279089e-01,  1.23088292e-04,  7.33154774e-01,\n",
            "        -7.26281665e-03,  1.05636798e-01,  1.42936349e+00,\n",
            "         1.83348227e+00,  3.18317151e+00, -5.57639182e-01,\n",
            "        -1.19824815e+00,  7.04030273e-03,  4.11850834e+00,\n",
            "        -9.37917054e-01, -3.01513767e+00, -2.06595585e-01,\n",
            "        -1.18419431e-01,  6.54670759e-04,  1.28463614e+00,\n",
            "        -5.78775890e-02,  2.99785995e+00, -8.18999484e-03,\n",
            "         1.43890618e-03,  3.29752803e+00, -1.46099770e+00,\n",
            "         1.69656035e-02, -3.25844705e-01,  2.42309600e-01,\n",
            "        -1.15722513e+00, -2.47224998e+00, -2.93748736e+00,\n",
            "         7.69738138e-01, -4.98010933e-01, -7.44680408e-03,\n",
            "         2.73367882e-01,  2.75772238e+00,  1.04610808e-03,\n",
            "        -1.62748322e-02, -1.34864497e+00, -3.15788269e+00,\n",
            "         4.52667058e-01,  1.92143440e+00,  2.35776591e+00,\n",
            "         4.49605519e-03,  1.31375477e-01,  3.64365652e-02,\n",
            "         2.43100166e+00,  7.05154687e-02, -3.07287335e-01,\n",
            "         1.89538792e-01,  1.21332824e+00,  1.25920844e+00,\n",
            "        -2.80017662e+00,  3.96862984e+00, -1.21154385e-02,\n",
            "        -3.79462361e+00, -5.83754911e-04,  5.26107132e-01,\n",
            "        -1.48265827e+00,  1.88549533e-01,  2.68196511e+00,\n",
            "         3.42665005e+00, -2.78407753e-01,  3.32189131e+00,\n",
            "         1.02477307e-02, -4.94217277e-02, -1.15328717e+00,\n",
            "        -5.93812227e-01,  1.55650778e-02,  1.67778623e+00,\n",
            "         1.23970401e+00, -9.05978858e-01, -5.14680266e-01,\n",
            "        -4.51165438e+00,  1.91398308e-01,  1.72132120e-01,\n",
            "         1.13610737e-02,  1.79454768e+00, -2.00602740e-01,\n",
            "         9.30245638e-01, -2.56279922e+00, -1.31170225e+00,\n",
            "         1.06189406e+00,  2.28543252e-01,  1.57047713e+00,\n",
            "         2.67922997e-01,  1.33444264e-03, -3.12257600e+00,\n",
            "        -3.57772899e+00, -1.80115193e-01, -3.21273255e+00,\n",
            "         1.71061385e+00, -7.27711618e-02, -2.69347906e+00,\n",
            "        -9.25456882e-01,  4.36648178e+00,  3.70256019e+00,\n",
            "         2.18615818e+00,  2.98714042e-01,  1.01983882e-02,\n",
            "        -1.02048531e-01,  9.22836840e-01, -7.66487181e-01,\n",
            "         9.91111517e-01, -1.69355643e+00, -3.04401457e-01,\n",
            "        -2.74869353e-01,  2.81363547e-01,  4.03044796e+00,\n",
            "         1.17159531e-01,  8.29355359e-01, -2.52897389e-05,\n",
            "         3.60213447e+00, -8.24875497e-06,  1.78618869e-03,\n",
            "         1.99427262e-01,  2.14731693e+00, -3.50679851e+00,\n",
            "        -9.37016785e-01, -1.19439113e+00,  1.65465787e-01,\n",
            "        -1.02874529e+00, -2.76401329e+00, -1.18823004e+00,\n",
            "        -4.71313119e-01, -2.58232379e+00,  1.87232816e+00,\n",
            "         1.05143774e+00,  1.10358250e+00,  4.19155788e+00,\n",
            "        -2.04342508e+00, -1.42826945e-01,  1.82527214e-01,\n",
            "        -1.32075334e+00, -1.94529775e-06,  3.72922015e+00,\n",
            "        -6.99973851e-02,  4.62165475e-02,  1.74010074e+00,\n",
            "        -3.05655766e+00,  3.11111188e+00,  2.63374376e+00,\n",
            "        -3.93602824e+00,  3.07860732e+00, -3.68413292e-02,\n",
            "         3.51359749e+00, -1.06175876e+00,  8.06884944e-01,\n",
            "         1.14126772e-01, -1.92611003e+00,  2.43573856e+00,\n",
            "         1.41240181e-02, -1.19492102e+00, -2.05484480e-01,\n",
            "        -1.32077694e+00,  3.82803604e-02,  2.06374660e-01,\n",
            "         3.69220281e+00,  6.91328406e-01,  3.68799925e+00,\n",
            "         6.55675173e-01, -2.94098639e+00, -9.07130897e-01,\n",
            "         8.76729906e-01, -2.44677495e-02, -2.36287131e-04,\n",
            "         3.83831596e+00,  4.08067435e-01,  1.15393043e+00,\n",
            "        -1.52349579e+00,  4.81687874e-01, -2.26984191e+00,\n",
            "        -2.00254250e+00,  4.32144374e-01, -3.50317776e-01,\n",
            "        -2.49608466e-03, -1.54910134e-02,  3.80268216e+00,\n",
            "         4.76139449e-02, -2.59686804e+00, -1.36038736e-01,\n",
            "        -7.05581486e-01, -2.86397004e+00,  3.78986883e+00,\n",
            "        -1.61658230e-04,  3.43467630e-02, -5.97561114e-02,\n",
            "         1.00089633e+00,  5.79315051e-02, -9.75956023e-03,\n",
            "        -3.50223899e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.07512303e-01,  1.28656909e-01,  9.79249597e-01,\n",
            "        -3.67036134e-01,  8.18260610e-01, -7.03448236e-01,\n",
            "        -7.98678398e-01, -6.76759053e-03,  2.53073573e-01,\n",
            "         7.57281303e-01,  8.60546649e-01,  1.40388620e-05,\n",
            "         7.11807143e-03, -5.09780198e-02, -1.12908392e-03,\n",
            "        -2.78193294e-03, -9.49097145e-03, -8.13839316e-01,\n",
            "        -4.35407817e-01, -7.31733978e-01, -2.84354854e-02,\n",
            "        -1.75865609e-02, -4.61892724e-01, -2.01390637e-03,\n",
            "        -3.75633390e-05, -9.86564398e-01, -8.93653572e-01,\n",
            "         5.19963505e-04,  8.25636923e-01, -1.48109924e-02,\n",
            "        -3.39671224e-01,  3.13131541e-01,  3.91851455e-01,\n",
            "        -2.08630739e-03, -1.71107659e-03, -7.17665488e-03,\n",
            "        -7.11198628e-01, -7.10274279e-01,  1.36860146e-03,\n",
            "         4.95724787e-04,  9.07253325e-01,  3.14718001e-02,\n",
            "        -6.41943142e-02, -5.78874373e-04, -3.31672169e-02,\n",
            "         1.37769422e-02,  5.53050786e-02,  1.66061267e-01,\n",
            "         4.12953906e-02,  9.37824190e-01,  7.87001252e-01,\n",
            "         6.57080114e-01,  7.52780121e-03, -9.24941897e-01,\n",
            "         7.06176937e-01,  8.56394768e-02,  1.95991416e-02,\n",
            "        -9.78556275e-01, -9.95636106e-01,  4.78572734e-02,\n",
            "         2.69941259e-02,  1.17902122e-01, -1.05666537e-02,\n",
            "         3.20606887e-06,  1.73078108e-04,  7.13021398e-01,\n",
            "        -3.92487139e-01,  1.75289989e-01,  1.86262112e-02,\n",
            "        -7.34035252e-03,  3.99730802e-02,  8.28310549e-01,\n",
            "         7.43050337e-01,  9.44564521e-01, -4.82472569e-01,\n",
            "        -9.70148742e-01,  1.15550915e-03,  9.95397866e-01,\n",
            "        -4.76651698e-01, -7.07742512e-01, -3.85205477e-01,\n",
            "        -1.55383080e-01,  7.37463779e-05,  8.35797727e-01,\n",
            "        -3.79028857e-01,  5.58622181e-03, -5.09068021e-04,\n",
            "         2.47158040e-03,  8.57303500e-01, -9.65567291e-01,\n",
            "         1.40106911e-03, -3.15181047e-01, -6.38040781e-01,\n",
            "        -2.09972933e-01, -4.67606671e-02, -6.29778893e-04,\n",
            "         3.58172096e-02, -1.03457794e-02, -1.78136826e-02,\n",
            "         7.68197060e-01,  9.39196229e-01, -8.42241347e-02,\n",
            "         1.18237726e-01, -5.43021321e-01, -8.76920745e-02,\n",
            "         4.43650156e-01,  3.04286164e-04,  9.85638380e-01,\n",
            "         1.36650950e-01,  3.99451196e-01,  1.60144104e-04,\n",
            "         8.89708519e-01,  3.53655331e-02, -3.75488251e-01,\n",
            "         3.54062080e-01,  8.64216626e-01,  3.78643483e-01,\n",
            "        -9.42119136e-02,  1.27363250e-01, -5.88814903e-04,\n",
            "        -9.60263550e-01, -1.64662868e-01,  7.22711205e-01,\n",
            "        -6.52527332e-01,  2.39118206e-04,  7.76650151e-03,\n",
            "         8.67382288e-01, -2.84385396e-06,  4.63017710e-02,\n",
            "         1.91842597e-02, -1.14960225e-04,  7.53611267e-01,\n",
            "        -5.38488626e-01,  5.63886203e-03,  3.44830662e-01,\n",
            "         9.70400512e-01, -4.45425212e-02, -8.37945095e-07,\n",
            "        -9.94504213e-01,  1.87461480e-01,  5.71276009e-01,\n",
            "         8.01449455e-03,  9.54844177e-01, -2.87908292e-03,\n",
            "         7.70903751e-02, -6.81948222e-05, -9.30713296e-01,\n",
            "        -5.59245586e-01,  3.26516740e-02,  9.15485322e-01,\n",
            "         7.59626031e-01,  6.97678328e-02, -8.70427012e-01,\n",
            "        -5.80459088e-03, -1.59133971e-01, -3.17796797e-01,\n",
            "         5.83640672e-02, -5.72905093e-02, -3.13172676e-02,\n",
            "        -1.19532796e-03,  1.27954915e-01,  3.42695334e-04,\n",
            "         9.63563383e-01,  3.33167553e-01,  8.92359093e-02,\n",
            "        -5.88992983e-02,  3.26527399e-03, -9.29691136e-01,\n",
            "         2.57273048e-01, -1.59712479e-04, -2.39544958e-01,\n",
            "        -2.43085384e-01,  8.33923579e-04,  3.07017181e-04,\n",
            "         1.82977542e-02,  5.36931336e-01, -2.66188215e-02,\n",
            "         7.05599010e-01, -2.97123054e-03,  2.12017462e-01,\n",
            "         6.45920308e-03,  6.97052479e-01, -1.34894013e-01,\n",
            "        -8.58401954e-02, -8.30158234e-01,  5.98366670e-02,\n",
            "        -7.73878336e-01, -3.25797945e-01, -4.08135820e-03,\n",
            "        -8.67954791e-01, -1.57687683e-02,  5.48943295e-04,\n",
            "         9.27474380e-01,  7.03688562e-01,  9.23634589e-01,\n",
            "        -8.06688547e-01,  5.23110986e-01,  1.79835439e-01,\n",
            "        -1.44823098e-05, -7.68015906e-02,  5.87073326e-01,\n",
            "        -2.18490786e-05,  4.42145206e-02,  9.91627574e-01,\n",
            "        -4.98725213e-02,  9.63514686e-01,  9.62714851e-01,\n",
            "        -8.34192574e-01,  6.82178434e-05, -4.49266881e-02,\n",
            "         9.06435922e-02, -7.86888003e-01,  6.67151928e-01,\n",
            "         1.24982267e-03, -4.39626217e-01,  4.38813440e-04,\n",
            "         1.47607513e-02, -8.10845137e-01, -3.43648973e-03,\n",
            "        -8.67935121e-01,  1.30212473e-04,  5.74948907e-01,\n",
            "         1.63508996e-01,  5.33700859e-06,  4.51375061e-04,\n",
            "        -4.32558171e-03, -9.90837514e-01, -4.28534895e-01,\n",
            "         1.45841232e-02, -4.99769896e-01, -1.37700187e-03,\n",
            "         5.89725614e-01,  5.01305699e-01,  4.59395319e-01,\n",
            "        -8.86617839e-01,  4.45945740e-01, -9.77235377e-01,\n",
            "        -7.95558080e-05,  1.95480958e-01, -8.14062834e-01,\n",
            "         7.41811037e-01, -6.57719970e-01,  9.40840319e-02,\n",
            "         5.81910498e-02, -9.75309074e-01,  2.82261103e-01,\n",
            "        -8.12766608e-04, -1.81472123e-01,  9.99198556e-01,\n",
            "        -8.75097327e-03, -9.05261782e-04, -7.47742116e-01,\n",
            "         4.98979585e-03,  5.81596494e-02, -4.14040565e-01,\n",
            "        -2.96396211e-05]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.3303342e+00,  2.6962044e+00,  2.4602132e+00, -5.6709093e-01,\n",
            "         1.1869391e+00, -8.9913839e-01, -1.2033238e+00, -4.8274889e+00,\n",
            "         2.7338311e-01,  4.7416897e+00,  1.4530256e+00,  2.8149524e+00,\n",
            "         7.2097337e-01, -9.8116714e-01, -4.8480887e+00, -2.3247693e+00,\n",
            "        -3.5238197e+00, -1.8771130e+00, -1.3306160e+00, -9.3648952e-01,\n",
            "        -2.2319360e-01, -4.2216296e+00, -5.0120974e-01, -3.5943010e+00,\n",
            "        -3.4527006e+00, -2.4984453e+00, -1.4492421e+00,  4.9753623e+00,\n",
            "         2.6132514e+00, -9.9572349e-01, -1.9672604e+00,  4.0824380e+00,\n",
            "         6.6498387e-01, -1.9487777e+00, -2.1109921e-03, -4.7347574e+00,\n",
            "        -3.2763002e+00, -3.2838988e+00,  3.1840189e+00,  2.2857778e+00,\n",
            "         1.5179788e+00,  6.8568043e-02, -6.1934829e-01, -4.0082679e+00,\n",
            "        -3.5032241e+00,  1.7896685e-01,  1.0049611e+00,  7.4958622e-01,\n",
            "         1.5123185e+00,  3.6712835e+00,  1.7286167e+00,  3.5713944e+00,\n",
            "         1.5281299e+00, -3.3585055e+00,  8.8918209e-01,  4.4775319e+00,\n",
            "         9.7413324e-02, -5.0670214e+00, -3.0732522e+00,  2.3945227e+00,\n",
            "         2.7001522e-02,  2.9545262e+00, -8.7631679e-01,  2.5870388e+00,\n",
            "         3.5586503e+00,  2.4538560e+00, -4.1475874e-01,  9.5300227e-01,\n",
            "         1.7060627e+00, -7.3647830e-03,  1.1216360e-01,  1.6996186e+00,\n",
            "         9.5732355e-01,  3.2975621e+00, -5.6221110e-01, -2.1007860e+00,\n",
            "         5.9991115e-01,  3.3386323e+00, -1.7250849e+00, -3.1237731e+00,\n",
            "        -4.0775973e-01, -1.1170554e+00,  9.9550545e-01,  1.2863175e+00,\n",
            "        -1.0451260e+00,  3.9867096e+00, -1.0490779e-02,  1.0010985e+00,\n",
            "         3.1129549e+00, -2.0223413e+00,  9.9407846e-01, -3.2628885e-01,\n",
            "        -7.5532383e-01, -1.9905732e+00, -3.4281120e+00, -3.9050136e+00,\n",
            "         1.7103823e+00, -1.4955664e+00, -9.8312020e-01,  1.2307851e+00,\n",
            "         1.8854263e+00, -1.6292782e-01,  9.8007566e-01, -1.4801378e+00,\n",
            "        -4.1468186e+00,  6.8460184e-01,  2.2705138e+00,  2.6502442e+00,\n",
            "         1.0006249e+00,  4.2317325e-01,  7.0603007e-01,  1.4520396e+00,\n",
            "         4.3644899e-01, -3.9481762e-01,  1.1578681e+00,  1.3101375e+00,\n",
            "         4.0035796e-01, -3.3730335e+00,  4.1765375e+00, -1.7808938e-01,\n",
            "        -3.7433960e+00, -9.0986270e-01,  9.2026997e-01, -1.5020417e+00,\n",
            "         5.9979844e-01,  3.6645136e+00,  3.6485534e+00, -4.0687212e-01,\n",
            "         4.1612406e+00,  1.9221140e-02, -1.0386118e+00,  9.8195970e-01,\n",
            "        -6.0495275e-01,  2.7550597e-02,  2.6282928e+00,  2.1049984e+00,\n",
            "        -1.0510725e+00, -1.5019581e+00, -5.3586774e+00,  3.9898324e-01,\n",
            "         9.5182741e-01,  8.1973284e-01,  2.7755959e+00, -3.3348200e-01,\n",
            "         8.8754338e-01, -3.0313132e+00, -1.6778154e+00, -6.3179404e-01,\n",
            "         4.2181930e-01,  1.5610783e+00,  1.0452414e+00,  9.0086353e-01,\n",
            "        -2.5431209e+00, -3.5575366e+00, -1.1728672e+00, -4.2055969e+00,\n",
            "         2.7012093e+00, -5.7400543e-02, -3.5807738e+00, -1.9130477e+00,\n",
            "         3.6539068e+00,  3.9076805e+00,  3.0466824e+00,  7.2695881e-01,\n",
            "         8.9639559e-02, -6.3605689e-02,  1.9147017e+00, -1.6612741e+00,\n",
            "         2.6400077e-01, -2.3906837e+00, -1.1910357e+00, -2.4837053e-01,\n",
            "         3.5219169e-01,  5.0021663e+00,  2.7891457e-01,  1.5926278e+00,\n",
            "        -9.9951595e-01,  4.2955489e+00, -9.9339193e-01,  9.8357332e-01,\n",
            "         6.5485311e-01,  2.1192255e+00, -4.4524560e+00, -1.9295042e+00,\n",
            "        -2.1271105e+00,  2.4287806e-01, -1.0302014e+00, -3.3008046e+00,\n",
            "        -2.1860330e+00, -1.3249717e+00, -3.1313524e+00,  2.6866405e+00,\n",
            "         1.6405675e+00,  8.7471789e-01,  3.4007998e+00, -1.2822074e+00,\n",
            "         5.8304453e-01,  1.8194738e-01, -2.3117557e+00, -9.6330428e-01,\n",
            "         2.8276136e+00, -1.0691391e+00,  5.7473969e-01,  2.7364514e+00,\n",
            "        -3.9022062e+00,  1.9928153e+00,  2.5853040e+00, -4.0402937e+00,\n",
            "         3.7050016e+00, -1.0293854e+00,  4.3955941e+00, -1.0696493e+00,\n",
            "         9.3896598e-01,  1.0986247e+00, -2.1834004e+00,  3.4284852e+00,\n",
            "         1.4789220e-02, -1.1301720e+00, -1.2027878e+00, -1.3291574e+00,\n",
            "         1.0326562e+00,  1.2027357e+00,  3.7273846e+00,  8.2610261e-01,\n",
            "         3.9960938e+00, -7.9003280e-01, -2.7277350e+00, -8.9741760e-01,\n",
            "         8.9259994e-01, -5.4919702e-01, -9.9932289e-01,  4.8381286e+00,\n",
            "         5.5124569e-01,  1.1977111e+00, -1.4062963e+00,  1.3798738e+00,\n",
            "        -2.2351611e+00, -2.8799307e+00,  1.0853775e+00, -1.1394517e+00,\n",
            "         9.9872053e-01, -9.5405668e-01,  4.7378640e+00,  8.3333187e-02,\n",
            "        -3.4982653e+00,  7.9238540e-01, -1.6319919e+00, -3.7873964e+00,\n",
            "         4.0485415e+00, -9.9817747e-01, -8.9611471e-01, -9.6952122e-01,\n",
            "         1.9578016e+00,  5.8638569e-02, -9.6082145e-01, -4.4855971e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.26920404e-05,  7.80031485e-07,  9.67512846e-01,\n",
            "        -2.01774717e-04,  8.29494834e-01, -1.43314516e-02,\n",
            "        -9.75427687e-01, -8.08657229e-01, -4.65347707e-01,\n",
            "         9.21021849e-02,  8.96288812e-01,  5.41073462e-08,\n",
            "         3.54416152e-05, -3.78861341e-06, -1.96067799e-06,\n",
            "        -6.28711365e-04, -5.13534807e-02, -3.10367229e-03,\n",
            "        -8.73644352e-01, -6.89296722e-01, -2.19541699e-01,\n",
            "        -9.99941409e-01, -4.64805186e-01, -7.50341546e-03,\n",
            "        -1.11576053e-04, -8.62153292e-01, -8.80774677e-01,\n",
            "         1.78166404e-02,  5.11577491e-05, -2.61930400e-04,\n",
            "        -5.83016813e-01,  2.05149427e-02,  1.03634200e-04,\n",
            "        -6.35099655e-04, -7.40655363e-01, -3.38210011e-05,\n",
            "        -7.33571960e-06, -5.63294441e-02,  4.16330015e-03,\n",
            "         9.78863239e-01,  9.05641258e-01,  1.07039046e-02,\n",
            "        -5.46263657e-08, -2.20311130e-03, -4.43630964e-02,\n",
            "         4.17649187e-02,  2.54388192e-06,  8.48026048e-07,\n",
            "         3.95274788e-01,  5.99867008e-06,  9.13358450e-01,\n",
            "         9.97887075e-01,  3.35676130e-03, -9.93979454e-01,\n",
            "         1.79012910e-01,  9.99838531e-01,  6.91522807e-02,\n",
            "        -6.44803792e-03, -8.23257148e-01,  9.29684211e-06,\n",
            "        -1.86019309e-03,  9.94578838e-01, -8.14301968e-01,\n",
            "         6.79808849e-08,  1.95294982e-04,  4.25359394e-06,\n",
            "        -4.32419747e-01,  8.42469573e-01,  3.52206229e-08,\n",
            "        -4.37777583e-03,  6.20835461e-03,  9.87151623e-01,\n",
            "        -4.01060432e-02,  9.67115939e-01, -5.96303437e-07,\n",
            "        -5.61093092e-01,  5.73413246e-08,  7.36643434e-01,\n",
            "        -7.66527236e-01, -9.15920675e-01, -4.25920784e-02,\n",
            "        -7.88840801e-02,  2.36587529e-03,  7.90025666e-02,\n",
            "        -6.34923205e-03,  9.95559156e-01, -1.76413232e-04,\n",
            "         4.53130160e-05,  3.92848670e-01, -7.37401962e-01,\n",
            "         1.02546073e-06, -3.15166473e-01, -8.89787853e-01,\n",
            "        -4.38452465e-04, -1.11029558e-02, -5.57351159e-03,\n",
            "         1.24707840e-01, -8.72415490e-03, -4.53231619e-10,\n",
            "         6.38095975e-01,  6.74178243e-01, -2.14441538e-01,\n",
            "         3.75952691e-01, -4.71522242e-01, -9.99931931e-01,\n",
            "         8.49410594e-01,  1.17173069e-03,  2.10421354e-01,\n",
            "         1.15070271e-03,  5.50395958e-02,  1.47934955e-07,\n",
            "         8.94270182e-01,  7.80661345e-01, -4.94571656e-01,\n",
            "         2.96106407e-07,  4.98787671e-01,  3.71119171e-01,\n",
            "        -2.15339809e-04,  1.52337097e-03, -7.86713287e-02,\n",
            "        -9.65432107e-01, -1.19525567e-03,  9.34377372e-01,\n",
            "        -8.62063706e-01,  5.00061196e-06,  9.77077305e-01,\n",
            "         4.27214945e-06, -6.96351635e-04,  4.96742278e-02,\n",
            "         2.11977020e-01, -9.91789550e-02,  5.15225455e-02,\n",
            "        -5.25192618e-01,  6.58977330e-02,  4.78612492e-06,\n",
            "         9.42943335e-01, -3.00204575e-01, -5.01007764e-13,\n",
            "        -9.99992132e-01,  7.95589387e-01,  7.28548944e-01,\n",
            "         7.40315974e-01,  2.92350087e-05, -2.69915676e-03,\n",
            "         1.13857552e-01, -4.07929420e-02, -2.37975037e-04,\n",
            "        -9.26296353e-01,  1.46925554e-01,  9.12254632e-01,\n",
            "         9.67064202e-01,  9.51767743e-01, -7.54155934e-01,\n",
            "        -9.98373330e-01, -9.65194941e-01, -6.25951486e-07,\n",
            "         8.18232095e-08, -3.74282189e-02, -9.68974769e-01,\n",
            "        -2.85123429e-06,  8.36325530e-03,  1.04040555e-04,\n",
            "         9.95568514e-01,  6.38536334e-01,  7.75774300e-01,\n",
            "         7.35002046e-04,  9.35236767e-06, -9.88381326e-01,\n",
            "         5.38554415e-02, -2.11678841e-03, -2.14591399e-01,\n",
            "        -2.43085533e-01,  8.45899913e-12,  6.64916233e-10,\n",
            "         2.58773506e-01,  7.58432329e-01, -9.30476367e-01,\n",
            "         9.99864340e-01, -6.76230629e-05,  7.67510322e-09,\n",
            "         5.41578680e-02,  9.55916405e-01, -9.99725819e-01,\n",
            "        -6.68737528e-07, -9.95385468e-01,  8.42011154e-01,\n",
            "        -3.73220108e-02, -3.58209247e-03, -9.90801156e-01,\n",
            "        -9.75584388e-01, -9.38304424e-01,  1.17814370e-05,\n",
            "         2.98766849e-06,  6.98215604e-01,  9.97762322e-01,\n",
            "        -8.67340147e-01,  6.96378708e-01,  1.80831015e-01,\n",
            "        -1.47256518e-09, -1.38794053e-02,  9.16886389e-01,\n",
            "        -3.22113510e-06,  7.76099324e-01,  9.98786807e-01,\n",
            "        -1.97773744e-08,  8.89896929e-01,  8.71653199e-01,\n",
            "        -9.99898493e-01,  6.36612952e-01, -2.33661831e-13,\n",
            "         9.97085094e-01, -8.62036228e-01,  9.59134281e-01,\n",
            "         2.59815715e-06, -2.21638717e-02,  9.64719931e-08,\n",
            "         1.47823114e-02, -7.45224953e-01, -2.07741931e-03,\n",
            "        -8.69043231e-01,  4.48043611e-05,  8.08041636e-03,\n",
            "         1.07433661e-05,  4.45556104e-01,  2.49844503e-11,\n",
            "        -1.54476374e-01, -8.45147610e-01, -7.03600347e-01,\n",
            "         9.55536544e-01, -8.76405835e-01, -9.61877763e-01,\n",
            "         9.99982059e-01,  5.77473462e-01,  2.35402822e-05,\n",
            "        -8.86103630e-01,  9.65770841e-01, -9.77347493e-01,\n",
            "        -1.88873850e-09,  7.26254582e-01, -9.72198784e-01,\n",
            "         1.46540733e-05, -8.10207784e-01,  4.47059609e-02,\n",
            "         7.93905437e-01, -9.70579147e-01,  8.87322426e-01,\n",
            "        -6.12314616e-04, -3.97344818e-03,  8.24882761e-02,\n",
            "        -9.60849762e-01, -2.70751593e-06, -9.56598759e-01,\n",
            "         5.63906440e-07,  1.26432115e-02, -1.72354619e-03,\n",
            "        -9.95152950e-01]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 5.1864605e+00,  3.4270449e+00,  2.0518403e+00, -8.2392800e-01,\n",
            "         1.1869478e+00, -1.8980902e+00, -2.1942742e+00, -5.8136134e+00,\n",
            "        -5.0415707e-01,  5.1784134e+00,  1.4530226e+00,  3.8095539e+00,\n",
            "         1.7086211e+00, -1.4229189e+00, -5.8218069e+00, -3.3035772e+00,\n",
            "        -3.7237451e+00, -1.6681552e+00, -1.3482796e+00, -8.4661454e-01,\n",
            "        -2.2319357e-01, -5.2199726e+00, -5.0344551e-01, -4.2402873e+00,\n",
            "        -3.8074882e+00, -1.3016737e+00, -1.3792119e+00,  5.9753537e+00,\n",
            "         3.6132469e+00, -9.9758333e-01, -1.9658741e+00,  4.0824533e+00,\n",
            "         8.4369308e-01, -2.9447653e+00, -9.5194632e-01, -4.7333393e+00,\n",
            "        -3.7656834e+00, -4.2669020e+00,  4.1806188e+00,  2.2696908e+00,\n",
            "         1.5027364e+00,  2.4200547e-01, -1.0856258e+00, -5.0030408e+00,\n",
            "        -4.4918737e+00,  2.9403597e-01,  2.0040369e+00,  8.9961606e-01,\n",
            "         1.3965759e+00,  4.4398756e+00,  1.7439560e+00,  3.5599883e+00,\n",
            "         2.2043939e+00, -2.9082043e+00,  1.8096451e-01,  5.3950191e+00,\n",
            "         9.0693945e-01, -6.0376482e+00, -1.1668428e+00,  3.2964437e+00,\n",
            "        -1.8602451e-03,  2.9544330e+00, -1.8712509e+00,  3.5869639e+00,\n",
            "         4.4976697e+00,  3.4538541e+00, -4.6300715e-01,  1.9488989e+00,\n",
            "         1.9488076e+00, -7.3646028e-03,  2.8628320e-01,  2.5721912e+00,\n",
            "        -4.0129643e-02,  2.5085478e+00, -5.7162362e-01, -6.3442880e-01,\n",
            "         8.8309485e-01,  3.3115196e+00, -2.7246747e+00, -4.0119405e+00,\n",
            "        -4.0775976e-01, -2.1170332e+00,  1.8147130e+00,  1.2926749e+00,\n",
            "        -2.0431378e+00,  4.9277964e+00, -1.0469790e-02,  2.0000849e+00,\n",
            "         3.1097629e+00, -9.4488704e-01,  1.9778638e+00, -3.2628831e-01,\n",
            "        -1.4209135e+00, -2.1977880e+00, -4.4280324e+00, -4.5117507e+00,\n",
            "         1.2539785e-01, -2.4940095e+00, -9.8242158e-01,  2.2305663e+00,\n",
            "         1.8827161e+00, -2.1786059e-01,  1.9458458e+00, -1.1126540e+00,\n",
            "        -5.1441560e+00,  1.2959425e+00,  3.2703905e+00,  2.6509609e+00,\n",
            "         1.9930503e+00,  1.4197085e+00,  8.3846772e-01,  1.4430684e+00,\n",
            "         1.1257720e+00, -5.4209930e-01,  1.1635298e+00,  2.2910111e+00,\n",
            "         3.8973084e-01, -3.3724570e+00,  4.8684249e+00, -2.2493047e-01,\n",
            "        -4.6766543e+00, -1.7916229e+00,  1.6990696e+00, -2.4981503e+00,\n",
            "         1.4579172e+00,  4.6381269e+00,  4.5253563e+00, -4.2141211e-01,\n",
            "         5.0467396e+00,  9.4894731e-01, -2.0382509e+00,  1.9790838e+00,\n",
            "        -6.0502875e-01,  6.5993518e-02,  3.4721725e+00,  1.7639618e+00,\n",
            "        -3.1402439e-01, -2.4956875e+00, -6.2701759e+00,  1.1479634e+00,\n",
            "         9.5509070e-01,  9.9745882e-01,  2.9083130e+00, -1.3170069e+00,\n",
            "         8.8839144e-01, -3.0312688e+00, -1.2617586e+00, -1.6317220e+00,\n",
            "         5.8562458e-01,  1.5607793e+00,  2.0448685e+00,  1.8503540e+00,\n",
            "        -2.5382564e+00, -3.5568204e+00, -2.0167923e+00, -5.2004318e+00,\n",
            "         3.6915112e+00, -3.7451155e-02, -3.6193950e+00, -2.9089985e+00,\n",
            "         3.6073391e+00,  3.9517734e+00,  3.0551085e+00,  1.2303822e+00,\n",
            "         1.0887883e+00,  1.0464095e-03,  2.9134483e+00, -2.6612549e+00,\n",
            "         5.6181412e-02, -2.3917954e+00, -1.1991963e+00, -2.4805123e-01,\n",
            "         3.6483929e-01,  5.9734864e+00,  2.7990532e-01,  9.9298984e-01,\n",
            "        -1.9989954e+00,  5.2424569e+00, -1.9905872e+00,  1.3175336e+00,\n",
            "         6.5318257e-01,  1.9065100e+00, -4.7510724e+00, -2.7896972e+00,\n",
            "        -3.0439672e+00,  1.2418556e+00, -1.0299834e+00, -3.5824755e-03,\n",
            "        -3.1860211e+00, -2.1967778e+00, -3.1315415e+00,  3.6598794e+00,\n",
            "         1.6389706e+00,  8.6381036e-01,  3.3976545e+00, -1.3222746e+00,\n",
            "         8.6058915e-01,  1.8284246e-01, -3.3093522e+00, -1.9632802e+00,\n",
            "         1.8292321e+00, -1.9775852e+00,  1.5747390e+00,  3.7051468e+00,\n",
            "        -4.8020716e+00,  1.4214302e+00,  2.5512321e+00, -5.0332656e+00,\n",
            "         3.7116070e+00, -2.0284090e+00,  3.2789624e+00, -1.3019745e+00,\n",
            "         1.9349829e+00,  1.1973306e+00, -2.1820316e+00,  4.4254570e+00,\n",
            "         1.4784714e-02, -9.6221566e-01, -2.2027838e+00, -1.3291574e+00,\n",
            "         1.9703661e+00,  2.1688309e+00,  3.7137909e+00,  9.1336447e-01,\n",
            "         4.2417269e+00, -3.7799922e-01, -2.0704253e+00, -8.7439525e-01,\n",
            "         1.8925438e+00, -1.3600552e+00, -1.9972067e+00,  5.8381276e+00,\n",
            "         6.5866560e-01,  2.0316594e+00, -1.4035202e+00,  2.3609462e+00,\n",
            "        -2.2346423e+00, -3.2341766e+00,  1.0889068e+00, -2.1313038e+00,\n",
            "         9.9880630e-01, -1.1405091e+00,  5.7339406e+00,  1.0830923e+00,\n",
            "        -3.4982703e+00,  1.5008650e+00, -2.3728163e+00, -4.7825708e+00,\n",
            "         8.2676135e-02, -1.9890158e+00, -1.0389445e+00, -1.9056197e+00,\n",
            "         2.7329898e+00,  1.2645021e-02, -1.6666923e+00, -5.4855599e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.21619482e-05,  5.81002446e-09,  9.67337489e-01,\n",
            "        -5.95773940e-07,  8.13948736e-03, -1.69832411e-03,\n",
            "        -9.75589097e-01, -3.87441760e-05, -9.05579984e-01,\n",
            "         1.41445256e-03,  7.40286589e-01,  3.68598052e-07,\n",
            "         1.00414752e-06, -5.39338529e-08, -2.61180020e-07,\n",
            "        -1.46521115e-05, -8.19166587e-07, -7.51952171e-01,\n",
            "        -6.68374658e-01, -2.52465576e-01, -1.30310314e-08,\n",
            "        -5.10137081e-01, -5.12116790e-01, -1.05367938e-07,\n",
            "        -4.85954524e-06,  4.23981436e-02, -8.63020897e-01,\n",
            "         9.50024059e-06,  1.27662042e-06, -1.86642091e-11,\n",
            "        -9.57059145e-01,  1.03456840e-01,  3.05277132e-03,\n",
            "        -8.99767911e-05, -1.77284047e-01, -1.07997628e-04,\n",
            "        -4.58186975e-07, -1.72463618e-02,  1.45131378e-06,\n",
            "         8.66813818e-04,  2.00862765e-01,  3.39867771e-02,\n",
            "        -5.82801840e-06, -4.29428294e-02, -3.94182503e-02,\n",
            "         2.71870375e-01,  1.55562518e-09,  5.33952516e-05,\n",
            "         7.69071339e-04,  7.54865771e-03,  6.80127050e-05,\n",
            "         9.22773480e-01,  8.57769977e-04, -9.93937969e-01,\n",
            "         8.17169063e-03,  6.71706855e-01,  1.39300963e-02,\n",
            "        -1.02277957e-02, -1.60031810e-01,  1.62633933e-05,\n",
            "        -5.45738712e-02,  9.94387686e-01, -7.00928807e-01,\n",
            "         1.15819503e-07,  7.35885561e-01,  8.14970932e-04,\n",
            "        -8.65748346e-01,  6.03597728e-05,  2.01475615e-07,\n",
            "        -3.47215030e-03,  7.15321209e-03,  9.72150326e-01,\n",
            "        -7.77179599e-01,  8.80734265e-01, -5.40781975e-01,\n",
            "        -1.37008280e-01,  3.10011131e-07,  5.07317841e-01,\n",
            "        -1.29144348e-04, -7.38217612e-04, -3.86504024e-01,\n",
            "        -1.11177899e-02,  2.58125868e-02,  1.45644275e-02,\n",
            "        -3.88020180e-06,  5.75427650e-10, -1.22191886e-05,\n",
            "         2.31426452e-06,  9.95138586e-01, -8.58385801e-01,\n",
            "         1.02793036e-08, -3.02165329e-01, -9.84293044e-01,\n",
            "        -2.49768212e-03, -6.12608630e-07, -3.42954709e-09,\n",
            "         2.96495885e-01, -9.78157997e-01, -2.66838379e-05,\n",
            "         9.73434799e-05,  9.54488218e-01, -2.24260628e-01,\n",
            "         9.83664155e-01, -2.94312507e-01, -3.67939323e-02,\n",
            "         1.37323350e-05,  7.09315166e-02,  1.03835404e-01,\n",
            "         9.06317844e-04,  4.23918664e-01,  4.91845887e-12,\n",
            "         8.93533170e-01,  2.30591886e-05, -2.62347966e-01,\n",
            "         8.68330826e-04,  9.11612153e-01,  3.20046067e-01,\n",
            "        -2.48542165e-05,  1.73805490e-01, -1.09312753e-03,\n",
            "        -2.87129806e-04, -6.77657954e-04,  6.39268709e-03,\n",
            "        -9.48866844e-01,  7.39184965e-04,  1.83824050e-05,\n",
            "         1.64221103e-06, -8.74671992e-03,  1.59752175e-01,\n",
            "         3.00059528e-05, -2.99376772e-08,  9.90688741e-01,\n",
            "        -8.92202277e-03,  4.43538811e-05,  3.96089694e-09,\n",
            "         8.54061637e-03, -2.25408962e-06, -1.07737040e-12,\n",
            "        -9.99213994e-01,  1.89947255e-04,  2.41193866e-05,\n",
            "         9.60245192e-01,  1.03719594e-06, -1.60909630e-09,\n",
            "         7.82639503e-01, -6.35509059e-06, -9.21590865e-01,\n",
            "        -9.89638627e-01,  1.80463801e-04,  9.15448666e-01,\n",
            "         9.45097625e-01,  3.35965562e-03, -9.61277008e-01,\n",
            "        -1.03234430e-04, -9.64514971e-01, -2.69435740e-09,\n",
            "         7.47093856e-02,  6.18525565e-01, -3.75631771e-06,\n",
            "        -3.32102190e-09,  6.05774462e-01,  4.76097011e-06,\n",
            "         9.95566487e-01,  9.58376408e-01,  1.45808384e-01,\n",
            "         2.42304318e-02,  2.47597834e-03, -7.59220898e-01,\n",
            "        -1.55242726e-01, -2.82721680e-06, -8.91076550e-02,\n",
            "        -2.29639038e-01,  3.60539532e-09,  1.86129494e-08,\n",
            "         6.35889307e-07,  1.28369094e-04, -4.28358419e-03,\n",
            "         5.39009809e-01, -3.11814714e-04,  2.17213979e-04,\n",
            "         1.84594395e-09,  5.21262735e-03, -2.84276623e-02,\n",
            "        -7.81519804e-03, -1.69114454e-03,  9.77667630e-01,\n",
            "        -7.66046464e-01, -1.60436213e-11, -9.00157844e-04,\n",
            "        -4.80394103e-02, -3.61051224e-02,  1.01033067e-04,\n",
            "         9.89819348e-01, -7.87056610e-02,  9.97428536e-01,\n",
            "        -3.39851350e-01,  8.21123421e-01,  3.11723306e-06,\n",
            "        -5.36066587e-08, -7.46761262e-02,  6.38312876e-01,\n",
            "        -1.19470303e-06,  1.38092100e-05,  9.99836087e-01,\n",
            "        -9.96439755e-02,  3.28190863e-01,  9.07830298e-01,\n",
            "        -2.82199811e-02,  1.51868846e-07, -4.15503673e-05,\n",
            "         4.56274003e-02, -1.03131041e-03,  9.94353950e-01,\n",
            "         2.14720153e-08, -4.90204385e-03,  1.05985033e-04,\n",
            "         1.47797400e-02, -3.25209469e-01, -1.45421014e-04,\n",
            "        -9.51282203e-01,  8.18396373e-08,  6.46679327e-02,\n",
            "         6.07395521e-07,  2.07945554e-08,  9.32266417e-12,\n",
            "        -3.70934792e-02, -9.62851822e-01, -6.92712665e-01,\n",
            "         4.76221880e-03, -9.80740786e-01, -1.23295886e-02,\n",
            "         9.34477091e-01,  6.23919487e-01,  8.10469210e-04,\n",
            "        -9.39590812e-01,  1.37029821e-03, -1.47266258e-02,\n",
            "        -1.40297227e-11,  1.12804808e-02, -9.95938420e-01,\n",
            "         1.75182961e-07, -2.11529876e-03,  6.90659903e-08,\n",
            "         7.58352458e-01, -9.97146130e-01,  9.05687392e-01,\n",
            "        -6.62655708e-10, -9.99960542e-01,  1.83288410e-01,\n",
            "        -3.91968280e-01, -4.62558906e-04, -9.48054552e-01,\n",
            "         8.73461801e-08,  1.15224704e-01, -1.48596891e-05,\n",
            "        -3.07023462e-10]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 6.173836  ,  4.408767  ,  2.0491042 , -1.7956737 ,  2.116032  ,\n",
            "        -2.897559  , -3.1162026 , -6.810388  , -1.5024015 ,  6.1698956 ,\n",
            "         1.4788656 ,  4.8094616 ,  2.707806  , -2.3608217 , -6.8090916 ,\n",
            "        -4.30012   , -4.690524  , -1.571646  , -2.3482347 , -0.2580651 ,\n",
            "        -0.22407521, -5.975864  , -0.5655949 , -5.23384   , -4.781662  ,\n",
            "         0.04242358, -1.3050632 ,  6.969991  ,  4.5707464 , -1.9775678 ,\n",
            "        -1.9303036 ,  4.8938026 ,  1.8436024 , -3.9440908 , -0.5679606 ,\n",
            "        -4.733103  , -4.765582  , -4.775181  ,  5.1790996 ,  2.2721028 ,\n",
            "         0.20364158,  1.2373229 , -1.9413648 , -6.002204  , -5.491717  ,\n",
            "         0.3245005 ,  3.0036395 ,  1.895473  ,  2.396527  ,  5.425584  ,\n",
            "         1.7461402 ,  3.4233289 ,  3.1922596 , -2.8979878 ,  1.1809572 ,\n",
            "         6.3917494 ,  0.14925672, -7.0367684 , -0.16141933,  4.2936654 ,\n",
            "        -0.05463045,  2.9367044 , -2.8711722 ,  4.586897  ,  4.581954  ,\n",
            "         4.0561304 , -1.3158513 ,  2.9488776 ,  2.947995  , -0.00867651,\n",
            "         1.0206751 ,  3.547735  , -1.0391096 ,  1.8097252 , -0.60526836,\n",
            "        -0.6891167 ,  1.8757789 ,  3.3067098 , -3.7246442 , -5.007498  ,\n",
            "        -0.40777817, -3.1170268 ,  2.8145652 ,  1.2949502 , -3.0431352 ,\n",
            "         5.927487  , -0.01150932,  2.9998915 ,  3.0933616 , -1.2871814 ,\n",
            "         2.9774563 , -0.33070645, -2.4194984 , -3.1937528 , -5.420541  ,\n",
            "        -5.5091753 ,  1.1242489 , -3.4939373 , -1.7498263 ,  3.2305412 ,\n",
            "         1.8809067 , -0.2281382 ,  2.3997965 , -0.31682792, -6.1418343 ,\n",
            "         2.2690308 ,  4.2596116 ,  2.7213025 ,  2.9868755 ,  1.4340748 ,\n",
            "         1.8384619 ,  1.4401369 ,  1.2445186 , -1.5338485 ,  1.8939291 ,\n",
            "         3.2687087 ,  0.33169848, -4.1006145 ,  5.450542  , -1.2235621 ,\n",
            "        -5.6358294 , -1.0898598 ,  2.6986048 , -2.720689  ,  2.4578736 ,\n",
            "         5.636979  ,  5.249573  , -1.4122486 ,  6.04445   ,  1.7582871 ,\n",
            "        -3.0379972 ,  2.9672117 , -1.4968591 ,  0.58976954,  4.4437265 ,\n",
            "         2.7543504 , -1.3135195 , -3.4954853 , -3.930937  ,  2.1457176 ,\n",
            "         1.940687  ,  1.9942763 ,  3.907664  , -2.3169997 ,  1.0525807 ,\n",
            "        -3.8516393 , -2.107399  , -2.6290295 ,  1.5848414 ,  1.5601743 ,\n",
            "         3.0446408 ,  2.5895905 , -1.9661856 , -3.5567722 , -2.0168395 ,\n",
            "        -6.200136  ,  4.691307  ,  0.7226292 , -4.618846  , -3.906443  ,\n",
            "         3.277641  ,  4.9345    ,  3.055272  ,  2.093288  ,  2.0781972 ,\n",
            "         0.02423782,  3.9133875 , -3.6430168 , -0.15652859, -2.5408876 ,\n",
            "        -2.084698  , -0.23380838,  1.3329716 ,  6.961793  ,  1.2721195 ,\n",
            "         1.0707784 , -2.9989717 ,  6.2405043 , -2.990538  ,  2.315261  ,\n",
            "         0.910953  ,  1.9119104 , -5.742795  , -3.7896113 , -4.0439496 ,\n",
            "         2.2418494 , -1.0299835 , -0.3302709 , -4.158915  , -0.04809516,\n",
            "        -3.1777563 ,  4.5968456 ,  2.63807   , -0.07887125,  3.359674  ,\n",
            "        -0.35392448,  1.857732  ,  1.1667367 , -4.3052325 , -2.9632552 ,\n",
            "         1.6036704 , -2.977585  ,  2.574733  ,  4.704686  , -5.8017344 ,\n",
            "         0.3407995 ,  1.7240546 , -6.0316553 ,  3.7120125 , -3.028361  ,\n",
            "         4.2789054 , -2.3014815 ,  2.933557  ,  2.1941352 , -2.3175154 ,\n",
            "         5.4254494 ,  0.01478102, -0.33746487, -3.2027838 , -1.8451319 ,\n",
            "         2.9557633 ,  3.0910294 ,  3.8575633 ,  1.9133551 ,  4.8126926 ,\n",
            "        -0.3792286 , -2.0444963 , -0.8531525 ,  2.8906968 , -2.3361049 ,\n",
            "        -2.9971988 ,  6.6998935 ,  0.7350363 ,  3.0288365 , -1.7418363 ,\n",
            "         2.4499536 , -0.02933158, -4.2155404 ,  1.1876882 , -3.1312983 ,\n",
            "         0.51671314, -2.140428  ,  6.7316794 ,  2.083091  , -3.5152926 ,\n",
            "         1.5046109 , -3.356601  , -5.76795   ,  0.1853833 , -2.9889748 ,\n",
            "        -1.6897267 , -1.9964685 ,  3.721051  ,  0.12501313, -2.6652982 ,\n",
            "        -6.484671  ]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.40586018e-03,  1.11232999e-04,  8.92406523e-01,\n",
            "        -5.23809111e-03,  9.71270204e-01, -2.12447281e-04,\n",
            "        -5.80225170e-01, -9.17472783e-03, -9.73102450e-01,\n",
            "         9.77363527e-01,  5.85802607e-02,  8.82326034e-08,\n",
            "         2.30140768e-06, -6.50353904e-04, -4.49132962e-08,\n",
            "        -1.73109561e-01, -2.89186928e-03, -1.60965949e-01,\n",
            "        -5.36425784e-02,  4.89953190e-01, -3.09724230e-02,\n",
            "        -1.51021895e-03, -9.14895773e-01, -1.34022243e-03,\n",
            "        -8.11679456e-06,  9.02258471e-05, -2.26436228e-01,\n",
            "         2.91012317e-01,  2.28270583e-05, -9.39590454e-01,\n",
            "        -7.21447170e-01,  2.69885570e-01,  9.93231952e-01,\n",
            "        -9.55013908e-04, -3.09464723e-01, -3.72694376e-05,\n",
            "        -3.91543321e-02, -6.97123399e-03,  9.37571675e-02,\n",
            "         9.78980780e-01,  2.36367941e-01,  9.72034037e-01,\n",
            "        -4.89847298e-06, -1.62477031e-01, -1.70092016e-01,\n",
            "         8.64086390e-01,  1.08921602e-04,  4.18756088e-07,\n",
            "         5.69617376e-04,  1.91237035e-04,  5.46160009e-05,\n",
            "         9.84667540e-01,  5.84109439e-05, -9.98971403e-01,\n",
            "         5.92204809e-01,  9.99896169e-01, -1.05113664e-03,\n",
            "        -2.44173389e-02,  7.60997772e-01,  8.47438633e-01,\n",
            "        -6.27775431e-01,  9.94064093e-01, -4.68658436e-05,\n",
            "         1.39126988e-09,  3.49435431e-05,  3.08747202e-01,\n",
            "        -9.73819077e-01,  1.48894019e-09,  3.33229965e-03,\n",
            "        -1.52058110e-01,  3.06722359e-03,  8.05022195e-02,\n",
            "        -7.03525126e-01,  8.84350002e-01, -1.73031038e-03,\n",
            "        -2.72414256e-02,  4.72680910e-07,  9.47374284e-01,\n",
            "        -8.34610603e-07, -5.85640967e-01, -5.76912723e-02,\n",
            "        -9.99459445e-01,  1.05636446e-02,  8.56903625e-06,\n",
            "        -9.99221742e-01,  3.97491931e-07, -7.18642317e-04,\n",
            "         6.25003449e-05,  9.92000580e-01,  5.56516588e-01,\n",
            "         3.32289599e-02, -7.85922538e-03, -9.97846901e-01,\n",
            "        -5.64358354e-01, -3.58763039e-01, -3.52573959e-04,\n",
            "         2.33639171e-03, -5.11378457e-04, -1.71581547e-07,\n",
            "         1.60887994e-05,  6.47122622e-01, -3.24542254e-01,\n",
            "         9.76997197e-01,  2.45642409e-01, -9.89686787e-01,\n",
            "         1.58407238e-05,  1.88910794e-02,  9.80555475e-01,\n",
            "         3.77764780e-04,  6.31694198e-02,  2.86823430e-04,\n",
            "         5.53704381e-01,  1.91353653e-02, -9.69777524e-01,\n",
            "         7.86397278e-01,  8.10580790e-01, -5.90936959e-01,\n",
            "        -8.94326627e-01,  1.91595946e-02, -9.60694909e-01,\n",
            "        -1.03794900e-03, -9.48223487e-07,  4.32283059e-07,\n",
            "        -8.86285082e-02,  4.12631576e-04,  1.70221910e-01,\n",
            "         2.37378117e-04, -3.68081237e-04,  1.70923397e-02,\n",
            "         9.42127954e-04, -6.53257288e-08,  4.28730156e-03,\n",
            "        -5.38412933e-05,  9.17475164e-01,  1.09430784e-02,\n",
            "         5.06095402e-03, -4.25691485e-01, -4.93768027e-07,\n",
            "         6.93351388e-01,  1.47447497e-01,  1.42340865e-02,\n",
            "         7.76889175e-03,  1.36780727e-04, -1.50546995e-07,\n",
            "         8.09556663e-01, -2.72406578e-06, -7.49357641e-01,\n",
            "        -9.39662457e-01,  1.39355578e-03,  8.53812397e-01,\n",
            "         3.14020908e-05,  9.51941967e-01, -8.05941939e-01,\n",
            "        -6.90417826e-01, -1.24389343e-02, -4.06203782e-07,\n",
            "         4.17089385e-09,  7.67812967e-01, -1.47627215e-04,\n",
            "        -4.55597615e-07,  2.68067747e-01,  1.40157805e-04,\n",
            "         9.97848868e-01,  7.63021526e-04,  6.53317213e-01,\n",
            "         4.56441790e-02,  1.71440537e-03, -3.15653592e-01,\n",
            "        -1.53375557e-03, -1.45055019e-04, -7.87574649e-01,\n",
            "        -1.42516002e-01,  2.55804718e-01,  5.77633083e-03,\n",
            "         6.32316470e-01,  6.46892877e-04, -7.06988811e-01,\n",
            "         9.83448446e-01, -2.69004996e-08,  1.08083310e-02,\n",
            "         4.29526210e-01,  8.14711899e-02, -4.93785228e-05,\n",
            "        -1.70350351e-04, -2.38241599e-04,  8.29914391e-01,\n",
            "        -1.78803845e-07, -8.46655368e-08, -6.61866903e-01,\n",
            "        -1.19706965e-04, -9.66095805e-01,  3.06111087e-06,\n",
            "         7.58108974e-01, -7.92693794e-01,  9.80517209e-01,\n",
            "        -3.36290956e-01,  9.43645298e-01,  7.77282059e-01,\n",
            "        -3.02870688e-03, -9.70427296e-04,  9.20254827e-01,\n",
            "        -1.52869379e-05,  3.47099736e-08,  9.99965847e-01,\n",
            "        -1.01488958e-07, -7.48432457e-01,  6.34653986e-01,\n",
            "        -6.40705168e-01,  7.67363235e-06, -1.37908535e-06,\n",
            "         5.22843674e-02, -3.51012364e-04,  9.98647928e-01,\n",
            "         2.00135051e-03, -8.91393498e-02,  8.65390539e-05,\n",
            "         1.09192692e-02,  2.10867390e-01, -5.80967680e-05,\n",
            "        -9.51311886e-01,  5.38643981e-05,  2.35932018e-03,\n",
            "         1.24851340e-05,  5.21980212e-07,  9.35184479e-01,\n",
            "        -3.16131423e-04, -7.82173216e-01,  1.41402215e-01,\n",
            "         2.40417230e-05, -9.93662298e-01, -8.09345674e-03,\n",
            "         9.99744534e-01,  2.44373530e-01,  2.13404535e-03,\n",
            "        -9.88351285e-01,  4.84725207e-01, -7.59348750e-01,\n",
            "        -6.37651756e-05,  2.47989789e-01, -9.98817027e-01,\n",
            "        -2.55083607e-04, -7.80850351e-01,  1.93050168e-02,\n",
            "         1.84627238e-03, -8.87181938e-01,  8.91185403e-01,\n",
            "        -4.08553007e-07, -9.99997318e-01,  8.16712379e-01,\n",
            "        -4.39380102e-07, -2.64856480e-05, -7.96341419e-01,\n",
            "         1.55434418e-06,  1.37124769e-03, -9.97196257e-01,\n",
            "        -9.99876797e-01]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 6.90457344e+00,  4.88001633e+00,  1.43362224e+00,\n",
            "        -2.53229094e+00,  2.11640978e+00, -2.77796698e+00,\n",
            "        -3.23234057e+00, -7.75166512e+00, -2.15042114e+00,\n",
            "         6.57853556e+00,  2.46997213e+00,  5.79318762e+00,\n",
            "         3.69261265e+00, -1.09796083e+00, -7.72320414e+00,\n",
            "        -5.25062180e+00, -5.29058981e+00, -5.71822643e-01,\n",
            "        -3.34562802e+00,  5.36016047e-01, -7.08031058e-01,\n",
            "        -4.79302263e+00, -1.55678034e+00, -6.04618883e+00,\n",
            "        -5.75589705e+00,  9.02279862e-05, -2.30429873e-01,\n",
            "         7.96931648e+00,  5.46425724e+00, -2.94013882e+00,\n",
            "        -9.38697457e-01,  4.90231466e+00,  2.84274650e+00,\n",
            "        -4.91259575e+00, -1.07348144e+00, -5.13440895e+00,\n",
            "        -4.80505419e+00, -5.40348339e+00,  6.15437078e+00,\n",
            "         2.27267194e+00,  2.50543296e-01,  2.16098094e+00,\n",
            "        -1.94139969e+00, -6.92653036e+00, -6.15331507e+00,\n",
            "         1.31068909e+00,  3.97529268e+00,  2.33455706e+00,\n",
            "         3.23576474e+00,  5.73295403e+00,  1.80318284e+00,\n",
            "         2.43178439e+00,  4.17722702e+00, -3.88180256e+00,\n",
            "         2.17827964e+00,  7.33843040e+00, -8.46252143e-01,\n",
            "        -7.99569464e+00,  9.98656154e-01,  5.26105785e+00,\n",
            "        -7.40451515e-01,  2.91496205e+00, -3.84019637e+00,\n",
            "         5.58546209e+00,  5.20370579e+00,  5.05574274e+00,\n",
            "        -2.16192555e+00,  3.44230914e+00,  3.86070466e+00,\n",
            "        -8.07811975e-01,  2.01797080e+00,  4.34691954e+00,\n",
            "        -1.45998240e+00,  1.75530696e+00, -8.42426300e-01,\n",
            "        -3.41495611e-02,  1.69492722e+00,  2.39003420e+00,\n",
            "        -3.82516742e+00, -6.00057030e+00, -6.27026796e-01,\n",
            "        -4.11223841e+00,  3.79269600e+00,  1.30073535e+00,\n",
            "        -4.04312897e+00,  6.91203642e+00, -1.27708940e-02,\n",
            "         3.77863932e+00,  2.77568269e+00,  6.28288150e-01,\n",
            "         1.37440574e+00, -1.57498047e-02, -3.41706419e+00,\n",
            "        -3.47501087e+00, -4.82035017e+00, -6.46943617e+00,\n",
            "         2.12399483e+00, -4.33539104e+00, -1.82727361e+00,\n",
            "         4.21700144e+00,  9.54365969e-01, -3.36722255e-01,\n",
            "         2.22709298e+00,  4.60516125e-01, -2.63191271e+00,\n",
            "         3.25992823e+00,  5.06802082e+00,  2.72796702e+00,\n",
            "         3.95833063e+00,  1.51798666e+00,  2.09647036e+00,\n",
            "         8.28189015e-01,  1.54577506e+00, -2.28107214e+00,\n",
            "         1.90583014e+00,  4.26709890e+00, -6.79104567e-01,\n",
            "        -3.90475178e+00,  5.65731812e+00, -2.02700520e+00,\n",
            "        -6.39844227e+00, -1.63895822e+00,  3.32717299e+00,\n",
            "        -2.73174429e+00,  3.43252707e+00,  6.60063219e+00,\n",
            "         6.05542755e+00, -1.42682457e+00,  6.26836491e+00,\n",
            "         1.88130367e+00, -4.03721952e+00,  3.93612909e+00,\n",
            "        -1.50178742e+00,  1.58370447e+00,  5.38825607e+00,\n",
            "         3.28343630e+00, -2.12907100e+00, -4.45176172e+00,\n",
            "         8.54594648e-01,  1.78723383e+00,  2.94012070e+00,\n",
            "         2.79046965e+00,  4.55191946e+00, -3.30461526e+00,\n",
            "         2.03823829e+00, -4.74802971e+00, -9.98412669e-01,\n",
            "        -3.61737967e+00,  1.58275068e+00,  1.27273321e+00,\n",
            "         3.90196633e+00,  1.88714194e+00, -1.11544371e+00,\n",
            "        -2.93198037e+00, -1.24414340e-02, -7.18578863e+00,\n",
            "         5.64029312e+00,  1.03175318e+00, -5.59668159e+00,\n",
            "        -4.84075975e+00,  2.27777791e+00,  5.62836742e+00,\n",
            "         3.45929718e+00,  2.79636765e+00,  2.31910586e+00,\n",
            "         4.56777811e-02,  4.90874672e+00, -4.58791733e+00,\n",
            "        -5.44198632e-01, -7.68461525e-01, -2.08470154e+00,\n",
            "        -1.64180249e-01,  1.33514118e+00,  7.91252232e+00,\n",
            "         1.84283793e+00,  9.19729888e-01, -8.97289991e-01,\n",
            "         6.44259214e+00, -3.95304799e+00,  3.26503825e+00,\n",
            "         9.60026920e-01,  8.21495801e-02, -6.61986113e+00,\n",
            "        -4.77254200e+00, -5.03678322e+00,  3.23675323e+00,\n",
            "        -9.53615665e-01, -3.70137721e-01, -5.15621138e+00,\n",
            "        -1.19765384e-04, -3.17257619e+00,  5.48418951e+00,\n",
            "         2.64411020e+00, -1.07865262e+00,  2.48153758e+00,\n",
            "        -3.49912435e-01,  2.85611153e+00,  1.29519141e+00,\n",
            "        -5.30440998e+00, -3.86872625e+00,  1.59322333e+00,\n",
            "        -3.91481495e+00,  2.56532621e+00,  5.48926401e+00,\n",
            "        -6.80045176e+00, -9.69470263e-01,  7.66109109e-01,\n",
            "        -6.97289419e+00,  4.68864250e+00, -4.01486540e+00,\n",
            "         5.00885487e+00, -6.61381841e-01,  3.64929414e+00,\n",
            "         3.16095066e+00, -2.31790042e+00,  6.42444277e+00,\n",
            "         1.46438032e-02,  2.14349926e-01, -4.01129341e+00,\n",
            "        -1.84805346e+00,  3.20548463e+00,  3.87957644e+00,\n",
            "         3.93596125e+00,  2.91330171e+00,  5.80556536e+00,\n",
            "        -4.18413371e-01, -1.16226113e+00,  1.42356291e-01,\n",
            "         2.02143788e+00, -3.31142879e+00, -3.08492303e+00,\n",
            "         7.69988775e+00,  1.00041366e+00,  3.91261911e+00,\n",
            "        -2.57431126e+00,  3.33316612e+00, -9.94676292e-01,\n",
            "        -5.14528990e+00,  1.26090598e+00, -4.11258936e+00,\n",
            "        -1.96825285e-02, -3.13958287e+00,  7.69623375e+00,\n",
            "         2.37874079e+00, -3.43976498e+00,  1.49717391e+00,\n",
            "        -4.28509903e+00, -6.75632906e+00,  1.14870286e+00,\n",
            "        -3.91982627e+00, -5.56501746e-01, -2.54815149e+00,\n",
            "         4.67196417e+00,  1.25080258e-01, -3.66296601e+00,\n",
            "        -7.48434162e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.54289106e-04,  1.28509079e-08,  4.71328497e-01,\n",
            "        -4.02674090e-07,  9.65432346e-01, -1.53206577e-06,\n",
            "        -7.91515887e-01, -8.97561313e-06, -9.84599710e-01,\n",
            "         7.00748563e-01,  2.53916353e-01,  6.10647090e-02,\n",
            "         5.77878891e-05, -1.79761901e-01, -7.70681510e-08,\n",
            "        -7.62244053e-06, -1.21206876e-08,  3.73977572e-01,\n",
            "        -5.21632182e-06,  4.80204970e-01, -4.34671674e-05,\n",
            "        -4.11779946e-03, -9.44129467e-01, -5.74290170e-04,\n",
            "        -8.63137075e-07,  5.15289903e-02,  2.04785109e-01,\n",
            "         4.48454131e-07,  8.36526578e-06, -3.90416644e-05,\n",
            "         3.31000611e-02,  1.95660278e-01,  2.92580307e-01,\n",
            "        -9.49133158e-01, -2.32972030e-04, -2.42158454e-02,\n",
            "        -9.78638185e-04, -6.28821831e-03,  1.00646132e-04,\n",
            "         2.19937847e-05,  1.99472189e-01,  9.95989144e-01,\n",
            "        -4.44169928e-05, -6.78353369e-01, -9.34327662e-01,\n",
            "         9.80500579e-01,  2.34570848e-07,  3.24093094e-06,\n",
            "         5.78119695e-01,  1.54404163e-01,  6.43349704e-05,\n",
            "         9.76896107e-01,  1.38975929e-05, -9.98205602e-01,\n",
            "         2.68756121e-05,  9.99903798e-01, -5.76501936e-02,\n",
            "        -4.86884412e-04,  9.59845841e-01,  3.06018054e-01,\n",
            "        -9.39764321e-01,  9.90586758e-01, -3.68061956e-05,\n",
            "         5.76557966e-07,  9.43599820e-01,  8.81235749e-02,\n",
            "        -9.46217775e-01,  1.56230417e-05,  1.97381169e-07,\n",
            "        -9.41460609e-01,  2.04274477e-03,  1.93997007e-02,\n",
            "        -5.42225409e-03,  3.46475929e-01, -9.20523405e-01,\n",
            "        -4.00055759e-02,  1.22398939e-02,  9.04450715e-01,\n",
            "        -1.91552385e-06, -2.51127403e-05, -1.06871955e-01,\n",
            "        -1.67977507e-03,  7.38269277e-03,  1.80388506e-05,\n",
            "        -9.77603998e-03,  1.69877179e-08, -1.91194601e-02,\n",
            "         5.89859746e-06,  9.46379781e-01,  5.91910541e-01,\n",
            "         8.99364520e-03, -1.09823782e-03, -9.82445061e-01,\n",
            "        -4.44070071e-01, -1.60703639e-05, -1.00428624e-05,\n",
            "         9.96078789e-01, -4.13073242e-01, -8.79237128e-10,\n",
            "         1.89259694e-07, -4.12370563e-02, -4.13487464e-01,\n",
            "         9.92068648e-01,  4.74302471e-01, -5.16043619e-05,\n",
            "         1.24081247e-03,  3.81180458e-02,  9.89941359e-01,\n",
            "         6.09663188e-01,  9.82385874e-01,  6.93263893e-04,\n",
            "         1.67337298e-01,  1.41726370e-04, -2.72954702e-02,\n",
            "         1.65577471e-01,  5.55060685e-01, -8.49945664e-01,\n",
            "        -3.86687607e-01,  4.03542828e-04, -9.16840672e-01,\n",
            "        -8.75792524e-04, -3.36062999e-06,  2.16904013e-07,\n",
            "        -1.69417500e-01,  2.07984215e-03,  6.68786768e-08,\n",
            "         7.07951315e-08, -3.45066994e-01,  8.02640319e-01,\n",
            "         7.15674004e-12, -4.34325420e-06,  9.99607980e-01,\n",
            "         2.74561532e-02,  1.38618285e-04,  9.35149491e-01,\n",
            "         4.94342157e-06, -1.19619588e-04, -5.35775229e-08,\n",
            "         7.32301235e-01,  1.42086719e-05,  2.19094116e-04,\n",
            "         3.73272114e-02,  8.14860687e-06, -5.57221558e-09,\n",
            "         9.89235640e-01, -6.54053926e-01, -7.58601308e-01,\n",
            "        -7.34434277e-02,  9.75687988e-03,  8.50865960e-01,\n",
            "         7.97736347e-02,  8.55749130e-01, -1.42532259e-01,\n",
            "        -3.85003630e-03, -3.80530255e-03, -3.54141005e-09,\n",
            "         3.43283818e-06,  8.12734723e-01, -4.14009662e-08,\n",
            "        -8.80553230e-09,  6.06734455e-01,  4.06657364e-07,\n",
            "         9.98020113e-01,  7.58664974e-04,  1.58010498e-05,\n",
            "         7.97044933e-02,  9.33151972e-03, -1.11500949e-01,\n",
            "        -1.36902645e-01, -1.16913736e-01, -9.54682410e-01,\n",
            "         4.49254274e-01,  4.21740951e-05,  2.03879245e-06,\n",
            "         1.04442071e-02,  7.25139141e-01, -2.32882857e-01,\n",
            "         8.42452765e-01, -9.39792102e-08,  2.10683589e-04,\n",
            "         4.46472768e-06,  7.59201884e-01, -4.28381645e-05,\n",
            "        -9.63805616e-01, -4.70664730e-07,  7.49840168e-03,\n",
            "        -5.36572916e-05, -1.78814696e-06, -7.82898307e-01,\n",
            "        -2.24074144e-02, -9.99278128e-01,  7.80663252e-01,\n",
            "         9.93860781e-01, -8.46732914e-01,  8.95081282e-01,\n",
            "         5.62390208e-01,  6.85043633e-01,  2.45102390e-04,\n",
            "        -2.57518491e-06, -4.28690970e-01,  5.77977538e-01,\n",
            "        -2.25677639e-02,  1.02613424e-03,  9.99959826e-01,\n",
            "        -3.08638810e-05, -9.43600774e-01, -2.24188879e-01,\n",
            "        -1.76651731e-01,  1.00948491e-04, -4.28922400e-02,\n",
            "         8.69104918e-03, -8.94557070e-06,  5.98052621e-01,\n",
            "         7.14448222e-04, -2.00503543e-01,  9.24845114e-02,\n",
            "         9.99871548e-03,  4.30045277e-02, -1.07117005e-01,\n",
            "        -1.86594263e-01,  2.29778962e-05,  2.94370018e-03,\n",
            "         1.93301073e-08,  1.03567935e-07,  1.73325952e-06,\n",
            "        -1.67738006e-01, -1.65280327e-01,  1.54479995e-01,\n",
            "         7.63053522e-02, -4.78873134e-01, -1.20991805e-04,\n",
            "         2.56818365e-02,  6.07605755e-01,  1.91450525e-07,\n",
            "        -9.80801642e-01,  5.12035191e-01, -3.70743349e-02,\n",
            "        -3.88464131e-12,  7.96546042e-03, -1.35931773e-02,\n",
            "        -6.71362795e-05, -3.51657718e-02,  2.02384584e-07,\n",
            "         2.69188080e-03, -9.88563955e-01,  2.43084550e-01,\n",
            "        -5.97407779e-06, -9.99993443e-01,  6.06173098e-01,\n",
            "        -5.03579900e-03, -3.61469165e-06, -8.74914110e-01,\n",
            "         1.28695874e-05, -8.60424188e-04, -5.61018893e-03,\n",
            "        -7.26688450e-06]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 7.8603745e+00,  5.8740129e+00,  5.1177692e-01, -3.4961674e+00,\n",
            "         2.1166537e+00, -3.6954014e+00, -3.2422676e+00, -8.7334127e+00,\n",
            "        -2.4300921e+00,  6.8419166e+00,  2.5072975e+00,  6.7919035e+00,\n",
            "         4.6826358e+00, -2.0972922e+00, -8.6729784e+00, -6.2217607e+00,\n",
            "        -6.2793956e+00,  3.9324889e-01, -4.1294403e+00,  5.4177487e-01,\n",
            "        -1.5789368e+00, -4.0547910e+00, -1.7747660e+00, -7.0261478e+00,\n",
            "        -6.7535605e+00,  5.1836550e-02,  2.0772216e-01,  8.6891193e+00,\n",
            "         6.4607630e+00, -3.9396164e+00,  3.3112220e-02,  5.8933444e+00,\n",
            "         3.8424518e+00, -5.9080505e+00, -6.5554595e-01, -5.1342611e+00,\n",
            "        -5.7984986e+00, -5.4171991e+00,  7.1540399e+00,  2.1619942e+00,\n",
            "         2.0281531e-01,  3.1444280e+00, -2.3451803e+00, -7.9152484e+00,\n",
            "        -7.1458707e+00,  2.3103762e+00,  4.9469218e+00,  3.3207462e+00,\n",
            "         4.2352600e+00,  6.6832776e+00,  2.7962551e+00,  2.2246675e+00,\n",
            "         5.1549978e+00, -3.6291046e+00,  3.1132126e+00,  8.3298044e+00,\n",
            "        -5.8026511e-02, -8.9808912e+00,  1.9622951e+00,  6.2603278e+00,\n",
            "        -1.7386878e+00,  2.6772795e+00, -4.8388329e+00,  6.5854421e+00,\n",
            "         5.2553396e+00,  6.0517607e+00, -1.7944070e+00,  4.4422936e+00,\n",
            "         4.8551202e+00, -1.8076979e+00,  3.0179567e+00,  5.3361878e+00,\n",
            "        -2.4188836e+00,  3.6187297e-01, -1.5944858e+00, -4.0074512e-02,\n",
            "         2.6752572e+00,  1.5248895e+00, -3.9450517e+00, -7.0000138e+00,\n",
            "        -6.4155775e-01, -5.1121235e+00,  4.7926507e+00,  1.5636928e+00,\n",
            "        -5.0431137e+00,  7.9115086e+00, -2.5535992e-01,  4.7581263e+00,\n",
            "         1.7959063e+00,  6.8070823e-01,  2.3735433e+00, -1.2951300e-01,\n",
            "        -4.4146471e+00, -4.4557805e+00, -5.8160219e+00, -7.4681001e+00,\n",
            "         3.1215403e+00, -5.3352022e+00, -2.7615802e+00,  5.2043924e+00,\n",
            "        -4.1260824e-02, -4.3981081e-01,  2.7630532e+00,  5.1565677e-01,\n",
            "        -3.6315136e+00,  3.2624040e+00,  6.0544734e+00,  3.2339149e+00,\n",
            "         4.6243191e+00,  2.5163326e+00,  3.0964646e+00,  1.7247935e-01,\n",
            "         2.5201809e+00, -3.2798660e+00,  2.6909783e+00,  4.8581309e+00,\n",
            "        -1.2559576e+00, -4.8892589e+00,  6.5737581e+00, -2.4809666e+00,\n",
            "        -7.3704371e+00, -2.5973618e+00,  4.2585139e+00, -2.7316999e+00,\n",
            "         4.4324999e+00,  7.5816474e+00,  6.9491014e+00, -1.5003077e+00,\n",
            "         7.2305813e+00,  2.7644649e+00, -5.0368690e+00,  4.8411665e+00,\n",
            "         4.9342617e-02,  1.7834513e+00,  3.5014362e+00,  3.8760099e+00,\n",
            "        -3.1247754e+00, -5.4514084e+00,  9.3371248e-01,  1.9777181e+00,\n",
            "         3.9049385e+00,  3.0814588e+00,  5.4249730e+00, -4.3045382e+00,\n",
            "         3.0370295e+00, -5.7371445e+00, -1.0498883e+00, -4.5019741e+00,\n",
            "         1.2723352e+00,  1.2592824e+00,  4.9019318e+00,  1.9026499e+00,\n",
            "        -1.4355594e-01, -2.9208853e+00, -1.9269299e-02, -8.1822882e+00,\n",
            "         6.6351662e+00,  1.3769901e+00, -6.5847988e+00, -5.7781348e+00,\n",
            "         1.2787354e+00,  6.6227884e+00,  3.4591868e+00,  2.7986872e+00,\n",
            "         2.6742117e+00,  7.9875238e-02,  5.9080229e+00, -4.7390189e+00,\n",
            "        -9.9077272e-01, -1.5621890e+00, -2.8942297e+00,  4.8378542e-01,\n",
            "         1.7445686e+00,  8.8860731e+00,  2.8240802e+00,  9.1949099e-01,\n",
            "        -1.8969769e+00,  7.4425159e+00, -4.9478402e+00,  4.2583938e+00,\n",
            "         1.9196278e+00,  1.0462338e+00, -7.6106997e+00, -5.7722545e+00,\n",
            "        -6.0346055e+00,  4.2336259e+00, -9.5446390e-01, -1.3689873e+00,\n",
            "        -5.7531562e+00, -2.8090127e-02, -3.9632089e+00,  6.4428501e+00,\n",
            "         3.6252236e+00, -1.2444972e+00,  1.4824963e+00,  6.3632238e-01,\n",
            "         3.8550065e+00,  2.2821515e+00, -2.7207456e+00, -4.8682790e+00,\n",
            "         6.5943974e-01, -4.9147911e+00,  3.5630155e+00,  6.2698798e+00,\n",
            "        -7.7975941e+00, -1.7699251e+00, -2.2822784e-01, -7.8955741e+00,\n",
            "         4.7565594e+00, -4.0152712e+00,  5.5786567e+00, -1.6400646e+00,\n",
            "         4.6445975e+00,  4.1523724e+00, -2.3178997e+00,  7.4244251e+00,\n",
            "         1.0601721e-02,  1.2058936e+00, -5.0111036e+00, -2.0290232e-01,\n",
            "         4.2019372e+00,  3.9231591e+00,  3.9400334e+00,  3.9129508e+00,\n",
            "         6.8032255e+00, -4.1734597e-01, -1.6798061e-01,  1.5572689e-01,\n",
            "         3.0209951e+00, -4.3095145e+00, -3.8411083e+00,  8.6984758e+00,\n",
            "         1.8445756e+00,  4.8986530e+00, -2.9173255e+00,  4.3329239e+00,\n",
            "        -3.9747734e-02, -6.1294904e+00,  1.6701736e+00, -5.0982056e+00,\n",
            "        -1.8921547e-02, -4.0521469e+00,  8.5959415e+00,  3.3575170e+00,\n",
            "        -2.5822034e+00,  1.4976836e+00, -5.2727389e+00, -7.7554855e+00,\n",
            "         9.9200696e-01, -4.9101791e+00, -4.0424019e-03, -3.4433274e+00,\n",
            "         5.6544404e+00, -3.1303263e-01, -4.6578584e+00, -8.4823322e+00]],\n",
            "      dtype=float32)>)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.59280455e-06,  9.95713055e-01,  3.08009207e-01,\n",
            "        -4.74021167e-01,  7.14159664e-03, -1.33600715e-03,\n",
            "        -7.92317837e-03, -9.35929438e-06,  4.97228978e-03,\n",
            "         4.26999740e-02,  8.10937166e-01,  9.84106004e-01,\n",
            "         6.96241707e-02,  9.24979389e-01, -4.80739534e-01,\n",
            "        -9.29995000e-01, -1.01440505e-03, -9.99059081e-01,\n",
            "        -3.78410627e-12, -5.65123677e-01, -4.53329936e-04,\n",
            "        -4.60309088e-01,  9.93439555e-01, -1.26504483e-06,\n",
            "        -7.25476980e-01, -9.68585789e-01, -9.99344110e-01,\n",
            "         3.82259350e-06,  4.97292906e-01, -6.86760902e-01,\n",
            "        -3.25594709e-04,  1.70253061e-05,  2.97122425e-03,\n",
            "        -9.37263489e-01, -1.29716292e-01, -1.46552702e-04,\n",
            "        -9.84307706e-01, -2.79617645e-02,  1.50444723e-08,\n",
            "         8.57810769e-03,  6.17494464e-01,  2.81028617e-02,\n",
            "        -6.85678959e-01, -3.87870154e-04, -8.10782611e-02,\n",
            "        -8.70992467e-02,  2.78790385e-01,  6.13716207e-02,\n",
            "         1.44550115e-01,  9.84283626e-01,  3.27801555e-01,\n",
            "         9.80288267e-01,  3.27742950e-04, -8.41346942e-03,\n",
            "         9.78323579e-01,  7.49561252e-07,  8.56445551e-01,\n",
            "        -6.12278120e-04, -6.41366758e-04,  5.92870419e-09,\n",
            "        -4.97803032e-01,  8.48215818e-01, -5.37858009e-01,\n",
            "         9.94040489e-01,  2.09842008e-02,  1.09339732e-10,\n",
            "         5.70454717e-01,  4.76404375e-06,  2.80601799e-01,\n",
            "        -1.33023281e-02,  8.45331475e-02,  3.11523266e-02,\n",
            "         1.09288581e-01,  9.97247159e-01, -2.16254476e-03,\n",
            "        -1.50465071e-01,  3.18897665e-02,  1.13795280e-01,\n",
            "        -5.72663426e-01, -5.62256388e-02, -8.17260861e-01,\n",
            "        -7.59779036e-01,  9.20358598e-01,  2.32202280e-02,\n",
            "        -1.82057029e-05,  2.85892072e-03, -9.69726220e-02,\n",
            "         5.84790308e-04,  6.44151913e-03, -9.15918112e-01,\n",
            "         3.80980633e-02, -2.23040995e-11,  8.44852030e-01,\n",
            "        -3.52156639e-01, -8.66939154e-05, -9.22128856e-01,\n",
            "         3.96919698e-01, -3.40635875e-09, -2.11639293e-02,\n",
            "         5.73214889e-02,  9.79861856e-01,  7.00240433e-01,\n",
            "        -5.87289035e-01, -5.77062543e-04, -7.94336117e-08,\n",
            "         2.74714231e-02,  7.40176201e-01,  2.03823065e-03,\n",
            "         2.84523726e-01, -1.57782465e-01,  1.64990351e-01,\n",
            "         7.61783659e-01,  6.56857592e-05,  7.73476064e-02,\n",
            "         1.76932275e-01,  4.12278622e-02,  1.18323632e-01,\n",
            "        -7.05736399e-01,  9.88892436e-01, -7.84673631e-01,\n",
            "        -4.05995661e-06, -9.18686867e-01,  2.19504628e-02,\n",
            "        -3.35936667e-03,  1.05658174e-01,  5.29827503e-03,\n",
            "         1.96850393e-02, -4.06442881e-02,  3.13765137e-04,\n",
            "         8.00831437e-01, -1.51438797e-02, -5.28153718e-01,\n",
            "        -6.99885488e-02,  5.05415380e-01,  1.15203848e-02,\n",
            "         1.44569814e-01, -3.28678101e-01, -8.02310742e-03,\n",
            "        -9.08173442e-01,  1.27447009e-01,  3.02724689e-02,\n",
            "         3.78460079e-01,  6.93324059e-02, -1.63030982e-01,\n",
            "        -7.54883303e-08, -3.97884846e-01, -7.67711625e-02,\n",
            "         5.33368051e-01,  5.80024421e-01,  9.09307718e-01,\n",
            "         9.54205751e-01,  1.17351249e-01, -1.16156205e-03,\n",
            "        -3.54135782e-03, -5.92559850e-08, -7.79374301e-01,\n",
            "         1.25550187e-05, -3.00168216e-01, -3.75914723e-01,\n",
            "        -6.01552308e-01,  9.16834772e-01,  6.85381532e-01,\n",
            "         5.15502274e-01,  3.42656970e-01,  5.84305346e-01,\n",
            "        -2.89621566e-05,  3.06302006e-03,  8.48095953e-01,\n",
            "         7.37946928e-01, -7.20827058e-02, -3.13500990e-04,\n",
            "        -7.63392746e-01,  1.15215793e-01,  1.24276225e-02,\n",
            "        -1.00273341e-01,  4.11234826e-01, -2.48778164e-01,\n",
            "         1.24172453e-04, -1.06308679e-03,  7.82921553e-01,\n",
            "         7.27460206e-01,  1.00621866e-04, -8.97506833e-01,\n",
            "        -6.43162072e-01, -4.38771851e-04,  1.11783044e-02,\n",
            "        -5.44475317e-01, -9.11732786e-06, -2.01369967e-05,\n",
            "         1.14952102e-01, -6.29817087e-10,  4.14851643e-02,\n",
            "         9.22713801e-03,  2.26342261e-01,  4.46582958e-03,\n",
            "        -8.62833206e-03, -9.94759381e-01,  8.37088406e-01,\n",
            "        -7.16090312e-11, -3.04666581e-09,  9.76734795e-04,\n",
            "        -3.06083425e-03,  5.38974162e-03, -4.23890895e-10,\n",
            "        -8.84029199e-04,  3.70958537e-01,  1.92002654e-01,\n",
            "        -4.63208636e-08,  5.58595121e-01, -4.00185794e-01,\n",
            "         7.52981927e-04, -1.31033855e-02,  5.94472647e-01,\n",
            "         7.69140959e-01, -1.87665180e-04,  2.02675874e-04,\n",
            "         9.95997310e-01, -1.62106410e-01, -1.58412673e-03,\n",
            "         2.29799398e-03,  4.14889365e-01,  3.37910771e-01,\n",
            "         3.20836261e-04,  8.77782285e-01,  3.54493260e-02,\n",
            "        -5.85658967e-01, -7.03204496e-05,  1.90106039e-06,\n",
            "         3.43934178e-01,  1.10767642e-02, -4.41225566e-05,\n",
            "         5.60236595e-06, -2.87604570e-01,  4.89938825e-01,\n",
            "        -6.50912523e-01,  1.59285758e-02, -6.03635944e-02,\n",
            "        -6.59588575e-01,  9.21222806e-01,  9.71964836e-01,\n",
            "         3.62985022e-03, -9.34354402e-03,  8.40616643e-01,\n",
            "         9.56477582e-01, -1.94946193e-08, -2.51950143e-04,\n",
            "        -3.10198098e-01, -9.82236961e-05,  2.90127933e-01,\n",
            "        -8.78703222e-02, -2.61621270e-02,  3.00895482e-01,\n",
            "         1.10480130e-06,  4.41614568e-01, -8.40939432e-02,\n",
            "        -2.23334200e-06]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.3403244e+00,  4.2303786e+00,  3.6294892e+00, -1.0129026e+00,\n",
            "         9.8173058e-01, -8.7554067e-01, -4.0523138e+00, -4.6353517e+00,\n",
            "         1.7745419e+00,  2.9464791e+00,  1.1354913e+00,  3.8004954e+00,\n",
            "         6.9738023e-02,  1.6401228e+00, -4.5637379e+00, -1.6724600e+00,\n",
            "        -3.9102693e+00, -4.3987393e+00, -4.8349862e-05, -7.8568596e-01,\n",
            "        -4.8356376e+00, -2.4456239e+00,  2.8597941e+00, -3.5871835e+00,\n",
            "        -3.8272693e+00, -2.1337738e+00, -4.0111666e+00,  2.3168075e+00,\n",
            "         5.4576921e-01, -8.4225094e-01, -2.1185422e+00,  6.4908891e+00,\n",
            "         1.5212268e-01, -1.9998159e+00, -1.3045508e-01, -5.8865933e+00,\n",
            "        -2.4913781e+00, -3.1893616e+00,  4.2743454e+00,  4.4311590e+00,\n",
            "         1.1375768e+00,  2.7162008e+00, -8.5443276e-01, -4.1352525e+00,\n",
            "        -1.0921212e+00, -3.3765001e+00,  2.9005805e-01,  6.1450683e-02,\n",
            "         1.4558998e-01,  3.3038256e+00,  3.8372025e-01,  2.3061051e+00,\n",
            "         3.2774435e-04, -1.4936937e+00,  2.2588181e+00,  4.0389142e+00,\n",
            "         1.2798995e+00, -1.9966040e+00, -3.7906673e+00,  1.9403248e+00,\n",
            "        -5.4679000e-01,  3.6514597e+00, -8.3834994e-01,  3.0464065e+00,\n",
            "         4.9147654e+00,  4.4490547e+00,  6.4842850e-01,  4.8828711e-06,\n",
            "         2.8834799e-01, -2.1619026e-02,  8.6422756e-02,  3.3702562e+00,\n",
            "         2.2910382e-01,  3.2935157e+00, -3.7344936e-03, -1.5161623e-01,\n",
            "         3.1901527e-02,  4.8476114e+00, -6.5153718e-01, -1.9984004e+00,\n",
            "        -1.1493090e+00, -9.9581391e-01,  2.0676138e+00,  4.0041384e-01,\n",
            "        -1.8207002e-05,  1.7285317e+00, -9.7432442e-02,  9.4332490e-03,\n",
            "         1.1108363e+00, -1.5630805e+00,  3.9753668e-02, -2.9422686e-01,\n",
            "         2.1946278e+00, -3.6790645e-01, -3.3050361e+00, -2.8928699e+00,\n",
            "         4.1999039e-01, -4.5378287e-03, -2.7260549e+00,  1.8076102e+00,\n",
            "         3.7094598e+00,  8.6777872e-01, -6.7351878e-01, -2.3590910e+00,\n",
            "        -1.4042817e+00,  1.1528629e+00,  1.7234126e+00,  4.3235332e-01,\n",
            "         2.9259750e-01, -1.5986808e-01,  1.6775213e-01,  2.9102683e+00,\n",
            "         2.3826672e-02,  7.7814393e-02,  1.7910974e-01,  4.1266844e-02,\n",
            "         4.3551679e+00, -3.2964082e+00,  4.1682181e+00, -1.0575024e+00,\n",
            "        -3.6328692e+00, -1.5806007e+00,  5.2115560e-01, -3.7469685e+00,\n",
            "         1.6594019e+00,  2.4010990e+00,  3.9684720e+00, -3.0472107e+00,\n",
            "         3.4475000e+00,  2.0852187e+00, -1.5176063e-02, -1.8000650e+00,\n",
            "        -7.0106804e-02,  5.6182158e-01,  1.7282559e-02,  1.4560625e-01,\n",
            "        -3.4157565e-01, -2.0251213e-02, -5.8884869e+00,  1.3407162e-01,\n",
            "         3.0282723e-02,  4.0432203e-01,  9.8499045e-02, -1.6449894e-01,\n",
            "        -1.3787612e-01, -4.8199468e+00, -1.0484578e-01,  2.3722577e+00,\n",
            "         2.2815332e+00,  1.5392314e+00,  2.2065086e+00,  1.1789443e-01,\n",
            "        -3.6646559e+00, -1.3490577e+00, -1.6100619e-02, -3.8900907e+00,\n",
            "         9.3525356e-01, -3.1076103e-01, -3.9830947e-01, -7.1216434e-01,\n",
            "         2.8818412e+00,  3.6673546e+00,  5.7019693e-01,  3.5710001e-01,\n",
            "         7.3140723e-01, -2.0272665e+00,  3.0637872e-03,  1.2493767e+00,\n",
            "         1.3094957e+00, -1.0876888e+00, -4.8252831e+00, -1.5557703e+00,\n",
            "         1.1901671e-01,  4.2705212e+00, -1.0066646e-01,  7.0341957e-01,\n",
            "        -2.5412637e-01,  1.1004273e+00, -1.0631024e-03,  1.1041555e+00,\n",
            "         9.2333394e-01,  1.2751577e+00, -3.2073834e+00, -7.6355433e-01,\n",
            "        -4.3891970e-04,  1.1205104e-02, -6.1058116e-01, -2.0348303e+00,\n",
            "        -1.9085389e+00,  1.9444832e-01, -1.8126956e+00,  1.3181256e+00,\n",
            "         2.1906779e+00,  4.4552433e-01,  8.3977562e-01, -4.6447453e+00,\n",
            "        -3.9674947e+00,  1.7994090e+00, -1.1193410e+00, -4.0968832e-08,\n",
            "         4.7366781e+00, -3.2494913e-03,  5.3899786e-03, -1.2840152e-01,\n",
            "        -2.6386544e-01,  5.9733434e+00,  2.7477482e-01, -6.0063949e+00,\n",
            "         4.3638430e+00, -4.2398953e-01,  4.2670956e+00, -1.3104152e-02,\n",
            "         2.1836081e+00,  1.0293305e+00, -4.5505672e+00,  2.1941731e+00,\n",
            "         3.1060834e+00, -2.6881254e+00, -1.5848340e-03,  3.0256101e-01,\n",
            "         4.4150579e-01,  3.5309467e-01,  5.1262684e+00,  1.3660213e+00,\n",
            "         4.7763400e+00, -6.8882382e-01, -1.7230994e+00,  1.2103023e-01,\n",
            "         2.7944674e+00,  2.1639204e+00, -8.5516101e-01,  3.4456062e+00,\n",
            "        -2.9624999e-01,  5.5516005e-01, -1.5232296e+00,  4.4298592e-01,\n",
            "        -1.8557982e+00, -8.0348778e-01,  1.6077327e+00,  2.2964156e+00,\n",
            "         3.6298661e-03, -9.7566508e-03,  1.9702265e+00,  1.9028580e+00,\n",
            "        -3.2173007e+00, -1.3039668e-01, -6.6417402e-01, -4.3831525e+00,\n",
            "         3.7979219e+00, -8.8097572e-02, -2.6168099e-02,  4.1137204e+00,\n",
            "         2.1763480e+00,  4.7448283e-01, -8.4397212e-02, -3.8295205e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 7.09411800e-01,  5.05882800e-02,  9.87187028e-01,\n",
            "        -8.48553240e-01,  7.91592538e-01, -7.03861892e-01,\n",
            "        -9.98928845e-01, -5.68790827e-03,  3.09638262e-01,\n",
            "         3.57307762e-01,  8.12784910e-01,  5.60298358e-05,\n",
            "         6.44370317e-02, -7.63776666e-03, -9.69590098e-02,\n",
            "        -9.35616732e-01, -2.38678947e-01, -9.87865150e-01,\n",
            "        -1.51388034e-01, -6.52707398e-01, -9.99362290e-01,\n",
            "        -9.56361294e-01,  9.69122410e-01, -1.55753130e-02,\n",
            "        -1.14929710e-04, -9.63623643e-01, -9.33029830e-01,\n",
            "         3.30710754e-04,  8.96188974e-01, -5.61961113e-03,\n",
            "        -4.10903424e-01,  4.30222303e-01,  6.25486732e-01,\n",
            "        -6.40381277e-01, -4.66573751e-04, -8.77994359e-01,\n",
            "        -9.94638920e-01, -9.86991942e-01,  1.45139265e-05,\n",
            "         7.16317713e-01,  8.25539827e-01,  9.85252321e-01,\n",
            "        -6.06678903e-01, -9.80757060e-04, -4.20039659e-03,\n",
            "        -7.67445937e-02,  8.50543141e-01,  7.56569624e-01,\n",
            "         3.85002568e-02,  5.99330664e-01,  3.61738712e-01,\n",
            "         1.18396217e-02,  3.18638161e-02, -3.03669542e-01,\n",
            "         9.91823614e-01,  6.52911514e-02,  9.76175308e-01,\n",
            "        -8.54853332e-01, -9.99560177e-01,  2.24706411e-01,\n",
            "        -8.68377984e-01,  1.25701958e-02, -1.94239914e-01,\n",
            "         5.58851636e-04,  1.41865894e-04,  5.59455574e-01,\n",
            "        -2.64694780e-01,  2.17699376e-03,  7.93055117e-01,\n",
            "        -2.95226574e-02,  1.24397062e-01,  3.10135614e-02,\n",
            "        -5.99854589e-01,  3.24056298e-01, -2.22270340e-01,\n",
            "        -7.29836166e-01,  7.43451528e-04,  2.27506422e-02,\n",
            "        -9.19166684e-01, -4.11946714e-01, -8.32785368e-01,\n",
            "        -2.40730792e-02,  1.73996851e-01,  3.90538394e-01,\n",
            "        -7.99115282e-03,  1.87381934e-02, -2.24782707e-04,\n",
            "         1.78672024e-04, -2.15010159e-02,  7.06186175e-01,\n",
            "         6.65374333e-04, -2.87123710e-01,  9.68148410e-01,\n",
            "        -1.36518061e-01, -6.39158070e-01, -1.86892412e-05,\n",
            "         2.42366470e-04, -9.14085060e-02, -9.67008054e-01,\n",
            "         9.46520448e-01,  4.01451737e-01,  6.37308955e-01,\n",
            "        -1.53649470e-03, -8.63030136e-01, -8.65445752e-03,\n",
            "         7.33657360e-01,  6.26971041e-06,  8.51205111e-01,\n",
            "         5.36643922e-01,  7.75266066e-02,  1.63946956e-09,\n",
            "         9.56070900e-01,  1.25915632e-01, -5.45715213e-01,\n",
            "         5.93948424e-01,  4.34845686e-02,  7.18177034e-05,\n",
            "        -5.99163115e-01,  8.85252059e-01, -4.31532338e-02,\n",
            "        -2.13930950e-01, -8.84719610e-01,  8.97068024e-01,\n",
            "        -3.35123777e-01,  5.08147707e-07,  1.52926609e-01,\n",
            "         9.74989593e-01, -1.35914990e-04,  1.43829927e-01,\n",
            "         9.69237626e-01, -1.17868818e-04,  7.32025325e-01,\n",
            "        -7.43398666e-02,  8.92460227e-01,  4.09402519e-01,\n",
            "         1.54946789e-01, -9.89206746e-05, -1.59792890e-08,\n",
            "        -6.92106783e-01,  1.27614424e-01,  1.37673870e-01,\n",
            "         6.19650602e-01,  4.90197569e-01, -4.42323711e-04,\n",
            "        -1.28155977e-01, -6.10684147e-05, -1.69947416e-01,\n",
            "         1.90752849e-01,  4.86232191e-01,  9.10333753e-01,\n",
            "         9.46327507e-01,  1.93013772e-01, -1.25196710e-01,\n",
            "        -2.33861897e-03, -7.67544031e-01, -6.93529308e-01,\n",
            "         3.38210911e-02, -2.94332445e-01, -1.17645646e-02,\n",
            "        -3.71523440e-01,  9.50046718e-01,  9.46861037e-05,\n",
            "         5.71671486e-01,  8.24369967e-01,  6.43440068e-01,\n",
            "        -4.18502629e-01,  2.09115352e-03,  7.21265674e-01,\n",
            "         2.61929840e-01, -1.31322565e-02, -2.09718868e-01,\n",
            "        -9.13276136e-01,  1.26089947e-03,  1.21801022e-04,\n",
            "         1.17867209e-01,  4.16851975e-03, -3.84410501e-01,\n",
            "         5.91486543e-02, -4.60170321e-02,  5.35782516e-01,\n",
            "         1.42301172e-02,  7.37761855e-01, -9.92545128e-01,\n",
            "        -6.61171973e-01, -9.91621614e-02,  6.22849882e-01,\n",
            "        -5.45722306e-01, -6.53855562e-01, -1.65492238e-04,\n",
            "         7.80883491e-01, -1.06917469e-04,  8.30012467e-03,\n",
            "         9.81395304e-01,  4.17988151e-01, -1.35407180e-01,\n",
            "        -9.59873080e-01, -9.99208808e-01,  9.47041810e-01,\n",
            "        -1.60870593e-06, -9.75975394e-02,  1.85141880e-02,\n",
            "        -3.01613873e-05,  6.57162011e-01,  7.00810015e-01,\n",
            "        -1.47284180e-01,  9.99800980e-01,  6.42339289e-02,\n",
            "        -3.35273236e-01,  9.99795973e-01, -8.25458825e-01,\n",
            "         4.35933024e-02, -1.36976754e-02,  9.76512074e-01,\n",
            "         5.13138203e-03, -1.03110699e-02,  5.74997721e-05,\n",
            "         9.80721712e-01, -9.55564439e-01, -1.34283155e-01,\n",
            "         2.91346014e-01,  5.50006144e-03,  6.81547970e-02,\n",
            "         6.08931541e-01,  9.73589122e-05,  1.85156940e-03,\n",
            "        -1.94594893e-03, -3.53078961e-01,  1.39665082e-01,\n",
            "         6.69364035e-01,  8.68170202e-01, -8.24558898e-04,\n",
            "         1.42018571e-01, -2.66948730e-01,  7.35638201e-01,\n",
            "        -9.08890903e-01,  2.63960183e-01, -9.49561059e-01,\n",
            "        -1.09511702e-05,  2.27813765e-01,  9.79315996e-01,\n",
            "         1.63471773e-01, -2.61790127e-01,  6.71467697e-03,\n",
            "         5.21178901e-01, -9.79854941e-01,  1.63764704e-03,\n",
            "        -1.12498295e-04, -8.34472120e-01,  9.91975605e-01,\n",
            "        -2.22053450e-06, -2.55430042e-08,  9.96960104e-01,\n",
            "         1.17025978e-04,  4.41823334e-01, -7.16014981e-01,\n",
            "        -5.30650199e-04]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.2380347e+00,  5.1437669e+00,  3.3917522e+00, -1.3348521e+00,\n",
            "         1.4430206e+00, -8.7533146e-01, -4.1712227e+00, -5.6226721e+00,\n",
            "         1.7495418e+00,  3.9174817e+00,  1.1395363e+00,  4.7976036e+00,\n",
            "         1.0201801e+00, -8.5078847e-01, -5.5600162e+00, -2.6641119e+00,\n",
            "        -4.8821840e+00, -4.1379099e+00, -9.9846458e-01, -7.8007495e-01,\n",
            "        -4.8356314e+00, -3.4455044e+00,  2.0990565e+00, -4.5314770e+00,\n",
            "        -4.4309459e+00, -1.9943335e+00, -3.1197100e+00,  3.3154864e+00,\n",
            "         1.4656605e+00, -1.4166989e+00, -1.6407675e+00,  6.8160119e+00,\n",
            "         1.0931196e+00, -2.9965477e+00, -7.4777054e-03, -6.8440738e+00,\n",
            "        -3.4907269e+00, -4.1835542e+00,  5.2710633e+00,  4.4318910e+00,\n",
            "         1.1800383e+00,  2.7202168e+00, -1.2811142e+00, -5.1307750e+00,\n",
            "        -2.0381024e+00, -2.7810977e+00,  1.2899020e+00,  1.0589963e+00,\n",
            "         1.0597519e+00,  4.2526121e+00,  3.8370723e-01,  2.2010856e+00,\n",
            "         9.9741679e-01, -5.1772624e-01,  2.7497509e+00,  5.0321846e+00,\n",
            "         2.2736161e+00, -2.9407690e+00, -4.2357669e+00,  2.0692537e+00,\n",
            "        -1.3264931e+00,  3.6486166e+00, -1.8380197e+00,  4.0429492e+00,\n",
            "         5.7160091e+00,  4.9391704e+00, -2.7115983e-01,  3.5761416e-01,\n",
            "         1.2802541e+00, -2.9534305e-02,  1.2891535e-01,  3.6298292e+00,\n",
            "        -6.9292295e-01,  2.3062069e+00, -2.2665356e-01, -9.2840254e-01,\n",
            "         9.0920722e-01,  4.3710599e+00, -1.6245450e+00, -1.9981791e+00,\n",
            "        -1.1977694e+00, -1.9944129e+00,  2.7723529e+00,  4.1327700e-01,\n",
            "        -8.6442888e-01,  2.7185502e+00, -5.1047218e-01,  1.0079150e+00,\n",
            "        -2.1166979e-01,  8.7964398e-01,  1.0318669e+00, -2.9542908e-01,\n",
            "         2.0680320e+00, -1.0621523e+00, -3.9467287e+00, -3.8846638e+00,\n",
            "         1.4181865e+00, -1.0009116e+00, -3.7025936e+00,  1.8164260e+00,\n",
            "         3.6239598e+00,  8.6563635e-01, -1.1427816e-01, -3.2723975e+00,\n",
            "        -2.3703356e+00,  1.1532514e+00,  2.6920800e+00,  1.2779243e+00,\n",
            "         1.2925363e+00,  7.7691227e-02,  4.5807439e-01,  1.9170913e+00,\n",
            "         7.9561985e-01, -6.1226314e-01,  9.2853415e-01,  4.3516502e-02,\n",
            "         3.5959091e+00, -4.2740822e+00,  4.8270698e+00, -2.0456579e+00,\n",
            "        -4.1794081e+00, -1.5898764e+00,  1.4580113e+00, -4.2193670e+00,\n",
            "         1.6635411e+00,  3.3940792e+00,  4.8348641e+00, -3.1722052e+00,\n",
            "         4.0366826e+00,  2.0861154e+00, -1.0124911e+00,  9.3652606e-01,\n",
            "        -7.4582539e-02,  1.5235893e+00,  1.0155710e+00,  1.5661928e-01,\n",
            "        -3.2259732e-01, -1.0112661e+00, -6.7505326e+00,  1.3409339e-01,\n",
            "         1.3920404e-01,  1.0914507e+00,  1.0655240e+00, -1.6687506e-01,\n",
            "        -1.3250160e-01, -5.6498551e+00, -1.7199156e-01,  1.9332770e-01,\n",
            "         3.2790718e+00,  1.5380709e+00,  2.2176025e+00,  3.0804780e-01,\n",
            "        -2.9171200e+00, -1.3201354e+00, -1.0159589e+00, -4.8877397e+00,\n",
            "         1.9330399e+00, -3.0331147e-01, -4.7425938e-01, -1.7090436e+00,\n",
            "         2.1458962e+00,  4.0635791e+00,  7.3489875e-01,  1.2500818e+00,\n",
            "         8.2512134e-01, -2.0262001e+00,  1.0015242e+00,  9.1111374e-01,\n",
            "         7.7600980e-01, -1.5783994e+00, -4.8253069e+00, -1.5546813e+00,\n",
            "         2.2303450e-01,  5.2548275e+00,  5.6140041e-01,  1.6737412e+00,\n",
            "        -1.2401085e+00,  1.2467653e+00, -9.9856454e-01,  2.0856483e+00,\n",
            "         9.4297183e-01,  1.2750064e+00, -4.1772957e+00, -1.7612430e+00,\n",
            "        -9.9953520e-01,  7.6051193e-01, -6.1227012e-01, -2.0637350e+00,\n",
            "        -2.9082215e+00,  1.0476369e+00, -1.8819914e+00,  2.1380768e+00,\n",
            "         2.3344018e+00,  4.4528860e-01, -1.5941453e-01, -5.5676165e+00,\n",
            "        -3.9203939e+00,  1.8023224e+00, -2.1073084e+00, -9.9411619e-01,\n",
            "         5.1868367e+00, -1.0032101e+00,  9.9821770e-01,  8.6889338e-01,\n",
            "        -1.1034839e+00,  5.9786768e+00,  3.6296216e-01, -6.5212531e+00,\n",
            "         4.8042679e+00, -1.4238917e+00,  5.2303648e+00, -1.3726594e-02,\n",
            "         2.2244234e+00,  2.0196607e+00, -5.5055985e+00,  3.1906931e+00,\n",
            "         3.1061804e+00, -1.8931720e+00, -4.1944459e-01,  3.0239531e-01,\n",
            "         1.4403465e+00,  1.3530488e+00,  5.1491799e+00,  2.1280501e+00,\n",
            "         5.6036496e+00, -6.9921476e-01, -1.3279201e+00,  1.4827421e-01,\n",
            "         2.7959628e+00,  1.3290496e+00, -1.8551188e+00,  4.4454856e+00,\n",
            "        -2.7359933e-01,  9.7735178e-01, -1.5211730e+00,  1.3607521e+00,\n",
            "        -1.8296366e+00, -1.7413031e+00,  1.7075005e+00,  2.2824378e+00,\n",
            "         1.7450660e-01, -3.9297774e-01,  2.8556561e+00,  1.9920380e+00,\n",
            "        -3.5137250e+00,  3.7543711e-01, -1.6501790e+00, -5.1590128e+00,\n",
            "         2.8978560e+00, -1.0872515e+00, -6.2175747e-03,  3.5809209e+00,\n",
            "         3.1550167e+00,  4.7460735e-01, -9.5651054e-01, -4.7409363e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.31232616e-06,  4.94977226e-10,  9.84089494e-01,\n",
            "        -3.53408941e-05,  9.84414816e-01, -8.16495180e-01,\n",
            "        -9.53153074e-01, -1.92840866e-06,  7.57617772e-01,\n",
            "         2.33503470e-05,  9.40837264e-01,  3.93102691e-03,\n",
            "         9.54468131e-01, -2.07659673e-06, -4.28493117e-08,\n",
            "        -1.19886354e-04, -2.01740269e-09, -9.98513937e-01,\n",
            "        -3.20819952e-02, -6.42427266e-01, -4.84809483e-04,\n",
            "        -7.50292018e-02,  9.66267705e-01, -1.62707165e-05,\n",
            "        -4.55321093e-11,  7.60879159e-01, -9.90727603e-01,\n",
            "         3.22456351e-09,  3.09914327e-07, -1.44706415e-12,\n",
            "        -5.25554240e-01,  1.74049154e-01,  2.46838908e-06,\n",
            "        -8.81528307e-04, -3.27141322e-02, -1.29430540e-04,\n",
            "        -2.75002647e-04, -3.67423445e-01,  1.26364441e-07,\n",
            "         5.48731032e-06,  8.26831162e-01,  9.96258497e-01,\n",
            "        -7.64197393e-05, -9.28852379e-01, -1.45525864e-05,\n",
            "        -9.25523400e-01,  1.24366443e-05,  1.84132680e-01,\n",
            "         7.51488268e-01,  3.58522683e-02,  1.73367728e-02,\n",
            "         9.72740412e-01,  3.33201866e-09,  4.15465474e-01,\n",
            "         8.01949918e-01,  3.92323807e-02,  4.49788161e-02,\n",
            "        -1.23748779e-01, -9.99725461e-01,  1.65452017e-04,\n",
            "        -8.69855464e-01,  9.90712762e-01, -9.26916122e-01,\n",
            "         4.96494522e-06,  7.23856920e-06,  3.79391806e-03,\n",
            "        -3.17608923e-01,  1.65741625e-08,  1.28850104e-08,\n",
            "        -3.04071847e-02,  9.03896540e-02,  3.30612689e-01,\n",
            "        -9.34403062e-01,  8.57509196e-01, -2.14313999e-01,\n",
            "        -3.78092029e-03,  1.24224084e-06,  1.64896995e-01,\n",
            "        -1.67347416e-01, -3.67238885e-04, -8.32933545e-01,\n",
            "        -1.18320287e-09,  2.81350524e-03,  6.08921014e-02,\n",
            "        -1.20410675e-06,  1.73455135e-07, -4.82711187e-07,\n",
            "         8.91885211e-05, -2.68444330e-01, -7.05002606e-01,\n",
            "         4.01476674e-09, -3.33530992e-01,  7.93447852e-01,\n",
            "        -4.61055635e-07, -3.58824286e-06, -4.93902197e-10,\n",
            "         1.10337867e-04, -2.64892522e-02, -1.51280601e-05,\n",
            "         4.21674922e-03,  9.98550057e-01,  6.98435724e-01,\n",
            "         3.09325665e-01, -9.86127317e-01, -3.14351164e-05,\n",
            "         8.24483097e-01,  7.16640852e-06,  9.49401081e-01,\n",
            "         1.07105132e-02,  5.06068707e-01,  3.12944781e-10,\n",
            "         7.40745306e-01,  3.62464085e-08, -9.23434377e-01,\n",
            "         1.83174107e-02,  1.96864177e-02,  9.97925878e-01,\n",
            "        -2.33184069e-01,  2.26564500e-02, -3.20964347e-07,\n",
            "        -5.35589134e-05, -1.96638957e-05,  8.38450968e-01,\n",
            "        -8.26750875e-01,  1.57086644e-09,  1.62921551e-05,\n",
            "         1.79169376e-07, -4.82960731e-01,  9.71499801e-01,\n",
            "         4.98629585e-02, -1.09904608e-09,  9.59079564e-01,\n",
            "        -3.05778086e-01,  3.73261391e-05,  3.81111167e-02,\n",
            "         7.90957034e-01, -7.40651391e-04, -7.46470553e-14,\n",
            "        -9.99839544e-01,  5.92682738e-08,  7.23354897e-05,\n",
            "         3.31409693e-01,  9.55124735e-04, -1.00324082e-09,\n",
            "        -5.28048426e-02, -4.03917375e-06, -2.45029688e-01,\n",
            "        -6.66570425e-01,  9.73122427e-04,  9.11393583e-01,\n",
            "         8.59188616e-01,  5.83534129e-03, -9.32855368e-01,\n",
            "        -1.98750061e-09, -6.77852239e-03, -3.63426373e-08,\n",
            "         7.61893451e-01,  5.91368258e-01, -3.34037270e-10,\n",
            "        -1.35164535e-09,  9.72401083e-01,  3.83662676e-12,\n",
            "         6.25935972e-01,  2.33213399e-02,  5.17273426e-01,\n",
            "        -9.62753594e-01,  6.13678822e-07, -8.46296251e-02,\n",
            "         4.65077221e-01, -5.36459902e-06, -1.72957450e-01,\n",
            "        -9.02094424e-01,  4.73603734e-09,  7.42743297e-11,\n",
            "         6.48021398e-07,  8.59007239e-03, -1.11790598e-07,\n",
            "         1.13168084e-04, -7.07394851e-04,  8.88941526e-01,\n",
            "         4.31992930e-08,  7.85675347e-01, -1.91953659e-04,\n",
            "        -2.97012739e-02, -2.09797800e-01,  2.82029897e-01,\n",
            "        -5.42549789e-01, -8.02186264e-07, -2.43655154e-06,\n",
            "        -7.60244012e-01, -4.85383040e-08,  1.82514766e-03,\n",
            "         9.81349230e-01,  4.18002516e-01, -6.84551001e-01,\n",
            "        -9.99685824e-01, -9.96412754e-01,  1.86102593e-03,\n",
            "        -1.81262760e-13, -1.66319922e-01,  8.67522717e-01,\n",
            "        -1.40932477e-09,  1.92833936e-03,  3.92554473e-04,\n",
            "        -3.02237342e-04,  9.99887943e-01, -5.25612235e-01,\n",
            "        -8.46256614e-01,  4.81420368e-01, -8.96684360e-03,\n",
            "         4.05379497e-02, -8.79312493e-03,  7.75844336e-01,\n",
            "         2.19825438e-08, -4.30130661e-01,  7.27865636e-01,\n",
            "         8.38908553e-01, -7.21511900e-01, -2.25311633e-05,\n",
            "         2.84557641e-01,  4.93030879e-04,  1.81384501e-03,\n",
            "         1.52357141e-04,  2.21467156e-09,  2.00882301e-12,\n",
            "        -3.03922985e-02, -8.28395367e-01,  8.16674352e-01,\n",
            "         4.09961760e-01,  3.23203564e-01, -2.33605334e-07,\n",
            "         3.11092094e-06, -1.80934250e-01,  1.82446837e-01,\n",
            "        -9.08912838e-01,  1.86122116e-02, -5.15626278e-04,\n",
            "        -5.03465162e-13,  5.89196503e-01,  9.04867649e-01,\n",
            "         1.62799362e-04, -3.64398744e-07,  2.52682320e-09,\n",
            "         4.12640860e-03, -7.03605175e-01,  2.81654596e-01,\n",
            "        -3.17778274e-13, -1.00422324e-06,  9.24405336e-01,\n",
            "        -5.03082701e-04, -5.09892474e-04,  9.98275518e-01,\n",
            "         2.19872922e-11,  4.40960467e-01, -2.66248836e-08,\n",
            "        -2.48894083e-09]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.2242327e+00,  6.1404638e+00,  2.4129725e+00, -2.3345263e+00,\n",
            "         2.4376950e+00, -1.2847544e+00, -5.1369500e+00, -6.6191182e+00,\n",
            "         9.9060434e-01,  4.9173059e+00,  1.7453513e+00,  5.7974443e+00,\n",
            "         2.0201695e+00, -1.8507327e+00, -6.5390491e+00, -3.6630056e+00,\n",
            "        -5.8653369e+00, -3.6228075e+00, -1.9984565e+00, -7.6229668e-01,\n",
            "        -4.8356352e+00, -4.4454246e+00,  2.0327189e+00, -5.5257072e+00,\n",
            "        -5.0498233e+00,  9.9830180e-01, -2.6852870e+00,  4.1159873e+00,\n",
            "         2.4551196e+00, -2.2083166e+00, -1.5547009e+00,  6.8850360e+00,\n",
            "         2.0847309e+00, -3.9963977e+00, -8.8272518e-01, -6.8448677e+00,\n",
            "        -4.4905705e+00, -5.1498876e+00,  6.2708192e+00,  4.4277816e+00,\n",
            "         1.1799546e+00,  3.1398664e+00, -2.2773530e+00, -6.1302528e+00,\n",
            "        -3.0379436e+00, -2.7371612e+00,  2.2897389e+00,  2.0578866e+00,\n",
            "         2.0587361e+00,  5.2523012e+00,  3.8429838e-01,  2.1409280e+00,\n",
            "         1.9914532e+00,  4.4219899e-01,  3.7497048e+00,  6.0302687e+00,\n",
            "         3.2715194e+00, -3.9305849e+00, -4.4467235e+00,  3.0375724e+00,\n",
            "        -1.3324876e+00,  3.6137905e+00, -2.8376632e+00,  5.0429220e+00,\n",
            "         5.7259116e+00,  5.9326797e+00, -3.2898554e-01,  1.3573811e+00,\n",
            "         2.2796803e+00, -3.1236872e-02,  1.0019641e+00,  4.6149497e+00,\n",
            "        -1.6920142e+00,  1.3061029e+00, -2.1775804e-01, -1.8808272e+00,\n",
            "         1.9066550e+00,  3.7729833e+00, -2.6240869e+00, -2.6992350e+00,\n",
            "        -1.1977731e+00, -2.9943993e+00,  3.7716796e+00,  4.1436887e-01,\n",
            "        -1.8092799e+00,  3.7171388e+00, -1.2989379e+00,  2.0078750e+00,\n",
            "        -2.8866422e-01, -8.7718207e-01,  2.0313883e+00, -3.4679672e-01,\n",
            "         1.0809194e+00, -2.0600123e+00, -4.9047604e+00, -4.8837047e+00,\n",
            "         2.4160120e+00, -2.0008426e+00, -4.7017078e+00,  2.7953691e+00,\n",
            "         3.6169310e+00,  8.6438954e-01,  3.9338988e-01, -2.4896798e+00,\n",
            "        -3.3694956e+00,  1.1991489e+00,  3.6916325e+00,  2.2694113e+00,\n",
            "         2.2925007e+00,  5.6156135e-01,  1.4579351e+00,  9.5212924e-01,\n",
            "         1.7942073e+00, -1.6122396e+00,  1.9177728e+00,  4.5646090e-02,\n",
            "         3.4459558e+00, -5.2740488e+00,  5.4184756e+00, -3.0455887e+00,\n",
            "        -5.1542029e+00, -2.1485858e+00,  2.4181213e+00, -5.2188053e+00,\n",
            "         2.6299682e+00,  4.3921223e+00,  5.8312850e+00, -4.1720834e+00,\n",
            "         5.0347996e+00,  3.0449777e+00, -2.0124834e+00,  1.9343003e+00,\n",
            "        -7.4660665e-01,  2.4392257e+00,  2.0155330e+00,  1.1069324e+00,\n",
            "        -1.3072389e+00, -2.0106478e+00, -6.3610249e+00,  1.3467105e-01,\n",
            "         1.1387128e+00,  2.0611806e+00,  2.0651128e+00, -1.1607475e+00,\n",
            "        -1.2742291e-01, -6.6493163e+00, -1.1689211e+00, -8.0510926e-01,\n",
            "         4.2790718e+00,  1.5361146e+00,  3.2122455e+00,  1.2509593e+00,\n",
            "        -1.9342912e+00, -1.2845135e+00, -1.1592035e+00, -5.8870883e+00,\n",
            "         2.9328356e+00,  6.7977101e-01, -6.8152809e-01, -2.7084174e+00,\n",
            "         2.1368687e+00,  5.0478978e+00,  7.3484516e-01,  2.2496865e+00,\n",
            "         1.8250797e+00, -2.0259938e+00,  2.0013943e+00, -8.8515446e-02,\n",
            "         5.0380039e-01, -2.5501869e+00, -4.9320846e+00, -1.4833535e+00,\n",
            "         2.7295414e-01,  6.2458010e+00,  1.5607692e+00,  1.6942779e+00,\n",
            "        -2.2398968e+00,  2.2416713e+00, -1.9985375e+00,  3.0845366e+00,\n",
            "         1.9151641e+00,  1.2749985e+00, -5.1608157e+00, -2.7607045e+00,\n",
            "        -1.9995351e+00,  1.7604707e+00, -6.1227006e-01, -3.0636840e+00,\n",
            "        -3.9081416e+00, -9.9679315e-01, -1.8822236e+00,  3.0976219e+00,\n",
            "         2.3328228e+00,  4.4528523e-01, -8.3763617e-01, -4.5841265e+00,\n",
            "        -3.1623681e+00,  1.8024255e+00, -2.5183921e+00, -1.9938397e+00,\n",
            "         4.1904178e+00, -2.0031481e+00,  1.9982016e+00,  1.8688864e+00,\n",
            "        -2.1029046e+00,  4.8949132e+00, -6.0009998e-01, -7.5184078e+00,\n",
            "         4.8890262e+00, -2.4238911e+00,  6.2285295e+00, -5.7250142e-01,\n",
            "         2.2275107e+00,  3.0112703e+00, -5.5932827e+00,  4.1905508e+00,\n",
            "         3.1060655e+00, -9.1081971e-01, -1.4194322e+00,  2.9263437e-01,\n",
            "         2.4403043e+00,  2.3528047e+00,  5.8741708e+00,  3.1265416e+00,\n",
            "         6.5709786e+00, -3.7094718e-01, -1.1988360e+00,  1.1467494e+00,\n",
            "         2.9756978e+00,  3.3524537e-01, -2.8551188e+00,  5.4440989e+00,\n",
            "        -1.8294838e-01,  1.9770160e+00, -1.5213267e+00,  2.3590128e+00,\n",
            "        -5.1570474e-04, -2.7346997e+00,  2.6778080e+00,  1.5004271e+00,\n",
            "         1.5209466e-03, -1.3744922e+00,  3.7036123e+00,  2.9898419e+00,\n",
            "        -3.5195022e+00,  3.8859382e-01, -2.6467590e+00, -6.1583304e+00,\n",
            "         1.6208460e+00, -2.0872436e+00, -8.3974451e-01,  3.5275536e+00,\n",
            "         4.1434407e+00,  4.7518328e-01, -1.9531186e+00, -5.7388654e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         6.14698708e-01,  4.79109734e-01,  9.59853709e-01,\n",
            "        -7.77770206e-02,  1.64054260e-01, -8.59830752e-02,\n",
            "        -2.37335474e-03, -1.93220183e-01,  8.75836849e-01,\n",
            "        -4.25516488e-03,  8.66121900e-06,  1.10923700e-01,\n",
            "         1.52852550e-01, -1.67688704e-03,  4.28669807e-03,\n",
            "         9.12518799e-01, -1.64171914e-04, -9.81277108e-01,\n",
            "        -6.73341990e-01,  9.99230504e-01,  8.57825816e-01,\n",
            "         2.58876473e-01, -1.19568595e-08, -2.70967193e-10,\n",
            "        -8.14280659e-02,  5.13520062e-01,  8.37011397e-01,\n",
            "         3.26055742e-04,  9.13800061e-01, -6.97987911e-04,\n",
            "         2.31944793e-03, -1.00632315e-06, -9.38602328e-01,\n",
            "         1.70467943e-01,  6.35179051e-04,  9.07975674e-01,\n",
            "         7.30619133e-01,  8.97674620e-01, -2.83040889e-02,\n",
            "        -2.65623063e-01, -9.51373100e-01, -1.04419084e-03,\n",
            "         6.59005309e-04,  4.41008508e-01, -1.29343406e-03,\n",
            "        -3.33387841e-04,  7.76327014e-01,  7.79805487e-06,\n",
            "         1.77227426e-03,  8.28881934e-02,  9.14826244e-02,\n",
            "        -1.80334803e-02,  2.30782621e-06, -9.29074883e-01,\n",
            "        -1.14634648e-01, -4.15505439e-01, -7.75563717e-01,\n",
            "        -5.40368617e-01,  1.27514079e-03,  1.97437639e-05,\n",
            "         3.88912559e-01,  9.75834072e-01, -2.58958023e-02,\n",
            "         4.99654673e-02, -1.06750034e-01,  9.88337100e-01,\n",
            "         1.71832449e-03,  2.95390445e-03, -9.89552319e-01,\n",
            "        -1.67116940e-01, -2.93996260e-02,  8.53482902e-01,\n",
            "        -6.69638932e-01, -3.37274112e-02, -5.59798889e-02,\n",
            "         2.79984772e-01, -6.34569806e-05,  5.25836367e-04,\n",
            "         9.98254001e-01, -2.30584979e-01,  9.38053787e-01,\n",
            "        -9.90551353e-01,  3.26207578e-01,  9.22784805e-01,\n",
            "        -1.40721668e-05, -5.06412923e-01,  3.02629378e-02,\n",
            "        -2.27150867e-05,  8.10324252e-01,  8.17002833e-01,\n",
            "        -6.50131106e-01,  9.99999106e-01,  9.06665385e-01,\n",
            "        -1.54378489e-01,  8.41362357e-01, -8.23003054e-01,\n",
            "         1.31145038e-03, -8.97088945e-01,  1.64061606e-01,\n",
            "         1.06482382e-03, -4.83015738e-03,  8.21373362e-07,\n",
            "         2.04970390e-01, -8.31379235e-01, -1.23913577e-02,\n",
            "         7.99366415e-01,  1.43742436e-05,  7.17888176e-02,\n",
            "         9.87327158e-01,  8.71593954e-07,  5.40216127e-03,\n",
            "        -2.77026120e-04,  1.19340578e-02, -7.16842175e-01,\n",
            "         9.81785178e-01,  8.23102236e-01, -2.03817108e-04,\n",
            "         2.40975335e-01,  1.56990707e-01,  2.65640020e-01,\n",
            "        -1.13198822e-02,  6.42746031e-01, -9.77698922e-01,\n",
            "        -4.36740356e-06,  2.18538865e-01, -2.15966135e-01,\n",
            "         7.47803890e-04, -9.83741656e-02,  4.27368237e-03,\n",
            "         2.49303747e-02, -5.53819478e-01, -7.54401833e-02,\n",
            "        -3.92899965e-05, -8.44059110e-01,  8.63365605e-02,\n",
            "        -3.64707198e-08, -1.33511465e-04,  9.56504822e-01,\n",
            "         3.40704137e-04,  5.94923556e-01, -4.78224516e-01,\n",
            "        -9.03170672e-04]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.59908748e+00,  9.23279572e+00, -3.93349022e-01,\n",
            "        -3.07110757e-01,  7.46502578e-01, -1.70546913e+00,\n",
            "        -2.91374040e+00, -1.07329817e+01,  6.32467806e-01,\n",
            "         9.92312717e+00,  1.02983570e+00,  1.03929653e+01,\n",
            "         1.20756972e+00, -4.81841773e-01, -1.03189507e+01,\n",
            "        -3.72142673e+00, -9.46201420e+00, -7.08319235e+00,\n",
            "        -1.02144635e+00,  1.80050325e+00, -1.86393750e+00,\n",
            "        -9.36732578e+00, -4.13923979e-01, -1.04656363e+01,\n",
            "        -1.04328642e+01, -2.53616929e+00, -1.81917059e+00,\n",
            "         8.02275944e+00,  2.07192159e+00, -2.53017855e+00,\n",
            "        -6.15508795e+00,  9.73034191e+00,  1.29525971e+00,\n",
            "        -3.43509841e+00, -7.16652215e-01, -1.08949051e+01,\n",
            "        -8.44417000e+00, -1.07237883e+01,  5.97073793e+00,\n",
            "         1.97489798e+00, -8.03185642e-01,  1.34904251e-01,\n",
            "        -4.75612688e+00, -1.08866434e+01, -7.93249369e-01,\n",
            "        -2.49977088e+00,  2.12607121e+00,  1.51571298e+00,\n",
            "         8.73873353e-01,  7.74811316e+00,  3.10838848e-01,\n",
            "         1.95549130e+00,  1.27807081e+00, -1.51886970e-01,\n",
            "         8.88137698e-01,  9.27901363e+00,  9.65685606e-01,\n",
            "        -1.01130133e+01, -1.05847244e+01,  1.00755539e+01,\n",
            "        -5.36715269e-01,  4.05050188e-01, -9.99602079e-01,\n",
            "         1.94547391e+00,  1.03030128e+01,  1.08853846e+01,\n",
            "         4.79215956e+00,  9.94998276e-01,  1.17540181e+00,\n",
            "        -1.63552514e-03,  9.82693806e-02,  6.55782938e+00,\n",
            "         4.34006155e-01,  7.61647606e+00, -3.06257725e+00,\n",
            "        -9.55221832e-01,  7.78779328e-01,  5.27390003e+00,\n",
            "        -3.44012380e-02, -4.05393553e+00, -7.47362971e-02,\n",
            "        -1.00335407e+00,  2.57483244e+00,  7.28478879e-02,\n",
            "        -9.87058520e-01,  3.97570372e+00, -3.12405920e+00,\n",
            "         1.00000167e+00,  1.14395475e+00,  2.10047439e-01,\n",
            "         4.51965189e+00, -7.39083707e-01,  1.73928154e+00,\n",
            "        -1.77668309e+00, -1.09163485e+01, -4.96538210e+00,\n",
            "         1.13252115e+00, -9.98195529e-01, -9.90896165e-01,\n",
            "         1.75743937e-01,  1.77785385e+00,  9.69770074e-01,\n",
            "        -1.52187347e+00, -9.60807228e+00, -4.81110287e+00,\n",
            "         1.43654323e+00,  4.59067059e+00,  1.19288182e+00,\n",
            "         3.95532656e+00,  1.49544787e+00,  1.02918124e+00,\n",
            "        -8.01591039e-01,  1.97185075e+00,  3.76422286e-01,\n",
            "         2.05471015e+00,  5.22117972e-01,  2.01168323e+00,\n",
            "        -9.94324780e+00,  7.02211714e+00, -7.64226496e-01,\n",
            "        -1.00825529e+01, -1.26666200e+00,  1.38926959e+00,\n",
            "        -9.34924793e+00,  2.91869950e+00,  1.07202311e+01,\n",
            "         1.00485706e+01, -1.88591588e+00,  1.04405346e+01,\n",
            "         1.73648155e+00, -1.52585387e+00, -2.33297682e+00,\n",
            "        -8.17841411e-01,  4.88074255e+00,  1.28900182e+00,\n",
            "         2.65693128e-01, -2.34053493e-01, -1.27317643e+00,\n",
            "        -1.05859737e+01,  5.71197927e-01,  1.21150327e+00,\n",
            "         7.16430664e-01,  2.29416084e+00, -2.09806442e+00,\n",
            "         2.38444749e-03, -6.58884716e+00, -1.72792530e+00,\n",
            "         1.72155648e-01,  1.00450397e+00,  1.51603043e+00,\n",
            "         4.69709873e+00,  1.46171701e+00, -7.40636289e-01,\n",
            "        -2.81411934e+00, -2.76042485e+00, -2.99732304e+00,\n",
            "         5.45657110e+00,  4.73616600e-01, -2.82398319e+00,\n",
            "        -4.36839151e+00,  9.09363365e+00,  1.06177149e+01,\n",
            "         2.48541636e-03,  8.89961123e-02,  1.03748119e+00,\n",
            "        -3.96816880e-02,  9.96489584e-01, -1.65168858e+00,\n",
            "        -1.20549366e-01, -2.33689809e+00, -3.39130926e+00,\n",
            "        -6.76294267e-01,  1.80732977e+00,  1.10216904e+01,\n",
            "         2.31399655e+00,  3.63559103e+00, -1.22526622e+00,\n",
            "         2.31054044e+00, -9.99794364e-01,  4.27926254e+00,\n",
            "         1.33998740e+00,  3.00429529e-03, -9.55979919e+00,\n",
            "        -1.00775146e+00, -9.91845489e-01,  1.55572784e+00,\n",
            "        -8.10089111e-01, -3.38126011e-02, -6.88035154e+00,\n",
            "         2.87665665e-01, -3.49023890e+00,  1.02551329e+00,\n",
            "         3.52196765e+00, -2.37104669e-01,  1.84289479e+00,\n",
            "        -4.47970819e+00,  3.38695556e-01,  1.60874987e+00,\n",
            "        -8.63742065e+00, -9.93496001e-01,  8.16910458e+00,\n",
            "        -9.99971449e-01,  1.21101165e+00,  1.14774537e+00,\n",
            "        -2.94077253e+00,  8.07063866e+00,  4.51877260e+00,\n",
            "        -1.05091066e+01,  7.63465691e+00, -2.06833839e+00,\n",
            "         5.01822376e+00, -1.45869064e+00,  1.65945649e-01,\n",
            "         2.12192869e+00, -8.30560303e+00,  1.99873710e+00,\n",
            "         5.53380370e-01, -1.19259095e+00, -2.06390262e+00,\n",
            "         1.10204613e+00,  1.28660142e+00,  1.19859922e+00,\n",
            "         1.01240330e+01,  6.52822778e-02,  1.01390381e+01,\n",
            "        -9.85141098e-02,  1.63164914e-01, -9.34866607e-01,\n",
            "         2.38484359e+00,  1.16905105e+00, -1.76996291e+00,\n",
            "         4.69966459e+00,  1.58315599e-01,  2.98098773e-01,\n",
            "        -1.13207269e-02,  1.20681906e+00, -2.24254656e+00,\n",
            "        -4.67407846e+00,  2.42143869e+00, -2.19427004e-01,\n",
            "         7.50381383e-04, -2.00836092e-01,  3.07001972e+00,\n",
            "         1.47983170e+00, -9.35673237e-01, -1.49768376e+00,\n",
            "        -6.93502474e+00, -1.09205666e+01,  8.65804777e-02,\n",
            "        -1.71951365e+00, -6.24508783e-02,  2.24601197e+00,\n",
            "         7.67521715e+00,  6.86489701e-01, -5.47816217e-01,\n",
            "        -9.79148102e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.50104199e-06,  1.69506857e-05, -8.39646935e-01,\n",
            "        -5.20200365e-06,  9.09928024e-01, -7.96263039e-01,\n",
            "        -8.01879942e-01, -1.93858214e-05, -2.35825434e-01,\n",
            "         1.04863560e-04,  7.68968582e-01,  9.04605329e-01,\n",
            "         3.48575762e-03, -7.06488645e-05, -1.95941652e-06,\n",
            "        -9.75858143e-07, -3.06089021e-08, -5.98096132e-01,\n",
            "        -4.00539115e-02,  9.46986616e-01, -2.73964106e-04,\n",
            "        -3.69631737e-01, -4.54096138e-01, -1.18385526e-06,\n",
            "        -1.85785623e-07,  7.61098981e-01, -9.47239101e-01,\n",
            "         6.36016807e-07,  1.09489091e-10, -1.38340714e-10,\n",
            "        -9.95005965e-01,  2.47980322e-04,  6.96845390e-08,\n",
            "        -9.65963542e-01, -5.90533018e-01, -5.77352464e-01,\n",
            "        -9.62954346e-06, -9.99279618e-01,  2.25404648e-07,\n",
            "         2.11460982e-04, -6.63310111e-01,  5.48129618e-01,\n",
            "        -1.31609631e-05, -9.34561491e-01, -2.67333711e-08,\n",
            "        -7.53269315e-01,  5.98868510e-08,  1.96661009e-03,\n",
            "         9.51768696e-01,  6.32799044e-02,  3.02668137e-04,\n",
            "         9.41304803e-01,  1.23329232e-06,  6.56924069e-01,\n",
            "         1.84852467e-03,  4.30202257e-04,  8.90064389e-02,\n",
            "        -1.47589717e-05, -1.00000000e+00,  9.74690557e-01,\n",
            "        -5.80098629e-01, -2.23932993e-02, -9.63902950e-01,\n",
            "         9.91118031e-06,  1.56469680e-02,  2.55086366e-03,\n",
            "         9.99779165e-01,  1.58207433e-06,  2.19271780e-12,\n",
            "        -3.34272734e-08,  2.85539340e-04,  4.35086622e-06,\n",
            "        -5.12026727e-01,  9.27744865e-01, -9.91574168e-01,\n",
            "        -3.86152595e-01,  1.24439699e-04,  3.91159981e-01,\n",
            "        -2.91668713e-01, -6.68821990e-01, -7.45146349e-02,\n",
            "        -3.66721498e-09,  6.47031367e-02,  1.71047694e-04,\n",
            "        -3.75681593e-05,  1.29399467e-07, -5.68641553e-07,\n",
            "         1.40539138e-04,  9.65583697e-03,  7.55260766e-01,\n",
            "         2.37425149e-11, -5.66347957e-01,  6.28635645e-01,\n",
            "        -1.31741135e-05, -3.59942624e-03, -9.22363768e-08,\n",
            "         9.96906522e-08, -6.44464046e-04, -2.16297622e-06,\n",
            "         4.70940404e-06,  9.44319427e-01,  7.48352468e-01,\n",
            "        -8.86704564e-01, -2.87401497e-01, -2.41934843e-02,\n",
            "         7.75416076e-01,  3.23036492e-01,  7.00075328e-02,\n",
            "         2.76860297e-01,  9.74123180e-01,  1.14039334e-11,\n",
            "        -7.00439036e-01,  3.67975583e-09, -5.53023279e-01,\n",
            "         6.05536345e-03,  8.93699825e-01,  9.53340471e-01,\n",
            "        -4.06884141e-02,  5.24558052e-02, -8.62082561e-06,\n",
            "        -1.34594166e-06, -8.98116443e-04,  2.36545857e-02,\n",
            "        -9.63518023e-03,  5.80409747e-08,  1.37820665e-04,\n",
            "         2.92445402e-05, -3.69698368e-03,  1.35526734e-05,\n",
            "         2.75146961e-03, -4.76660489e-09, -9.10773695e-01,\n",
            "        -9.38336432e-01,  2.14498024e-02,  9.78156209e-01,\n",
            "         2.58436948e-01, -1.55292524e-04, -4.04669986e-09,\n",
            "        -9.99961793e-01,  3.11100564e-04,  3.70301723e-01,\n",
            "         1.27550520e-04,  2.56080856e-03, -1.32468503e-09,\n",
            "         1.64763164e-03, -2.18601849e-06, -9.89015520e-01,\n",
            "        -6.47231936e-01,  9.73035412e-07,  9.07965302e-01,\n",
            "         2.23400560e-03,  9.83806968e-01,  1.04254417e-01,\n",
            "        -1.19474472e-03, -1.58794858e-02, -1.03058548e-10,\n",
            "         3.08340043e-02,  4.94742572e-01, -2.76860579e-09,\n",
            "        -9.40161272e-07,  9.03693199e-01,  7.87927092e-08,\n",
            "         2.44719209e-03,  2.20622533e-04,  1.99106545e-03,\n",
            "        -3.20283435e-02,  4.20094437e-07, -9.49943304e-01,\n",
            "        -1.42338887e-01, -1.68617157e-06, -8.32311332e-01,\n",
            "        -5.85309625e-01,  6.95944777e-08,  1.72744943e-10,\n",
            "         4.41479244e-07,  9.86731827e-01, -1.46654556e-05,\n",
            "        -2.23560575e-02, -1.28033827e-03,  3.49848554e-03,\n",
            "         4.53010962e-11,  5.43798089e-01, -5.96808828e-03,\n",
            "        -5.83312809e-01, -4.90885880e-03,  9.80531693e-01,\n",
            "        -6.68357551e-01, -3.99846904e-04, -1.02960553e-06,\n",
            "        -7.61310756e-01, -1.59531273e-02,  1.68345601e-03,\n",
            "         9.96781051e-01, -8.35004866e-01,  9.49244797e-01,\n",
            "        -9.98386085e-01,  6.47136331e-01,  2.76957802e-03,\n",
            "        -5.05068076e-09, -8.63702744e-02,  6.76955283e-02,\n",
            "        -3.83176143e-07,  1.33683728e-02,  9.72942412e-01,\n",
            "        -2.77884305e-03,  9.92543578e-01,  5.53516269e-01,\n",
            "        -9.54393148e-01,  2.42987710e-07, -1.41773447e-02,\n",
            "         4.32555983e-03, -9.20236886e-01,  1.61831966e-03,\n",
            "         2.65055547e-07, -3.65239717e-02,  4.88471948e-02,\n",
            "         4.98712480e-01, -2.87741065e-01, -2.44977145e-05,\n",
            "         6.50577307e-01,  1.81623083e-03,  1.93300984e-05,\n",
            "         1.33861595e-05,  1.17875152e-06,  2.46526888e-09,\n",
            "        -9.22391862e-02,  1.70627952e-01, -7.31930971e-01,\n",
            "         9.82968450e-01,  6.42532229e-01, -4.39104736e-01,\n",
            "         1.01122874e-04,  6.97960556e-01,  4.58613911e-04,\n",
            "        -1.10713178e-02,  9.14606512e-01, -9.96811032e-01,\n",
            "        -2.48202081e-09,  4.24625158e-01, -8.37284267e-01,\n",
            "         1.10343099e-01, -1.49909916e-08,  1.12779196e-06,\n",
            "         6.08924252e-04, -6.90400302e-02, -8.82737219e-01,\n",
            "        -7.97650418e-11, -6.34485900e-01,  9.40778864e-06,\n",
            "        -1.44025207e-01, -2.40736336e-01,  9.61893976e-01,\n",
            "         3.69224267e-06,  3.34462404e-01, -4.66077790e-06,\n",
            "        -1.05828246e-09]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.56487274e+00,  1.02320175e+01, -1.22069907e+00,\n",
            "        -1.09406865e+00,  1.52820742e+00, -2.31762075e+00,\n",
            "        -3.89240217e+00, -1.17220497e+01, -2.40362331e-01,\n",
            "         1.09215269e+01,  1.02992046e+00,  1.13919516e+01,\n",
            "         2.20747042e+00, -1.47041082e+00, -1.12930660e+01,\n",
            "        -4.71635389e+00, -1.04422617e+01, -7.08035660e+00,\n",
            "        -2.02144217e+00,  1.80237865e+00, -1.86648750e+00,\n",
            "        -1.03537731e+01, -4.89849061e-01, -1.14457569e+01,\n",
            "        -1.13665085e+01,  9.98931348e-01, -1.80422091e+00,\n",
            "         8.64842510e+00,  2.92665505e+00, -3.52998853e+00,\n",
            "        -6.15369987e+00,  1.01244831e+01,  2.28610945e+00,\n",
            "        -4.43481588e+00, -9.55913246e-01, -1.08903198e+01,\n",
            "        -9.43236732e+00, -1.17196455e+01,  6.97071791e+00,\n",
            "         1.55563712e+00, -8.00519288e-01,  1.10735536e+00,\n",
            "        -5.75563240e+00, -1.18821793e+01, -1.79190135e+00,\n",
            "        -2.47913527e+00,  3.12348032e+00,  2.51527333e+00,\n",
            "         1.86958730e+00,  8.74599838e+00,  4.48138982e-01,\n",
            "         1.75498760e+00,  2.27537608e+00,  7.87392735e-01,\n",
            "         1.31092405e+00,  1.02743063e+01,  9.97504711e-01,\n",
            "        -1.11021442e+01, -9.94250679e+00,  1.10633764e+01,\n",
            "        -6.62616730e-01, -4.80201542e-02, -1.99832511e+00,\n",
            "         2.94536066e+00,  1.11432323e+01,  1.17676096e+01,\n",
            "         4.55581570e+00,  1.99453723e+00,  2.17401171e+00,\n",
            "        -1.63586880e-03,  9.26935613e-01,  7.54156923e+00,\n",
            "        -5.65474689e-01,  6.62292337e+00, -3.07722378e+00,\n",
            "        -1.87896311e+00,  1.77087855e+00,  5.25983191e+00,\n",
            "        -1.03433359e+00, -4.84804201e+00, -7.47362003e-02,\n",
            "        -2.00333071e+00,  3.57463837e+00,  7.52325356e-02,\n",
            "        -1.97523749e+00,  4.97447014e+00, -3.74305797e+00,\n",
            "         1.99991632e+00,  1.09769058e+00,  9.85162675e-01,\n",
            "         5.51855946e+00, -7.39082873e-01,  7.39349604e-01,\n",
            "        -2.75657296e+00, -1.18136978e+01, -5.96182108e+00,\n",
            "         1.83597171e+00, -1.99459064e+00, -1.99012160e+00,\n",
            "         1.12699223e+00,  1.77673566e+00,  9.69210982e-01,\n",
            "        -1.41119444e+00, -8.83776093e+00, -5.79965496e+00,\n",
            "         2.43589902e+00,  5.59064102e+00,  2.18900657e+00,\n",
            "         4.95072365e+00,  2.49388504e+00,  2.02897000e+00,\n",
            "        -8.68161976e-01,  2.89260006e+00, -6.22726202e-01,\n",
            "         2.59952807e+00,  1.45921516e+00,  1.86727595e+00,\n",
            "        -1.09310970e+01,  7.80611420e+00, -1.76202297e+00,\n",
            "        -1.09036903e+01, -1.32707930e+00,  2.38902354e+00,\n",
            "        -1.00028620e+01,  3.90807724e+00,  1.17090015e+01,\n",
            "         1.09023352e+01, -2.88589668e+00,  1.14177628e+01,\n",
            "         1.98407519e+00, -2.52555060e+00, -1.53204393e+00,\n",
            "        -1.79555988e+00,  4.87986565e+00,  2.28800392e+00,\n",
            "         2.66321927e-01, -1.21132636e+00, -2.27311635e+00,\n",
            "        -8.55764771e+00,  5.77830553e-01,  1.16535771e+00,\n",
            "         1.71605921e+00,  3.28328753e+00, -3.09591866e+00,\n",
            "         2.51262332e-03, -7.58401632e+00, -2.72650409e+00,\n",
            "        -7.70523369e-01,  2.00448275e+00,  1.51585495e+00,\n",
            "         5.21431684e+00,  2.45004797e+00,  1.04880989e-01,\n",
            "        -2.81407022e+00, -3.64365053e+00, -3.99495888e+00,\n",
            "         6.45558500e+00,  5.42372167e-01, -3.79578710e+00,\n",
            "        -5.35861874e+00,  9.09257984e+00,  1.15630865e+01,\n",
            "         2.44727684e-03,  2.75403142e-01,  2.03714037e+00,\n",
            "        -3.86877991e-02,  9.99490082e-01, -2.42505646e+00,\n",
            "        -1.43313140e-01, -3.09917736e+00, -4.38005686e+00,\n",
            "        -6.70501530e-01,  2.00355124e+00,  1.19878359e+01,\n",
            "         3.31059265e+00,  3.64374185e+00, -2.20435572e+00,\n",
            "        -9.72185671e-01, -1.99973941e+00,  5.27133703e+00,\n",
            "         1.33621454e+00,  7.32786715e-01, -1.05120821e+01,\n",
            "        -2.00761628e+00, -1.99150360e+00,  2.55259299e+00,\n",
            "        -8.10085118e-01, -1.03341162e+00, -7.87685347e+00,\n",
            "        -9.99325871e-01, -3.51499033e+00,  1.21452546e+00,\n",
            "         3.32255769e+00, -1.23523164e+00,  1.82409942e+00,\n",
            "        -3.56413531e+00,  7.70382583e-01,  1.64662313e+00,\n",
            "        -9.63125229e+00, -1.98741615e+00,  7.20057726e+00,\n",
            "        -1.99785471e+00,  2.20955729e+00,  2.14654899e+00,\n",
            "        -3.90545702e+00,  2.79498577e+00,  3.96988225e+00,\n",
            "        -1.15045252e+01,  7.67406416e+00, -3.04335880e+00,\n",
            "         5.99305964e+00, -2.31925488e+00,  1.66297197e-01,\n",
            "         3.11111975e+00, -8.30560207e+00,  2.99771380e+00,\n",
            "         5.47687292e-01, -2.96102613e-01, -3.06386924e+00,\n",
            "         7.76299000e-01,  2.28645349e+00,  2.03061819e+00,\n",
            "         1.02595139e+01,  5.25733411e-01,  1.11268234e+01,\n",
            "        -9.86414105e-02,  2.23447710e-01, -9.32873785e-01,\n",
            "         2.40706444e+00,  7.62507737e-01, -2.76985669e+00,\n",
            "         5.67900229e+00,  8.63312840e-01,  1.27589703e+00,\n",
            "        -1.13284802e-02,  1.55500209e+00, -3.21984363e+00,\n",
            "        -5.65335274e+00,  2.88582158e+00, -1.21247649e+00,\n",
            "         8.64516616e-01, -1.01345098e+00,  4.06692123e+00,\n",
            "         2.01980591e+00, -9.35558736e-01, -1.45162785e+00,\n",
            "        -7.92606354e+00, -1.19202976e+01,  1.03456996e-05,\n",
            "        -2.65234542e+00, -9.22234118e-01,  1.97064984e+00,\n",
            "         8.48518753e+00,  6.86495304e-01, -7.15032816e-01,\n",
            "        -1.07912560e+01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.18929128e-11,  6.77033114e-08, -8.41295719e-01,\n",
            "        -5.74986018e-07,  2.78940046e-04, -4.25081365e-02,\n",
            "        -8.07043817e-03, -1.50348956e-10, -3.04827034e-01,\n",
            "         3.33584644e-08,  5.73962403e-04,  3.88159009e-07,\n",
            "         1.28070917e-02, -5.72254930e-06, -4.55488180e-06,\n",
            "        -1.91191560e-08, -6.64747235e-09, -8.21836293e-01,\n",
            "        -2.85452302e-03,  8.45241725e-01, -3.81875318e-03,\n",
            "        -1.68436393e-03, -5.04946709e-01, -1.82798843e-09,\n",
            "        -1.29336229e-07,  9.56988513e-01, -9.47077096e-01,\n",
            "         1.30348708e-05,  3.63191421e-10, -2.41468737e-12,\n",
            "        -9.81912792e-01,  3.73570435e-02,  1.03638374e-11,\n",
            "        -1.96185391e-02, -8.00976396e-01, -1.73146163e-05,\n",
            "        -1.81950982e-11, -8.61912153e-10,  4.89449420e-04,\n",
            "         9.05371070e-01,  1.47510890e-03,  1.01612359e-02,\n",
            "        -2.18487969e-07, -3.40297702e-04, -3.50593564e-06,\n",
            "        -8.15254450e-01,  3.84263387e-07,  1.51697964e-06,\n",
            "         9.81582582e-01,  7.75078419e-08,  1.32232094e-06,\n",
            "         9.39598143e-01,  2.15213181e-08,  9.45323288e-01,\n",
            "         1.73522281e-07,  1.07548243e-04,  7.66912650e-04,\n",
            "        -2.32477447e-07,  4.81220543e-01,  1.85853833e-06,\n",
            "        -2.31565565e-01, -6.02289848e-02, -1.53735164e-06,\n",
            "         8.93294782e-05,  9.76447723e-08,  7.19363670e-05,\n",
            "         9.98462081e-01,  1.94276222e-08,  2.25689778e-09,\n",
            "        -1.17338706e-04,  2.63350071e-11,  4.12494643e-04,\n",
            "        -9.16227102e-01,  9.73415434e-01, -2.43878856e-01,\n",
            "        -3.12371354e-04,  9.88117669e-14,  6.09941721e-01,\n",
            "        -2.16856992e-04, -2.63955981e-01, -3.33166518e-03,\n",
            "        -5.86360249e-09,  1.52732246e-02,  5.12926257e-10,\n",
            "        -1.36152547e-08,  1.51421764e-10, -1.39180001e-08,\n",
            "         1.05920229e-02,  6.61855519e-01,  5.88327460e-02,\n",
            "         4.02080418e-11, -5.24446011e-01,  6.08885527e-01,\n",
            "        -5.38359746e-10, -9.65591425e-07, -7.92497212e-06,\n",
            "         1.87570477e-05, -8.61608669e-08, -1.12089005e-10,\n",
            "         3.05388384e-02,  9.43789005e-01,  7.48020470e-01,\n",
            "        -8.79762650e-01, -9.02193427e-01, -7.89732412e-02,\n",
            "         5.14669318e-06,  1.97797708e-05,  3.57182398e-05,\n",
            "         2.25753029e-04,  4.96590184e-03,  6.03796943e-11,\n",
            "        -7.21108198e-01,  1.35362730e-04, -2.53293943e-03,\n",
            "         1.82137802e-01,  5.85211767e-03,  9.47958291e-01,\n",
            "        -1.54903578e-03,  6.71881821e-08, -7.29660405e-06,\n",
            "        -1.29834945e-07, -2.21269875e-06,  3.63411636e-05,\n",
            "        -2.39793753e-05,  3.59024387e-04,  4.95969252e-05,\n",
            "         1.87720381e-10, -5.45692556e-02,  9.05857801e-01,\n",
            "         7.31020093e-01, -1.40450854e-11, -4.87833887e-01,\n",
            "        -1.06468625e-01,  4.94943839e-03,  1.69941894e-04,\n",
            "         2.09203063e-05, -6.50633709e-04, -1.08203992e-07,\n",
            "         7.61519432e-01,  2.82524681e-11,  5.88750932e-03,\n",
            "         6.99123984e-06,  1.17364289e-05, -7.15106308e-11,\n",
            "         2.41809115e-02, -2.14872928e-11, -9.14929152e-01,\n",
            "        -8.86762917e-01,  8.43958987e-04,  9.07810390e-01,\n",
            "         9.39976722e-02,  5.24864256e-01,  1.09334707e-01,\n",
            "        -1.67017043e-01, -9.99025404e-01, -1.53925281e-08,\n",
            "         1.44430345e-07,  6.03257298e-01, -4.50876086e-10,\n",
            "        -7.08161038e-04,  7.12362349e-01,  5.34802844e-12,\n",
            "         2.43927538e-03,  7.75272250e-01,  8.14684574e-03,\n",
            "         1.51400551e-01,  1.56124544e-10, -3.77731957e-02,\n",
            "        -4.71848488e-01, -2.20912824e-07, -6.93114623e-02,\n",
            "        -5.83557010e-01,  1.90696126e-10,  3.45082674e-09,\n",
            "         6.55026655e-09,  9.77631748e-01, -9.67368633e-02,\n",
            "        -3.36298943e-01, -4.98028639e-05,  2.53794915e-05,\n",
            "         6.84221430e-11,  8.81352007e-01, -4.54946871e-08,\n",
            "        -1.69909065e-08, -1.25569886e-05,  1.39126510e-04,\n",
            "        -7.69783401e-06, -3.87566797e-05, -1.08959138e-01,\n",
            "        -9.29326177e-01, -1.67018065e-04,  2.63266083e-05,\n",
            "         8.50282013e-01, -9.74002242e-01,  8.35791469e-01,\n",
            "        -9.95402575e-01,  6.18083477e-01,  1.49162318e-08,\n",
            "        -5.51056519e-06, -7.01528136e-03,  5.19805133e-01,\n",
            "        -4.23660079e-10,  2.29134485e-02,  2.10548639e-02,\n",
            "        -1.29465754e-08,  1.38730571e-01,  8.09200108e-01,\n",
            "        -9.86278296e-01,  1.17702266e-05, -1.28239810e-01,\n",
            "         2.49353051e-03, -1.01291626e-07,  1.64774105e-01,\n",
            "         2.18151075e-09, -2.23154634e-01,  1.19327226e-04,\n",
            "         2.30562940e-01,  3.82791042e-01, -3.13305804e-07,\n",
            "         5.04029214e-01,  3.64333362e-04,  6.21432991e-05,\n",
            "         4.62721255e-05,  1.09573899e-04,  3.07114846e-07,\n",
            "        -1.73951063e-04,  8.26425195e-01, -7.28651166e-01,\n",
            "         3.10006719e-02, -2.28211716e-01, -6.69887841e-01,\n",
            "         5.38112188e-04,  9.48642194e-01,  7.03413025e-05,\n",
            "        -1.25590023e-02,  7.99251199e-02, -9.96810436e-01,\n",
            "        -6.60037081e-10,  6.09097537e-03, -9.74867940e-01,\n",
            "         8.55602473e-02, -4.62064818e-05,  1.03804365e-01,\n",
            "         2.26427637e-05, -6.47807086e-04, -8.94806445e-01,\n",
            "        -1.84327253e-09, -7.85676762e-03,  2.94830650e-03,\n",
            "        -2.35135378e-08, -2.08391815e-01,  7.79198527e-01,\n",
            "         2.72026406e-13,  4.42386903e-02, -6.90581503e-09,\n",
            "        -9.57070151e-04]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 5.31280947e+00,  1.12313156e+01, -1.22568679e+00,\n",
            "        -2.08390498e+00,  2.51942873e+00, -3.31546664e+00,\n",
            "        -4.88985062e+00, -1.26596556e+01, -3.14832658e-01,\n",
            "         1.14018955e+01,  1.02957773e+00,  1.23630943e+01,\n",
            "         3.17984629e+00, -2.46955013e+00, -1.18002920e+01,\n",
            "        -5.69333744e+00, -1.11799822e+01, -6.86204624e+00,\n",
            "        -3.02143264e+00,  1.81913531e+00, -2.32249737e+00,\n",
            "        -1.07688465e+01, -5.55923700e-01, -1.23992224e+01,\n",
            "        -1.21424351e+01,  1.91495860e+00, -1.80262399e+00,\n",
            "         8.73043633e+00,  2.92750120e+00, -4.52995300e+00,\n",
            "        -6.14510202e+00,  1.09401932e+01,  3.28608894e+00,\n",
            "        -5.42677355e+00, -1.11553848e+00, -1.11413498e+01,\n",
            "        -1.64411676e+00, -1.17911367e+01,  7.90657187e+00,\n",
            "         1.54193270e+00,  1.61310732e-01,  2.09661245e+00,\n",
            "        -6.75411081e+00, -1.28547068e+01, -2.79173303e+00,\n",
            "        -2.46971583e+00,  3.95020103e+00,  3.44912457e+00,\n",
            "         2.83535886e+00,  9.72894478e+00,  1.00641227e+00,\n",
            "         1.73646104e+00,  3.27023339e+00,  1.78593826e+00,\n",
            "         2.30635023e+00,  1.12114611e+01,  1.48731732e+00,\n",
            "        -1.20506258e+01,  5.24571419e-01,  1.12601767e+01,\n",
            "        -1.18807817e+00, -6.09265044e-02, -2.99033046e+00,\n",
            "         3.94336963e+00,  1.11388960e+01,  1.27675476e+01,\n",
            "         3.58489776e+00,  2.99361062e+00,  2.65517807e+00,\n",
            "        -7.54185021e-02,  1.00217021e+00,  8.52760792e+00,\n",
            "        -1.56508291e+00,  5.67982864e+00, -4.07436323e+00,\n",
            "        -1.87902987e+00,  2.68541360e+00,  5.24259329e+00,\n",
            "        -2.03374124e+00, -5.83481693e+00, -7.47353137e-02,\n",
            "        -3.00320697e+00,  4.55010462e+00,  7.64436722e-02,\n",
            "        -2.97492766e+00,  5.96835661e+00, -4.73765945e+00,\n",
            "         2.95624447e+00,  1.08203900e+00,  5.89007661e-02,\n",
            "         6.48226023e+00, -7.13106215e-01,  7.07153380e-01,\n",
            "        -3.73800778e+00, -1.27953033e+01, -6.92857790e+00,\n",
            "         2.83500767e+00, -1.85832083e+00, -2.12119198e+00,\n",
            "         1.33051860e+00,  1.77496135e+00,  9.68445659e-01,\n",
            "        -1.38361633e+00, -8.14622784e+00, -2.34817839e+00,\n",
            "         3.43557119e+00,  6.59028149e+00,  3.16445422e+00,\n",
            "         5.93791008e+00,  2.50756478e+00,  2.98305368e+00,\n",
            "        -9.09957469e-01,  3.88822269e+00, -1.12509930e+00,\n",
            "         2.74699187e+00,  2.32473612e+00,  1.81124556e+00,\n",
            "        -1.19289169e+01,  8.72423458e+00, -2.75902152e+00,\n",
            "        -1.16047192e+01, -2.32688189e+00,  3.16765094e+00,\n",
            "        -1.09893885e+01,  4.19161892e+00,  1.26436663e+01,\n",
            "         1.15068731e+01, -3.88529992e+00,  1.24106932e+01,\n",
            "         2.98389077e+00, -3.52130032e+00, -5.34082234e-01,\n",
            "        -2.79493713e+00,  4.87960577e+00,  3.28773117e+00,\n",
            "         1.25251043e+00, -1.44552684e+00, -3.27107930e+00,\n",
            "         9.99822378e-01,  6.10951841e-01,  1.65070844e+00,\n",
            "         2.61144614e+00,  4.26928282e+00, -4.09308529e+00,\n",
            "         1.00243700e+00, -8.42996597e+00, -2.07979631e+00,\n",
            "        -1.77013695e+00,  3.00239015e+00,  1.51493943e+00,\n",
            "         6.21374846e+00,  3.42828107e+00,  1.09773785e-01,\n",
            "        -2.77746129e+00, -3.81435418e+00, -4.98718500e+00,\n",
            "         7.44714451e+00,  7.23657787e-01, -4.75747967e+00,\n",
            "        -6.32971144e+00,  9.04255867e+00,  1.25452662e+01,\n",
            "         2.44158902e-03,  1.23401809e+00,  3.03636003e+00,\n",
            "         1.52642682e-01,  1.99284923e+00, -2.35782599e+00,\n",
            "        -5.12450695e-01, -6.84727550e-01, -4.38018513e+00,\n",
            "        -6.67839706e-01,  2.00768614e+00,  1.28358164e+01,\n",
            "         4.30760002e+00,  4.38944149e+00, -3.20430422e+00,\n",
            "        -4.17331934e-01, -2.99527860e+00,  6.27113485e+00,\n",
            "         1.35894573e+00,  1.38179493e+00, -1.12987690e+01,\n",
            "        -3.00731969e+00, -1.11084914e+00,  3.45569587e+00,\n",
            "        -8.01993012e-01, -1.40055323e+00, -8.87521935e+00,\n",
            "        -1.65349770e+00, -4.47211313e+00,  2.17407823e+00,\n",
            "         4.25578022e+00, -2.22209835e+00,  1.20758104e+00,\n",
            "        -3.03677487e+00,  1.75964975e+00,  1.65652072e+00,\n",
            "        -1.05417719e+01, -2.98653698e+00,  6.86136198e+00,\n",
            "        -2.88398743e+00,  2.40956640e+00,  3.14652896e+00,\n",
            "        -4.88204765e+00,  1.39807597e-01,  3.13158655e+00,\n",
            "        -1.25036173e+01,  8.66894722e+00, -4.03785658e+00,\n",
            "         4.18909025e+00, -3.31352353e+00,  1.66290209e-01,\n",
            "         4.09151697e+00, -8.61321163e+00,  3.99696589e+00,\n",
            "         5.47678649e-01,  4.03329253e-01, -4.05343723e+00,\n",
            "         5.54693103e-01,  2.71954703e+00,  3.02322030e+00,\n",
            "         1.10291758e+01,  1.52439690e+00,  1.20638237e+01,\n",
            "        -1.85288125e-04,  1.18920434e+00, -9.25846338e-01,\n",
            "         3.00853300e+00, -2.32303157e-01, -3.76793814e+00,\n",
            "         5.74218464e+00,  1.81982005e+00,  2.23053670e+00,\n",
            "        -1.25908293e-02,  1.59584081e+00, -3.22010660e+00,\n",
            "        -5.84771442e+00,  3.52251339e+00, -2.20861745e+00,\n",
            "         8.44048858e-01, -1.05454803e+00,  5.06636858e+00,\n",
            "         3.01107407e+00, -6.70702040e-01, -1.44768238e+00,\n",
            "        -8.81624889e+00, -1.29195404e+01,  2.95248860e-03,\n",
            "        -3.60941339e+00, -1.90717304e+00,  1.04339778e+00,\n",
            "         5.40742493e+00,  6.94307208e-01, -1.69672561e+00,\n",
            "        -1.17911139e+01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 8.8859932e-05,  1.2585366e-03, -3.4027132e-01, -1.3793893e-04,\n",
            "         9.9448168e-01, -5.3855325e-03, -5.3851742e-02, -9.3676208e-05,\n",
            "        -8.6244369e-01,  9.8098979e-05,  9.1503441e-01,  1.8362640e-06,\n",
            "         9.9453205e-01, -6.0956769e-02, -2.2474122e-03, -4.5926001e-07,\n",
            "        -6.2432292e-08, -9.1411167e-01, -3.2230768e-02,  2.7839261e-01,\n",
            "        -1.1276513e-03, -9.4782367e-02, -5.8818030e-01, -6.2531889e-03,\n",
            "        -4.8491052e-05,  1.7417154e-03, -9.3513727e-01,  3.4898434e-10,\n",
            "         3.9970091e-06, -2.2360509e-05, -9.9923694e-01,  1.3412803e-01,\n",
            "         9.9324805e-01, -1.5595099e-07, -3.7910565e-04, -6.1382401e-01,\n",
            "         2.7362510e-04, -1.3276377e-03,  9.4705445e-01,  1.7257310e-07,\n",
            "         5.6379807e-01,  7.9353034e-01, -4.0947724e-04, -2.0333394e-04,\n",
            "        -7.2206867e-01, -9.0664274e-01,  1.8807228e-05,  8.2268534e-06,\n",
            "         1.0635455e-03,  9.9995077e-01,  1.7181759e-06,  6.3637465e-01,\n",
            "         1.7217287e-06,  9.6395570e-01,  3.7318904e-02,  4.8712478e-04,\n",
            "         6.6586123e-05, -1.0221950e-06,  4.5488992e-01,  6.8952227e-01,\n",
            "        -3.8312903e-01, -3.5831732e-01, -1.2867340e-02,  9.1981940e-07,\n",
            "         9.9835002e-01,  9.3060917e-01,  9.9738210e-01,  4.5711943e-03,\n",
            "         7.6833076e-04, -7.9000372e-01,  4.8150931e-04,  9.3220621e-03,\n",
            "        -9.8740155e-01,  9.4206780e-01, -4.5037046e-07, -9.8547828e-01,\n",
            "         5.7388121e-07,  7.1611965e-01, -7.7584235e-07, -3.3745891e-01,\n",
            "        -2.4731295e-02, -1.5507830e-07,  1.6670514e-04, -9.3505565e-05,\n",
            "        -8.4953666e-05,  7.8762736e-04, -2.2196618e-03,  5.1659390e-02,\n",
            "         5.0992835e-01,  1.5380540e-03,  2.4619116e-03, -1.7768018e-01,\n",
            "         7.5810023e-02, -1.7153148e-05, -2.8279168e-03, -3.0950349e-04,\n",
            "         9.9839103e-01, -1.8181209e-01, -7.4489230e-01,  8.9584905e-01,\n",
            "         9.4419187e-01,  1.9915149e-01, -9.7834009e-01, -9.8788732e-01,\n",
            "        -1.7065647e-04,  8.3017677e-01,  9.9944931e-01,  9.9882209e-01,\n",
            "         2.9624188e-01,  7.9526817e-03,  9.9918216e-01, -9.3635023e-01,\n",
            "         1.1110497e-02, -2.7530016e-03,  3.1379128e-01,  3.4018528e-01,\n",
            "         8.0625361e-01, -8.3867627e-01,  9.8364975e-04,  4.9328077e-01,\n",
            "        -6.1286154e-09, -1.0490948e-04,  1.0102150e-09, -5.3753030e-01,\n",
            "         9.9464083e-01,  3.1462497e-07,  7.7709711e-07, -9.6450174e-01,\n",
            "         7.2152340e-03,  3.7197247e-01, -1.1546656e-07,  3.6101210e-01,\n",
            "        -6.4658010e-01,  6.1776370e-02,  9.9826580e-01,  1.9524987e-04,\n",
            "        -1.7520396e-01, -2.3894127e-02,  9.3304038e-01,  2.1656585e-04,\n",
            "         1.8124053e-09,  9.6067454e-04,  1.0845691e-06, -2.3103312e-02,\n",
            "         4.5109697e-04, -6.4558641e-04,  3.5283676e-01, -7.7320701e-01,\n",
            "         9.9920225e-01,  9.0707469e-01,  2.4706932e-07,  7.6988322e-01,\n",
            "         3.1794044e-01, -4.4481009e-02, -4.0573493e-02, -5.5563305e-08,\n",
            "         1.1176995e-09,  4.5765802e-01, -9.7053828e-07, -1.9644475e-02,\n",
            "         8.4487897e-01,  3.6018202e-05,  4.9851416e-03,  3.1398080e-02,\n",
            "         2.1658418e-01,  6.9468397e-01,  2.0237072e-01, -9.6747100e-01,\n",
            "        -7.6144809e-01,  5.7069592e-06, -4.6654833e-03, -5.6124026e-01,\n",
            "         6.7425109e-02,  2.8857880e-03,  5.0404051e-04,  9.9428982e-01,\n",
            "        -9.7816598e-01, -7.1456146e-01, -8.6244530e-05,  9.5467943e-01,\n",
            "         5.3589447e-05,  3.9010295e-01, -2.4948238e-10, -1.2930809e-03,\n",
            "        -7.4439658e-06,  8.5040682e-07, -7.0766867e-03, -6.0471821e-01,\n",
            "        -9.9998462e-01, -2.9784469e-03, -9.9407500e-03,  1.0324046e-08,\n",
            "         5.0988609e-01, -7.6769930e-01,  5.0557934e-02, -9.9470371e-01,\n",
            "         4.9383348e-01,  9.0933901e-01, -1.4868372e-07, -6.3344252e-01,\n",
            "         9.4835907e-01,  1.4489618e-10,  3.2114140e-06,  9.9872553e-01,\n",
            "        -1.9015269e-10, -4.3032163e-01,  9.7250694e-01, -9.9999309e-01,\n",
            "         8.8605213e-01, -9.5687783e-01,  6.3039280e-02, -9.3293971e-01,\n",
            "         5.5552996e-06,  2.2678860e-06, -9.9695832e-01,  9.9394994e-04,\n",
            "         2.2491833e-04,  8.5199583e-01, -3.9069095e-01, -4.0454623e-01,\n",
            "         1.1695623e-03,  9.8265761e-01,  3.8807720e-04,  8.0741527e-05,\n",
            "         6.5343347e-03, -3.0407531e-04,  9.7365063e-01,  9.3522161e-02,\n",
            "         9.8238757e-04, -6.7100495e-01, -6.1148077e-01,  8.4154658e-07,\n",
            "         8.9627105e-01,  9.9618286e-01, -6.8212040e-02,  5.3751838e-01,\n",
            "        -3.2261021e-02, -1.3504027e-01,  1.9919691e-03, -9.8233223e-01,\n",
            "        -6.2944331e-05, -2.3324259e-10,  3.3989105e-05,  1.0822967e-08,\n",
            "         3.0566975e-01, -5.6826803e-03, -2.7411533e-08, -2.3395944e-02,\n",
            "         1.1148414e-04, -4.9858620e-05, -4.2297506e-01,  8.2165045e-01,\n",
            "         4.2076284e-04,  3.8585615e-05, -1.1989481e-02, -2.0674658e-04]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 5.96558952e+00,  1.22158918e+01, -6.50705576e-01,\n",
            "        -2.75354481e+00,  2.96199918e+00, -8.41290414e-01,\n",
            "        -5.88758755e+00, -1.27318001e+01, -1.30280674e+00,\n",
            "         1.14663601e+01,  1.80878568e+00,  1.32439499e+01,\n",
            "         4.12702942e+00, -6.74262196e-02, -1.20502605e+01,\n",
            "        -6.49870491e+00, -9.04430008e+00, -5.76885176e+00,\n",
            "        -4.01102781e+00,  8.35022211e-01, -2.86986852e+00,\n",
            "        -1.02630491e+01, -6.74879253e-01, -1.18335714e+01,\n",
            "        -1.28697481e+01,  1.96608696e-02, -1.69815361e+00,\n",
            "         7.13474798e+00,  2.86992645e+00, -5.52617073e+00,\n",
            "        -5.22204351e+00,  1.15577583e+01,  3.71158886e+00,\n",
            "        -6.01750851e+00, -2.00044131e+00, -1.04214840e+01,\n",
            "         3.57027590e-01, -1.21807146e+01,  8.90363789e+00,\n",
            "         4.41095978e-01,  8.36968124e-01,  2.87524772e+00,\n",
            "        -2.73434258e+00, -1.33606062e+01, -3.65257597e+00,\n",
            "        -1.50959277e+00,  4.25377655e+00,  1.09959674e+00,\n",
            "         3.24829602e+00,  1.02051239e+01,  9.75848019e-01,\n",
            "         7.52275944e-01,  3.82603383e+00,  2.72797251e+00,\n",
            "         2.42424393e+00,  1.17772789e+01,  2.39575911e+00,\n",
            "        -1.23294029e+01,  4.90931988e-01,  1.07064829e+01,\n",
            "        -2.07432246e+00, -3.75054181e-01, -3.71744347e+00,\n",
            "         4.93099356e+00,  1.21026392e+01,  1.18200598e+01,\n",
            "         3.31860709e+00,  2.87414312e+00,  3.15957618e+00,\n",
            "        -1.07144237e+00,  1.68210459e+00,  9.19118118e+00,\n",
            "        -2.53660655e+00,  4.68210983e+00, -1.77303758e-02,\n",
            "        -2.48386955e+00,  2.82036757e+00,  4.47896719e+00,\n",
            "        -2.14138341e+00, -6.39738750e+00, -7.48646036e-02,\n",
            "        -2.82188225e+00,  4.52051640e+00, -4.45887208e-01,\n",
            "        -3.96292996e+00,  6.86620092e+00, -2.10750961e+00,\n",
            "         3.79262900e+00,  5.81880033e-01,  1.74788909e-03,\n",
            "         7.37222528e+00, -1.56270313e+00,  3.45537156e-01,\n",
            "        -4.72736788e+00, -1.36952610e+01, -7.66248894e+00,\n",
            "         3.68227696e+00, -8.55416000e-01, -1.41865730e+00,\n",
            "         2.07731795e+00,  1.77541709e+00,  2.01848879e-01,\n",
            "        -2.36489797e+00, -7.17120552e+00, -1.97702968e+00,\n",
            "         3.65394735e+00,  7.53307676e+00,  4.11112738e+00,\n",
            "         6.85439396e+00,  1.04897869e+00,  3.93397784e+00,\n",
            "        -1.70998693e+00,  4.87395477e+00, -2.03191471e+00,\n",
            "         2.97854185e+00,  2.37498188e+00,  1.11624348e+00,\n",
            "        -1.22909651e+01,  9.70927715e+00,  5.41249275e-01,\n",
            "        -1.14478683e+01, -3.22843623e+00,  3.93925452e+00,\n",
            "        -1.06071720e+01,  3.77762389e+00,  1.30347672e+01,\n",
            "         1.08188610e+01, -2.89997435e+00,  1.27862520e+01,\n",
            "         3.46095181e+00, -3.95757103e+00,  3.79671127e-01,\n",
            "        -1.79519391e+00,  4.88292789e+00,  4.19834423e+00,\n",
            "         1.81135905e+00, -1.43536472e+00, -3.85765696e+00,\n",
            "         1.87764788e+00,  2.32117817e-01,  1.33552444e+00,\n",
            "         3.58686876e+00,  4.51067829e+00, -5.05654860e+00,\n",
            "         3.19079846e-01, -8.56606293e+00,  3.72217894e-01,\n",
            "        -2.24276757e+00,  3.92618394e+00,  1.51114774e+00,\n",
            "         6.27727127e+00,  1.02161753e+00,  3.29356253e-01,\n",
            "        -1.75955093e+00, -3.39174652e+00, -5.90169573e+00,\n",
            "         8.10364056e+00,  1.71947885e+00, -4.79357004e+00,\n",
            "        -7.20931673e+00,  8.04734421e+00,  1.32592125e+01,\n",
            "         4.98637650e-03,  1.36264336e+00,  3.87727857e+00,\n",
            "         8.56952250e-01,  9.96391714e-01, -2.83249855e+00,\n",
            "        -9.99691546e-01,  3.18720818e-01, -3.61527634e+00,\n",
            "        -6.34641945e-01,  2.18291116e+00,  1.27905788e+01,\n",
            "         1.56291401e+00,  4.04316235e+00, -2.26543808e+00,\n",
            "        -9.99696374e-01, -3.93900442e+00,  7.26671934e+00,\n",
            "         2.28328824e+00,  4.11924213e-01, -1.08744869e+01,\n",
            "        -3.96008897e+00, -1.42369950e-02,  4.31750584e+00,\n",
            "        -7.95028150e-01, -2.23536444e+00, -9.87175083e+00,\n",
            "        -2.98153865e-03, -4.52720785e+00,  2.53707767e+00,\n",
            "         9.27226901e-01, -1.46779442e+00,  5.24321832e-02,\n",
            "        -3.03473878e+00,  2.03761721e+00,  1.63739204e+00,\n",
            "        -1.14143362e+01, -3.94378901e+00,  5.86941004e+00,\n",
            "         9.95888472e-01,  2.45848346e+00,  4.14107847e+00,\n",
            "        -5.40837431e+00, -4.60294098e-01,  2.13693714e+00,\n",
            "        -1.34375944e+01,  9.28007221e+00, -4.03722429e+00,\n",
            "         7.47061014e-01, -1.68789351e+00,  1.02836005e-01,\n",
            "         5.03623152e+00, -8.62711334e+00,  3.12181544e+00,\n",
            "         9.34246182e-02,  1.39437366e+00, -1.53757095e+00,\n",
            "        -4.39874619e-01,  2.12805200e+00,  3.02677202e+00,\n",
            "         1.14760571e+01,  2.48693895e+00,  1.30095005e+01,\n",
            "        -1.27426686e-03,  2.16616511e+00,  9.37970951e-02,\n",
            "         2.99454665e+00, -1.23055327e+00, -4.66234398e+00,\n",
            "         6.30944538e+00,  1.51329339e+00,  3.21201730e+00,\n",
            "        -6.84598833e-02,  2.55241704e+00, -2.99376750e+00,\n",
            "        -6.68396330e+00,  2.87181711e+00, -2.37635303e+00,\n",
            "        -1.26089677e-02, -5.77563271e-02,  4.90431833e+00,\n",
            "         6.69013917e-01,  3.15856576e-01, -1.88465901e-02,\n",
            "        -9.68850803e+00, -1.39135008e+01,  2.46840194e-02,\n",
            "        -4.00228834e+00, -4.79685813e-01,  1.16200900e+00,\n",
            "         5.63126135e+00,  6.83374047e-01, -1.97750247e+00,\n",
            "        -1.07940626e+01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.7099302e-08,  3.0938233e-04, -8.3746904e-01, -6.7567562e-06,\n",
            "         2.4798267e-02, -6.3473337e-05, -7.1593279e-01, -4.5242507e-07,\n",
            "        -8.6317617e-01,  6.4319576e-04,  3.7423134e-04,  9.2333991e-08,\n",
            "         1.7055251e-01, -1.1155149e-04, -3.4423858e-02, -1.3147062e-06,\n",
            "        -4.0585378e-06, -6.7179912e-01, -8.1066489e-01,  7.4417669e-01,\n",
            "        -7.8582822e-04, -1.9756468e-05, -6.1785781e-01, -4.6126503e-13,\n",
            "        -1.4097527e-10,  1.6646223e-02, -9.3323708e-01,  2.0973780e-04,\n",
            "         3.8515441e-06, -7.8005884e-05, -9.9985236e-01,  2.2980202e-02,\n",
            "         3.2070951e-05, -4.1454609e-06, -7.6464450e-01, -4.2042395e-01,\n",
            "        -8.5639947e-11, -1.8416686e-04,  1.6770104e-03,  5.8238532e-02,\n",
            "         1.5545368e-02,  8.6266786e-01, -3.2938906e-06, -2.9834810e-10,\n",
            "        -9.6298056e-03, -9.0324807e-01,  8.6811942e-06,  1.1223503e-07,\n",
            "         8.7825006e-01,  1.6794822e-04,  3.1860829e-05,  3.0025724e-01,\n",
            "         7.8920466e-06,  9.9758589e-01,  1.5502174e-02,  9.2601962e-03,\n",
            "         1.6132837e-04, -8.8072261e-09, -7.2211730e-01,  6.9322228e-02,\n",
            "        -2.5531682e-01, -3.7722865e-01, -1.0384064e-03,  2.3572566e-03,\n",
            "         4.8793049e-06,  3.8907960e-02,  9.9736959e-01,  1.4518913e-05,\n",
            "         6.5470899e-06, -8.3091432e-01,  1.4850428e-08,  7.3232793e-04,\n",
            "        -9.1952002e-01,  9.9872601e-01, -5.6456053e-04, -1.3158596e-01,\n",
            "         1.5329407e-08,  9.8417813e-01, -6.0937367e-05, -9.8025627e-02,\n",
            "        -2.6059641e-02, -6.4155832e-03,  1.8632016e-05, -7.6765608e-11,\n",
            "        -7.7284063e-04,  1.7240643e-06, -1.3451275e-05,  1.0379614e-01,\n",
            "         5.1459742e-01, -7.5372887e-01,  1.4023391e-09, -9.1459668e-01,\n",
            "        -4.9887046e-01, -1.0849840e-05, -4.6680748e-04, -4.6061101e-05,\n",
            "         1.9311717e-08, -6.1598338e-02, -2.4004027e-04,  1.6004028e-02,\n",
            "         9.4340819e-01,  1.8639794e-01, -9.7970694e-01, -9.8933023e-01,\n",
            "        -9.9353534e-01,  1.8801586e-01,  1.7413242e-03,  7.9225540e-01,\n",
            "         1.1414072e-05,  2.2621251e-04,  2.8309362e-02, -9.9051684e-01,\n",
            "         9.9083025e-04, -7.3388427e-01,  5.6701458e-05,  8.3029666e-04,\n",
            "         8.0370569e-01, -6.7526810e-02,  5.8484147e-06,  5.4231354e-05,\n",
            "        -8.8764536e-06, -1.4659691e-04,  9.9634451e-01, -9.0594916e-04,\n",
            "         9.2746610e-05,  1.7746788e-05,  7.2022522e-04, -1.6987340e-05,\n",
            "         4.7379158e-06,  6.9240040e-01, -8.0099642e-07,  8.7987339e-01,\n",
            "        -7.9405743e-01,  6.2035415e-06,  2.7942620e-02,  2.6884064e-01,\n",
            "        -6.7900187e-01, -2.4000565e-04, -7.6157963e-01,  1.3005175e-09,\n",
            "         9.8530514e-08,  4.9186008e-05,  8.5797474e-06, -2.6694033e-10,\n",
            "         2.7028938e-05, -1.5979650e-08, -8.7960854e-02, -9.3038982e-01,\n",
            "         1.0105210e-06,  9.0660852e-01,  8.4125990e-01,  5.6699879e-05,\n",
            "         7.9125804e-01, -9.1599500e-01, -9.9867618e-01, -1.4402348e-03,\n",
            "         1.4088956e-10,  8.2181764e-01, -2.6566343e-06, -9.4036502e-04,\n",
            "         4.0518516e-01,  2.8428432e-10,  4.9849064e-03,  9.6289432e-01,\n",
            "         4.6889214e-03,  6.9562542e-01,  2.0061912e-09, -7.9650056e-01,\n",
            "        -9.5933360e-01, -1.9079571e-06, -2.7138811e-02, -5.6073689e-01,\n",
            "         1.5794347e-05,  9.1744450e-06,  2.4916144e-04,  1.3181980e-02,\n",
            "        -8.5939574e-01,  6.2953704e-03, -3.9255108e-05,  1.1733046e-06,\n",
            "         1.2437571e-04,  1.3805553e-04, -3.6365629e-04, -9.3887287e-08,\n",
            "        -2.4388945e-02,  1.9836079e-05, -3.9896287e-02, -2.5340540e-05,\n",
            "        -3.9466550e-03, -2.7622012e-03, -3.1281178e-04,  2.6906779e-11,\n",
            "         1.0949333e-02, -3.1650132e-01, -6.9112176e-01, -9.9793804e-01,\n",
            "         7.8850955e-02,  4.2055713e-04, -1.8590037e-03, -3.8180244e-03,\n",
            "         9.9600285e-01,  1.8124341e-08,  2.3016762e-05,  1.5911044e-01,\n",
            "        -5.5055630e-11, -8.9253283e-01,  9.6227562e-01, -9.4619662e-01,\n",
            "         1.8803821e-05, -4.0920451e-02,  7.8119612e-01, -7.6138217e-04,\n",
            "         8.0120379e-01,  1.6940969e-05, -9.9999982e-01,  1.5662776e-09,\n",
            "         9.0001479e-02,  5.4072190e-02, -5.8080277e-06, -4.1353890e-01,\n",
            "         7.5118201e-08,  2.6806783e-05,  1.9855521e-07,  3.2361067e-06,\n",
            "         5.9492844e-03, -7.9679055e-05,  9.7410524e-01,  1.1042765e-01,\n",
            "         4.6257500e-07, -8.2765895e-01, -9.9775803e-01,  9.8436588e-01,\n",
            "         1.2878345e-01,  8.3989614e-01, -3.6153164e-02,  3.4269535e-03,\n",
            "        -9.9440938e-01, -2.0539731e-10,  3.1111915e-07, -9.9708545e-01,\n",
            "        -9.8362751e-03, -1.8737321e-01,  2.5989878e-01,  8.1976714e-06,\n",
            "         3.0336609e-01,  1.5246745e-02, -9.4282825e-04, -1.5173477e-08,\n",
            "         2.9785767e-01, -1.5534040e-05, -8.1890821e-03,  5.7130110e-01,\n",
            "         5.0125614e-08,  5.9371692e-01, -2.7311468e-02, -1.0189110e-05]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 6.64600325e+00,  1.32150345e+01, -1.22434092e+00,\n",
            "        -3.75168133e+00,  3.00815344e+00, -8.55136275e-01,\n",
            "        -6.32254219e+00, -1.37020416e+01, -1.30567193e+00,\n",
            "         1.14767733e+01,  1.80957782e+00,  1.42428465e+01,\n",
            "         5.12647200e+00, -3.92452292e-02, -1.29535656e+01,\n",
            "        -7.47885704e+00, -9.86206150e+00, -5.04326296e+00,\n",
            "        -5.00932217e+00,  1.00185490e+00, -2.87008524e+00,\n",
            "        -1.03110342e+01, -7.21532643e-01, -1.26997194e+01,\n",
            "        -1.31542082e+01,  1.67854968e-02, -1.68290424e+00,\n",
            "         8.12744808e+00,  3.85369706e+00, -6.52613497e+00,\n",
            "        -5.20982885e+00,  1.15634174e+01,  4.71158266e+00,\n",
            "        -7.01188421e+00, -1.00751626e+00, -1.06042318e+01,\n",
            "        -2.40042031e-01, -1.26953573e+01,  9.90110779e+00,\n",
            "         1.39344168e+00,  3.00013274e-01,  3.87478304e+00,\n",
            "        -3.60598254e+00, -1.43219109e+01, -4.62955141e+00,\n",
            "        -1.50920415e+00,  5.25294161e+00,  2.09536266e+00,\n",
            "         3.22163272e+00,  1.11807203e+01,  1.86539340e+00,\n",
            "         3.09805363e-01,  4.77586317e+00,  3.41725659e+00,\n",
            "         3.42017031e+00,  1.27419033e+01,  3.38895011e+00,\n",
            "        -1.32247725e+01, -9.12055433e-01,  1.16668367e+01,\n",
            "        -2.65537667e+00, -3.97614181e-01, -4.70672226e+00,\n",
            "         5.93097258e+00,  1.31009226e+01,  1.28200598e+01,\n",
            "         3.31834221e+00,  3.87386465e+00,  3.94268560e+00,\n",
            "        -1.23023987e+00,  1.74298751e+00,  9.81305504e+00,\n",
            "        -2.57257390e+00,  3.68079686e+00, -9.96434987e-01,\n",
            "        -9.63841856e-01,  3.64725184e+00,  4.42406416e+00,\n",
            "        -3.10140276e+00, -6.39970160e+00, -1.95555210e-01,\n",
            "        -3.82186437e+00,  5.49880028e+00, -1.55581966e-01,\n",
            "        -4.96219492e+00,  7.86284590e+00, -2.10639763e+00,\n",
            "         4.79226923e+00,  5.68981230e-01, -9.81533170e-01,\n",
            "         8.32500172e+00, -1.55608475e+00, -5.63334048e-01,\n",
            "        -5.72732782e+00, -1.46916828e+01, -8.64939213e+00,\n",
            "         4.68027401e+00, -1.83654881e+00, -2.38904595e+00,\n",
            "         3.02701235e+00,  1.77556837e+00,  1.88602850e-01,\n",
            "        -2.29021621e+00, -7.14060879e+00, -2.97491717e+00,\n",
            "         4.59661818e+00,  8.53242397e+00,  5.11007833e+00,\n",
            "         7.85170126e+00,  1.48880029e+00,  4.56551504e+00,\n",
            "        -2.69513917e+00,  5.86453056e+00, -2.03034067e+00,\n",
            "         3.94227338e+00,  3.37229681e+00,  1.10899174e+00,\n",
            "        -1.23064318e+01,  1.06815281e+01,  1.73137516e-01,\n",
            "        -1.22214289e+01, -4.22843456e+00,  4.93828917e+00,\n",
            "        -1.04519358e+01,  4.73258448e+00,  1.40035877e+01,\n",
            "         1.17767410e+01, -3.00056934e+00,  1.37277069e+01,\n",
            "         3.58718705e+00, -4.95515013e+00,  1.37786829e+00,\n",
            "        -2.07644176e+00,  5.25837374e+00,  5.11567259e+00,\n",
            "         1.82132614e+00, -2.34958768e+00, -4.85691404e+00,\n",
            "        -9.99969900e-01,  7.81701878e-03,  1.30796301e+00,\n",
            "         4.58315754e+00,  5.45632601e+00, -6.05542231e+00,\n",
            "         2.78501242e-01, -9.50791931e+00, -7.90025949e-01,\n",
            "        -3.20665050e+00,  4.47553301e+00,  1.50814188e+00,\n",
            "         7.27698183e+00,  1.03005970e+00,  1.08651984e+00,\n",
            "        -1.73878336e+00, -4.34951973e+00, -6.89795685e+00,\n",
            "         9.09874249e+00,  2.71781826e+00, -4.74669075e+00,\n",
            "        -8.20800114e+00,  7.74751091e+00,  1.39761534e+01,\n",
            "         4.98497952e-03,  2.00176406e+00,  4.08242273e+00,\n",
            "         8.58773887e-01,  1.19523799e+00, -3.82667661e+00,\n",
            "        -1.93821692e+00, -2.67162055e-01, -3.49325705e+00,\n",
            "        -6.33908212e-01,  2.27168894e+00,  1.37286053e+01,\n",
            "         1.58243024e+00,  5.04301500e+00, -3.18451977e+00,\n",
            "         2.20757484e-01, -4.91196918e+00,  7.84211493e+00,\n",
            "         2.47126126e+00,  1.38055620e-04, -1.17535782e+01,\n",
            "        -4.95988464e+00, -1.01400256e+00,  5.29508638e+00,\n",
            "        -7.80527592e-01, -2.27914405e+00, -1.05093613e+01,\n",
            "        -2.76220846e-03, -5.52221346e+00,  2.97857499e+00,\n",
            "         1.92541540e+00, -9.24594522e-01, -9.43173110e-01,\n",
            "        -3.44800568e+00,  3.03683090e+00,  1.64679086e+00,\n",
            "        -1.24143219e+01, -4.93881416e+00,  4.87147236e+00,\n",
            "         1.80106819e+00,  2.45566535e+00,  4.95686007e+00,\n",
            "        -6.39275551e+00, -1.43434978e+00,  1.98717964e+00,\n",
            "        -1.44197474e+01,  9.84643364e+00, -4.08173418e+00,\n",
            "         1.46761549e+00, -2.68067670e+00,  1.10198140e+00,\n",
            "         6.02906370e+00, -8.62719631e+00,  4.12176371e+00,\n",
            "         9.34245437e-02,  2.36267972e+00, -2.53204179e+00,\n",
            "        -4.39872652e-01,  3.09462166e+00,  3.02890682e+00,\n",
            "         1.18286657e+01,  3.48343945e+00,  1.40016108e+01,\n",
            "        -9.25344648e-05,  2.16706061e+00,  1.11011855e-01,\n",
            "         3.69534850e+00, -1.21532917e+00, -4.70232630e+00,\n",
            "         7.30944252e+00,  1.29504219e-01,  4.20896006e+00,\n",
            "        -6.95189685e-02,  2.58425117e+00, -2.99265647e+00,\n",
            "        -7.34718657e+00,  2.94682240e+00, -3.37267566e+00,\n",
            "        -9.98571217e-01, -1.05261862e+00,  5.89870596e+00,\n",
            "         6.74654722e-01,  3.13257307e-01,  1.67972848e-01,\n",
            "        -1.06569891e+01, -1.49129953e+01,  3.17953974e-01,\n",
            "        -4.99731636e+00, -8.59105527e-01,  6.49812698e-01,\n",
            "         6.27911329e+00,  6.83388948e-01, -2.97647810e+00,\n",
            "        -1.17940607e+01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.65655214e-01,  9.99887705e-01, -8.38569760e-01,\n",
            "        -5.56805968e-01,  9.96161938e-01, -7.73794949e-01,\n",
            "        -9.99905884e-01, -7.91776359e-01, -6.40141189e-01,\n",
            "         9.87436831e-01,  8.69048595e-01,  4.67468053e-03,\n",
            "         4.17105248e-03, -4.98782173e-02, -2.54751262e-06,\n",
            "        -1.77512600e-04, -5.83796762e-03, -7.96642721e-01,\n",
            "        -3.27970507e-03,  9.62660015e-01, -1.48574354e-05,\n",
            "        -1.00337908e-01, -8.65517676e-01, -9.99962211e-01,\n",
            "        -3.15233160e-06,  1.38939749e-02, -9.26017880e-01,\n",
            "         5.74577646e-03,  3.73311991e-07, -9.18711603e-01,\n",
            "        -9.99726713e-01,  4.59306180e-01,  9.82219279e-01,\n",
            "        -9.99997020e-01,  2.07108504e-04, -9.95476961e-01,\n",
            "        -1.27142295e-02, -9.98730481e-01,  2.15391396e-03,\n",
            "         1.65674999e-01,  1.01048715e-01,  9.99493420e-01,\n",
            "        -5.42210619e-05, -9.99830246e-01, -4.08892194e-03,\n",
            "        -7.26762176e-01,  5.13754905e-09,  3.85516933e-06,\n",
            "         9.99079883e-01,  1.23363143e-05,  1.38916664e-06,\n",
            "        -5.74410677e-01,  4.37801471e-03,  6.62724197e-01,\n",
            "         8.49032998e-01,  1.96076512e-01,  9.98947322e-01,\n",
            "        -2.04955541e-07,  4.52928156e-01,  4.39107686e-01,\n",
            "        -9.98330891e-01, -1.81155100e-01, -9.92255032e-01,\n",
            "         1.38075518e-09,  9.99912381e-01,  1.87388738e-03,\n",
            "         9.97051299e-01,  8.78256559e-01,  4.88607930e-06,\n",
            "        -5.44398185e-03,  5.65666705e-03,  1.00456749e-03,\n",
            "        -6.14312530e-01,  9.88403201e-01, -2.26428825e-02,\n",
            "        -1.33860677e-01,  9.29549515e-01,  5.92824519e-01,\n",
            "        -3.20977924e-05, -9.89421427e-01, -1.61738157e-01,\n",
            "        -9.98664916e-01,  9.99941409e-01,  2.01388495e-03,\n",
            "        -9.99986529e-01,  2.42674537e-06, -1.27300620e-01,\n",
            "         3.33062803e-06, -3.35264057e-01,  7.44167149e-01,\n",
            "         1.51997854e-04, -2.63465010e-02, -9.14513648e-01,\n",
            "        -1.87905170e-02, -9.01625574e-01, -1.85752846e-02,\n",
            "         9.31476116e-01, -8.81363451e-01, -1.70678177e-04,\n",
            "         7.20381811e-02,  5.39216042e-01, -2.41760954e-01,\n",
            "        -9.72550750e-01, -9.99682546e-01, -1.33213237e-01,\n",
            "         9.90263641e-01,  9.37094092e-02,  1.35544896e-01,\n",
            "         1.02541603e-01,  8.26018720e-08,  6.50092697e-05,\n",
            "        -5.69984436e-01,  6.76321855e-04, -9.92880404e-01,\n",
            "         3.73454714e-05,  9.96999562e-01,  1.02418967e-01,\n",
            "        -9.53441620e-01,  7.47469539e-06,  3.35778207e-01,\n",
            "        -5.06125099e-04, -9.88975942e-01,  6.44241954e-05,\n",
            "        -9.06629145e-01,  8.66180062e-02,  1.17426842e-01,\n",
            "         8.92301559e-01, -9.83995318e-01,  3.02831968e-03,\n",
            "         4.72202203e-07, -9.32730152e-04,  3.44755175e-03,\n",
            "        -7.33422816e-01,  9.70610380e-01,  5.74054539e-01,\n",
            "         7.82874107e-01, -4.47123587e-01, -1.36629751e-06,\n",
            "         6.62699759e-01,  8.52385350e-03,  2.78810203e-01,\n",
            "         2.12453562e-03,  7.38080757e-07, -6.39717340e-01,\n",
            "         1.53114134e-02, -6.24236360e-04, -5.15124679e-01,\n",
            "        -3.39729153e-02,  2.55291288e-05,  8.99167180e-01,\n",
            "         1.93404080e-03,  9.63360727e-01,  3.80713791e-01,\n",
            "        -7.15242445e-01, -6.94111645e-01, -4.31511580e-06,\n",
            "         3.08248082e-06,  4.22905060e-03, -8.80901498e-05,\n",
            "        -2.06489936e-02,  9.75266814e-01,  9.22031086e-06,\n",
            "         8.68258774e-02,  9.71777201e-01,  3.67506524e-04,\n",
            "         9.25462902e-01,  1.22553306e-02, -1.06293805e-01,\n",
            "        -9.78054285e-01, -2.93221765e-05, -9.99703467e-01,\n",
            "        -1.42632902e-01,  1.95443077e-04,  3.43690976e-04,\n",
            "         2.84210593e-03,  4.86064821e-01, -9.99354720e-01,\n",
            "        -3.14040154e-01, -9.30950161e-09,  3.35715558e-05,\n",
            "         2.37698689e-01,  7.42660314e-02, -3.93263035e-04,\n",
            "        -2.13284772e-02, -1.80963036e-02,  2.02565581e-01,\n",
            "        -2.98581109e-03, -1.13350085e-04, -9.99898314e-01,\n",
            "        -1.86710487e-04, -9.99993801e-01,  2.49006739e-03,\n",
            "         4.29853708e-06, -7.43093491e-01, -1.14565669e-02,\n",
            "        -9.41377699e-01,  1.18555059e-03,  9.03513372e-01,\n",
            "        -1.11086434e-02, -1.15809758e-04,  9.99183416e-01,\n",
            "         3.28643061e-02,  7.28821105e-05,  8.83125007e-01,\n",
            "        -1.97649794e-03, -8.50800395e-01,  7.63912678e-01,\n",
            "        -9.99632597e-01,  1.84991241e-01, -3.12106968e-05,\n",
            "         9.33989346e-01, -1.02063276e-01,  9.18445051e-01,\n",
            "         8.97529781e-01, -4.76732433e-01,  3.96934301e-01,\n",
            "         7.95216262e-02,  5.69893658e-01, -9.77911353e-01,\n",
            "        -4.55235153e-01,  5.66431321e-04,  8.17400455e-01,\n",
            "         2.70730787e-04,  2.48905225e-03,  6.45467341e-01,\n",
            "        -6.62090431e-04,  9.67672825e-01,  1.54311970e-01,\n",
            "         4.24597878e-03, -9.69301701e-01, -9.99242306e-01,\n",
            "         1.03822080e-02,  6.75181866e-01,  9.52925622e-01,\n",
            "        -6.31961882e-01,  9.97429192e-01, -5.90233028e-01,\n",
            "        -5.59254706e-01,  8.70052695e-01, -4.61728536e-02,\n",
            "        -7.94286316e-04, -4.43575382e-02,  2.28799345e-05,\n",
            "         6.87992419e-09,  3.64207029e-01,  2.30198043e-06,\n",
            "        -1.78566739e-01, -1.00000000e+00,  6.43885881e-02,\n",
            "        -4.11392888e-04, -1.19472003e-04, -3.18182439e-01,\n",
            "         2.07638688e-04,  4.10456050e-06, -9.46440756e-01,\n",
            "        -1.31327631e-02]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 7.62242031e+00,  1.41955700e+01, -1.21648371e+00,\n",
            "        -4.67424345e+00,  3.12751722e+00, -1.04433632e+00,\n",
            "        -7.31488848e+00, -1.45557489e+01, -1.49405062e+00,\n",
            "         1.18551054e+01,  1.89739990e+00,  1.52000227e+01,\n",
            "         6.10886097e+00, -9.90030944e-01, -1.38606949e+01,\n",
            "        -8.42754078e+00, -1.07802515e+01, -3.83962297e+00,\n",
            "        -6.00794125e+00,  1.99794328e+00, -3.81590366e+00,\n",
            "        -1.02054853e+01, -1.31493235e+00, -1.36104841e+01,\n",
            "        -1.41169796e+01,  1.41424239e-02, -1.63067901e+00,\n",
            "         9.04522228e+00,  4.18502998e+00, -7.51635790e+00,\n",
            "        -5.19818497e+00,  1.16011705e+01,  5.69275951e+00,\n",
            "        -7.99780512e+00,  2.08844198e-03, -1.15453691e+01,\n",
            "        -1.07894218e+00, -1.36948853e+01,  1.08868198e+01,\n",
            "         1.67374626e-01,  3.02522063e-01,  4.87246227e+00,\n",
            "        -3.61846232e+00, -1.52338161e+01, -5.60723305e+00,\n",
            "        -1.50600886e+00,  5.50008535e+00,  3.06976676e+00,\n",
            "         4.21062231e+00,  1.20570869e+01,  2.56255126e+00,\n",
            "        -6.73688531e-01,  5.73631287e+00,  3.89570212e+00,\n",
            "         4.31273270e+00,  1.36567144e+01,  4.37894869e+00,\n",
            "        -1.40922947e+01,  9.48335826e-01,  1.25870361e+01,\n",
            "        -3.64760590e+00, -1.85061246e-01, -5.69076347e+00,\n",
            "         6.92629766e+00,  1.21329746e+01,  1.38170500e+01,\n",
            "         3.31468987e+00,  3.29464555e+00,  3.89870119e+00,\n",
            "        -1.32007277e+00,  2.73589396e+00,  1.07407084e+01,\n",
            "        -2.99066162e+00,  2.85837674e+00, -1.38904467e-01,\n",
            "        -1.34668916e-01,  3.62787223e+00,  3.43178964e+00,\n",
            "        -2.10231709e+00, -7.16184855e+00, -6.59368873e-01,\n",
            "        -4.82169390e+00,  6.31962204e+00,  7.76660979e-01,\n",
            "        -5.95903444e+00,  8.83587456e+00, -2.10861611e+00,\n",
            "         5.77350950e+00, -3.58978838e-01,  9.97141361e-01,\n",
            "         9.30497551e+00, -2.06690550e-01, -1.56049931e+00,\n",
            "        -6.21893787e+00, -1.54077425e+01, -8.14252090e+00,\n",
            "         4.83437681e+00, -2.83246994e+00, -2.38340592e+00,\n",
            "         4.02627134e+00,  1.28026128e+00, -2.46643782e-01,\n",
            "        -2.14497972e+00, -6.15625477e+00, -3.95596242e+00,\n",
            "         4.80341053e+00,  9.53024387e+00,  5.08652782e+00,\n",
            "         8.85121155e+00,  2.27150965e+00,  3.56639123e+00,\n",
            "        -2.61275458e+00,  5.57860661e+00, -3.02556372e+00,\n",
            "         3.97691369e+00,  4.36713982e+00,  1.02781974e-01,\n",
            "        -1.23239965e+01,  1.16562042e+01,  3.49694431e-01,\n",
            "        -1.30117006e+01, -5.21825933e+00,  5.62541485e+00,\n",
            "        -1.08937902e+01,  5.71501446e+00,  1.49454641e+01,\n",
            "         1.25916758e+01, -3.57231879e+00,  1.44355125e+01,\n",
            "         3.94830775e+00, -5.91165638e+00,  2.37123799e+00,\n",
            "        -1.22943187e+00,  5.29159355e+00,  1.05310035e+00,\n",
            "         2.55393291e+00, -3.34089899e+00, -5.82583094e+00,\n",
            "         7.97612369e-01,  2.34581120e-02,  2.28116465e+00,\n",
            "         4.37874031e+00,  6.41404486e+00, -7.05105305e+00,\n",
            "         1.14243269e+00, -9.18568134e+00, -1.02050257e+00,\n",
            "        -4.14220572e+00,  4.47607279e+00,  1.47348392e+00,\n",
            "         7.27780199e+00,  1.99066675e+00,  9.53395844e-01,\n",
            "        -1.01071537e+00, -3.32439756e+00, -7.85953426e+00,\n",
            "         1.00218430e+01,  3.43982601e+00, -5.26308727e+00,\n",
            "        -7.95565271e+00,  6.74758959e+00,  1.41415606e+01,\n",
            "         9.28683206e-02,  2.34520149e+00,  3.05678797e+00,\n",
            "         1.62582171e+00,  1.95408449e-01, -4.81859064e+00,\n",
            "        -2.52683854e+00, -1.72960028e-01, -4.44376898e+00,\n",
            "        -6.30689025e-01,  2.57761860e+00,  1.44869089e+01,\n",
            "         1.32873058e+00,  5.44252682e+00, -4.01933718e+00,\n",
            "        -3.27895641e-01, -5.81521654e+00,  8.83913231e+00,\n",
            "         3.15575004e+00,  7.44031221e-02, -1.26565742e+01,\n",
            "        -5.95081758e+00, -2.01269889e+00,  6.28945541e+00,\n",
            "        -1.62939286e+00, -2.11498594e+00, -1.12151499e+01,\n",
            "        -1.86727761e-04, -6.47517252e+00,  3.93370771e+00,\n",
            "         2.00032091e+00, -1.00096262e+00, -1.93056834e+00,\n",
            "        -2.42960334e+00,  3.09813905e+00,  1.54644823e+00,\n",
            "        -1.34142008e+01, -5.91663551e+00,  4.14600897e+00,\n",
            "         3.28763910e-02,  2.53754926e+00,  1.38979137e+00,\n",
            "        -7.39256954e+00, -1.25904489e+00,  1.00636852e+00,\n",
            "        -1.53899069e+01,  9.51436615e+00, -4.85173941e+00,\n",
            "         1.68878114e+00, -1.43669796e+00,  1.58106160e+00,\n",
            "         6.97509193e+00, -8.74285316e+00,  3.86737204e+00,\n",
            "         7.96913132e-02,  2.84286690e+00, -2.64056563e+00,\n",
            "        -4.91287053e-01,  4.09261084e+00,  3.03441596e+00,\n",
            "         1.27497416e+01,  4.48045158e+00,  1.48569365e+01,\n",
            "        -6.64806517e-04,  2.09875202e+00,  1.59302011e-01,\n",
            "         4.68053818e+00, -2.08092713e+00, -5.01846313e+00,\n",
            "         8.30943584e+00,  8.25482488e-01,  5.12774324e+00,\n",
            "        -8.29497874e-01,  3.32860899e+00, -3.75332761e+00,\n",
            "        -8.31647778e+00,  2.81551456e+00, -4.09066820e+00,\n",
            "        -2.95667738e-01, -2.01625848e+00,  6.89481735e+00,\n",
            "         1.66408670e+00,  3.81949186e-01,  1.28475740e-03,\n",
            "        -1.15924854e+01, -1.27078066e+01,  1.78976327e-01,\n",
            "        -5.96753883e+00, -4.07799496e-04, -3.32093775e-01,\n",
            "         6.90486145e+00,  8.24870467e-01, -3.85953689e+00,\n",
            "        -1.27939901e+01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 6.26563690e-08,  1.10117720e-12, -8.37621093e-01,\n",
            "        -5.41615054e-06,  9.99189377e-01, -5.03121953e-07,\n",
            "        -1.77555218e-01, -1.07424093e-07, -9.81817603e-01,\n",
            "         4.64083069e-12,  3.08204726e-05,  5.29112458e-06,\n",
            "         3.16343375e-07, -4.85437777e-05, -5.62695277e-08,\n",
            "        -6.94578716e-07, -4.46249737e-15, -9.92814422e-01,\n",
            "        -7.73423351e-03,  9.92618978e-01, -8.04153737e-04,\n",
            "        -1.02604728e-03, -8.65731776e-01, -5.65584746e-10,\n",
            "        -1.16658711e-07,  5.29874563e-01, -9.26068842e-01,\n",
            "         1.38186832e-11,  1.27764593e-04, -1.13146548e-09,\n",
            "        -9.99549985e-01,  9.48404908e-01,  1.66536243e-10,\n",
            "        -9.83982801e-01, -7.43985534e-01, -3.08866482e-02,\n",
            "        -2.47272908e-07, -6.43570672e-08,  6.43946834e-08,\n",
            "         6.21819538e-08,  8.55823100e-01,  9.99356985e-01,\n",
            "        -1.74019354e-09, -2.62705916e-12, -9.99996364e-01,\n",
            "        -4.67008024e-01,  3.45338748e-07,  1.46869825e-05,\n",
            "         7.86703229e-01,  2.43505533e-03,  2.24633112e-08,\n",
            "        -7.22501397e-01,  7.39423604e-06,  8.43939960e-01,\n",
            "         9.45590557e-08,  4.04373743e-03,  9.99818027e-01,\n",
            "        -1.92546030e-03,  9.50234950e-01,  1.08469438e-04,\n",
            "        -7.19008684e-01, -1.84469834e-01, -9.34095851e-07,\n",
            "         2.89085875e-08,  1.72128342e-02,  4.49793624e-05,\n",
            "         9.94903088e-01,  2.42911528e-06,  7.18041410e-05,\n",
            "        -7.77206659e-01,  1.72029200e-08,  3.09830485e-03,\n",
            "        -1.24670984e-03,  9.52586889e-01, -7.72606552e-01,\n",
            "        -1.59887657e-01,  1.84582705e-09,  7.54334450e-01,\n",
            "        -7.89952992e-09, -9.99999762e-01, -5.97424865e-01,\n",
            "        -2.41298804e-11,  7.15702015e-04, -1.37234417e-06,\n",
            "        -1.70311161e-08,  4.48198978e-10, -8.79113429e-07,\n",
            "         4.90797043e-04, -3.97654176e-01, -1.18474767e-03,\n",
            "         1.63426634e-07, -1.32187421e-03, -1.35021537e-06,\n",
            "        -4.64182303e-05, -1.80133721e-08, -1.38698601e-11,\n",
            "         1.79688461e-04, -9.49950814e-01, -1.75207388e-05,\n",
            "         4.02107823e-08,  8.53762507e-01, -8.41988862e-01,\n",
            "        -8.35609138e-01, -9.99929845e-01, -1.50481901e-11,\n",
            "         8.34297836e-01,  9.63739311e-09,  5.80809057e-01,\n",
            "         8.80385995e-01,  1.21737330e-05,  1.72471211e-08,\n",
            "        -3.10557425e-01,  9.32863474e-01, -9.03530233e-03,\n",
            "         1.15469351e-01,  2.78801890e-04, -6.61095858e-01,\n",
            "        -9.99999285e-01,  7.62970827e-04, -1.05942572e-05,\n",
            "        -4.35760921e-06, -2.67439873e-06,  2.01030934e-06,\n",
            "        -1.53901234e-01,  3.85391031e-05,  1.46846094e-11,\n",
            "         9.43670670e-08, -9.87022340e-01,  9.97759581e-01,\n",
            "         2.51529901e-03, -3.01244418e-10,  8.06999877e-02,\n",
            "        -2.64699608e-02,  1.07395381e-09,  9.67589855e-01,\n",
            "         3.36984840e-06, -8.27289914e-05, -6.21565091e-11,\n",
            "         7.24982083e-01,  1.21493906e-06,  8.84137918e-08,\n",
            "         4.67765029e-04,  2.06947703e-08, -2.57708568e-13,\n",
            "         9.54144239e-01, -3.47565333e-06, -8.67486000e-01,\n",
            "        -3.71983901e-06,  8.10668290e-01,  9.00238395e-01,\n",
            "         1.83365832e-03,  1.90359596e-02,  9.60289061e-01,\n",
            "        -3.42186308e-03, -9.85891402e-01, -4.79534745e-10,\n",
            "         9.81103182e-01,  9.93249714e-01, -4.86804564e-12,\n",
            "        -8.38125089e-08,  9.99793828e-01,  5.09934721e-18,\n",
            "         9.25962552e-02,  1.37661591e-01,  5.54727320e-10,\n",
            "         9.13698673e-01,  1.48785357e-08, -7.82148074e-03,\n",
            "        -6.02237089e-03, -1.10410117e-02, -3.40078846e-02,\n",
            "        -5.57651758e-01,  1.62181694e-12,  8.13798862e-10,\n",
            "         7.75691973e-08,  9.99994874e-01, -3.63135086e-08,\n",
            "         1.95420325e-01, -9.44829495e-08,  2.91005918e-03,\n",
            "         1.25040655e-14,  7.36302733e-01, -7.26107161e-11,\n",
            "        -1.12613544e-01, -4.52419464e-03,  2.50687604e-09,\n",
            "        -1.00724446e-06, -3.54873296e-03, -4.14772163e-04,\n",
            "        -7.60751307e-01, -9.89695847e-01,  2.09870283e-03,\n",
            "         9.94320571e-01, -1.22401398e-03, -1.62577704e-02,\n",
            "        -9.05752301e-01,  4.38961713e-03,  4.34419380e-05,\n",
            "        -4.63010605e-14, -9.66780543e-01,  7.02956855e-01,\n",
            "        -9.93074641e-14,  9.98302817e-01,  3.07245642e-07,\n",
            "        -1.71946901e-09, -9.58494663e-01,  7.45530427e-03,\n",
            "        -9.99835849e-01,  6.62369002e-03, -1.51823377e-04,\n",
            "         9.86024082e-01, -3.80913225e-05,  1.27310991e-01,\n",
            "         3.68293070e-13, -4.74677421e-03,  3.52983743e-01,\n",
            "         7.38206059e-02,  1.73060596e-01, -6.09055169e-05,\n",
            "        -9.01699543e-01,  2.71626083e-10,  8.48518478e-11,\n",
            "         5.18465956e-12,  2.09398863e-08,  2.01339878e-12,\n",
            "        -5.21949085e-04,  9.67899978e-01,  1.68576136e-01,\n",
            "         9.99455273e-01, -5.20941212e-05, -1.71167217e-03,\n",
            "         4.64486255e-10,  4.82584182e-05,  9.79411006e-01,\n",
            "        -3.99731770e-02,  4.23867968e-05, -9.98901606e-01,\n",
            "        -1.58913196e-19,  3.86373997e-02, -7.82767892e-01,\n",
            "        -5.82855642e-01, -8.35060820e-09,  5.25755475e-08,\n",
            "         1.08105987e-01,  8.58728647e-01,  1.53763875e-01,\n",
            "        -2.54779451e-07, -3.35726691e-05,  5.73044643e-04,\n",
            "        -2.05033591e-14, -5.41695510e-04, -8.69517028e-01,\n",
            "         2.43786192e-13,  1.00328506e-03, -5.95868642e-06,\n",
            "        -6.14640228e-10]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 8.61601162e+00,  1.51944952e+01, -1.22648263e+00,\n",
            "        -5.67334604e+00,  3.90522575e+00, -2.04409885e+00,\n",
            "        -8.25025940e+00, -1.55502625e+01, -2.34565806e+00,\n",
            "         1.27937737e+01,  1.89749992e+00,  1.61986923e+01,\n",
            "         7.10183716e+00, -1.98698425e+00, -1.47926493e+01,\n",
            "        -9.42327309e+00, -1.17628565e+01, -2.83738971e+00,\n",
            "        -7.00792456e+00,  2.79916930e+00, -4.59496689e+00,\n",
            "        -1.10308971e+01, -1.31578457e+00, -1.46098709e+01,\n",
            "        -1.48111649e+01,  5.89970708e-01, -1.63005257e+00,\n",
            "         9.56914330e+00,  5.18460751e+00, -8.51617241e+00,\n",
            "        -4.19955683e+00,  1.24187746e+01,  6.69275856e+00,\n",
            "        -8.99727726e+00, -9.98380601e-01, -1.17092896e+01,\n",
            "        -1.68865192e+00, -1.36953897e+01,  1.18674297e+01,\n",
            "         1.66790962e-01,  1.29856539e+00,  5.87245989e+00,\n",
            "        -4.61845875e+00, -1.62272167e+01, -6.60722351e+00,\n",
            "        -5.06236970e-01,  6.47230291e+00,  4.06975889e+00,\n",
            "         1.06650805e+00,  1.30567722e+01,  3.56226301e+00,\n",
            "        -9.12858427e-01,  6.73564148e+00,  3.90700245e+00,\n",
            "         5.31272984e+00,  1.46548815e+01,  4.66233969e+00,\n",
            "        -1.50203876e+01,  1.83941650e+00,  1.35861187e+01,\n",
            "        -4.64760399e+00, -1.86606124e-01, -6.07183790e+00,\n",
            "         7.92629671e+00,  1.21330061e+01,  1.48170338e+01,\n",
            "         2.98485732e+00,  4.29242373e+00,  4.89862442e+00,\n",
            "        -2.31376004e+00,  3.45332575e+00,  1.17359056e+01,\n",
            "        -3.98984599e+00,  1.85900605e+00, -1.13590789e+00,\n",
            "        -1.64365888e-01,  4.62443733e+00,  2.45074821e+00,\n",
            "        -3.10102963e+00, -8.00361252e+00, -6.89347088e-01,\n",
            "        -5.82169294e+00,  7.31710148e+00, -5.34315109e-02,\n",
            "        -6.95895767e+00,  9.83263206e+00, -3.10813475e+00,\n",
            "         6.77349567e+00, -4.20863777e-01, -1.18474825e-03,\n",
            "         1.03047638e+01, -2.06750005e-01, -1.54851246e+00,\n",
            "        -7.21893024e+00, -1.64060974e+01, -9.14245319e+00,\n",
            "         5.83436584e+00, -1.83271217e+00, -1.03404725e+00,\n",
            "         4.77396393e+00,  1.27705669e+00, -1.22796774e+00,\n",
            "        -1.20644891e+00, -5.16406631e+00, -4.94657183e+00,\n",
            "         1.23073983e+00,  1.05302391e+01,  6.08588696e+00,\n",
            "         9.83674145e+00,  3.27098179e+00,  4.56638718e+00,\n",
            "        -2.68193197e+00,  6.57860327e+00, -1.02745616e+00,\n",
            "         4.97539711e+00,  5.03008699e+00, -7.94757664e-01,\n",
            "        -1.33209801e+01,  1.26560516e+01, -6.23978674e-01,\n",
            "        -1.39877453e+01, -6.21825933e+00,  6.62106895e+00,\n",
            "        -1.08941851e+01,  6.71488762e+00,  1.59407368e+01,\n",
            "         1.35914822e+01, -3.57479072e+00,  1.54352741e+01,\n",
            "         4.94765997e+00, -6.90882015e+00,  3.31259418e+00,\n",
            "        -1.71275008e+00,  2.96941400e+00,  2.05304861e+00,\n",
            "         3.55386686e+00, -3.35513163e+00, -6.82550144e+00,\n",
            "         9.18068230e-01,  9.85022902e-01,  3.24823523e+00,\n",
            "         5.37682486e+00,  7.38505173e+00, -8.05105305e+00,\n",
            "         1.87615049e+00, -1.01851187e+01, -1.33405530e+00,\n",
            "        -4.22474480e+00,  5.47601795e+00,  1.47347569e+00,\n",
            "         8.27525139e+00,  2.88659239e+00,  1.95277810e+00,\n",
            "        -1.00140059e+00, -2.47352767e+00, -8.85772705e+00,\n",
            "         1.10212555e+01,  2.95513225e+00, -1.07799470e+00,\n",
            "        -8.91488171e+00,  5.74908161e+00,  1.51375055e+01,\n",
            "         9.28652212e-02,  3.31840777e+00,  3.88534045e+00,\n",
            "         1.54947424e+00,  1.18114293e+00, -5.02820492e+00,\n",
            "        -3.41727209e+00, -1.07403302e+00, -4.39957142e+00,\n",
            "        -6.29418552e-01,  2.77922821e+00,  1.54576178e+01,\n",
            "         1.75312924e+00,  6.43900537e+00, -5.01933241e+00,\n",
            "         6.38488531e-01, -6.81490135e+00,  9.83895874e+00,\n",
            "         4.14526844e+00,  9.42361534e-01, -1.36533251e+01,\n",
            "        -6.95081139e+00, -3.01267982e+00,  7.28840256e+00,\n",
            "        -1.62940800e+00, -3.11223030e+00, -1.21727076e+01,\n",
            "        -9.97997463e-01, -7.47501898e+00,  4.93361950e+00,\n",
            "         2.99285913e+00, -9.71130013e-01, -2.93048429e+00,\n",
            "        -1.50341427e+00,  4.09751177e+00,  2.54629421e+00,\n",
            "        -1.44141436e+01, -6.91656399e+00,  3.14481497e+00,\n",
            "        -9.67123508e-01,  3.53754902e+00,  1.74374962e+00,\n",
            "        -7.56068707e+00, -1.92705464e+00,  7.87192211e-03,\n",
            "        -1.63898811e+01,  1.05134344e+01, -4.86316299e+00,\n",
            "         2.68328953e+00, -2.43669796e+00,  2.82693326e-01,\n",
            "         7.97255564e+00, -8.74342060e+00,  4.86737204e+00,\n",
            "         1.00261547e-01,  3.84285474e+00, -3.55751801e+00,\n",
            "        -1.48166525e+00,  5.09133148e+00,  3.04995680e+00,\n",
            "         1.36703434e+01,  5.48021984e+00,  1.58535872e+01,\n",
            "        -5.21949143e-04,  2.05890918e+00,  1.70223981e-01,\n",
            "         5.65540123e+00, -3.07979584e+00, -6.01699448e+00,\n",
            "         9.30589390e+00,  6.40365422e-01,  6.12774324e+00,\n",
            "        -8.29600632e-01,  4.07447386e+00, -3.75329924e+00,\n",
            "        -9.30989838e+00,  3.12843776e+00, -5.08490229e+00,\n",
            "        -9.83552992e-01, -3.00618386e+00,  7.89468813e+00,\n",
            "         2.66408682e+00,  1.28857780e+00,  9.88387585e-01,\n",
            "        -1.25851841e+01, -1.37077980e+01,  6.27238909e-03,\n",
            "        -6.96753788e+00, -2.59652704e-01, -1.33151591e+00,\n",
            "         7.79581642e+00,  1.82463741e+00, -4.85914469e+00,\n",
            "        -1.37939386e+01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 9.95100141e-01,  9.81904924e-01, -1.28881063e-03,\n",
            "        -5.33098588e-03,  9.86599028e-01, -2.12546900e-01,\n",
            "        -9.30675566e-01, -4.52409513e-05, -9.96928453e-01,\n",
            "         7.43294848e-08,  9.13015101e-04,  2.24026875e-03,\n",
            "         1.87263915e-09, -1.73970126e-02, -1.44533333e-04,\n",
            "        -1.05695108e-07, -1.10357505e-05, -9.67042267e-01,\n",
            "        -6.53952837e-01,  1.33757363e-03, -1.17050868e-05,\n",
            "        -7.55012934e-07, -9.64949310e-01, -4.45071510e-06,\n",
            "        -8.77037292e-06,  5.95826924e-01, -9.23477948e-01,\n",
            "         4.65032272e-03,  7.37919845e-06, -2.22290182e-05,\n",
            "        -9.98863935e-01,  5.43395802e-02,  3.17824632e-01,\n",
            "        -9.29105454e-07,  1.25352234e-01, -9.98558700e-01,\n",
            "        -5.98938968e-05, -6.97217524e-01,  8.37922648e-11,\n",
            "         1.45624846e-08,  5.70198715e-01,  1.24164013e-04,\n",
            "        -9.98562336e-01, -5.45160947e-06, -9.99932587e-01,\n",
            "        -2.30092391e-01,  6.55047596e-03,  6.79065342e-05,\n",
            "         1.70418789e-05,  8.79519939e-01,  2.01056054e-07,\n",
            "        -6.60632968e-01,  9.15537700e-02,  5.33660531e-01,\n",
            "         5.47397349e-06,  2.13149731e-04,  9.70844924e-01,\n",
            "        -5.49331198e-05,  2.07600862e-01,  8.43582384e-04,\n",
            "        -1.92950040e-01, -8.29166055e-01, -4.88789193e-03,\n",
            "         3.18083778e-07,  9.99868870e-01,  5.86853456e-03,\n",
            "         9.70618606e-01,  9.99561369e-01,  2.06522000e-05,\n",
            "        -5.30844845e-04,  5.55888910e-05,  6.60016594e-05,\n",
            "        -4.90648538e-01,  9.52556074e-01, -6.05521262e-01,\n",
            "         6.61506593e-01,  9.98049676e-01,  9.61535096e-01,\n",
            "        -3.76215903e-05, -9.99277771e-01, -6.24704123e-01,\n",
            "        -4.64134109e-06,  2.31429096e-03,  1.53597191e-01,\n",
            "        -4.51881718e-03,  1.61009263e-02, -9.01388919e-09,\n",
            "         1.81653291e-01,  2.22739965e-01,  1.24196619e-01,\n",
            "         2.35965326e-02, -8.92848056e-03, -9.32110071e-01,\n",
            "        -1.73274010e-01, -1.02884711e-04, -5.11091002e-07,\n",
            "         1.86522439e-01, -8.88058636e-03, -3.89765576e-02,\n",
            "         4.28359112e-04,  8.57790053e-01, -9.64576364e-01,\n",
            "        -8.35622072e-01, -9.93554473e-01, -2.83565393e-09,\n",
            "         4.70961690e-01,  4.06762301e-05,  9.99826312e-01,\n",
            "         4.98510510e-01,  1.65355741e-05,  2.82335170e-02,\n",
            "        -6.60326779e-01,  2.75523126e-01, -2.37995550e-01,\n",
            "         5.30409634e-01,  1.66389946e-05, -6.58993423e-01,\n",
            "        -2.33712524e-01,  1.44571648e-04, -5.68651676e-01,\n",
            "        -2.33441211e-10, -2.55533516e-01,  1.15514531e-05,\n",
            "        -9.90991235e-01,  9.99998152e-01,  2.53373082e-06,\n",
            "         1.76754926e-04, -6.26287147e-05,  5.54358840e-01,\n",
            "         9.97533321e-01, -5.59556007e-04,  8.42700675e-02,\n",
            "        -5.61080039e-01,  9.51448146e-06,  9.95440304e-01,\n",
            "         3.72193259e-04, -2.16394226e-04, -1.90757498e-01,\n",
            "         4.38614368e-01,  2.13676877e-03,  5.82933892e-04,\n",
            "         2.20453735e-08,  2.53852863e-06, -2.97058490e-03,\n",
            "         2.21832246e-02, -2.91996685e-07, -9.80463862e-01,\n",
            "        -9.73396122e-01,  3.11485976e-01,  9.00200129e-01,\n",
            "         3.41972561e-10,  9.98622656e-01,  9.79077578e-01,\n",
            "        -1.59356914e-05, -2.06189416e-03, -2.81722678e-05,\n",
            "         8.98520708e-01,  3.53769183e-01, -1.35328246e-05,\n",
            "        -4.05899891e-06,  9.99126554e-01,  1.41310984e-05,\n",
            "         9.26275998e-02,  3.39948863e-01,  3.83265757e-08,\n",
            "         8.82743239e-01,  7.91884986e-07, -4.21645463e-01,\n",
            "        -9.03226554e-01, -8.64009053e-06, -1.62461902e-06,\n",
            "        -5.25988221e-01,  1.91084677e-04,  2.01308576e-04,\n",
            "         8.44500773e-03,  5.09018600e-01, -1.76236620e-06,\n",
            "        -1.68365054e-02, -2.24019546e-04,  9.56153417e-06,\n",
            "         6.57807675e-08, -2.66536567e-02, -1.38104053e-06,\n",
            "        -9.11142025e-03, -2.19269509e-06,  1.11877591e-06,\n",
            "        -2.33315378e-01, -5.38920576e-05, -4.55418043e-02,\n",
            "        -3.06247085e-01, -6.20440245e-01,  2.02500960e-05,\n",
            "         1.22652354e-03, -4.36972232e-06, -1.37675763e-03,\n",
            "        -7.60552168e-01,  5.50226271e-02,  8.33222449e-01,\n",
            "        -3.51255112e-05, -2.83486792e-04,  9.47861016e-01,\n",
            "        -4.42508536e-07,  1.09176641e-08,  9.48866546e-01,\n",
            "        -3.99850396e-04, -8.82292330e-01, -5.09350717e-01,\n",
            "        -9.98768747e-01,  3.75775244e-07, -9.99819458e-01,\n",
            "         8.37125070e-03, -9.96396303e-01,  8.08308482e-01,\n",
            "         7.05520433e-05, -1.57028611e-04,  9.95546699e-01,\n",
            "         8.37436840e-02,  9.99129117e-01, -5.86461683e-04,\n",
            "        -9.85707462e-01,  3.23944623e-05,  1.49784319e-03,\n",
            "         1.21210746e-07,  8.87223086e-06,  1.42542310e-02,\n",
            "         2.79685199e-01,  9.67892051e-01,  2.50424892e-01,\n",
            "         1.08831409e-04, -9.58277643e-01, -9.91595685e-01,\n",
            "         4.25650892e-09,  9.00307178e-01,  4.34718560e-03,\n",
            "        -8.77115548e-01,  2.52084865e-04, -9.98851061e-01,\n",
            "        -1.80029565e-06,  1.71898991e-01, -4.54559661e-02,\n",
            "        -5.41654089e-03, -1.47232868e-06,  1.02813428e-05,\n",
            "         1.92337495e-04,  9.18894649e-01,  1.63682088e-01,\n",
            "        -3.85683149e-01, -9.99986053e-01,  2.32334656e-04,\n",
            "        -3.76637743e-08, -2.52249956e-01, -9.80827630e-01,\n",
            "         2.77167231e-01,  6.98653457e-05, -1.70480330e-02,\n",
            "        -3.69412251e-10]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 9.54796886e+00,  1.52577353e+01, -1.25715268e+00,\n",
            "        -6.64635944e+00,  3.79899335e+00, -2.82485771e+00,\n",
            "        -9.14315605e+00, -1.64566898e+01, -3.24007440e+00,\n",
            "         1.37399178e+01,  1.89663482e+00,  1.71891212e+01,\n",
            "         7.51999235e+00, -2.97808528e+00, -1.57090998e+01,\n",
            "        -9.82183456e+00, -1.27368536e+01, -2.05954647e+00,\n",
            "        -5.30501270e+00,  2.97513056e+00, -3.96632695e+00,\n",
            "        -1.07915640e+01, -2.01322007e+00, -1.51778002e+01,\n",
            "        -1.57902403e+01,  7.06535041e-01, -1.61224461e+00,\n",
            "         1.05658875e+01,  5.21143055e+00, -7.94332600e+00,\n",
            "        -4.08142948e+00,  1.14508581e+01,  7.69242334e+00,\n",
            "        -9.97132397e+00,  1.35022953e-01, -1.26677675e+01,\n",
            "        -1.75842202e+00, -1.43463955e+01,  1.25439672e+01,\n",
            "         8.85390460e-01,  6.47957683e-01,  4.92790127e+00,\n",
            "        -3.61865830e+00, -1.70500107e+01, -7.55157614e+00,\n",
            "        -2.34568298e-01,  6.80953932e+00,  4.97262049e+00,\n",
            "         2.06190300e+00,  1.39115744e+01,  4.55668259e+00,\n",
            "        -7.94678926e-01,  7.04993725e+00,  3.90924287e+00,\n",
            "         6.27654886e+00,  1.55821638e+01,  4.29707766e+00,\n",
            "        -1.50727663e+01,  1.83931589e+00,  1.45581255e+01,\n",
            "        -5.59234619e+00, -1.18585467e+00, -6.10868263e+00,\n",
            "         8.54492664e+00,  1.21573811e+01,  1.55562935e+01,\n",
            "         2.10287070e+00,  5.28966570e+00,  4.11602402e+00,\n",
            "        -1.26383841e-01,  4.08408880e+00,  1.23840427e+01,\n",
            "        -3.52093458e+00,  1.85882771e+00, -1.68509877e+00,\n",
            "         7.95490324e-01,  5.61470318e+00,  1.96806705e+00,\n",
            "        -4.09070873e+00, -8.98666763e+00, -7.32850671e-01,\n",
            "        -6.30498266e+00,  7.37678146e+00,  1.55688345e-01,\n",
            "        -7.14356184e+00,  1.08201284e+01, -3.13908839e+00,\n",
            "         7.77072906e+00,  2.26537764e-01,  1.24841191e-01,\n",
            "         1.12866144e+01, -2.06699833e-01, -2.02360153e+00,\n",
            "        -8.21224594e+00, -1.68079472e+01, -1.01352549e+01,\n",
            "         6.73516226e+00, -8.59125137e-01, -3.91419455e-02,\n",
            "         3.78019738e+00,  1.28531206e+00, -2.22715068e+00,\n",
            "        -1.20648575e+00, -4.54762506e+00, -4.94837236e+00,\n",
            "         5.12218773e-01,  1.15283775e+01,  7.07449198e+00,\n",
            "         1.06399832e+01,  2.99232101e+00,  5.56033659e+00,\n",
            "        -2.68195057e+00,  7.03629637e+00, -1.05949080e+00,\n",
            "         5.97534466e+00,  1.13259898e-02, -7.91032434e-01,\n",
            "        -1.39817972e+01,  1.36164751e+01, -6.45983219e-01,\n",
            "        -1.21851835e+01, -7.21778488e+00,  7.40441084e+00,\n",
            "        -1.09459133e+01,  7.71479750e+00,  1.68259621e+01,\n",
            "         1.45378351e+01, -4.52778053e+00,  1.64255695e+01,\n",
            "         4.94678211e+00, -7.82176781e+00,  2.58834273e-01,\n",
            "        -6.65477276e-01,  2.82913208e+00,  3.05299067e+00,\n",
            "         3.96472645e+00, -3.35328460e+00, -7.82535791e+00,\n",
            "         4.70516801e-01,  1.95023155e+00,  3.29387617e+00,\n",
            "         6.37248850e+00,  8.06108952e+00, -9.04522228e+00,\n",
            "         1.89338255e+00, -1.11827030e+01, -2.33368707e+00,\n",
            "        -3.47490716e+00,  6.47416067e+00,  1.47327399e+00,\n",
            "         8.48906994e+00,  3.64272928e+00,  2.28426886e+00,\n",
            "        -9.93856430e-01, -3.47324371e+00, -9.80461311e+00,\n",
            "         1.20005035e+01,  3.55582094e+00, -1.34585154e+00,\n",
            "        -8.51563835e+00,  4.81315136e+00,  1.57715387e+01,\n",
            "         9.29113626e-02,  3.32057214e+00,  4.01330805e+00,\n",
            "         1.38839197e+00,  2.22320810e-01, -5.95239830e+00,\n",
            "        -3.41774273e+00, -1.94785821e+00, -5.02616644e+00,\n",
            "        -5.84587872e-01,  3.74967289e+00,  1.61365738e+01,\n",
            "         2.32980013e+00,  7.39278507e+00, -5.11858988e+00,\n",
            "        -9.98859704e-01, -7.78075886e+00,  1.06724730e+01,\n",
            "         5.13306618e+00, -2.66599748e-02, -1.45817366e+01,\n",
            "        -7.84068680e+00, -3.99190950e+00,  8.24211121e+00,\n",
            "        -2.59753680e+00, -4.11164808e+00, -1.21728935e+01,\n",
            "        -3.16399008e-01, -8.47022629e+00,  5.83024502e+00,\n",
            "         3.42211127e-02, -1.97104096e+00, -3.79334545e+00,\n",
            "        -9.99080122e-01,  5.07956266e+00,  2.08552670e+00,\n",
            "        -1.54139347e+01, -7.88778496e+00,  2.34390116e+00,\n",
            "        -3.82946789e-01,  4.35652447e+00,  1.82032394e+00,\n",
            "        -6.58915520e-01, -1.41673231e+00, -5.62007189e-01,\n",
            "        -1.67857952e+01,  1.15100193e+01, -4.68517923e+00,\n",
            "         3.64197755e+00, -3.30057597e+00,  1.21402287e+00,\n",
            "         8.91456127e+00, -9.65044117e+00,  5.85851049e+00,\n",
            "         9.95709747e-02,  4.73242235e+00, -4.55738688e+00,\n",
            "        -2.47909570e+00,  6.08956099e+00,  3.06655836e+00,\n",
            "         1.45198212e+01,  6.42950296e+00,  1.67594891e+01,\n",
            "         2.87745833e-01,  2.05856681e+00,  2.55913526e-01,\n",
            "         5.64658117e+00, -3.98981905e+00, -6.96189880e+00,\n",
            "         9.33151627e+00,  1.47526670e+00,  6.67941380e+00,\n",
            "        -1.82953310e+00,  4.88660812e+00, -3.75326753e+00,\n",
            "        -1.01827259e+01,  3.80919528e+00, -6.39477015e-01,\n",
            "        -9.64250743e-01, -2.95596147e+00,  7.21079779e+00,\n",
            "         3.65947914e+00,  1.58208275e+00,  6.46070004e-01,\n",
            "        -1.35305567e+01, -1.47024479e+01,  2.95036361e-02,\n",
            "        -7.92959785e+00, -2.57871658e-01, -2.33055973e+00,\n",
            "         8.66970062e+00,  9.05465841e-01, -1.70724448e-02,\n",
            "        -1.47934046e+01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.26885568e-05,  6.64366782e-02, -8.51479113e-01,\n",
            "        -1.13649364e-03,  3.69317218e-04, -3.90021764e-02,\n",
            "        -9.90371644e-01, -1.41067394e-05, -9.97057855e-01,\n",
            "         8.35694373e-04,  3.10660084e-03,  3.13806297e-08,\n",
            "         7.57638372e-06, -3.56893042e-06, -4.24235509e-07,\n",
            "        -4.59422927e-06, -1.08659780e-02, -7.93946862e-01,\n",
            "        -1.34819269e-03,  8.90697896e-01, -6.74070120e-02,\n",
            "        -2.50063986e-01, -9.72214699e-01, -5.19074206e-08,\n",
            "        -3.34286654e-10,  5.57221949e-01, -8.84144843e-01,\n",
            "         8.96243334e-01,  1.76319852e-04, -4.57904255e-03,\n",
            "        -9.88387465e-01,  3.33212018e-02,  9.77503836e-01,\n",
            "        -5.01901980e-07, -7.49929965e-01, -1.74893551e-02,\n",
            "        -2.73628248e-05, -3.68576639e-06,  4.44981015e-05,\n",
            "         7.87045777e-01,  1.36819974e-01,  1.73741236e-01,\n",
            "        -9.35618758e-01, -3.16590332e-09, -3.81520775e-04,\n",
            "        -1.82179213e-01,  3.19412538e-05,  3.60512161e-07,\n",
            "         1.44364805e-07,  1.33117553e-07,  8.75920648e-07,\n",
            "        -6.92118883e-01,  1.11221547e-04,  1.82165861e-01,\n",
            "         1.04088322e-04,  7.89291458e-04, -1.16035067e-01,\n",
            "        -1.81729047e-04, -7.00842738e-01,  1.57061464e-03,\n",
            "        -1.13938645e-01, -8.58516455e-01, -7.12323413e-07,\n",
            "         4.03024281e-09,  1.63624662e-07,  7.41336362e-06,\n",
            "         9.69967246e-01,  1.02641434e-05,  5.72690216e-04,\n",
            "        -1.19922951e-01,  2.31876061e-06,  6.88253939e-01,\n",
            "        -7.24334153e-04,  6.95528507e-01, -6.97833020e-04,\n",
            "         6.09275877e-01,  8.45137791e-08,  3.84098113e-01,\n",
            "        -1.44401966e-07, -9.75937009e-01, -6.24758601e-02,\n",
            "        -6.00560894e-03,  1.47219464e-01,  2.84081217e-13,\n",
            "        -5.72595298e-02,  2.13258019e-07, -9.57802087e-08,\n",
            "         2.45641202e-01,  3.11561152e-02, -4.30482179e-01,\n",
            "         4.60303966e-07, -1.84302591e-03, -8.39797258e-01,\n",
            "        -7.48666207e-06, -1.67869644e-07, -4.42590239e-03,\n",
            "         2.92697441e-05, -4.16890451e-08, -8.46678972e-07,\n",
            "         3.38764787e-02,  8.26108158e-01, -9.95781958e-01,\n",
            "        -8.30885053e-01, -9.99563396e-01, -9.99879956e-01,\n",
            "         1.50426349e-03,  3.37599813e-05,  9.99839127e-01,\n",
            "         1.31953374e-01,  1.44336600e-05,  1.00880268e-03,\n",
            "        -2.23707527e-01,  7.66952157e-01, -5.12269512e-03,\n",
            "         6.58940449e-02,  9.73976057e-05, -6.47789001e-01,\n",
            "        -2.38247984e-03,  9.81436606e-05, -1.33232819e-02,\n",
            "        -3.74860683e-05, -3.80759919e-03,  3.14245326e-03,\n",
            "        -4.93749112e-01,  9.92954447e-05,  1.00554544e-02,\n",
            "         1.35200974e-02, -8.16307247e-01,  9.99958158e-01,\n",
            "         9.99599099e-01, -6.84562314e-04,  8.34573257e-06,\n",
            "        -1.13994226e-01,  5.87782370e-06,  2.62958616e-01,\n",
            "         7.04301372e-02, -3.80917214e-07, -1.90106857e-05,\n",
            "         6.98868155e-01,  6.99457132e-06,  1.36334366e-09,\n",
            "         3.75302761e-07,  2.94712208e-05, -2.78133393e-06,\n",
            "         8.43838215e-01, -7.66548851e-08, -9.97147739e-01,\n",
            "        -1.88124104e-04,  3.55136290e-05,  8.97443175e-01,\n",
            "         2.07438469e-02,  5.60117364e-01,  4.87295270e-01,\n",
            "        -2.77515687e-02, -9.99681652e-01, -3.95692745e-03,\n",
            "         2.75911805e-09,  1.62800134e-03, -2.38381335e-06,\n",
            "        -1.12072355e-03,  9.95461881e-01,  5.76314441e-10,\n",
            "         9.27151144e-02,  8.89890015e-01,  5.76433778e-01,\n",
            "         9.80286419e-01,  2.46728554e-10, -3.75529110e-01,\n",
            "        -7.82865658e-02, -5.88883646e-04, -5.30644273e-03,\n",
            "        -5.26278496e-01,  7.70250917e-05,  1.84676703e-03,\n",
            "         4.09818254e-02,  1.74901411e-01, -9.78482008e-01,\n",
            "         6.80183530e-01, -2.95704353e-07,  4.16794717e-01,\n",
            "         9.44778621e-01, -2.11295014e-06, -2.24041196e-06,\n",
            "        -9.53749861e-08, -1.06534350e-03,  3.07242037e-04,\n",
            "        -2.47417338e-04, -7.35451067e-07, -1.84307307e-01,\n",
            "        -7.45667436e-04, -9.38093662e-03,  2.23783854e-08,\n",
            "         6.77760625e-07, -1.62138417e-01, -3.94761488e-02,\n",
            "        -7.19370484e-01,  2.71487571e-02,  4.90687490e-02,\n",
            "        -1.17467149e-04, -1.44247375e-02,  8.84948313e-01,\n",
            "        -8.11603442e-08,  2.23597344e-05,  9.87575233e-01,\n",
            "        -1.87116441e-07, -6.82729483e-01, -5.13719976e-01,\n",
            "        -9.55026090e-01,  7.78223667e-03, -2.08769087e-02,\n",
            "         9.30285752e-01, -1.53443965e-04,  8.23217273e-01,\n",
            "         5.22475783e-03, -9.99995470e-01,  4.78689414e-11,\n",
            "         9.81735066e-02,  1.84719674e-02, -7.65964145e-08,\n",
            "        -1.01671822e-01,  5.35357647e-10,  1.45286432e-08,\n",
            "         2.43377690e-05,  4.94069063e-05,  9.99150395e-01,\n",
            "        -5.14111416e-05,  9.68171716e-01,  2.22974434e-01,\n",
            "         3.42572775e-07, -9.97031391e-01, -5.42690396e-01,\n",
            "         9.01617944e-01,  7.59985030e-01,  4.83417092e-03,\n",
            "        -9.86563087e-01,  6.37384653e-02, -9.98908877e-01,\n",
            "        -1.77220087e-02,  1.91962201e-04, -9.07884836e-01,\n",
            "        -6.63130403e-01, -4.80137736e-01,  9.99358535e-01,\n",
            "         4.86907689e-03,  9.37122881e-01,  1.20830186e-01,\n",
            "        -4.99625748e-04, -8.50426495e-01,  6.56857610e-01,\n",
            "        -2.00618171e-08, -1.48413051e-02, -9.52453017e-01,\n",
            "         4.50430093e-08,  7.20050335e-01, -5.91820121e-01,\n",
            "        -9.99230266e-01]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.00925932e+01,  1.57565832e+01, -1.26385117e+00,\n",
            "        -7.64586020e+00,  3.81098080e+00, -3.82049108e+00,\n",
            "        -9.69591713e+00, -1.73150444e+01, -3.26391959e+00,\n",
            "         1.37471027e+01,  1.91837740e+00,  1.81753540e+01,\n",
            "         8.40153122e+00, -3.89972639e+00, -1.65854168e+01,\n",
            "        -1.07351608e+01, -1.37073698e+01, -1.08398521e+00,\n",
            "        -6.30344296e+00,  2.94170117e+00, -4.94098139e+00,\n",
            "        -1.10124645e+01, -2.13121152e+00, -1.60749092e+01,\n",
            "        -1.63955631e+01,  6.54072762e-01, -1.39444959e+00,\n",
            "         1.15649910e+01,  5.39050770e+00, -8.94229126e+00,\n",
            "        -4.07259798e+00,  1.14533730e+01,  8.69237614e+00,\n",
            "        -1.09344988e+01, -9.72795546e-01, -1.36497450e+01,\n",
            "        -1.76828206e+00, -1.53436432e+01,  1.34866810e+01,\n",
            "         1.06362092e+00,  3.97634953e-01,  4.93544388e+00,\n",
            "        -4.57436037e+00, -1.77715397e+01, -8.46849632e+00,\n",
            "        -2.33882025e-01,  7.56093740e+00,  5.91270065e+00,\n",
            "         2.28134561e+00,  1.48092890e+01,  5.55622864e+00,\n",
            "        -8.52021158e-01,  7.96304750e+00,  4.44388056e+00,\n",
            "         7.27590036e+00,  1.65218258e+01, -8.87183905e-01,\n",
            "        -1.59206152e+01, -8.68960619e-01,  1.54139948e+01,\n",
            "        -6.59053612e+00, -1.29000783e+00, -6.78222227e+00,\n",
            "         9.53552437e+00,  1.30994635e+01,  1.65550442e+01,\n",
            "         2.09188986e+00,  6.28307247e+00,  4.97966719e+00,\n",
            "        -1.40875608e-01,  1.49626291e+00,  1.33372374e+01,\n",
            "        -1.84619212e+00,  8.58774126e-01, -2.67261934e+00,\n",
            "         7.16918528e-01,  6.16471863e+00,  1.93727851e+00,\n",
            "        -4.58919716e+00, -9.85123920e+00, -1.05560780e+00,\n",
            "        -7.30494595e+00,  8.18389797e+00,  5.82666934e-01,\n",
            "        -8.13959694e+00,  1.17809772e+01, -3.19771051e+00,\n",
            "         8.76332760e+00,  3.11753899e-02, -4.60495591e-01,\n",
            "         1.22175140e+01, -1.90542289e-03, -2.69326138e+00,\n",
            "        -9.20753574e+00, -1.77977695e+01, -1.11204433e+01,\n",
            "         7.72164965e+00, -8.59136760e-01, -3.94715928e-02,\n",
            "         4.75756216e+00,  1.17731977e+00, -3.08100891e+00,\n",
            "        -1.19099236e+00, -4.50985718e+00, -5.74378824e+00,\n",
            "         1.50202835e+00,  1.25280504e+01,  7.83650732e+00,\n",
            "         1.16107626e+01,  3.97205830e+00,  6.55240440e+00,\n",
            "        -3.55921006e+00,  8.01288795e+00, -1.05947280e+00,\n",
            "         6.97516823e+00,  1.00597954e+00, -7.71479607e-01,\n",
            "        -1.47971354e+01,  1.43462429e+01, -1.47568583e+00,\n",
            "        -1.29998627e+01, -8.21778107e+00,  8.39402008e+00,\n",
            "        -1.19299965e+01,  8.63053989e+00,  1.77495689e+01,\n",
            "         1.55299597e+01, -4.74088478e+00,  1.73579750e+01,\n",
            "         5.32102871e+00, -8.81907749e+00,  1.24344206e+00,\n",
            "        -1.65403819e+00,  3.82097411e+00,  3.90200305e+00,\n",
            "         4.96178675e+00, -3.32614994e+00, -8.80258560e+00,\n",
            "         8.65084708e-01,  2.06908202e+00,  4.24917936e+00,\n",
            "         6.62118149e+00,  9.01795101e+00, -1.00448322e+01,\n",
            "         2.65322447e+00, -1.21643047e+01, -3.32974148e+00,\n",
            "        -4.42599630e+00,  6.50627422e+00,  1.45892942e+00,\n",
            "         8.76967907e+00,  6.33013964e-01,  2.34765196e+00,\n",
            "        -2.77615078e-02, -4.37627554e+00, -1.07935162e+01,\n",
            "         1.29591570e+01,  4.52658367e+00, -1.76710355e+00,\n",
            "        -9.09006405e+00,  4.48911428e+00,  1.67458115e+01,\n",
            "         9.29827914e-02,  2.91295791e+00,  4.95317364e+00,\n",
            "         2.30484819e+00,  1.21343815e+00, -6.89475536e+00,\n",
            "        -3.85975552e+00, -1.98045993e+00, -5.02180624e+00,\n",
            "        -5.85065901e-01,  4.50732899e+00,  1.70598888e+01,\n",
            "         2.33925748e+00,  8.38584995e+00, -5.90223360e+00,\n",
            "         9.76202548e-01, -8.61303806e+00,  1.15434761e+01,\n",
            "         6.12078285e+00, -2.11295014e-06, -1.55339899e+01,\n",
            "        -8.83244133e+00, -4.97994995e+00,  9.23534298e+00,\n",
            "        -2.91846108e+00, -4.08886623e+00, -1.30468264e+01,\n",
            "        -7.45667552e-04, -9.35413170e+00,  6.41436672e+00,\n",
            "         1.03383601e+00, -2.96968246e+00, -4.58873129e+00,\n",
            "        -9.08209920e-01,  5.77999067e+00,  2.07092643e+00,\n",
            "        -1.64139156e+01, -8.88641167e+00,  1.40529668e+00,\n",
            "        -1.34640110e+00,  4.35859251e+00,  2.80750680e+00,\n",
            "        -1.63202810e+00, -1.01121485e+00, -5.67770839e-01,\n",
            "        -1.77852669e+01,  1.25099735e+01, -4.77972412e+00,\n",
            "         3.64035749e+00, -4.29990053e+00,  1.16671836e+00,\n",
            "         9.90093327e+00, -9.71261978e+00,  6.85747385e+00,\n",
            "         9.94966775e-02,  5.72692394e+00, -4.92923403e+00,\n",
            "        -1.02027215e-01,  6.10366344e+00,  3.09507346e+00,\n",
            "         1.52624435e+01,  7.42078447e+00,  1.74012966e+01,\n",
            "        -5.16859182e-05,  2.06228995e+00,  2.89772213e-01,\n",
            "         2.20769000e+00, -4.86996269e+00, -7.37393427e+00,\n",
            "         1.03307123e+01,  9.97792542e-01,  7.65685701e+00,\n",
            "        -2.82062984e+00,  5.86286926e+00, -3.76661372e+00,\n",
            "        -1.05757856e+01,  4.75064373e+00, -1.62256992e+00,\n",
            "        -8.15528214e-01, -3.30008864e+00,  8.20457172e+00,\n",
            "         4.65892315e+00,  1.71394193e+00,  6.30343378e-01,\n",
            "        -1.44234238e+01, -1.57023487e+01,  7.87517846e-01,\n",
            "        -8.89536858e+00, -3.08330864e-01, -2.58164430e+00,\n",
            "         9.61608982e+00,  9.07833457e-01, -1.01705694e+00,\n",
            "        -1.57934046e+01]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 9.29268658e-01,  5.28046722e-03, -7.22999917e-03,\n",
            "        -2.84020439e-06,  9.99182343e-01, -9.49861575e-03,\n",
            "        -6.82762777e-03, -5.40391829e-06, -9.97308373e-01,\n",
            "         3.43120269e-06,  2.36572698e-04,  1.05920306e-03,\n",
            "         9.87550993e-06, -9.72422808e-02, -3.93761503e-08,\n",
            "        -5.69224085e-06, -7.53897389e-09, -7.66192973e-02,\n",
            "        -1.20980070e-08,  6.90666258e-01, -1.72439904e-05,\n",
            "        -2.16036324e-06, -9.73130524e-01, -1.87553950e-02,\n",
            "        -2.65510295e-07,  7.55943775e-01, -8.84004593e-01,\n",
            "         1.89346360e-06,  1.94315870e-08, -2.45060949e-08,\n",
            "        -9.95478511e-01,  9.12580132e-01,  2.05378547e-05,\n",
            "        -6.87760040e-02, -6.15915835e-01, -8.63771558e-01,\n",
            "        -1.79188839e-06, -9.92124856e-01,  1.47855346e-07,\n",
            "         1.31131765e-05,  8.77376676e-01,  9.75652695e-01,\n",
            "        -1.36536121e-01, -6.21916901e-04, -4.18097014e-03,\n",
            "        -1.43770561e-01,  2.07458087e-03,  1.32411849e-04,\n",
            "         3.53824347e-03,  1.61626429e-06,  3.51103868e-10,\n",
            "        -3.54753524e-01,  2.06674486e-05,  2.42097184e-01,\n",
            "         5.67869085e-09,  3.06055159e-03, -6.99509501e-01,\n",
            "        -1.06787914e-03, -6.79598927e-01,  9.51485187e-02,\n",
            "        -9.98069823e-01, -9.78505790e-01, -9.73485470e-01,\n",
            "         7.16571391e-01,  9.99324381e-01,  6.14639139e-04,\n",
            "         9.68601346e-01,  4.16057787e-07,  7.46976525e-08,\n",
            "        -2.90806498e-03,  2.37598604e-11,  2.04006278e-06,\n",
            "        -9.63158600e-05, -1.51710808e-01, -9.66741145e-01,\n",
            "         4.76612747e-02,  4.63602890e-04,  7.83247888e-01,\n",
            "        -8.20854384e-10, -1.79520983e-03, -8.90558600e-01,\n",
            "        -7.82985589e-05,  3.76837879e-01,  1.32268539e-03,\n",
            "        -1.23226844e-01,  3.17897889e-06, -7.38388451e-07,\n",
            "         1.81812549e-03, -7.47619867e-01, -5.94128259e-02,\n",
            "         3.63265144e-07, -8.20112973e-07, -2.14677498e-01,\n",
            "        -2.96045184e-01, -3.47157002e-05, -7.96798905e-10,\n",
            "         3.56170744e-07, -2.31504485e-01,  1.77544989e-05,\n",
            "         7.19957149e-11,  8.26613307e-01, -9.99408007e-01,\n",
            "        -2.42048725e-01, -9.97648478e-01, -1.75723960e-06,\n",
            "         5.23618655e-03,  9.22203541e-01,  9.87579763e-01,\n",
            "         3.54445517e-01,  2.66412662e-05,  6.32645606e-05,\n",
            "        -2.53827292e-02,  2.30479855e-05, -7.61200607e-01,\n",
            "         9.99854565e-01,  7.81698525e-02, -6.75867736e-01,\n",
            "        -9.20044005e-01,  4.67045675e-06, -1.77945822e-01,\n",
            "        -1.60884188e-11, -5.18016517e-01,  1.60621330e-05,\n",
            "        -9.99651790e-01,  8.46174880e-05,  3.67408459e-09,\n",
            "         7.30315222e-08, -7.92315185e-01,  3.68674984e-03,\n",
            "         9.59404005e-08, -2.56811973e-06,  9.77211118e-01,\n",
            "        -9.39204881e-04,  8.38255801e-06,  8.29917550e-01,\n",
            "         5.30278488e-09, -3.17267678e-03, -3.51552635e-01,\n",
            "         1.03878893e-01, -5.41782811e-06,  8.71101680e-09,\n",
            "         7.05758737e-07,  3.98750863e-08, -2.80223305e-12,\n",
            "         1.00469226e-02, -6.64179606e-06,  7.38899648e-01,\n",
            "        -3.37289130e-05,  9.83935955e-09,  4.32781398e-01,\n",
            "         2.27221244e-06,  9.10203516e-01,  9.97377098e-01,\n",
            "        -2.99342862e-09, -5.42876835e-04, -2.15999982e-10,\n",
            "         7.57472932e-01,  1.13263319e-03, -1.63664510e-07,\n",
            "        -2.30307887e-06,  9.97688353e-01,  4.20488355e-08,\n",
            "         9.35201794e-02,  2.02795491e-01,  4.80973039e-09,\n",
            "         9.96931434e-01,  3.39653042e-07, -9.96949971e-01,\n",
            "        -9.90107238e-01, -5.58295142e-05, -1.16572301e-05,\n",
            "        -1.27535731e-01,  6.37979838e-08,  5.65805021e-06,\n",
            "         1.15454625e-10,  8.60900036e-04, -9.11629200e-03,\n",
            "        -4.07593034e-04, -4.32305399e-07,  5.20663083e-01,\n",
            "         9.26334476e-09, -7.58440316e-01, -1.09767251e-09,\n",
            "        -5.18544354e-02, -4.28806712e-10,  2.83770962e-08,\n",
            "        -1.73726736e-03, -1.04430387e-09, -4.38505458e-06,\n",
            "        -1.06266431e-04, -1.37422323e-01,  1.32621065e-01,\n",
            "         8.99418071e-03, -5.68026394e-07, -1.31882846e-01,\n",
            "        -6.88797414e-01,  1.40890867e-01,  3.25422026e-02,\n",
            "        -3.36370408e-06, -2.31898048e-05,  3.91838908e-01,\n",
            "        -2.04286582e-04,  2.65395471e-07,  7.07277179e-01,\n",
            "        -1.41501969e-05, -8.03673089e-01, -5.30761421e-01,\n",
            "        -4.83528747e-05,  1.90190838e-06, -9.98974979e-01,\n",
            "         3.98936754e-06, -3.91634405e-02,  8.40546429e-01,\n",
            "         4.83438962e-05, -6.40015066e-01,  7.94041455e-01,\n",
            "         9.90881249e-02,  9.88337159e-01, -9.44802421e-04,\n",
            "        -7.99355865e-01,  4.89264771e-08,  3.04316163e-05,\n",
            "         4.61513139e-08,  2.16763619e-05,  7.09532411e-04,\n",
            "        -5.15027386e-05,  9.66947258e-01,  2.28879660e-01,\n",
            "         5.14264639e-06, -1.17306206e-02, -4.36013215e-05,\n",
            "         3.92789079e-05,  5.98865980e-03,  2.20486952e-04,\n",
            "        -2.50522443e-03,  9.03703868e-01, -7.25193501e-01,\n",
            "        -2.33347102e-08,  1.12413773e-05, -5.68648987e-03,\n",
            "        -7.23704159e-01, -6.23872010e-10,  1.87614944e-07,\n",
            "         1.68515992e-08,  9.90154386e-01,  1.02495169e-03,\n",
            "        -6.85088150e-03, -9.52221977e-04,  3.11889388e-02,\n",
            "        -8.97065029e-02, -2.72380896e-02, -9.40148115e-01,\n",
            "         1.82644487e-03,  1.45810027e-05, -3.38658174e-06,\n",
            "        -4.50230040e-08]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.09886236e+01,  1.50083561e+01, -1.26272547e+00,\n",
            "        -8.59640503e+00,  3.90113235e+00, -4.44960546e+00,\n",
            "        -1.04348507e+01, -1.79672832e+01, -3.30530643e+00,\n",
            "         1.47076473e+01,  1.98860526e+00,  1.91326466e+01,\n",
            "         8.94026184e+00, -4.89960003e+00, -1.70093784e+01,\n",
            "        -1.13878689e+01, -1.46755419e+01, -7.68486485e-02,\n",
            "        -7.12949562e+00,  3.71551013e+00, -5.92999411e+00,\n",
            "        -1.01387053e+01, -2.14819264e+00, -1.52018871e+01,\n",
            "        -1.73068008e+01,  9.99283075e-01, -1.39410949e+00,\n",
            "         1.20926409e+01,  4.29616070e+00, -7.96974277e+00,\n",
            "        -3.04491520e+00,  1.10544577e+01,  9.68913364e+00,\n",
            "        -1.19259319e+01, -1.44057596e+00, -1.38643618e+01,\n",
            "        -2.53570890e+00, -1.63408089e+01,  1.44790010e+01,\n",
            "         1.06271505e+00,  1.36426258e+00,  2.26662469e+00,\n",
            "        -5.30000162e+00, -1.86549015e+01, -9.44700146e+00,\n",
            "        -1.44775242e-01,  7.57243681e+00,  4.08007002e+00,\n",
            "         2.90941811e+00,  1.57273417e+01,  6.55463171e+00,\n",
            "        -3.70938450e-01,  8.75349140e+00,  4.47661734e+00,\n",
            "         8.26832390e+00,  1.74702492e+01, -8.67390633e-01,\n",
            "        -1.68225899e+01, -8.33517551e-01,  1.63569698e+01,\n",
            "        -7.57635260e+00, -2.27099633e+00, -7.77594805e+00,\n",
            "         1.04370184e+01,  1.30515594e+01,  1.52067776e+01,\n",
            "         2.06915641e+00,  7.26058483e+00,  4.26668310e+00,\n",
            "        -1.13228369e+00,  2.47321939e+00,  1.42770033e+01,\n",
            "        -7.08219230e-01, -1.53223917e-01, -3.63733649e+00,\n",
            "         5.78346848e-01,  7.16137600e+00,  1.09319758e+00,\n",
            "        -4.84073162e+00, -1.08490553e+01, -1.52758563e+00,\n",
            "        -6.33404255e+00,  8.23058128e+00,  4.62348700e-01,\n",
            "        -8.76984596e+00,  1.26767893e+01, -3.83010149e+00,\n",
            "         9.76321507e+00, -9.67538476e-01, -5.94833679e-02,\n",
            "         1.31916952e+01, -4.80951136e-03, -2.77577662e+00,\n",
            "        -1.02074518e+01, -1.78639183e+01, -1.20459795e+01,\n",
            "         8.71772194e+00, -2.37796903e-01,  9.14527595e-01,\n",
            "         5.73425436e+00,  1.17738140e+00, -4.06245756e+00,\n",
            "        -2.46949196e-01, -3.51809311e+00, -5.41869259e+00,\n",
            "         1.68195164e+00,  1.35259390e+01,  8.83649254e+00,\n",
            "         1.23548832e+01,  4.95163918e+00,  7.55152845e+00,\n",
            "        -3.58160448e+00,  8.14904976e+00, -2.02651882e+00,\n",
            "         7.75970984e+00,  1.18760392e-01, -8.21467459e-01,\n",
            "        -1.49612885e+01,  1.47728062e+01, -7.14214802e-01,\n",
            "        -1.33162937e+01, -1.05306792e+00,  9.34774685e+00,\n",
            "        -1.13249149e+01,  9.62999916e+00,  1.86389618e+01,\n",
            "         1.63802795e+01, -5.41205931e+00,  1.83484383e+01,\n",
            "         6.20392466e+00, -8.37816429e+00,  2.24074054e+00,\n",
            "        -6.55040324e-01,  6.83445707e-02,  1.18798327e+00,\n",
            "         5.95870781e+00, -4.26751852e+00, -9.79889870e+00,\n",
            "         1.04345798e-01, -1.49631575e-01,  3.11872721e+00,\n",
            "         7.08613157e+00,  1.00037785e+01, -1.10441380e+01,\n",
            "         2.60144734e+00, -1.31609898e+01,  9.51501429e-01,\n",
            "        -5.41520596e+00,  7.38513374e+00,  4.63314027e-01,\n",
            "         7.85521030e+00,  1.55219066e+00,  3.32065916e+00,\n",
            "        -2.23846044e-02, -5.35825634e+00, -1.16629648e+01,\n",
            "         1.39379463e+01,  5.47696304e+00, -2.72288799e+00,\n",
            "        -6.92882442e+00,  3.49184632e+00,  1.76443634e+01,\n",
            "         9.37943310e-02,  3.69353795e+00,  4.48148489e+00,\n",
            "         3.23925591e+00,  2.15313435e-01, -7.32549143e+00,\n",
            "        -3.99094748e+00, -1.00737441e+00, -5.80653000e+00,\n",
            "        -5.84368467e-01,  5.47386074e+00,  1.75822659e+01,\n",
            "         1.32784724e+00,  8.38592052e+00, -6.87510204e+00,\n",
            "        -9.76791322e-01, -9.58798027e+00,  1.25380602e+01,\n",
            "         7.11459208e+00, -9.93090570e-01, -1.63904228e+01,\n",
            "        -9.83057022e+00, -5.97236156e+00,  1.02102833e+01,\n",
            "        -3.87612677e+00, -5.08881044e+00, -1.37574434e+01,\n",
            "        -1.06282321e-04, -1.03540764e+01,  6.94071579e+00,\n",
            "         8.99471901e-03, -1.02022052e+00, -5.53517723e+00,\n",
            "        -8.45666409e-01,  6.70916462e+00,  3.06613564e+00,\n",
            "        -1.17411194e+01, -9.12443352e+00,  4.15446430e-01,\n",
            "        -8.14486980e-01,  4.08490467e+00,  3.29116774e+00,\n",
            "        -1.51510441e+00, -1.10931492e+00, -5.92093468e-01,\n",
            "        -1.69594574e+01,  1.34708462e+01, -4.77849007e+00,\n",
            "         4.63886690e+00, -5.29980183e+00,  2.07043386e+00,\n",
            "         1.08403730e+01, -9.71887016e+00,  6.58907509e+00,\n",
            "         9.94163752e-02,  6.72335196e+00, -5.91942263e+00,\n",
            "        -1.09821498e+00,  5.16759443e+00,  3.09507704e+00,\n",
            "         1.62529850e+01,  8.33350563e+00,  1.83781166e+01,\n",
            "        -5.15027750e-05,  2.06236768e+00,  2.34503090e-01,\n",
            "         2.97830319e+00, -5.01805401e+00, -8.36072540e+00,\n",
            "         1.13213272e+01,  3.51841480e-01,  8.65603256e+00,\n",
            "        -3.80481291e+00,  6.53204489e+00, -3.82810235e+00,\n",
            "        -1.15029945e+01,  4.39134407e+00, -1.01983762e+00,\n",
            "        -9.29973543e-01, -9.85504866e-01,  7.32416487e+00,\n",
            "         5.65553713e+00,  2.65576100e+00,  2.25698546e-01,\n",
            "        -1.53799820e+01, -1.66998634e+01,  8.72100294e-01,\n",
            "        -9.89526176e+00, -2.72454191e-02, -2.55519223e+00,\n",
            "         1.05807486e+01,  1.44590211e+00, -1.78029373e-01,\n",
            "        -1.67932167e+01]], dtype=float32)>)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.19387329e-01,  1.50853485e-01,  9.74058509e-01,\n",
            "        -1.50824594e-03,  7.77186081e-02, -7.81009789e-04,\n",
            "        -1.81277543e-01, -2.58682936e-01,  3.91571932e-02,\n",
            "         1.04106532e-03,  4.57146700e-04,  9.18612182e-01,\n",
            "         6.54804567e-03,  8.83079231e-01, -2.04287823e-02,\n",
            "        -7.76924018e-04, -3.63580696e-02, -9.44683790e-01,\n",
            "        -4.68028293e-06, -7.53416836e-01, -2.97159646e-02,\n",
            "        -6.53673669e-06,  7.78755307e-01, -9.25866480e-05,\n",
            "        -8.94318728e-05, -8.18913221e-01, -7.01148152e-01,\n",
            "         7.77950190e-05,  2.52437666e-02, -3.45495529e-02,\n",
            "        -9.96108982e-04,  4.30135965e-01,  1.50260376e-02,\n",
            "        -3.82009521e-02, -2.18766853e-01, -1.48719046e-05,\n",
            "        -6.50275409e-01, -2.89770842e-01,  1.08708732e-03,\n",
            "         8.83632004e-02,  1.53081419e-04,  3.48360538e-02,\n",
            "        -1.03786282e-04, -3.28795344e-01, -1.04999237e-01,\n",
            "        -7.45615184e-01,  8.65823030e-03,  2.93019984e-04,\n",
            "         3.45410332e-02,  2.63524443e-01,  4.62868989e-01,\n",
            "         8.40899050e-01,  1.23057626e-02, -1.60515110e-03,\n",
            "         9.30330813e-01,  4.95193584e-04,  9.16336298e-01,\n",
            "        -5.94313085e-01, -3.45296483e-03,  3.51467878e-02,\n",
            "        -2.79726595e-01,  3.77944075e-02,  5.28122008e-01,\n",
            "         6.54271571e-03,  1.66350231e-03,  6.75314868e-06,\n",
            "         1.31317943e-01,  8.01007867e-01,  1.28822040e-03,\n",
            "        -1.46964542e-03,  3.42297293e-02,  1.89537570e-01,\n",
            "         7.41933346e-01,  9.57609832e-01, -1.30276219e-03,\n",
            "        -3.59961204e-02,  1.73476845e-01,  2.80674605e-04,\n",
            "        -1.24835804e-01, -5.09698510e-01, -1.12794316e-03,\n",
            "        -1.28997654e-01,  1.09016195e-01,  2.77632116e-05,\n",
            "         3.86559755e-01,  2.92633683e-03, -3.47343683e-01,\n",
            "         2.26272459e-05,  3.51462909e-03, -9.55980122e-01,\n",
            "         8.17768931e-01, -1.05041940e-08,  5.50321594e-04,\n",
            "        -1.99022889e-01, -8.97713542e-01, -9.73494589e-01,\n",
            "         4.13144589e-04, -6.25492772e-04, -5.72935402e-01,\n",
            "         6.20300651e-01,  1.14324376e-01,  1.34030133e-01,\n",
            "        -8.96233618e-01, -7.13313818e-01, -5.76545834e-04,\n",
            "         5.98395884e-04,  5.54988947e-06,  1.77848563e-01,\n",
            "         9.01102461e-03, -2.91976869e-01,  1.03260696e-01,\n",
            "         6.10120416e-01,  5.66952536e-03,  3.10085654e-01,\n",
            "         5.88107808e-03,  1.36004342e-03,  9.78499092e-03,\n",
            "        -5.94567478e-01,  2.47360185e-05, -7.48769045e-01,\n",
            "        -6.17953315e-02, -6.75443649e-01,  1.14436216e-05,\n",
            "        -3.83138716e-01,  4.89962167e-06,  4.61627059e-02,\n",
            "         8.89330331e-05, -9.98548605e-03, -1.24701783e-05,\n",
            "         1.54882465e-02, -4.50778641e-02, -1.92014083e-01,\n",
            "        -3.69509935e-01,  1.20967828e-01,  1.04302401e-02,\n",
            "         2.58924589e-02, -9.25956666e-01, -7.08608143e-03,\n",
            "        -9.30059612e-01,  3.82642388e-01,  2.64799178e-01,\n",
            "         1.29776250e-03,  1.15496274e-02, -3.11098814e-01,\n",
            "         4.82362861e-09, -4.29325223e-01, -1.42143965e-01,\n",
            "         2.23705083e-01,  2.46838368e-02,  3.11890244e-03,\n",
            "         1.40320312e-03,  3.17814648e-01, -3.00914884e-01,\n",
            "        -1.08282091e-02, -1.33743733e-01, -1.96371577e-03,\n",
            "         5.89802302e-02, -2.39104673e-01, -1.76894478e-04,\n",
            "        -2.13895366e-01,  4.01000261e-01, -2.39007268e-02,\n",
            "         4.93120700e-01,  1.18360654e-01,  5.66154644e-02,\n",
            "        -2.55895662e-03,  2.89764494e-01, -7.20720828e-01,\n",
            "         3.66165079e-02, -1.26555542e-05, -2.95926332e-01,\n",
            "         2.71875819e-04,  7.60796247e-04,  3.44692133e-02,\n",
            "         1.06077893e-02,  2.39852741e-02, -7.96596110e-01,\n",
            "         5.94703518e-02, -1.81150943e-01, -2.73111414e-06,\n",
            "         2.17545591e-02,  8.22240412e-01, -2.76698738e-01,\n",
            "        -1.47223428e-01, -9.51047754e-04,  8.97086978e-01,\n",
            "        -5.39217964e-02, -8.35247338e-03, -3.49333230e-03,\n",
            "        -3.36107254e-01, -1.08072354e-05,  4.18336829e-03,\n",
            "         8.13961267e-01,  7.72438407e-01,  1.10411998e-02,\n",
            "        -1.34877665e-02, -1.86888203e-01,  8.64944595e-04,\n",
            "        -7.20705293e-06,  1.12749483e-07,  1.36461809e-01,\n",
            "        -1.81883333e-05,  8.22599113e-01,  1.19864640e-09,\n",
            "        -9.66905430e-03,  4.94694114e-01,  1.59184188e-01,\n",
            "        -5.39003074e-01,  5.85971236e-01, -2.42899545e-02,\n",
            "         7.32807159e-01, -5.44373572e-01,  9.18906569e-01,\n",
            "         7.79999846e-06, -2.47793317e-01,  4.97738756e-02,\n",
            "         1.42148780e-02, -3.93100560e-01, -2.08745641e-03,\n",
            "         2.06747465e-02,  7.02947617e-01,  8.00434649e-02,\n",
            "         1.62229743e-02,  9.12966907e-01,  1.43153581e-03,\n",
            "         2.45682374e-02, -9.68197823e-01,  3.20730098e-02,\n",
            "         1.69017203e-05, -4.90627972e-05, -5.33884759e-07,\n",
            "         4.69018407e-02,  9.66640655e-03,  3.75825793e-01,\n",
            "        -1.63486511e-01,  1.52365258e-03, -4.35559750e-01,\n",
            "        -6.35941684e-01,  6.06849062e-06,  5.01664504e-02,\n",
            "        -9.25675452e-01, -5.70537930e-04,  9.68163610e-02,\n",
            "         8.37388098e-01, -3.30185935e-06, -2.07961327e-03,\n",
            "        -1.02287075e-02, -8.84309530e-01,  1.98495938e-04,\n",
            "        -1.15464572e-02,  3.81305307e-01,  7.55514130e-02,\n",
            "         8.48208293e-02,  5.27628872e-05, -2.59672165e-01,\n",
            "        -2.79369431e-07]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.55951309e-01,  3.21278930e-01,  2.98111534e+00,\n",
            "        -6.09368868e-02,  7.33582616e-01, -5.75611219e-02,\n",
            "        -1.29374707e+00, -1.84001708e+00,  2.56325817e+00,\n",
            "         4.90050614e-02,  5.79515763e-04,  2.21769047e+00,\n",
            "         6.74522761e-03,  1.57341385e+00, -5.96485019e-01,\n",
            "        -8.86049587e-03, -1.12627375e+00, -1.78743732e+00,\n",
            "        -2.76753932e-01, -1.04710793e+00, -1.24994028e+00,\n",
            "        -1.05210125e+00,  1.04519451e+00, -8.36078584e-01,\n",
            "        -1.35376528e-01, -1.15622127e+00, -9.59085584e-01,\n",
            "         1.14939737e+00,  3.99472006e-02, -3.53038460e-02,\n",
            "        -1.21208441e+00,  1.03334844e+00,  5.87577671e-02,\n",
            "        -7.07587823e-02, -2.22508207e-01, -1.18756914e+00,\n",
            "        -7.79985547e-01, -1.72204316e+00,  9.99191344e-01,\n",
            "         1.18819475e+00,  2.00917237e-02,  1.43611896e+00,\n",
            "        -2.41682283e-03, -1.00206161e+00, -2.49740973e-01,\n",
            "        -2.62230778e+00,  8.67101550e-03,  2.93034507e-04,\n",
            "         3.48479860e-02,  2.84308285e-01,  5.52809179e-01,\n",
            "         1.25352108e+00,  1.54787274e-02, -2.36923122e+00,\n",
            "         1.82187259e+00,  1.00936353e+00,  1.76362085e+00,\n",
            "        -1.06203949e+00, -2.79508305e+00,  1.99767411e+00,\n",
            "        -2.88056403e-01,  1.13116419e+00,  6.72172844e-01,\n",
            "         2.59285737e-02,  1.70421958e+00,  2.35739574e-02,\n",
            "         4.77868229e-01,  1.28106534e+00,  5.06761730e-01,\n",
            "        -1.71305693e-03,  3.42502557e-02,  1.91916287e-01,\n",
            "         2.82515144e+00,  2.22836494e+00, -5.11991838e-03,\n",
            "        -3.64126600e-02,  1.79172680e-01,  2.61157174e-02,\n",
            "        -1.25539258e-01, -2.89445686e+00, -8.76492485e-02,\n",
            "        -1.31990284e-01,  6.76691830e-01,  5.17281354e-04,\n",
            "         4.08119529e-01,  2.11786196e-01, -4.35123444e-01,\n",
            "         5.49677340e-03,  1.33523655e+00, -1.92373466e+00,\n",
            "         1.39194131e+00, -2.03907296e-01,  6.07361048e-02,\n",
            "        -2.09111050e-01, -1.57438827e+00, -2.76843524e+00,\n",
            "         5.16514410e-04, -8.79065514e-01, -9.48162854e-01,\n",
            "         7.26440549e-01,  1.14447832e+00,  1.35084808e-01,\n",
            "        -1.99590802e+00, -1.54153752e+00, -9.98843968e-01,\n",
            "         4.10293229e-02,  1.00785242e-02,  3.11937720e-01,\n",
            "         9.01631080e-03, -5.93802273e-01,  2.01825202e-01,\n",
            "         1.65883279e+00,  2.36534420e-02,  3.65251213e-01,\n",
            "         5.92526421e-03,  1.36549992e-03,  1.53408110e+00,\n",
            "        -8.05472970e-01,  9.95670378e-01, -9.70333517e-01,\n",
            "        -4.44206268e-01, -9.17561591e-01,  7.75380339e-03,\n",
            "        -4.23187226e-01,  7.22483639e-03,  7.54579604e-01,\n",
            "         2.68948898e-02, -1.32707286e+00, -4.22529802e-02,\n",
            "         1.23016787e+00, -4.51408215e-02, -1.31868660e+00,\n",
            "        -3.89660507e-01,  1.22502826e-01,  1.65543389e-02,\n",
            "         2.63278168e-02, -1.68929744e+00, -2.70401482e-02,\n",
            "        -2.83512378e+00,  4.42289740e-01,  2.72115529e-01,\n",
            "         1.30307162e-03,  2.61736333e-01, -3.26069772e-01,\n",
            "         6.45639433e-04, -9.06516492e-01, -1.48365721e-01,\n",
            "         1.28513110e+00,  4.09262292e-02,  4.62354301e-03,\n",
            "         7.20095038e-01,  3.29214364e-01, -2.81044269e+00,\n",
            "        -1.97258675e+00, -1.19936836e+00, -2.21090341e+00,\n",
            "         1.01874125e+00, -2.47705862e-01, -1.34512549e-02,\n",
            "        -2.59557068e-01,  2.58048034e+00, -2.33795628e-01,\n",
            "         9.80918646e-01,  1.25680178e-01,  7.64205530e-02,\n",
            "        -4.28620772e-03,  3.01392287e-01, -1.68593395e+00,\n",
            "         2.68887043e-01, -7.81468093e-01, -6.94495976e-01,\n",
            "         6.03931118e-03,  7.91131810e-04,  1.30561745e+00,\n",
            "         5.49159169e-01,  2.39541426e-01, -1.09295094e+00,\n",
            "         1.33428276e+00, -1.83255106e-01, -7.93713552e-04,\n",
            "         2.17619203e-02,  1.16383433e+00, -1.46176183e+00,\n",
            "        -1.48606196e-01, -2.59254277e-01,  1.63358808e+00,\n",
            "        -5.39751016e-02, -2.34605804e-01, -5.73482454e-01,\n",
            "        -1.04476464e+00, -5.94410360e-01,  1.58751439e-02,\n",
            "         2.16723657e+00,  1.51189768e+00,  2.61129618e+00,\n",
            "        -2.81599951e+00, -1.89194962e-01,  7.38648279e-03,\n",
            "        -2.05640405e-01,  6.26741155e-07,  2.77348399e+00,\n",
            "        -3.70170710e-05,  1.22882783e+00,  9.87246692e-01,\n",
            "        -1.15879774e+00,  2.98299551e+00,  1.97843468e+00,\n",
            "        -2.00481296e+00,  1.43251836e+00, -2.34060258e-01,\n",
            "         1.34576166e+00, -8.35679829e-01,  2.89339352e+00,\n",
            "         1.88133784e-03, -1.09804952e+00,  5.90751544e-02,\n",
            "         1.43237812e-02, -2.23397660e+00, -1.46620460e-02,\n",
            "         1.23891401e+00,  1.05073726e+00,  8.42280239e-02,\n",
            "         5.82967818e-01,  1.54564655e+00,  1.07977104e+00,\n",
            "         1.00786954e-01, -2.44010544e+00,  7.97866821e-01,\n",
            "         1.80970204e+00, -8.08410812e-03, -1.07952608e-02,\n",
            "         6.00226521e-01,  9.82214697e-03,  3.97627681e-01,\n",
            "        -1.08166707e+00,  5.22196256e-02, -1.04266262e+00,\n",
            "        -2.05901861e+00,  3.93383380e-05,  6.26303613e-01,\n",
            "        -1.62904000e+00, -2.16721604e-03,  2.01409602e+00,\n",
            "         1.21238542e+00, -7.10714012e-02, -1.37609482e-01,\n",
            "        -1.79896879e+00, -1.43388343e+00,  1.93955457e+00,\n",
            "        -1.17185488e-02,  4.11997139e-01,  2.96220565e+00,\n",
            "         1.20653987e+00,  6.59714686e-03, -2.67028034e-01,\n",
            "        -1.64804757e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.54376025e-02,  8.01345333e-03,  9.94009018e-01,\n",
            "        -6.60865083e-02,  6.74470067e-01, -3.15749124e-02,\n",
            "        -9.53609169e-01, -1.62319452e-01,  9.67137396e-01,\n",
            "         7.24516392e-01,  1.32966507e-03,  9.38556623e-05,\n",
            "         3.46992142e-03, -4.93027605e-02, -2.43783191e-01,\n",
            "        -4.99098033e-01, -4.69983190e-01, -1.09942500e-02,\n",
            "        -6.50533378e-01, -7.78196573e-01, -4.67114061e-01,\n",
            "        -6.43033087e-01,  6.36665642e-01, -2.02882383e-03,\n",
            "        -3.30862167e-05, -8.30716193e-01, -5.92656955e-02,\n",
            "         4.35465649e-02,  7.67239153e-01, -2.90745520e-04,\n",
            "        -1.00994788e-01,  1.62105098e-01,  4.05792862e-01,\n",
            "        -2.30010878e-02, -2.81246841e-01, -5.69313020e-02,\n",
            "        -9.33926404e-02, -8.94287705e-01,  1.20936813e-04,\n",
            "         8.19712639e-01,  4.49724942e-02,  9.09150839e-01,\n",
            "        -3.08655435e-05, -1.84199437e-01, -5.67476731e-04,\n",
            "        -1.16672656e-02,  7.54028201e-01,  4.55360636e-02,\n",
            "         8.63732956e-03,  5.62369883e-01,  4.62015897e-01,\n",
            "         8.89779702e-02,  9.28985029e-02, -1.71683118e-01,\n",
            "         9.65379119e-01,  3.17434482e-02,  7.15576172e-01,\n",
            "        -4.66785813e-03, -9.96855974e-01,  2.03160122e-02,\n",
            "        -8.29494774e-01,  5.01117051e-01, -1.47325233e-01,\n",
            "         1.66830502e-03,  4.45969345e-04,  7.27542162e-01,\n",
            "        -4.60861027e-01,  3.22245918e-02,  7.72268951e-01,\n",
            "        -2.45266058e-03,  7.01324165e-01,  3.62109207e-02,\n",
            "         9.84097242e-01,  4.59447414e-01, -9.34009254e-03,\n",
            "        -6.11161470e-01,  1.38242787e-04, -1.22647558e-03,\n",
            "        -7.74143398e-01, -9.83444393e-01, -8.87192264e-02,\n",
            "        -7.55473495e-01,  3.08984816e-01,  4.11907473e-04,\n",
            "        -1.28005400e-01,  1.96201891e-01, -3.70445788e-01,\n",
            "         4.49586078e-04, -1.01051204e-01, -8.17573905e-01,\n",
            "         3.34475248e-04, -2.01944947e-01, -7.31166840e-01,\n",
            "        -4.34301831e-02, -5.77767074e-01, -2.72630248e-04,\n",
            "         1.05403725e-03, -1.35905966e-01, -7.03422189e-01,\n",
            "         4.65353787e-01,  1.09594941e-01, -2.60632541e-02,\n",
            "        -4.50899273e-01, -3.90219577e-02, -9.58080351e-01,\n",
            "         1.87627189e-02,  5.17519657e-05,  2.32026681e-01,\n",
            "         4.29575779e-02, -5.22688031e-01,  8.71259661e-04,\n",
            "         2.45470434e-01,  3.79058123e-01,  2.16161117e-01,\n",
            "         4.74678695e-01,  2.84216441e-02,  7.69143224e-01,\n",
            "        -9.24630165e-01,  1.72246605e-01, -2.42616814e-02,\n",
            "        -1.90151215e-01, -2.53249817e-02,  1.47481794e-02,\n",
            "        -8.38108599e-01,  4.84060511e-05,  3.14465374e-01,\n",
            "         4.47470546e-01, -4.68057161e-03,  5.45971794e-04,\n",
            "         9.41578567e-01, -4.52288135e-04, -4.87762153e-01,\n",
            "        -3.32894176e-01,  1.40123621e-01,  1.10456482e-01,\n",
            "         4.03807878e-01, -1.91587722e-04, -2.63905928e-08,\n",
            "        -8.71079922e-01,  5.46607494e-01,  1.26237452e-01,\n",
            "         3.12391529e-03,  2.98025072e-01, -1.83046435e-03,\n",
            "         1.82636492e-02, -1.80628886e-05, -1.45572171e-01,\n",
            "         4.90633160e-01,  4.64952411e-03, -2.86630422e-01,\n",
            "         8.62518013e-01,  1.13742575e-01, -9.18354467e-02,\n",
            "        -8.85281503e-01, -9.75474596e-01, -4.15198430e-02,\n",
            "         2.66522877e-02, -8.35527554e-02, -4.50350484e-03,\n",
            "        -9.27458634e-04,  4.93803136e-02, -1.11975612e-06,\n",
            "         6.07391953e-01,  7.57828355e-02,  5.98872416e-02,\n",
            "        -7.74937100e-04,  2.71630008e-04, -9.89291668e-01,\n",
            "        -6.92824423e-02, -4.88748308e-04, -1.19747132e-01,\n",
            "         5.09374291e-02,  2.58522846e-06,  8.03134404e-03,\n",
            "         2.87032962e-01,  1.13692936e-02, -7.47023344e-01,\n",
            "         1.76742692e-02, -4.43675935e-01,  3.04026250e-02,\n",
            "         1.03979511e-03,  3.11439991e-01, -9.22242641e-01,\n",
            "        -9.40321088e-02, -1.74565110e-02,  6.89987168e-02,\n",
            "        -5.08249551e-02, -1.26238074e-05, -1.69494644e-01,\n",
            "        -9.04793024e-01, -2.57980399e-04,  1.25092138e-05,\n",
            "         9.92133081e-01,  9.07085598e-01,  9.24666286e-01,\n",
            "        -9.92858589e-01,  5.66583201e-02,  1.21699153e-02,\n",
            "        -8.00402850e-05, -1.30582247e-02,  1.56084761e-01,\n",
            "        -1.39019749e-05,  5.24954677e-01,  9.62997139e-01,\n",
            "        -1.57666728e-02,  9.98683095e-01,  6.61855098e-03,\n",
            "        -7.41672575e-01,  7.08635807e-01, -4.25936729e-02,\n",
            "         1.92684606e-01, -6.80832267e-01,  9.82265592e-01,\n",
            "         9.87032035e-05, -3.97679538e-01,  6.79162738e-04,\n",
            "         1.30990399e-02, -9.63442326e-01, -3.68838129e-03,\n",
            "         8.09010684e-01,  1.72134314e-03,  3.68900210e-01,\n",
            "         1.84197016e-02,  3.57228455e-05,  3.46623274e-05,\n",
            "        -5.23124039e-01, -5.12468219e-01,  7.07937956e-01,\n",
            "         9.85011756e-01, -5.98062754e-01, -2.43897852e-03,\n",
            "         8.89608324e-01,  7.41190970e-01,  4.98560160e-01,\n",
            "        -7.76672661e-01,  4.06472199e-03, -8.40534568e-01,\n",
            "        -7.75236331e-05,  7.31232149e-07, -7.57804215e-02,\n",
            "         3.31168681e-01, -6.43812418e-02,  6.03107736e-03,\n",
            "         9.38200772e-01, -7.74795488e-02,  4.41787502e-04,\n",
            "        -5.33341721e-04, -8.87032390e-01,  9.86286223e-01,\n",
            "        -2.01080155e-04, -6.96963034e-05,  9.83729661e-01,\n",
            "         2.33761035e-03,  6.23357948e-03, -8.13919678e-02,\n",
            "        -1.50271170e-02]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.2984000e+00,  1.2139205e+00,  2.9209347e+00, -1.9682150e-01,\n",
            "         8.6089742e-01, -6.3246816e-02, -1.9512357e+00, -2.7926192e+00,\n",
            "         2.5256250e+00,  1.0370798e+00,  1.3473274e-03,  3.1484661e+00,\n",
            "         9.8920131e-01, -7.2367209e-01, -1.5828247e+00, -9.7234297e-01,\n",
            "        -1.8239986e+00, -1.1133572e+00, -1.2711124e+00, -1.0409348e+00,\n",
            "        -1.2500600e+00, -1.7371545e+00,  7.5690478e-01, -1.5797375e+00,\n",
            "        -3.0025420e-01, -1.1935543e+00, -5.9629634e-02,  2.1471143e+00,\n",
            "         1.0352936e+00, -1.5096676e-01, -8.6696523e-01,  1.9758362e+00,\n",
            "         8.3749312e-01, -1.0509306e+00, -4.6317157e-01, -1.7802734e+00,\n",
            "        -1.7594289e+00, -2.4981468e+00,  1.9021312e+00,  1.1867808e+00,\n",
            "         4.9622808e-02,  1.6316302e+00, -1.7753360e-01, -1.9934633e+00,\n",
            "        -7.6931435e-01, -2.3388422e+00,  1.0083196e+00,  8.6370367e-01,\n",
            "         1.0343894e+00,  1.1914718e+00,  5.5457455e-01,  7.0930523e-01,\n",
            "         7.4466085e-01, -2.1237843e+00,  2.0215001e+00,  1.9971210e+00,\n",
            "         2.2305839e+00, -1.9320756e+00, -3.2291129e+00,  2.2357998e+00,\n",
            "        -1.1866044e+00,  9.0641195e-01, -3.2218117e-01,  1.0200444e+00,\n",
            "         2.3152990e+00,  1.0039876e+00, -4.9881417e-01,  2.0105758e+00,\n",
            "         1.4906937e+00, -2.5412650e-03,  9.3057311e-01,  5.1809233e-01,\n",
            "         2.4167659e+00,  1.2400988e+00, -1.7443163e-02, -7.2300899e-01,\n",
            "         4.3155462e-01, -6.3029581e-01, -1.0472764e+00, -2.8881326e+00,\n",
            "        -9.0708002e-02, -1.1316342e+00,  1.1276535e+00,  5.2612548e-04,\n",
            "        -5.9108537e-01,  1.1931678e+00, -5.5512792e-01,  1.0010298e+00,\n",
            "        -1.0967747e-01, -1.1502255e+00,  2.3621521e+00, -2.0498478e-01,\n",
            "        -9.3218732e-01, -3.5960838e-01, -2.3663301e+00, -3.6829102e+00,\n",
            "         9.8370117e-01, -9.1143346e-01, -1.1144083e+00,  7.3837978e-01,\n",
            "         2.4093017e-01, -3.4092553e-02, -1.7932116e+00, -2.3046639e+00,\n",
            "        -1.9831653e+00,  7.0019893e-02,  6.3552374e-01,  3.7288442e-01,\n",
            "         9.5344174e-01, -5.8917987e-01,  1.0117681e+00,  8.2040191e-01,\n",
            "         9.4187623e-01,  2.1964188e-01,  7.6252860e-01,  4.2759087e-02,\n",
            "         1.0322711e+00, -1.7534202e+00,  1.0175465e+00, -9.9151951e-01,\n",
            "        -8.4500551e-01, -9.1409874e-01,  1.6241121e-01, -1.4061446e+00,\n",
            "         1.3306652e-01,  1.7370113e+00,  5.0198275e-01, -2.1447423e+00,\n",
            "         2.6325527e-01,  2.0477633e+00, -1.0419600e+00, -5.3814310e-01,\n",
            "        -3.8903239e-01,  1.4661185e-01,  6.8069482e-01,  4.2829871e-01,\n",
            "        -1.3069841e+00, -8.4659845e-01, -3.7855208e+00,  6.3078099e-01,\n",
            "         2.8391135e-01,  4.5623234e-01,  1.2115903e+00, -3.5489491e-01,\n",
            "         1.9526603e-02, -1.0266207e+00, -1.5147500e-01,  5.3689557e-01,\n",
            "         1.0256885e+00, -2.9517150e-01,  1.6004903e+00,  3.6171779e-01,\n",
            "        -1.9784327e+00, -1.9602259e+00, -2.1970766e+00, -3.2024388e+00,\n",
            "         2.0081825e+00, -8.4799960e-02, -5.8696979e-01, -1.2304829e+00,\n",
            "         1.6505445e+00, -1.0527724e-03,  8.2733977e-01,  1.5467878e-01,\n",
            "         1.1192622e-01, -8.6743332e-04,  1.2657448e+00, -2.6135416e+00,\n",
            "        -2.6546881e-01, -1.1436236e+00, -6.9572061e-01,  5.1063184e-02,\n",
            "         1.8905348e-01,  2.2752466e+00,  7.6494169e-01,  1.2166692e+00,\n",
            "        -2.0885022e+00,  1.3614177e+00, -1.1660336e+00,  9.3454540e-01,\n",
            "         1.0430001e-01,  1.1499412e+00, -2.3710046e+00, -1.1451577e+00,\n",
            "        -1.1823270e+00,  1.8286722e+00, -5.3222574e-02, -3.7807423e-01,\n",
            "        -1.5695041e+00, -1.4988861e+00, -1.3638306e+00,  1.0048597e+00,\n",
            "         2.7917120e+00,  1.5112258e+00,  1.7699816e+00, -3.6895208e+00,\n",
            "         5.7460960e-02,  1.2289966e-02, -1.1335099e+00, -9.8941308e-01,\n",
            "         1.7884189e+00, -9.9591088e-01,  2.2260861e+00,  1.9862260e+00,\n",
            "        -1.8783863e+00,  3.9045417e+00,  2.7656884e+00, -2.9621909e+00,\n",
            "         1.9162619e+00, -1.2332866e+00,  2.3299501e+00, -8.3158541e-01,\n",
            "         2.3589072e+00,  9.4750148e-01, -2.0826304e+00,  1.0516284e+00,\n",
            "         1.4035697e-02, -2.0072432e+00, -3.3266580e-01,  1.1253096e+00,\n",
            "         2.0491216e+00,  1.0833510e+00,  5.8684188e-01,  2.0728352e+00,\n",
            "         1.0315876e+00, -6.5650344e-01, -2.3564422e+00,  9.1654056e-01,\n",
            "         2.4951353e+00, -6.9099456e-01, -1.0068390e+00,  1.5989544e+00,\n",
            "         9.5472938e-01,  9.0043682e-01, -1.0420927e+00,  2.5907981e-01,\n",
            "        -1.2230109e+00, -2.8610229e+00,  5.8300323e-03, -7.6087669e-02,\n",
            "         7.7072310e-01, -6.8037629e-02,  2.4855814e+00,  2.2099836e+00,\n",
            "        -8.5272573e-02,  5.7361838e-03, -2.6884863e+00, -2.2294321e+00,\n",
            "         2.4948168e+00, -1.0011531e+00, -3.3703825e-01,  2.9152865e+00,\n",
            "         2.1114197e+00,  6.6031823e-03, -2.9165095e-01, -2.6283565e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.51406380e-06,  3.09780290e-09,  9.81763542e-01,\n",
            "        -1.17478623e-04,  7.87912286e-05, -1.46797247e-04,\n",
            "        -9.93365169e-01, -3.15953803e-05,  9.57598150e-01,\n",
            "         5.42412922e-02,  1.15597120e-03,  3.85345775e-03,\n",
            "         2.30588266e-04, -5.04138864e-09, -1.35383452e-04,\n",
            "        -8.23165989e-04, -1.46358041e-04, -7.80253649e-01,\n",
            "        -8.47177327e-01, -7.10020244e-01, -1.92940797e-06,\n",
            "        -1.64519809e-03,  6.31558478e-01, -1.16127161e-07,\n",
            "        -1.75642526e-05,  7.61131763e-01,  5.31676829e-01,\n",
            "         7.24823331e-05,  6.91040768e-04, -1.33137557e-10,\n",
            "        -1.83418602e-01,  2.33711585e-01,  3.59829173e-05,\n",
            "        -2.67344876e-03, -2.54060298e-01, -3.50503065e-02,\n",
            "        -7.22389643e-07, -5.86892128e-01,  4.11607361e-05,\n",
            "         8.06221459e-03,  5.01773179e-01,  5.25589526e-01,\n",
            "        -5.24585403e-07, -9.86328185e-01, -2.90506221e-02,\n",
            "        -9.77544844e-01,  2.41826747e-05,  5.86473756e-02,\n",
            "         3.84163037e-02,  8.12739506e-02,  1.44481296e-02,\n",
            "        -9.99142751e-02,  1.06554786e-02, -9.40382659e-01,\n",
            "         8.91670108e-01,  4.40400019e-02,  1.28187379e-03,\n",
            "        -3.11617204e-03, -9.84118104e-01,  2.89583968e-05,\n",
            "        -8.80319357e-01,  6.93891764e-01, -3.14728804e-02,\n",
            "         6.86402724e-04,  2.27769115e-03,  1.63699344e-01,\n",
            "        -8.65734220e-01,  3.32252981e-09,  1.27469248e-05,\n",
            "        -7.82567728e-03,  1.61909163e-01,  8.85396421e-01,\n",
            "         8.92917693e-01,  2.36415267e-01, -1.82000883e-02,\n",
            "        -1.16257643e-05,  9.72881139e-07, -9.27983224e-02,\n",
            "        -1.80892542e-01, -4.37935123e-05, -9.05326009e-02,\n",
            "        -4.28528892e-06,  1.30630597e-01,  7.69505132e-05,\n",
            "        -7.69360995e-05,  3.07365980e-07, -2.84463912e-02,\n",
            "         1.56994531e-04, -3.05323243e-01, -9.68542397e-01,\n",
            "         5.63733522e-07, -3.49064589e-01, -9.58559513e-01,\n",
            "        -1.45954397e-02, -1.59067102e-04, -9.04392323e-07,\n",
            "         1.66313704e-02, -5.56381159e-02, -2.07330319e-04,\n",
            "         7.08778634e-06,  1.98989004e-01, -6.06151335e-02,\n",
            "        -8.19506407e-01, -5.60546935e-01, -6.80040419e-01,\n",
            "         8.46627913e-03,  7.39993434e-03,  4.62456048e-01,\n",
            "         9.81359836e-03, -5.28471351e-01,  2.30662725e-10,\n",
            "         6.01795435e-01,  1.15623778e-04, -6.29774988e-01,\n",
            "         4.04925318e-04,  1.23694233e-04,  6.50616705e-01,\n",
            "        -1.99378049e-03,  9.05235112e-02, -2.07948469e-04,\n",
            "        -2.42067108e-04, -1.24686514e-04,  7.95991004e-01,\n",
            "        -9.44027066e-01,  1.00361904e-04,  1.72266141e-02,\n",
            "         9.93237045e-05, -2.66812518e-02,  1.00506581e-01,\n",
            "         5.57151943e-05, -5.52909469e-08,  3.97145003e-01,\n",
            "        -3.72497678e-01,  3.40532884e-03,  6.76214768e-07,\n",
            "         6.90066159e-01, -3.99559212e-05, -5.87759930e-09,\n",
            "        -9.99532938e-01,  6.56066637e-04,  1.14755835e-07,\n",
            "         6.73502743e-01,  2.14376021e-04, -1.29045050e-08,\n",
            "         4.17602286e-02, -7.88851867e-06, -5.77106373e-03,\n",
            "        -2.11748928e-01,  1.26074347e-05, -7.50667214e-01,\n",
            "         9.79755759e-01,  1.85933113e-01, -5.25538146e-01,\n",
            "        -9.71782720e-05, -9.63854074e-01, -1.41995292e-06,\n",
            "         9.41031098e-01,  1.11278035e-01, -4.04965704e-06,\n",
            "        -5.71559156e-07,  2.24830836e-01,  4.79436421e-05,\n",
            "         6.71526849e-01,  6.70329928e-01,  1.31474051e-03,\n",
            "         6.67292923e-02,  4.19939861e-05, -9.91531253e-01,\n",
            "        -4.49764818e-01, -2.27050968e-02, -8.63345206e-01,\n",
            "         2.64539212e-01,  7.07811454e-09,  4.60363844e-06,\n",
            "         2.33734578e-08,  1.52803899e-04, -1.34664442e-04,\n",
            "         6.48857374e-03, -2.27237237e-03,  1.74192246e-05,\n",
            "         1.95458053e-10,  1.65431917e-01, -2.92300671e-01,\n",
            "        -7.69481838e-01, -4.64071892e-02,  9.92512107e-01,\n",
            "        -5.31330444e-02, -1.72850648e-07, -5.34007143e-07,\n",
            "        -7.73379087e-01, -4.79419599e-04,  5.25399402e-04,\n",
            "         9.89443302e-01,  9.03844714e-01,  9.41019475e-01,\n",
            "        -9.94447172e-01,  6.57658815e-01,  1.16550233e-04,\n",
            "        -5.99092846e-06, -7.49413520e-02,  7.91074038e-01,\n",
            "        -4.99819180e-05,  2.81963094e-05,  9.94907320e-01,\n",
            "        -9.52687085e-01,  9.93997395e-01,  4.88984466e-01,\n",
            "        -6.69601381e-01,  1.11375221e-06, -4.41298907e-04,\n",
            "         3.01166564e-01, -2.89904565e-05,  9.92826462e-01,\n",
            "         1.02360564e-08, -8.83884251e-01,  1.99660519e-03,\n",
            "         1.38321500e-02, -9.56788778e-01, -3.71772833e-02,\n",
            "         7.94530928e-01,  1.23607251e-03,  3.34587856e-03,\n",
            "         1.60983077e-03,  1.38180239e-05,  5.79891950e-12,\n",
            "        -7.06788301e-01, -9.26191688e-01,  7.25806117e-01,\n",
            "         4.76996740e-03, -8.70469511e-01, -1.61242417e-06,\n",
            "         3.04616615e-03,  8.34833384e-01,  2.78376844e-02,\n",
            "        -7.52734423e-01,  4.58182622e-04, -3.21407540e-04,\n",
            "        -8.75325767e-09,  5.33130486e-03, -7.79698670e-01,\n",
            "        -4.17441857e-04, -5.13806648e-04,  7.29296135e-09,\n",
            "         1.64041966e-02, -6.26787022e-02,  2.98926532e-02,\n",
            "        -2.02106420e-08, -8.50667715e-01,  9.97404039e-01,\n",
            "        -2.15059578e-01, -1.37127182e-02,  9.93567109e-01,\n",
            "         2.75242405e-06,  7.11215148e-03, -6.70619613e-07,\n",
            "        -4.30778385e-07]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.2228065e+00,  2.1983850e+00,  2.3441594e+00, -1.1944561e+00,\n",
            "         1.8492897e+00, -1.5420148e-01, -2.9476836e+00, -3.7713108e+00,\n",
            "         1.9161856e+00,  2.0291972e+00,  6.5460536e-03,  4.1443224e+00,\n",
            "         1.9891657e+00, -1.7092477e+00, -2.5230389e+00, -1.9674428e+00,\n",
            "        -2.5037949e+00, -1.0579656e+00, -2.2711024e+00, -8.8722980e-01,\n",
            "        -1.2517937e+00, -1.7452793e+00,  7.4400485e-01, -2.5575235e+00,\n",
            "        -6.5269285e-01,  9.9890012e-01,  5.9248048e-01,  3.0371518e+00,\n",
            "         2.0199122e+00, -1.1240183e+00, -6.8801165e-01,  2.9430830e+00,\n",
            "         1.8133852e+00, -2.0493562e+00, -2.7555281e-01, -1.7802855e+00,\n",
            "        -2.7593546e+00, -3.4940307e+00,  2.8623154e+00,  1.1884793e+00,\n",
            "         5.6591707e-01,  2.3370850e+00, -3.2045034e-01, -2.9905105e+00,\n",
            "        -1.7668076e+00, -2.3380489e+00,  2.0064826e+00,  1.8384248e+00,\n",
            "         2.0331094e+00,  2.1788626e+00,  5.5480474e-01, -1.0026099e-01,\n",
            "         1.7107407e+00, -1.7413511e+00,  3.0212865e+00,  2.9870028e+00,\n",
            "         2.3295524e+00, -2.9268570e+00, -2.4138792e+00,  3.1989284e+00,\n",
            "        -1.3772181e+00,  8.5560685e-01, -1.3219831e+00,  2.0156281e+00,\n",
            "         2.3281937e+00,  1.9365140e+00, -1.3158140e+00,  3.0093117e+00,\n",
            "         2.4860582e+00, -1.6088232e-02,  1.8653141e+00,  1.4749078e+00,\n",
            "         1.4435678e+00,  2.4212949e-01, -1.8202946e-02, -1.6158047e+00,\n",
            "         1.3696816e+00, -8.3320695e-01, -2.0471995e+00, -1.0649971e+00,\n",
            "        -9.0785697e-02, -2.1314707e+00,  2.1245930e+00,  9.1693824e-04,\n",
            "        -1.5910492e+00,  2.1849682e+00, -6.8216723e-01,  2.0009434e+00,\n",
            "        -3.2270908e-01, -2.0682039e+00,  3.3577874e+00, -3.6484051e-01,\n",
            "        -1.9299144e+00, -1.3379190e+00, -2.7700431e+00, -4.6717906e+00,\n",
            "         1.9833930e+00, -1.9008415e+00, -2.0468001e+00,  1.7318381e+00,\n",
            "         2.0171840e-01, -6.0690083e-02, -1.1837454e+00, -1.3813164e+00,\n",
            "        -2.9823501e+00,  1.0699284e+00,  1.3255838e+00,  1.3696946e+00,\n",
            "         1.9520229e+00, -5.8857834e-01,  2.0112505e+00,  6.9600785e-01,\n",
            "         1.8908827e+00, -7.7775520e-01,  1.0448143e+00,  6.9380656e-02,\n",
            "         7.7662164e-01, -2.5463264e+00,  1.5758052e+00, -1.9386264e+00,\n",
            "        -1.7628759e+00, -9.0148395e-01,  1.1605629e+00, -2.3847909e+00,\n",
            "         1.1249733e+00,  2.7298558e+00,  1.0998932e+00, -3.1439729e+00,\n",
            "         1.1692935e+00,  2.7551286e+00, -2.0391126e+00,  4.2026570e-01,\n",
            "        -6.8226469e-01,  4.1526607e-01,  1.6796920e+00,  1.1514986e+00,\n",
            "        -1.9342405e+00, -1.8018218e+00, -4.1822376e+00,  1.5845741e+00,\n",
            "         2.7900490e-01,  9.9728680e-01,  2.2068119e+00, -1.3487263e+00,\n",
            "         5.9872497e-02, -1.2469920e+00, -6.1249959e-01, -2.1502408e-01,\n",
            "         2.0255649e+00, -9.7448516e-01,  2.5980043e+00,  1.3229921e+00,\n",
            "        -1.0873150e+00, -1.9579285e+00, -2.2217009e+00, -4.1948757e+00,\n",
            "         3.0058863e+00,  1.1174104e-01, -1.5135015e+00, -2.2122700e+00,\n",
            "         8.5012895e-01,  8.8382578e-01,  8.1400216e-01,  1.1521058e+00,\n",
            "         1.1048379e+00,  6.7216411e-02,  2.2209044e+00, -3.6018996e+00,\n",
            "        -4.8441827e-01, -1.9029523e+00, -1.6929412e+00,  2.7098310e-01,\n",
            "         1.0450369e+00,  3.1719716e+00,  1.1783354e+00,  2.0785184e+00,\n",
            "        -3.0631490e+00,  2.3425756e+00, -2.1653452e+00,  1.9329340e+00,\n",
            "         2.3778872e-01,  1.1546700e+00, -3.3249776e+00, -2.1441150e+00,\n",
            "        -2.1822424e+00,  2.8224828e+00, -5.3223357e-02, -1.3779774e+00,\n",
            "        -2.5693684e+00, -1.0286859e+00, -1.8603193e+00,  1.4897034e+00,\n",
            "         2.7346511e+00,  1.5051439e+00,  1.7468852e+00, -2.9563341e+00,\n",
            "         7.8913826e-01,  1.8147713e-01, -1.6884420e+00, -1.9892193e+00,\n",
            "         1.0796280e+00, -1.9958881e+00,  3.2252581e+00,  2.9853780e+00,\n",
            "        -2.8757308e+00,  2.9031425e+00,  2.8972945e+00, -3.9616306e+00,\n",
            "         1.9286635e+00, -2.2332864e+00,  3.3291345e+00, -1.7911420e+00,\n",
            "         2.8135390e+00,  1.9282632e+00, -2.8079948e+00,  2.0512488e+00,\n",
            "         1.3837575e-02, -1.9245499e+00, -1.3324912e+00,  1.0836017e+00,\n",
            "         3.0455675e+00,  1.7084936e+00,  1.3862399e+00,  3.0633674e+00,\n",
            "         8.7211442e-01, -1.2434875e+00, -2.2330475e+00,  9.1982514e-01,\n",
            "         2.4998887e+00, -1.3370900e+00, -2.0065429e+00,  2.5080121e+00,\n",
            "         1.2047646e+00,  1.8970463e+00, -1.0564100e+00,  2.6266971e-01,\n",
            "        -3.2290953e-04, -3.7562890e+00,  7.9523146e-01, -1.0748385e+00,\n",
            "        -4.1315383e-01, -1.0400528e+00,  3.4577124e+00,  3.1867299e+00,\n",
            "        -1.0670704e-01,  3.0014008e-02, -3.6030180e+00, -3.2078509e+00,\n",
            "         3.3229623e+00, -2.0001657e+00, -1.3311198e+00,  2.8789282e+00,\n",
            "         2.9565592e+00,  7.1661547e-03, -1.2812202e+00, -3.5766356e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 9.59791578e-07,  5.58434969e-08,  9.66089249e-01,\n",
            "        -6.98857533e-04,  9.51653957e-01, -9.67188862e-06,\n",
            "        -9.99218822e-01, -4.85820383e-01,  9.55413818e-01,\n",
            "         5.84628284e-01,  1.82764512e-03,  6.26980523e-07,\n",
            "         3.17154714e-04, -1.76323385e-06, -3.48350877e-04,\n",
            "        -4.03652703e-05, -7.94021487e-01, -5.42627454e-01,\n",
            "        -4.20294732e-01, -6.85006142e-01, -8.48784029e-01,\n",
            "        -9.39468443e-01,  6.31551266e-01, -1.33372126e-02,\n",
            "        -1.41684944e-02,  7.68697500e-01,  6.35499239e-01,\n",
            "         4.31109332e-02,  1.84519552e-02, -1.13846887e-04,\n",
            "        -1.69951648e-01,  1.81184992e-01,  8.82705649e-07,\n",
            "        -1.11326604e-04, -6.44718587e-01, -9.24485794e-04,\n",
            "        -5.54368228e-07, -1.50895998e-04,  1.16490005e-02,\n",
            "         8.28177214e-01,  1.04337288e-02,  7.51929241e-04,\n",
            "        -2.27056957e-10, -8.91274989e-01, -4.45550919e-01,\n",
            "        -7.77309775e-01,  1.31112465e-03,  2.42431415e-04,\n",
            "         8.95061195e-01,  3.05884168e-05,  8.77942592e-02,\n",
            "        -2.80746162e-01,  7.85898566e-02, -9.34680343e-01,\n",
            "         1.05780140e-02,  9.80651975e-01,  2.99975760e-02,\n",
            "        -2.57782926e-06, -9.51131165e-01,  4.03197510e-06,\n",
            "        -8.78204107e-01,  6.93796635e-01, -9.60512400e-01,\n",
            "         5.23065776e-03,  2.53416318e-03,  1.97558827e-03,\n",
            "        -8.67389679e-01,  1.29410170e-03,  4.37150845e-07,\n",
            "        -8.02145060e-03,  1.30238244e-02,  9.36798513e-01,\n",
            "         7.99846500e-02, -6.27236307e-01, -6.61054322e-09,\n",
            "        -7.05775693e-02,  8.75728858e-08, -5.96292913e-02,\n",
            "        -9.83658254e-01, -1.32789202e-02, -3.60126328e-03,\n",
            "        -8.66561830e-01,  5.81037020e-03,  1.92091466e-05,\n",
            "        -3.90837677e-02,  9.96074140e-01, -5.76403618e-01,\n",
            "         8.87811038e-05, -3.57365519e-01, -7.54242420e-01,\n",
            "         1.08025415e-05, -3.48970473e-01, -9.93889511e-01,\n",
            "        -1.35606306e-03, -1.64901003e-01, -1.07766062e-01,\n",
            "         8.45034659e-01, -7.19278678e-02, -5.61748084e-06,\n",
            "         4.18707505e-02,  1.62761971e-01, -8.30103755e-02,\n",
            "        -6.39161050e-01, -7.93055058e-01, -9.77110684e-01,\n",
            "         6.52262449e-01,  1.11900874e-04,  3.28509100e-02,\n",
            "         3.51001620e-01, -2.99040359e-02,  7.68082941e-07,\n",
            "         5.92222393e-01,  2.11242601e-01, -9.38989639e-01,\n",
            "         2.93266851e-08,  2.07027210e-06,  6.34795129e-01,\n",
            "        -4.39889845e-06,  1.25364910e-04, -8.93620431e-01,\n",
            "        -7.41640478e-02, -1.83235403e-04,  1.63531244e-01,\n",
            "        -9.95086312e-01,  2.28990684e-04,  9.98240232e-01,\n",
            "         1.18360513e-05, -7.33914599e-02,  9.94402671e-06,\n",
            "         1.56215101e-05, -1.07496670e-02,  6.90369129e-01,\n",
            "        -5.93091667e-01,  3.92094076e-01,  5.92468405e-06,\n",
            "         7.40638301e-02, -7.31938243e-01, -4.96487407e-10,\n",
            "        -9.98860717e-01,  9.05275881e-01,  9.14970338e-02,\n",
            "         6.87645912e-01,  1.62528977e-07, -3.53843123e-02,\n",
            "         4.88409605e-05, -1.29031260e-02, -1.69298936e-10,\n",
            "        -8.33849192e-01,  6.36302233e-01, -9.22253549e-01,\n",
            "         9.98499811e-01,  9.79434729e-01, -6.65967286e-01,\n",
            "        -9.60217893e-01, -7.84704626e-01, -2.07092908e-05,\n",
            "         3.03591833e-07,  1.28566504e-01, -9.42564964e-01,\n",
            "        -1.08192046e-03,  1.22963525e-01,  2.40346089e-01,\n",
            "         6.61874115e-01,  5.98620772e-01,  8.06447677e-03,\n",
            "         4.67463404e-01,  3.07011069e-04, -9.95760679e-01,\n",
            "        -4.53171015e-01, -3.53180990e-03, -9.40528810e-01,\n",
            "         2.64122009e-01,  1.99666186e-11,  6.76727313e-06,\n",
            "         8.10816646e-01,  7.53166735e-01, -7.68422246e-01,\n",
            "         9.78053868e-01, -1.59097272e-05,  1.60144153e-12,\n",
            "         1.62781635e-05,  8.17472756e-01, -9.94475842e-01,\n",
            "        -8.60948494e-05, -9.95623827e-01,  9.96827126e-01,\n",
            "        -3.27450180e-05, -8.23674500e-01, -5.13162434e-01,\n",
            "        -9.23305809e-01, -2.34168321e-01,  6.66628441e-09,\n",
            "         2.09439865e-09,  9.04625177e-01,  9.40078259e-01,\n",
            "        -9.99088585e-01,  7.83612847e-01,  1.77472115e-01,\n",
            "        -7.40114032e-08, -8.86129914e-04,  9.86610278e-02,\n",
            "        -6.02058787e-03,  9.45045650e-01,  9.96735752e-01,\n",
            "        -3.35192389e-08,  9.97288406e-01,  8.48093688e-01,\n",
            "        -9.99900401e-01,  8.43839586e-01, -2.68844581e-14,\n",
            "         7.74376154e-01, -9.35106456e-01,  9.92557466e-01,\n",
            "         7.48493403e-05, -9.91533697e-01,  1.43415164e-05,\n",
            "         1.33893099e-02, -9.34775174e-01, -9.16885305e-03,\n",
            "         7.94513285e-01,  1.52593793e-03,  4.39470960e-03,\n",
            "         4.56478493e-03,  9.01045203e-01,  5.54746068e-14,\n",
            "        -9.04065192e-01, -8.59836817e-01,  7.25705385e-01,\n",
            "         9.53232944e-01, -9.13356662e-01, -2.80530393e-01,\n",
            "         9.98204648e-01,  8.99288177e-01,  9.06488858e-05,\n",
            "        -7.59557188e-01,  2.90208906e-01, -4.05090163e-04,\n",
            "        -5.78901584e-08,  5.36189616e-01, -7.47331321e-01,\n",
            "         1.85772602e-04, -6.02407277e-01,  8.15666765e-02,\n",
            "         7.22863292e-03, -5.47686070e-02,  7.56604433e-01,\n",
            "        -1.23795673e-01, -2.78871576e-03,  2.58003920e-02,\n",
            "        -7.82359064e-01, -1.11735942e-04,  9.75641549e-01,\n",
            "         5.50381927e-08,  3.14256805e-03, -1.96139945e-06,\n",
            "        -9.77772892e-01]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.5687311e+00,  3.0826526e+00,  2.0300353e+00, -2.1574445e+00,\n",
            "         1.8493063e+00, -1.1537015e+00, -3.9455082e+00, -4.6675715e+00,\n",
            "         1.8904754e+00,  1.9102620e+00,  1.8276478e-03,  4.7351704e+00,\n",
            "         2.9718428e+00, -9.7865874e-01, -3.2295909e+00, -2.8408084e+00,\n",
            "        -2.4912281e+00, -8.8503349e-01, -4.4845924e-01, -8.3848572e-01,\n",
            "        -1.2517939e+00, -1.7373163e+00,  7.4399757e-01, -2.7150264e+00,\n",
            "        -6.4579105e-01,  1.0171369e+00,  7.5058782e-01,  4.0363560e+00,\n",
            "         3.0199049e+00, -1.1241192e+00, -6.8576497e-01,  2.9432874e+00,\n",
            "         2.5507579e+00, -3.0043259e+00, -7.6620722e-01, -1.7834219e+00,\n",
            "        -2.9381332e+00, -4.3862176e+00,  3.8484671e+00,  1.1826768e+00,\n",
            "         1.0436869e-02,  2.3993714e+00, -6.2562394e-01, -3.9505413e+00,\n",
            "        -2.5272343e+00, -2.3124502e+00,  2.8838670e+00,  2.6698833e+00,\n",
            "         1.4679681e+00,  3.1256440e+00,  5.5978256e-01, -2.8851295e-01,\n",
            "         2.0567863e+00, -1.6948912e+00,  1.0579304e-02,  3.4834809e+00,\n",
            "         3.3032832e+00, -3.5278549e+00, -1.8447456e+00,  4.0116072e+00,\n",
            "        -1.3717566e+00,  8.5560602e-01, -2.2165380e+00,  3.0053358e+00,\n",
            "         3.1115611e+00,  2.9365108e+00, -1.3229686e+00,  3.7875307e+00,\n",
            "         2.6851060e+00, -1.6086074e-02,  2.1498833e+00,  2.1951132e+00,\n",
            "         2.2961728e-01, -7.5651401e-01, -8.4785187e-01, -7.0696540e-02,\n",
            "         7.8040445e-01, -9.5387995e-01, -2.7094157e+00, -4.8882693e-01,\n",
            "        -9.0786196e-02, -3.1308322e+00,  1.3822147e+00,  1.5496751e-03,\n",
            "        -2.5894964e+00,  3.1207304e+00, -6.6671056e-01,  2.9529910e+00,\n",
            "        -3.8136664e-01, -9.8272371e-01,  4.2635164e+00, -3.6465585e-01,\n",
            "        -2.8955662e+00, -2.9829955e-01, -3.7384548e+00, -4.5076628e+00,\n",
            "         1.3293147e+00, -2.8919072e+00, -2.0267844e+00,  2.7299626e+00,\n",
            "         1.6531837e-01, -8.3207458e-02, -9.3443674e-01, -1.3678482e+00,\n",
            "        -2.2293613e+00,  1.0458901e+00,  2.3218057e+00,  1.3927326e+00,\n",
            "         2.8735435e+00, -3.0785999e-01,  2.0109489e+00,  6.8111533e-01,\n",
            "         1.0177673e+00, -1.7294899e+00,  1.0248501e+00,  1.0009789e+00,\n",
            "         7.4985570e-01, -2.4979620e+00,  2.3883405e+00, -1.9250007e+00,\n",
            "        -2.6615264e+00, -9.7162998e-01,  1.0634888e+00, -3.3822279e+00,\n",
            "         2.0542159e+00,  3.5329776e+00,  1.8530754e+00, -3.1753659e+00,\n",
            "         1.2330698e+00,  3.6587436e+00, -3.0289824e+00,  1.4193027e+00,\n",
            "        -6.8242729e-01,  4.1428196e-01,  2.2586272e+00,  7.4199699e-02,\n",
            "        -9.3842322e-01, -2.3856764e+00, -3.7360759e+00,  1.6069851e+00,\n",
            "         2.7810085e-01,  9.9077469e-01,  1.1147194e+00, -2.3419521e+00,\n",
            "         2.1497831e-01, -1.2453858e+00, -8.0785766e-04, -1.2145108e+00,\n",
            "         1.8950059e+00, -1.6115068e+00,  3.5972719e+00,  2.2854412e+00,\n",
            "        -1.0813619e+00, -1.9486997e+00, -1.0574987e+00, -5.1370049e+00,\n",
            "         3.8935623e+00,  1.2992543e-01, -1.8146716e+00, -3.1764579e+00,\n",
            "         6.6177619e-01,  9.1080838e-01,  7.9614413e-01,  6.9585574e-01,\n",
            "         2.0187469e+00,  5.1020265e-01,  3.0358384e+00, -4.6012583e+00,\n",
            "        -4.9499303e-01, -1.9042971e+00, -1.7426420e+00,  2.7053660e-01,\n",
            "         2.8596568e-01,  4.0039077e+00,  1.1762704e+00,  9.8913378e-01,\n",
            "        -1.0909998e+00,  2.7656105e+00, -3.0027444e+00,  2.1723433e+00,\n",
            "         1.9606060e-01,  1.1495136e+00, -3.1297946e+00, -3.1384985e+00,\n",
            "        -3.0781896e+00,  3.7324667e+00, -5.3471576e-02, -1.3793114e+00,\n",
            "        -3.5572855e+00, -1.6109945e+00, -1.8606193e+00,  1.6437907e+00,\n",
            "         2.7230890e+00,  1.4971143e+00,  1.7387462e+00, -3.8666527e+00,\n",
            "         1.0565797e+00,  1.7939228e-01, -2.5552502e+00, -2.9890065e+00,\n",
            "         9.9062532e-02, -2.3783607e+00,  4.2175975e+00,  3.2089610e+00,\n",
            "        -2.8962781e+00,  3.3010018e+00,  2.8887725e+00, -4.9604321e+00,\n",
            "         1.9295243e+00, -3.2330365e+00,  1.0311679e+00, -1.8736080e+00,\n",
            "         2.7949824e+00,  1.9104376e+00, -2.7644413e+00,  3.0429957e+00,\n",
            "         1.3391329e-02, -1.9139805e+00, -1.2818414e+00,  1.0835538e+00,\n",
            "         4.0385218e+00,  2.4166989e+00,  1.3690039e+00,  2.1889398e+00,\n",
            "         8.3977270e-01, -1.4954472e+00, -1.6270319e+00,  9.1964829e-01,\n",
            "         1.8661190e+00, -1.5474072e+00, -2.1705391e+00,  3.5079937e+00,\n",
            "         1.4684925e+00,  2.7024701e+00, -1.0129983e+00,  2.9950172e-01,\n",
            "        -4.0585655e-04, -3.9137778e+00,  8.8357532e-01, -2.0731692e+00,\n",
            "         9.9964589e-01, -1.0439252e+00,  4.4422712e+00,  4.1665096e+00,\n",
            "        -1.0611190e-01,  1.0002768e+00, -3.9863698e+00, -2.1439967e+00,\n",
            "         2.5806135e-02, -1.0514346e+00, -2.2828031e+00,  2.2174292e+00,\n",
            "         1.6173344e+00,  3.3451039e-03, -1.2818346e+00, -4.5556974e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.90052746e-08,  1.44125337e-10,  7.66400933e-01,\n",
            "        -1.28676789e-02,  7.35751033e-01, -1.69996335e-03,\n",
            "        -5.77016830e-01, -1.79774826e-03,  7.78146267e-01,\n",
            "         4.16366369e-01,  2.60294854e-07,  4.28045401e-04,\n",
            "         1.45646205e-04, -9.33556898e-10, -1.67991444e-02,\n",
            "        -3.67376342e-04, -7.83978924e-02, -6.13342047e-01,\n",
            "        -6.69156248e-03, -6.75320446e-01, -1.58564566e-04,\n",
            "        -9.17576253e-02,  6.30452931e-01, -4.88797960e-11,\n",
            "        -8.54645805e-07,  7.60078609e-01,  6.41272783e-01,\n",
            "         2.96057276e-02,  1.44389905e-05, -3.10541083e-07,\n",
            "        -4.16043282e-01,  5.67658544e-01,  9.37878497e-07,\n",
            "        -5.87828952e-10, -7.65270591e-01, -2.26988384e-08,\n",
            "        -7.27181396e-05, -1.75260229e-05,  1.49840821e-06,\n",
            "         1.64366560e-04,  2.29771256e-01,  8.29909040e-05,\n",
            "        -3.18988690e-11, -7.35343306e-08, -9.97783244e-01,\n",
            "        -8.33976924e-01,  2.69288048e-05,  3.82517674e-03,\n",
            "         9.38868179e-05,  9.78765544e-03,  3.67809457e-06,\n",
            "        -8.56392860e-01,  3.99935561e-06, -6.12108290e-01,\n",
            "         7.67763709e-07,  2.20313668e-03,  3.37026338e-03,\n",
            "        -7.95157440e-03, -6.84523821e-01,  5.80327865e-03,\n",
            "        -9.17639911e-01,  6.72468245e-01, -9.91749704e-01,\n",
            "         1.32760050e-07,  5.16462177e-02,  1.97388083e-02,\n",
            "        -8.70667160e-01,  5.32785291e-03,  1.05669880e-02,\n",
            "        -1.81557294e-02,  2.39926539e-02,  5.79484959e-06,\n",
            "        -6.46741271e-01, -8.51704001e-01, -4.20087576e-03,\n",
            "        -1.75535330e-03,  6.96896807e-09, -8.00818563e-01,\n",
            "        -1.02626938e-04, -8.18465371e-03, -9.40710306e-02,\n",
            "        -3.35663295e-04,  5.19777302e-07,  1.09931921e-06,\n",
            "        -1.03709732e-11,  1.54591191e-07, -8.73722136e-04,\n",
            "         2.30034741e-04, -3.92242312e-01, -9.61465597e-01,\n",
            "         2.58654898e-09, -3.50343108e-01, -9.93654311e-01,\n",
            "        -2.72722661e-01, -3.86470601e-05, -4.57245824e-06,\n",
            "         2.90181179e-05, -2.11700246e-01, -7.11059693e-06,\n",
            "         6.52526617e-02,  1.55689940e-01, -2.06850037e-01,\n",
            "        -7.34409571e-01, -4.70081925e-01, -7.86791891e-02,\n",
            "         1.60961214e-03,  4.84610518e-06,  9.77453291e-01,\n",
            "         2.22009294e-06, -3.97408767e-05,  1.16271554e-12,\n",
            "         5.88343680e-01,  7.55474175e-05, -7.54682720e-01,\n",
            "         7.19657750e-04,  1.94642889e-05,  2.45717555e-01,\n",
            "        -2.55434727e-03,  8.48162547e-03, -4.00889712e-06,\n",
            "        -7.59659469e-01, -7.86859200e-09,  1.25840415e-07,\n",
            "        -3.46452557e-02,  1.55926842e-04,  5.31199839e-06,\n",
            "         8.69602900e-06, -2.03762582e-07,  5.49514731e-03,\n",
            "         8.97956546e-03, -3.58170293e-09,  9.83590662e-01,\n",
            "        -5.49070165e-02,  1.31186307e-03,  3.38893165e-06,\n",
            "         1.17434440e-02, -4.14045098e-06, -1.55963851e-13,\n",
            "        -9.97777343e-01,  6.64839923e-01,  2.59091103e-05,\n",
            "         1.48748271e-02,  8.71267389e-07, -6.12437861e-06,\n",
            "         5.86209409e-02, -2.92945757e-09, -5.08819893e-03,\n",
            "        -8.39544296e-01,  9.93747592e-01, -9.89045858e-01,\n",
            "         8.86716366e-01,  2.85871560e-04, -6.74449623e-01,\n",
            "        -1.23464223e-03, -7.78073668e-01, -2.29218937e-08,\n",
            "         6.98192802e-04,  8.10730457e-01, -1.13879599e-08,\n",
            "        -1.02923450e-05,  3.63181949e-01,  3.03764758e-03,\n",
            "         6.61774993e-01,  9.28145349e-01,  9.88937318e-01,\n",
            "         6.27492964e-01,  1.22814299e-05, -9.44071412e-01,\n",
            "        -8.80980968e-01, -2.20407295e-04, -4.10196871e-01,\n",
            "         3.33085239e-01,  3.34332617e-06,  6.66224878e-06,\n",
            "         2.22348119e-03,  1.25326342e-05, -2.05884571e-05,\n",
            "         1.44803234e-05, -2.82495803e-05,  5.58559350e-07,\n",
            "         5.30829880e-10,  4.66227233e-01, -4.95875021e-04,\n",
            "        -4.67271358e-03, -4.47320454e-02,  2.97550336e-02,\n",
            "        -1.56014084e-05, -1.16207026e-04, -1.06181689e-02,\n",
            "        -7.31733255e-03, -2.10951921e-03,  4.64486068e-14,\n",
            "         4.38199610e-01,  1.26809791e-01,  6.37925804e-01,\n",
            "        -9.98749316e-01,  9.57189441e-01,  5.65623377e-05,\n",
            "        -1.23826161e-04, -1.06732175e-03, -2.81304151e-01,\n",
            "        -6.89479940e-09,  1.88359758e-03,  9.99283731e-01,\n",
            "        -3.90497662e-05,  9.70027685e-01,  9.72031534e-01,\n",
            "        -1.99896842e-01,  2.72588090e-06, -8.36180103e-09,\n",
            "         9.34614837e-01, -5.22436108e-04,  9.98129785e-01,\n",
            "         4.37863491e-07, -2.45591812e-03,  1.23158039e-03,\n",
            "         1.31294187e-02, -8.31094503e-01, -7.53824279e-05,\n",
            "         7.94478059e-01,  1.92361749e-05,  1.10718116e-01,\n",
            "         1.43023310e-02,  1.27892996e-09,  6.55367179e-16,\n",
            "        -2.89646257e-02, -5.60539782e-01,  7.26454973e-01,\n",
            "         5.71724251e-02, -9.13607359e-01, -1.20337093e-02,\n",
            "         9.89157498e-01,  9.85258222e-01,  5.59985987e-04,\n",
            "        -3.70885420e-04,  1.01675814e-05, -7.15955626e-04,\n",
            "        -5.58864706e-08,  4.26417822e-03, -9.93052125e-01,\n",
            "        -1.29524201e-01, -4.34924036e-01,  5.82455214e-05,\n",
            "         1.33367553e-02, -9.69831198e-02,  7.64658153e-01,\n",
            "        -1.21099987e-07, -9.94372904e-01,  1.39725357e-01,\n",
            "        -4.59467446e-06, -4.58640270e-02,  8.40456367e-01,\n",
            "         1.82792358e-11,  8.50108638e-03, -3.53149198e-06,\n",
            "        -5.12380677e-04]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.5195291e+00,  4.0819917e+00,  1.0115465e+00, -3.1572890e+00,\n",
            "         1.8619161e+00, -2.0338562e+00, -3.9827287e+00, -5.6649060e+00,\n",
            "         1.0406549e+00,  2.9066794e+00,  1.4121503e-03,  5.7345810e+00,\n",
            "         3.9714313e+00, -1.8235666e+00, -4.2081227e+00, -3.8386891e+00,\n",
            "        -3.4099493e+00, -7.2244966e-01, -1.4227493e+00, -8.2051051e-01,\n",
            "        -1.3241085e+00, -1.7573606e+00,  7.4216753e-01, -3.7008197e+00,\n",
            "        -1.1146713e+00,  9.9640125e-01,  7.6033652e-01,  5.0326695e+00,\n",
            "         4.0192194e+00, -2.0607350e+00, -4.4299209e-01,  3.9418240e+00,\n",
            "         3.5507495e+00, -4.0027986e+00, -1.2523491e+00, -2.0553811e+00,\n",
            "        -3.9357431e+00, -4.3947763e+00,  4.8464413e+00,  1.1945899e+00,\n",
            "         1.0090368e+00,  3.3992410e+00, -1.0107617e+00, -4.9477954e+00,\n",
            "        -3.5268157e+00, -1.3127310e+00,  3.8832223e+00,  3.6695695e+00,\n",
            "         2.4657159e+00,  4.1228867e+00,  1.3684827e+00, -1.2796547e+00,\n",
            "         3.0457292e+00, -7.1229249e-01,  1.0102648e+00,  4.4762869e+00,\n",
            "         4.1715279e+00, -4.5185480e+00, -8.3757758e-01,  5.0095668e+00,\n",
            "        -1.6956418e+00,  8.1523651e-01, -3.2155321e+00,  4.0053015e+00,\n",
            "         3.1438360e+00,  3.9100816e+00, -1.3358322e+00,  4.7874813e+00,\n",
            "         3.6846185e+00, -1.8157788e-02,  2.1825485e+00,  3.1391809e+00,\n",
            "        -7.7045280e-01, -1.2625837e+00, -1.8476164e+00, -1.0697013e+00,\n",
            "         1.7588191e+00, -1.1664789e+00, -1.7923865e+00, -5.2151382e-01,\n",
            "        -9.4389848e-02, -4.1308260e+00,  2.3792071e+00,  1.5512952e-03,\n",
            "        -3.5894868e+00,  4.1189542e+00, -1.5802516e+00,  3.9525833e+00,\n",
            "        -4.1449121e-01, -1.9649475e+00,  5.2284436e+00, -3.6584070e-01,\n",
            "        -2.8928959e+00, -1.2855985e+00, -4.7097569e+00, -5.5074806e+00,\n",
            "         2.3293147e+00, -3.5915661e+00, -3.0256755e+00,  3.7146785e+00,\n",
            "         1.5696755e-01, -2.0987868e-01, -9.3823516e-01, -5.1032591e-01,\n",
            "        -3.1443915e+00,  2.0451353e+00,  3.2946393e+00,  2.2570000e+00,\n",
            "         3.8676913e+00, -2.2707477e-01,  2.9882727e+00,  6.7514485e-01,\n",
            "         1.9957931e+00, -2.7293432e+00,  1.4755210e+00,  1.9597193e+00,\n",
            "         2.5085005e-01, -3.4586751e+00,  3.3585348e+00, -1.9298964e+00,\n",
            "        -3.6498272e+00, -1.4994711e+00,  2.0586543e+00, -4.3768282e+00,\n",
            "         3.0533221e+00,  4.5299001e+00,  2.6060550e+00, -4.1752391e+00,\n",
            "         2.2316570e+00,  4.6004858e+00, -4.0289712e+00,  2.3974254e+00,\n",
            "        -8.4201139e-01,  4.1458526e-01,  3.1799724e+00,  8.8189459e-01,\n",
            "        -1.9333063e+00, -3.3598146e+00, -3.4278796e+00,  2.5486577e+00,\n",
            "         6.8545491e-01,  1.3503460e+00,  2.1099062e+00, -3.3416944e+00,\n",
            "         2.1339563e-01, -2.2443299e+00, -1.0005445e+00, -1.2196927e+00,\n",
            "         2.8833334e+00, -2.6008587e+00,  4.5967603e+00,  3.2756786e+00,\n",
            "        -8.1886381e-01, -1.9478514e+00, -1.0404701e+00, -6.1364284e+00,\n",
            "         4.8926735e+00,  1.1291629e+00, -2.8145745e+00, -4.1760592e+00,\n",
            "         4.1273117e-01,  1.8868093e+00,  7.9596651e-01,  1.6527635e+00,\n",
            "         3.0166497e+00,  7.3734415e-01,  4.0047388e+00, -4.6013103e+00,\n",
            "        -1.3803819e+00, -2.7742968e+00, -1.0667834e+00,  3.4629455e-01,\n",
            "         1.2820553e+00,  4.9949512e+00,  1.8350257e+00,  1.9887525e+00,\n",
            "        -2.0621691e+00,  3.7018833e+00, -4.0024090e+00,  3.0634806e+00,\n",
            "         1.1066608e+00,  1.3567889e+00, -4.1254745e+00, -4.1384072e+00,\n",
            "        -4.0758934e+00,  4.7210317e+00, -5.5828318e-02, -2.3788731e+00,\n",
            "        -4.5169492e+00, -7.4557941e-03, -2.7879608e+00,  2.3818066e+00,\n",
            "         3.6722720e+00,  5.0000721e-01,  7.5466895e-01, -3.6893010e+00,\n",
            "         2.0562525e+00,  8.7931865e-01, -3.5549538e+00, -3.9889758e+00,\n",
            "        -3.1500304e-01, -3.3783047e+00,  5.1880026e+00,  4.2084293e+00,\n",
            "        -3.3993702e+00,  2.0928483e+00,  2.7279170e+00, -5.9595637e+00,\n",
            "         1.9376980e+00, -4.2329717e+00,  2.0310838e+00, -2.8733826e+00,\n",
            "         3.4869547e+00,  2.9058087e+00, -2.8102727e+00,  4.0429568e+00,\n",
            "         1.3372683e-02, -1.1998430e+00, -2.2818136e+00,  1.0834583e+00,\n",
            "         5.0381689e+00,  3.3528633e+00,  2.0147617e+00,  3.1889019e+00,\n",
            "         9.7143614e-01, -1.4906549e+00, -6.3400191e-01,  9.2118245e-01,\n",
            "         2.8653083e+00, -1.5493157e+00, -3.1433651e+00,  4.5076528e+00,\n",
            "         2.4588349e+00,  3.6926506e+00, -1.0130745e+00,  2.9980564e-01,\n",
            "        -7.2126737e-04, -4.9066133e+00,  1.8714151e+00, -2.9504828e+00,\n",
            "        -9.9864709e-01, -2.0429521e+00,  5.4421268e+00,  5.1665087e+00,\n",
            "        -9.7297944e-02,  1.0074105e+00, -4.9660869e+00, -3.0470653e+00,\n",
            "         1.4064589e-01, -2.0512059e+00, -3.2532351e+00,  1.2238905e+00,\n",
            "         2.2107971e+00,  9.6752793e-01, -2.2804966e+00, -5.5398026e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.50618595e-09,  1.43626902e-10,  1.89112546e-03,\n",
            "        -2.91145308e-09,  1.02650365e-02, -2.19373442e-06,\n",
            "        -4.64293735e-05, -2.27097898e-05,  1.12865873e-01,\n",
            "         1.67335693e-05,  3.85661245e-08,  7.98066139e-06,\n",
            "         3.83353154e-06, -9.41176313e-06, -6.39695031e-07,\n",
            "        -1.27882345e-06, -2.36184544e-10,  2.40103170e-01,\n",
            "        -6.08995651e-06, -6.26933813e-01, -8.94465160e-08,\n",
            "        -1.62335925e-06,  6.30450130e-01, -2.66536404e-06,\n",
            "        -6.48312678e-04,  9.26519752e-01,  5.98686934e-01,\n",
            "         5.88757842e-08,  2.57822489e-06, -3.90154992e-11,\n",
            "         3.66861284e-01,  9.46714103e-01,  5.64276525e-06,\n",
            "        -9.92027462e-01, -9.63917613e-01, -4.94580149e-07,\n",
            "        -9.44913609e-06, -8.22877465e-14,  4.85722534e-03,\n",
            "         7.71633327e-01,  3.40882252e-07,  3.55584826e-03,\n",
            "        -5.13506393e-06, -9.99970913e-01, -9.98756886e-01,\n",
            "        -4.40837801e-01,  2.79457254e-07,  1.29130228e-06,\n",
            "         9.98003423e-01,  1.58639147e-03,  1.54965846e-06,\n",
            "        -8.58159959e-01,  3.41176406e-06, -5.85651696e-01,\n",
            "         6.43462985e-13,  1.34190256e-02,  7.83832192e-01,\n",
            "        -1.19123433e-03,  7.43990481e-01,  5.00189060e-07,\n",
            "        -4.12892550e-01,  6.85264885e-01, -9.11451643e-05,\n",
            "         3.82627263e-07,  1.71929840e-02,  4.07984538e-04,\n",
            "        -8.21268678e-01,  1.22620296e-08,  2.49857640e-05,\n",
            "         4.31902474e-04,  3.41320811e-06,  2.20538982e-06,\n",
            "        -9.04843271e-01, -8.51271212e-01, -9.86755431e-01,\n",
            "        -6.35911594e-04,  1.33257493e-06, -8.52481186e-01,\n",
            "        -4.21757613e-05, -1.32880337e-03, -5.16757071e-01,\n",
            "        -1.95810060e-07,  5.80400629e-05, -2.31975645e-01,\n",
            "        -1.42199061e-08,  2.64009145e-07, -3.60967169e-05,\n",
            "         1.06822453e-01, -8.44952106e-01, -9.94612217e-01,\n",
            "         1.20834542e-07, -8.21747541e-01, -9.96557176e-01,\n",
            "        -6.10151154e-04, -6.42024034e-09, -1.25392849e-04,\n",
            "         9.06027198e-01, -3.70515090e-06, -7.23051419e-03,\n",
            "         2.39560701e-04,  3.05300616e-02, -2.68619359e-01,\n",
            "         1.68102458e-02,  3.36117268e-01, -6.13230668e-07,\n",
            "         4.71611820e-05,  3.47712842e-07,  3.26323118e-07,\n",
            "         1.01129152e-01, -2.66042316e-05,  3.94530129e-03,\n",
            "         5.85173011e-01,  6.34063443e-04, -1.00567206e-07,\n",
            "         1.36926898e-03,  1.95249508e-03,  7.90706098e-01,\n",
            "        -7.16256440e-01,  3.03868903e-04, -7.37654930e-03,\n",
            "        -1.66493963e-04, -3.11189774e-06,  4.92084291e-06,\n",
            "        -2.12741375e-04,  8.42865169e-01,  6.70633256e-01,\n",
            "         4.50091413e-08, -8.08224738e-01,  9.91608143e-01,\n",
            "         3.40253735e-07, -2.66994087e-12,  8.81590229e-03,\n",
            "        -9.39218410e-07,  6.20795618e-05,  3.44656944e-01,\n",
            "         3.08948778e-08, -9.86043394e-01, -3.78794866e-05,\n",
            "         7.61568010e-01, -6.17256774e-07,  5.12771634e-03,\n",
            "         3.68526555e-04,  4.66756243e-03, -1.92024646e-10,\n",
            "         9.15179399e-08, -2.19680018e-07, -5.92934310e-01,\n",
            "        -9.75288808e-01,  7.23065138e-02, -9.95026350e-01,\n",
            "         1.98417157e-03,  9.85501230e-01, -6.72577679e-01,\n",
            "        -5.47547643e-06, -1.35844853e-02, -1.88399591e-11,\n",
            "         9.98445094e-01,  9.92144458e-04, -1.46383472e-09,\n",
            "        -7.71190223e-10, -4.95352328e-01,  1.31057147e-08,\n",
            "         6.81713998e-01,  9.84608173e-01,  8.31952260e-04,\n",
            "         9.01124895e-01,  4.73828204e-02, -2.35905871e-04,\n",
            "        -9.82043624e-01, -2.09313929e-02, -1.99054852e-02,\n",
            "         3.85903686e-01,  2.90130498e-03,  9.68916964e-08,\n",
            "         5.64593128e-09,  9.87290680e-01, -2.34416029e-06,\n",
            "         1.47799537e-01, -1.06121507e-03,  1.23318183e-04,\n",
            "         6.76133316e-10,  9.79921520e-01, -6.58218369e-09,\n",
            "        -6.46200962e-04, -1.24084245e-05,  3.85953972e-05,\n",
            "        -5.42349044e-05, -1.56504497e-11, -2.04914697e-02,\n",
            "        -2.26910472e-01, -9.93403316e-01,  9.83510673e-01,\n",
            "         8.81979644e-01, -4.10515785e-01, -8.07595700e-02,\n",
            "        -9.90872979e-01,  8.28830972e-02,  1.82269764e-06,\n",
            "        -1.66635513e-02, -1.78564619e-03, -5.60353279e-01,\n",
            "        -4.90274101e-01,  1.30321644e-03,  1.75391312e-06,\n",
            "        -4.47017694e-04, -7.58845329e-01,  9.25989270e-01,\n",
            "        -3.88976812e-01,  2.26449501e-07, -5.44117996e-03,\n",
            "         9.01973307e-01, -1.33272169e-06,  9.95587528e-01,\n",
            "         5.67329698e-05, -5.17174311e-04,  9.95140433e-01,\n",
            "         5.98683907e-03, -7.42898345e-01, -1.08851991e-05,\n",
            "         6.62728399e-02,  1.00795421e-06,  5.71600854e-01,\n",
            "         1.92678708e-04,  2.04093120e-09,  8.19858909e-03,\n",
            "        -9.03424323e-01,  3.49394023e-01,  7.31479526e-01,\n",
            "         3.91374081e-01, -9.86997604e-01, -9.06876303e-05,\n",
            "         1.34425990e-08,  1.06038882e-04,  6.58764178e-03,\n",
            "        -1.33423146e-05,  1.51244079e-04, -7.19301577e-04,\n",
            "        -1.09986757e-07,  4.14477029e-07, -3.67956042e-01,\n",
            "        -9.56265032e-01, -1.75987452e-03,  1.49207972e-05,\n",
            "         3.03263031e-03,  3.71175289e-01,  7.62690008e-01,\n",
            "        -3.82440630e-05, -9.89372313e-01,  1.40155926e-01,\n",
            "        -1.13425165e-04, -7.71704614e-01,  2.23724514e-01,\n",
            "         4.58790538e-07,  1.98833590e-08, -6.07152120e-04,\n",
            "        -9.97945815e-02]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.3567209e+00,  4.7594995e+00,  1.8911277e-03, -4.1409688e+00,\n",
            "         2.7851756e+00, -3.0307281e+00, -4.9777546e+00, -6.4971352e+00,\n",
            "         1.1334919e-01,  3.8253589e+00,  2.4983849e-02,  6.4483070e+00,\n",
            "         4.8718410e+00, -2.8235388e+00, -4.3885055e+00, -4.7341666e+00,\n",
            "        -3.1260691e+00,  2.7202913e-01, -4.4166785e-01, -8.0714947e-01,\n",
            "        -2.3240449e+00, -1.7572248e+00,  7.4216801e-01, -4.6827717e+00,\n",
            "        -1.5340284e+00,  1.6332294e+00,  6.9109803e-01,  4.2607422e+00,\n",
            "         4.1518369e+00, -2.2537389e+00,  4.0838993e-01,  4.9314232e+00,\n",
            "         4.5494332e+00, -4.9869976e+00, -2.0428746e+00, -2.5205033e+00,\n",
            "        -1.0274106e+00, -5.1045680e+00,  4.8749514e+00,  1.1529431e+00,\n",
            "         2.0090368e+00,  8.1833607e-01, -1.6851188e+00, -5.8094363e+00,\n",
            "        -4.5229163e+00, -4.8013011e-01,  3.6144867e+00,  4.6483908e+00,\n",
            "         3.4645791e+00,  5.0801468e+00,  2.3357940e+00, -1.2863472e+00,\n",
            "         2.9112241e+00, -6.7103726e-01,  1.6559621e-02,  5.3851366e+00,\n",
            "         3.7110610e+00, -5.4625664e+00,  9.5946938e-01,  5.9701281e+00,\n",
            "        -1.6983756e+00,  8.3910519e-01, -4.1628432e+00,  4.9759493e+00,\n",
            "         3.1269686e+00,  4.0910325e+00, -1.1607156e+00,  5.7320914e+00,\n",
            "         2.6779015e+00,  4.1418269e-01,  3.1824689e+00,  4.1087775e+00,\n",
            "        -1.7498168e+00, -1.2607895e+00, -2.8255405e+00, -2.0685053e+00,\n",
            "         2.6200502e+00, -1.3756562e+00, -7.1060669e-01, -1.5106781e+00,\n",
            "        -5.7190889e-01, -4.4304366e+00,  3.3778412e+00, -6.4201647e-01,\n",
            "        -4.5892820e+00,  4.4817777e+00, -2.5801950e+00,  4.7884030e+00,\n",
            "        -1.2417014e+00, -2.9580853e+00,  6.1917229e+00, -1.2803839e+00,\n",
            "        -3.1826386e+00, -1.3396211e+00, -3.6844277e+00, -6.4523997e+00,\n",
            "         3.3291700e+00, -2.5924587e+00, -2.5407898e+00,  4.7132077e+00,\n",
            "         3.0627633e-02, -2.7537537e-01,  1.6812639e-02,  3.4974644e-01,\n",
            "        -4.0634794e+00,  3.0435371e+00,  4.2267337e+00,  3.2448673e+00,\n",
            "         4.8566108e+00, -5.4816365e-01,  3.9878838e+00,  6.7319536e-01,\n",
            "         2.9942181e+00, -3.7276170e+00,  2.2014573e+00,  2.9097769e+00,\n",
            "         1.0733132e+00, -4.4094472e+00,  3.7026341e+00, -2.9290676e+00,\n",
            "        -4.5221748e+00, -2.3092554e+00,  9.9663615e-01, -4.9580779e+00,\n",
            "         4.0527720e+00,  5.4763246e+00,  2.1282561e+00, -5.1623306e+00,\n",
            "         3.2202425e+00,  5.5927191e+00, -3.0772352e+00,  3.3885622e+00,\n",
            "        -1.8397686e+00,  4.3813717e-01,  3.4226849e+00,  1.8731449e+00,\n",
            "        -2.9104042e+00, -4.2110000e+00,  9.9999177e-01, -9.8644698e-01,\n",
            "         1.6853868e+00,  1.4689142e+00,  3.1067352e+00, -4.3412099e+00,\n",
            "         1.1900012e+00, -2.0196486e+00, -7.7632356e-01, -2.2006464e+00,\n",
            "         1.9470760e+00, -2.9974148e+00,  3.5939646e+00,  4.1170688e+00,\n",
            "        -8.1884557e-01, -1.6714100e+00, -1.3587248e-02, -7.0187936e+00,\n",
            "         5.8592739e+00,  1.0376198e-01, -3.8096526e+00, -4.7505093e+00,\n",
            "        -5.8261549e-01,  2.7014315e+00,  8.8714439e-01,  2.6500459e+00,\n",
            "         3.9965653e+00,  1.6946057e+00,  3.0401599e+00, -5.3533573e+00,\n",
            "        -2.3744771e+00, -1.7758613e+00, -9.9525791e-01,  4.0697795e-01,\n",
            "         2.2786424e+00,  5.7547574e+00,  1.6865877e+00,  2.8608544e+00,\n",
            "        -2.2240934e-01,  2.8818512e+00, -4.9628992e+00,  4.0626793e+00,\n",
            "         1.3028519e+00,  2.3304391e+00, -5.0077701e+00, -5.1364360e+00,\n",
            "        -5.0632153e+00,  5.7094951e+00, -9.8732251e-01, -3.3735936e+00,\n",
            "        -5.2947044e+00, -9.9891931e-01, -3.7610102e+00,  3.2740839e+00,\n",
            "         4.6532326e+00, -4.3738526e-01, -8.0935895e-02, -2.6927764e+00,\n",
            "         2.9674852e+00,  5.5964690e-01, -4.5178843e+00, -4.6855516e+00,\n",
            "        -6.3335216e-01, -4.3782554e+00,  2.4809253e+00,  5.2013907e+00,\n",
            "        -3.8248024e+00, -9.9665511e-01,  1.7637060e+00, -6.9567904e+00,\n",
            "         1.0356770e+00, -3.6813972e+00,  3.0309875e+00, -3.7473643e+00,\n",
            "         3.4766593e+00,  3.8028209e+00, -1.9386480e+00,  3.0131013e+00,\n",
            "         1.0316433e-02, -1.1761026e+00, -3.1675818e+00,  6.9134198e-02,\n",
            "         5.0692048e+00,  4.3526959e+00,  2.9530759e+00,  3.5229025e+00,\n",
            "         1.4158164e+00, -1.4905419e+00,  3.6485997e-01,  9.3204439e-01,\n",
            "         5.2360421e-01, -2.5454922e+00, -4.1429377e+00,  4.5744076e+00,\n",
            "         1.3592637e+00,  4.6576734e+00, -1.0719047e+00,  1.0969563e+00,\n",
            "        -7.2083238e-04, -5.6768770e+00,  2.8068345e+00, -3.9502094e+00,\n",
            "        -1.9110166e+00, -2.0647278e+00,  5.2395344e+00,  6.0907159e+00,\n",
            "         8.8678545e-01,  1.0026464e+00, -5.7036762e+00, -3.7209129e+00,\n",
            "         1.4669934e-01, -2.9827552e+00, -3.6494970e+00,  2.2757366e-01,\n",
            "         2.8072937e+00,  1.4431511e+00, -3.2098668e+00, -6.0898271e+00]],\n",
            "      dtype=float32)>)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 9.06755682e-03,  6.08745456e-01,  1.22697249e-01,\n",
            "        -1.12065219e-03,  1.11062124e-01, -8.19724917e-01,\n",
            "        -2.46741977e-02, -9.95139180e-06,  5.06504020e-03,\n",
            "         7.18347549e-01,  6.42035306e-01,  2.12405790e-02,\n",
            "         2.17040464e-01,  2.79596180e-01, -3.91154617e-01,\n",
            "        -6.19996488e-02, -8.36296380e-03, -9.84210134e-01,\n",
            "        -1.26053681e-04,  1.17883615e-01, -6.82730507e-03,\n",
            "        -3.17654878e-01,  8.27800035e-01, -2.43375767e-02,\n",
            "        -4.42676101e-04, -5.59583008e-01, -9.67210352e-01,\n",
            "         2.47304361e-05,  4.05592173e-01, -8.51163175e-04,\n",
            "        -3.46995250e-04,  2.94599558e-05,  4.02149837e-03,\n",
            "        -5.41991591e-01, -1.56015651e-02, -1.29475579e-01,\n",
            "        -2.05761564e-04, -3.84995714e-02,  3.80772864e-04,\n",
            "         1.47772059e-02,  3.15569103e-01,  4.37787930e-05,\n",
            "        -3.39086354e-02, -7.85272382e-03, -4.12440956e-01,\n",
            "        -6.87357783e-02,  3.86716634e-01,  3.52089703e-02,\n",
            "         9.64439690e-01,  5.70141710e-04,  3.13930213e-03,\n",
            "         9.48400497e-01,  1.26522523e-03, -2.76616693e-01,\n",
            "         9.49583203e-02,  2.70378552e-02,  4.34144706e-01,\n",
            "        -4.12316574e-03, -4.45706286e-02,  5.46515547e-03,\n",
            "         8.47708583e-02,  2.59648204e-01, -4.12602640e-05,\n",
            "         1.60739068e-02,  2.23198040e-05,  8.18481611e-04,\n",
            "         4.06073660e-01,  2.13541184e-02,  6.80026889e-01,\n",
            "        -6.30259454e-01,  3.72604907e-01,  9.77878273e-02,\n",
            "         3.55763324e-02,  9.98885214e-01, -2.59138087e-05,\n",
            "        -1.08845048e-02,  2.94021191e-03,  4.29189345e-03,\n",
            "        -7.10090389e-03, -4.29905616e-02, -5.15656658e-02,\n",
            "        -4.96059656e-02,  5.31887650e-01,  2.08942080e-03,\n",
            "        -1.95492525e-02,  1.40223792e-02, -3.13159764e-01,\n",
            "         3.42137337e-01,  7.72338302e-04, -9.22652245e-01,\n",
            "         6.27028348e-05, -2.69593070e-10,  2.68122137e-01,\n",
            "        -4.05141674e-02, -3.05793365e-04, -7.44540453e-01,\n",
            "         1.91951931e-01, -1.00727793e-09, -1.43809304e-01,\n",
            "         7.82758817e-02,  7.30963647e-01,  4.94527481e-02,\n",
            "        -7.74032950e-01, -1.38973386e-03, -1.76409315e-02,\n",
            "         4.14948474e-04,  4.81262326e-01,  5.39366663e-01,\n",
            "         8.46508332e-03,  7.67026961e-01,  6.78155538e-06,\n",
            "         1.72649696e-02,  1.16467709e-02, -5.74748218e-01,\n",
            "         6.61538094e-02,  1.60125326e-02,  1.13536427e-02,\n",
            "        -1.44502046e-02,  8.21236074e-01, -4.30362701e-01,\n",
            "        -4.03668769e-02, -3.03309876e-04,  5.48213050e-02,\n",
            "        -8.42088182e-03,  1.19107054e-03,  2.29541259e-03,\n",
            "         3.43610850e-06, -3.82726029e-08,  1.07340375e-03,\n",
            "         7.43956029e-01, -1.00279853e-01, -6.50877297e-01,\n",
            "        -3.67366076e-02,  5.25372267e-01,  8.69748354e-01,\n",
            "         1.82063114e-02, -6.82042241e-02, -9.12081957e-01,\n",
            "        -7.24544451e-02,  1.61344258e-06,  2.57276986e-02,\n",
            "         2.40466014e-01,  5.02929743e-03, -1.97807364e-02,\n",
            "         1.58835508e-04, -9.20536518e-01, -2.00832364e-04,\n",
            "         1.78106263e-01,  1.89025991e-06,  3.87696810e-02,\n",
            "         1.29235595e-01,  5.73578417e-01, -4.20074211e-03,\n",
            "        -3.39541323e-02, -7.64427288e-03, -9.67371017e-02,\n",
            "         5.20521998e-01,  8.03808689e-01, -1.40165225e-01,\n",
            "        -7.80544400e-01,  7.30899489e-03,  5.97093105e-01,\n",
            "         8.47712159e-02,  2.24149544e-02,  1.52410939e-01,\n",
            "        -1.30379982e-02,  3.03295702e-02,  8.21073830e-01,\n",
            "         7.19406664e-01, -1.93531089e-03, -3.61431316e-02,\n",
            "        -9.08299983e-01,  3.59696560e-02,  1.14958607e-01,\n",
            "         4.31411490e-02,  3.64529550e-01, -9.53963161e-01,\n",
            "         4.43663495e-03, -4.07903353e-05,  8.04976001e-03,\n",
            "         1.31767824e-01,  1.01127243e-03, -3.24330389e-01,\n",
            "        -6.70263767e-01, -2.55024910e-01,  9.22488272e-01,\n",
            "        -1.05494335e-02, -6.53900264e-04,  9.35730990e-03,\n",
            "         2.47296125e-01, -3.16288301e-10,  2.39549531e-03,\n",
            "         3.52062518e-04, -4.44301575e-01,  2.42166410e-04,\n",
            "        -7.76141405e-01, -4.93979126e-01, -2.25479864e-02,\n",
            "        -5.33862078e-07, -1.93412721e-04,  6.30987342e-05,\n",
            "        -2.56474279e-02,  8.45887959e-02, -1.99957594e-06,\n",
            "        -4.17963648e-03,  3.22426677e-05,  4.30980057e-01,\n",
            "        -4.68637736e-04,  7.65283763e-01, -1.37314096e-03,\n",
            "         7.98401833e-01, -6.42572582e-01, -6.34742037e-06,\n",
            "         1.81420922e-01, -2.65015825e-03,  2.72393499e-05,\n",
            "         8.04038107e-01, -1.69261813e-01, -9.38433886e-01,\n",
            "         4.10576105e-01,  6.29612744e-01,  2.61489917e-02,\n",
            "         5.23354902e-06,  2.72084922e-02,  3.96753885e-02,\n",
            "        -2.57547975e-01, -1.06974160e-02, -4.00286466e-02,\n",
            "         5.39704179e-03,  4.28462634e-04, -5.29586077e-06,\n",
            "         7.14340866e-01, -3.39239091e-01,  6.41496561e-04,\n",
            "        -5.84085751e-03,  3.02182585e-01, -2.67547672e-03,\n",
            "        -7.51808405e-01,  3.71447504e-06,  9.15522635e-01,\n",
            "        -1.29205763e-01, -9.08239558e-02,  9.40186381e-01,\n",
            "         7.44239688e-01, -1.07026956e-08, -3.15044983e-03,\n",
            "        -4.96743899e-03, -1.42087054e-03,  1.81634322e-01,\n",
            "        -6.32943586e-02,  7.07998931e-01,  5.61772704e-01,\n",
            "         2.91979330e-08,  7.49491870e-01, -1.20998835e-02,\n",
            "        -6.10303068e-05]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.57867277e+00,  9.23334777e-01,  8.31942320e-01,\n",
            "        -5.59808016e-01,  9.83629882e-01, -1.68118215e+00,\n",
            "        -2.04115629e+00, -2.28448176e+00,  4.35921860e+00,\n",
            "         1.02661097e+00,  7.79477060e-01,  1.96397078e+00,\n",
            "         2.22940117e-01,  3.18401933e-01, -2.46535420e+00,\n",
            "        -1.18800557e+00, -1.69985211e+00, -2.49629688e+00,\n",
            "        -4.98459876e-01,  3.38557035e-01, -2.13348866e+00,\n",
            "        -2.23113513e+00,  1.18270922e+00, -2.25106573e+00,\n",
            "        -1.98472524e+00, -1.25522327e+00, -2.04802203e+00,\n",
            "         6.09246433e-01,  5.77659547e-01, -8.57147912e-04,\n",
            "        -1.30838275e+00,  1.13407421e+00,  6.98933601e-02,\n",
            "        -6.23121560e-01, -1.56036075e-02, -3.00914550e+00,\n",
            "        -1.51978597e-01, -6.41547620e-01,  1.98058224e+00,\n",
            "         3.18895817e+00,  2.46297455e+00,  4.20687258e-01,\n",
            "        -3.47536989e-02, -3.14853811e+00, -4.48775291e-01,\n",
            "        -1.31599295e+00,  4.23173666e-01,  3.52236219e-02,\n",
            "         2.33263969e+00,  1.18239367e+00,  9.29890424e-02,\n",
            "         2.52446699e+00,  1.26722571e-03, -3.80462718e+00,\n",
            "         5.60250461e-01,  2.61951423e+00,  4.65216905e-01,\n",
            "        -1.76322687e+00, -3.34258866e+00,  2.10115218e+00,\n",
            "         8.59578773e-02,  3.55307794e+00, -2.99166832e-02,\n",
            "         1.27530861e+00,  2.93118072e+00,  2.37166023e+00,\n",
            "         4.32267725e-01,  3.60628180e-02,  8.29486966e-01,\n",
            "        -7.61445165e-01,  4.00781244e-01,  3.84139895e-01,\n",
            "         2.50212550e-01,  3.74826050e+00, -2.14280491e-03,\n",
            "        -1.08859185e-02,  3.00812279e-03,  3.24753970e-01,\n",
            "        -7.12051895e-03, -2.16446117e-01, -5.82028702e-02,\n",
            "        -1.29396185e-01,  8.16005468e-01,  2.64153164e-02,\n",
            "        -1.95818935e-02,  6.37300849e-01, -3.26998532e-01,\n",
            "         4.28765655e-01,  1.82471538e+00, -1.60731113e+00,\n",
            "         5.33112325e-04, -8.62821221e-01,  3.78508240e-01,\n",
            "        -4.84942086e-02, -3.79927427e-01, -1.81447959e+00,\n",
            "         1.95420459e-01, -4.59741103e-03, -6.84246540e-01,\n",
            "         1.13856328e+00,  2.92869830e+00,  7.88707212e-02,\n",
            "        -1.05763388e+00, -2.51275897e+00, -8.28261971e-01,\n",
            "         2.13438898e-01,  9.74326491e-01,  6.25534713e-01,\n",
            "         8.56746733e-03,  1.01322317e+00,  1.10740348e-05,\n",
            "         2.32211471e+00,  9.40145910e-01, -6.54592931e-01,\n",
            "         6.62628189e-02,  1.60156172e-02,  3.50251245e+00,\n",
            "        -2.04401350e+00,  2.11178613e+00, -5.33263385e-01,\n",
            "        -2.48842001e+00, -3.05214809e-04,  1.92144871e+00,\n",
            "        -1.31959605e+00,  7.60251284e-02,  6.02832198e-01,\n",
            "         1.51499736e+00, -8.65453109e-02,  2.00922227e+00,\n",
            "         9.59881365e-01, -1.01788990e-01, -2.96147871e+00,\n",
            "        -1.30654454e-01,  6.04537845e-01,  1.34488285e+00,\n",
            "         1.82427671e-02, -6.83550537e-02, -2.33164048e+00,\n",
            "        -1.59219670e+00,  4.17551273e-05,  2.70077139e-02,\n",
            "         2.61831045e-01,  5.32779563e-03, -1.97833609e-02,\n",
            "         9.88768220e-01, -2.66162252e+00, -4.40187193e-03,\n",
            "         1.51626527e+00,  6.21101959e-03,  8.58904898e-01,\n",
            "         2.71210289e+00,  6.53988063e-01, -2.06569767e+00,\n",
            "        -1.20667851e+00, -1.27320039e+00, -2.59637594e-01,\n",
            "         1.77778208e+00,  1.13814199e+00, -7.28986502e-01,\n",
            "        -1.04740453e+00,  1.14939487e+00,  2.53777623e+00,\n",
            "         8.49801823e-02,  2.24295743e-02,  3.18633646e-01,\n",
            "        -3.22436213e-01,  8.44447166e-02,  1.19040799e+00,\n",
            "         1.04764152e+00, -3.73824954e-01, -1.59751976e+00,\n",
            "        -2.72700977e+00,  4.25242513e-01,  1.61786890e+00,\n",
            "         4.78738807e-02,  7.58388638e-01, -1.87594128e+00,\n",
            "         2.41292024e+00, -4.07986845e-05,  1.63807571e-01,\n",
            "         1.42037228e-01,  2.14488816e+00, -2.60069180e+00,\n",
            "        -8.16787064e-01, -2.74290502e-01,  1.60583663e+00,\n",
            "        -1.06585305e-02, -3.18716258e-01,  1.56879961e-01,\n",
            "         1.73686504e+00, -2.29245275e-01,  1.55057418e+00,\n",
            "         4.18998022e-03, -6.94949031e-01,  2.53090191e+00,\n",
            "        -1.55717695e+00, -5.41310728e-01, -2.25544870e-02,\n",
            "        -2.16917181e+00, -1.90317840e-03,  2.15289164e+00,\n",
            "        -5.34425117e-02,  8.47920850e-02, -1.30232111e-01,\n",
            "        -2.81893671e-01,  2.47908068e+00,  7.62865245e-01,\n",
            "        -2.84545636e+00,  2.15621209e+00, -2.10177507e-02,\n",
            "         2.83920550e+00, -7.63811767e-01, -3.05886287e-03,\n",
            "         6.01816058e-01, -2.78461361e+00,  5.67156434e-01,\n",
            "         1.11092067e+00, -1.74093139e+00, -1.79142880e+00,\n",
            "         1.13948655e+00,  7.41860926e-01,  2.92283539e-02,\n",
            "         2.55143285e+00,  1.19567618e-01,  2.54657722e+00,\n",
            "        -3.51181835e-01, -2.52696657e+00, -2.29193640e+00,\n",
            "         1.98981595e+00,  5.14773369e-01, -7.00842142e-01,\n",
            "         2.76615047e+00, -3.53420198e-01,  6.41536957e-04,\n",
            "        -7.61586279e-02,  8.84553671e-01, -3.52557349e+00,\n",
            "        -1.05451155e+00,  6.34903414e-03,  1.58556032e+00,\n",
            "        -1.29932240e-01, -9.12000015e-02,  2.31157923e+00,\n",
            "         9.62629139e-01, -1.48239827e+00, -1.77090335e+00,\n",
            "        -5.15199155e-02, -2.89258718e+00,  2.05509114e+00,\n",
            "        -6.35449067e-02,  8.83164287e-01,  3.66237354e+00,\n",
            "         1.37461051e-02,  9.81200576e-01, -1.51233403e-02,\n",
            "        -1.81687796e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.2218489e-01,  2.7545702e-02,  4.5826431e-02, -6.2482554e-01,\n",
            "         6.5269202e-01, -9.2354077e-01, -9.5380110e-01, -1.4351658e-03,\n",
            "         8.1825924e-01,  8.5194314e-01,  5.5421293e-01,  5.9401401e-04,\n",
            "         4.9436429e-01, -1.6481188e-01, -1.5909597e-01, -2.7660945e-01,\n",
            "        -8.0206531e-01, -5.9704155e-01, -8.0559433e-02,  3.3271143e-01,\n",
            "        -9.2721045e-01, -9.8603493e-01,  6.1672926e-01, -4.1991699e-01,\n",
            "        -1.2552398e-02, -8.6044586e-01, -8.5947150e-01,  5.1668577e-04,\n",
            "         8.2302177e-01, -1.8585354e-02, -4.4553763e-01,  5.7146025e-01,\n",
            "         3.2030481e-01, -3.1226945e-01, -1.2712465e-03, -9.8761332e-01,\n",
            "        -7.3913532e-01, -4.7598657e-01,  3.9093525e-04,  8.9213969e-03,\n",
            "         9.8439163e-01,  3.0223763e-01, -8.9424103e-02, -4.3768759e-04,\n",
            "        -2.3962164e-02, -4.0805066e-01,  8.8743269e-01,  6.0402006e-01,\n",
            "         9.0838993e-01,  4.7192100e-02,  9.4298184e-02,  3.9936700e-01,\n",
            "         9.2001311e-02, -9.4621998e-01,  4.6214694e-01,  1.9686094e-02,\n",
            "         5.5034715e-01, -9.7072452e-02, -9.9586034e-01,  1.7395656e-01,\n",
            "        -4.0894744e-01,  5.4928195e-01, -2.1218915e-01,  9.2710648e-03,\n",
            "         3.2499206e-04,  6.7838407e-01, -3.3529970e-01,  3.1647065e-01,\n",
            "         4.6846822e-01, -6.4508408e-01,  4.1694176e-01,  4.4725849e-03,\n",
            "         4.8978265e-02,  9.5979702e-01, -1.7612757e-01, -9.9416748e-02,\n",
            "         8.9033548e-04, -3.0885017e-02, -5.0297672e-01, -2.1302317e-01,\n",
            "        -8.4283479e-02, -1.8392192e-01,  2.6826373e-01,  3.4175474e-02,\n",
            "        -1.1555728e-01,  5.9660535e-02, -3.1986849e-03,  1.9870169e-01,\n",
            "         3.0031022e-01, -5.0458366e-01,  1.1113856e-03, -6.9472605e-01,\n",
            "         3.3980176e-01, -4.1754837e-03, -3.0873081e-01, -6.7776104e-04,\n",
            "         1.6521232e-03, -5.5322438e-01, -8.3235556e-01,  5.7644969e-01,\n",
            "         7.0605332e-01, -4.6531421e-01, -1.0218356e-01, -8.5966825e-01,\n",
            "        -9.3082003e-03,  2.5582555e-01,  8.1454753e-05,  5.1332051e-01,\n",
            "         7.4346548e-01,  8.3232778e-01,  3.3761557e-07,  9.2308170e-01,\n",
            "         3.7150955e-01, -8.5913420e-01,  5.7521466e-02,  6.6196159e-02,\n",
            "         7.8363705e-01, -3.7217140e-02,  8.6408593e-02, -9.2277484e-04,\n",
            "        -3.7852037e-01, -4.1718371e-02,  9.4359243e-01, -8.0354846e-01,\n",
            "         1.4646744e-05,  4.2171929e-02,  7.0022315e-01, -8.5841934e-04,\n",
            "         9.7937346e-04,  6.8813509e-01, -1.8321297e-03, -9.6455401e-01,\n",
            "        -7.6742604e-02,  2.8451422e-01,  8.5773391e-01,  1.7516083e-01,\n",
            "        -1.9398324e-04, -6.7132883e-06, -9.7768605e-01,  1.0164189e-02,\n",
            "         3.9247558e-01,  7.9722357e-01,  4.1363392e-02, -6.2708638e-04,\n",
            "         4.9813268e-01, -1.5034221e-04, -6.8137343e-03,  3.3366150e-01,\n",
            "         2.6984289e-01,  4.2085391e-01,  9.4400662e-01,  7.7037501e-01,\n",
            "        -3.1331968e-01, -3.3146128e-02, -7.4944335e-01, -7.3127991e-01,\n",
            "         1.2085717e-02,  9.1091877e-01, -6.3651472e-02, -1.6952041e-01,\n",
            "         3.0717018e-01,  2.4702386e-03,  1.2948371e-01,  4.4492662e-01,\n",
            "         2.6948535e-01, -3.0939806e-01,  6.0107373e-03,  5.6558955e-01,\n",
            "         5.1225293e-01, -2.5559893e-02, -9.1865903e-01, -9.8987937e-01,\n",
            "         1.0248030e-03,  1.0369170e-04,  2.4730882e-01,  6.8519777e-01,\n",
            "        -3.7234473e-01,  1.2522285e-02, -4.4637553e-02,  2.9545790e-01,\n",
            "         7.2733368e-05,  9.5962596e-01, -3.7829001e-02, -2.7104652e-01,\n",
            "        -7.6592177e-01,  4.9584654e-01, -3.4578413e-02, -2.7822366e-01,\n",
            "        -1.8949470e-03,  9.8373342e-01, -2.0967980e-03,  3.7173696e-03,\n",
            "         6.3602489e-01, -6.1120021e-01,  7.1862467e-02, -8.5285616e-01,\n",
            "        -3.4560362e-01, -3.1030888e-03, -5.5146342e-05, -1.8543907e-01,\n",
            "         5.8576530e-01, -1.0816320e-03,  7.6139957e-01,  6.9501501e-01,\n",
            "        -2.9577149e-02,  9.6328306e-01,  3.8510680e-01, -3.9386654e-01,\n",
            "         9.7315431e-01, -8.1984632e-02,  2.9367924e-01, -6.4025456e-01,\n",
            "        -2.7015614e-03,  1.1447024e-01, -9.7395426e-01,  1.4582427e-03,\n",
            "         8.0411440e-01, -7.4446261e-01, -7.4784450e-02,  8.0902964e-01,\n",
            "         4.6456372e-03,  1.1547701e-01,  1.1663635e-01,  7.2504967e-03,\n",
            "         2.0991615e-03, -2.4674205e-02, -6.8128937e-01, -9.5971358e-01,\n",
            "         9.2211413e-01,  2.2546284e-02, -4.2564122e-04,  1.2598847e-01,\n",
            "        -3.0998236e-01,  2.9951870e-02, -8.0886170e-02,  5.0735742e-01,\n",
            "        -9.9709696e-01, -1.0312949e-04,  1.4252684e-01,  8.8985735e-01,\n",
            "         1.7190596e-01, -1.5156116e-01,  6.9436029e-02,  1.4280263e-01,\n",
            "        -8.7041551e-01, -2.2078493e-01, -1.9678033e-03, -7.9243845e-01,\n",
            "         8.6043221e-01, -5.5140994e-05, -2.3434504e-05,  9.9252045e-01,\n",
            "         1.6565557e-04,  7.5899911e-01, -2.1853978e-02, -7.5421995e-04]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.27830005e+00,  1.61462569e+00,  4.58711684e-02,\n",
            "        -7.77095854e-01,  1.11166024e+00, -1.61990380e+00,\n",
            "        -1.99090958e+00, -3.23420262e+00,  4.35762501e+00,\n",
            "         1.82140350e+00,  7.72342980e-01,  2.91537261e+00,\n",
            "         1.15646875e+00, -9.44608152e-01, -3.42704988e+00,\n",
            "        -2.16718483e+00, -2.49674988e+00, -2.19059920e+00,\n",
            "        -1.04798377e+00,  3.45921457e-01, -2.13385558e+00,\n",
            "        -3.13894606e+00,  7.20010519e-01, -2.99522614e+00,\n",
            "        -2.73578668e+00, -1.29531813e+00, -1.54508936e+00,\n",
            "         1.60545111e+00,  1.32869399e+00, -4.60719556e-01,\n",
            "        -4.90947932e-01,  1.15426970e+00,  1.04781973e+00,\n",
            "        -1.57376742e+00, -2.14907737e-03, -3.43444872e+00,\n",
            "        -1.10308421e+00, -6.65967762e-01,  2.96975207e+00,\n",
            "         3.20317888e+00,  2.73381209e+00,  4.30774629e-01,\n",
            "        -1.56636134e-01, -4.11838531e+00, -1.38018584e+00,\n",
            "        -4.56064671e-01,  1.42217481e+00,  1.02823281e+00,\n",
            "         3.32310128e+00,  2.12763071e+00,  1.19643465e-01,\n",
            "         2.50656271e+00,  7.55623937e-01, -3.08660388e+00,\n",
            "         5.60359538e-01,  3.59677434e+00,  1.13442135e+00,\n",
            "        -2.68403721e+00, -3.19337106e+00,  2.37090111e+00,\n",
            "        -4.34746861e-01,  3.53272533e+00, -1.02675903e+00,\n",
            "         2.26277781e+00,  3.51499867e+00,  3.37122989e+00,\n",
            "        -3.48801076e-01,  9.95327175e-01,  1.76406109e+00,\n",
            "        -7.71565080e-01,  4.51392919e-01,  6.52381122e-01,\n",
            "         4.91109788e-02,  4.16341114e+00, -2.00815082e-01,\n",
            "        -1.00000076e-01,  7.02485979e-01, -2.41901875e-01,\n",
            "        -9.19533670e-01, -2.17178136e-01, -8.50749388e-02,\n",
            "        -1.12896633e+00,  8.73293698e-01,  3.46254818e-02,\n",
            "        -5.44608653e-01,  1.61962509e+00, -4.36951846e-01,\n",
            "         1.36464977e+00,  1.18387043e+00, -5.55457950e-01,\n",
            "         9.69260156e-01, -8.60645056e-01,  3.60040575e-01,\n",
            "        -2.72027820e-01, -5.65608978e-01, -2.77336693e+00,\n",
            "         1.19317067e+00, -9.09145594e-01, -1.21160781e+00,\n",
            "         1.09542477e+00,  2.64593363e+00, -5.72436213e-01,\n",
            "        -7.63871670e-01, -3.44879460e+00, -1.46873200e+00,\n",
            "         2.82455117e-01,  1.93900192e+00,  1.29709661e+00,\n",
            "         9.66345727e-01,  1.30795860e+00,  8.13203692e-01,\n",
            "         1.61437500e+00,  1.20785344e+00, -1.29179239e+00,\n",
            "         8.45886469e-02,  1.07693791e-01,  2.68861890e+00,\n",
            "        -2.88460994e+00,  2.29418397e+00, -6.40306950e-01,\n",
            "        -2.80965519e+00, -8.80639702e-02,  2.46083140e+00,\n",
            "        -1.51761734e+00,  9.23809335e-02,  1.58872950e+00,\n",
            "         1.80761242e+00, -7.79855132e-01,  2.19621992e+00,\n",
            "         9.59658444e-01, -1.07850182e+00, -2.02610803e+00,\n",
            "        -7.70672113e-02,  7.58908212e-01,  2.27621531e+00,\n",
            "         1.77340791e-01, -1.33418232e-01, -3.30542707e+00,\n",
            "        -2.49796224e+00,  1.02566276e-02,  4.19867724e-01,\n",
            "         1.20885611e+00,  9.37014103e-01, -3.46948653e-02,\n",
            "         1.00612414e+00, -3.30605412e+00, -7.08964653e-03,\n",
            "         3.50723267e-01,  8.61928940e-01,  4.49777901e-01,\n",
            "         2.83928323e+00,  1.05884755e+00, -1.10587466e+00,\n",
            "        -1.12047756e+00, -2.25442147e+00, -1.25757897e+00,\n",
            "         2.75889039e+00,  1.57876706e+00, -1.47201073e+00,\n",
            "        -2.03143144e+00,  6.87879622e-01,  2.82253361e+00,\n",
            "         1.52941108e-01,  5.29441655e-01,  3.29489112e-01,\n",
            "        -3.30835640e-01,  1.05821896e+00,  6.42840207e-01,\n",
            "         5.74372768e-01, -1.26043081e+00, -1.59818411e+00,\n",
            "        -2.72577477e+00,  8.63012195e-01,  2.55298352e+00,\n",
            "         4.88121003e-01,  1.07319605e+00, -2.82290459e+00,\n",
            "         2.51348877e+00, -9.58984971e-01,  1.07188630e+00,\n",
            "         1.75789714e-01,  2.14493299e+00, -3.41295242e+00,\n",
            "        -1.81191683e+00, -1.11838353e+00,  2.18975830e+00,\n",
            "        -3.45973261e-02, -3.36093009e-01, -8.41772795e-01,\n",
            "         2.40223193e+00, -9.42846596e-01,  2.45705342e+00,\n",
            "         7.53438413e-01, -7.11082816e-01,  2.04669690e+00,\n",
            "        -1.47294915e+00, -3.61067563e-01, -3.11746215e-03,\n",
            "        -3.11130452e+00, -9.21213090e-01,  1.20224941e+00,\n",
            "        -1.05316973e+00,  1.00293326e+00,  8.57595861e-01,\n",
            "        -7.04789400e-01,  1.99098563e+00,  9.31655824e-01,\n",
            "        -3.04762793e+00,  2.20713329e+00, -1.01429069e+00,\n",
            "         3.05410075e+00, -7.63812244e-01, -2.86586490e-03,\n",
            "         1.55012751e+00, -3.72031021e+00,  1.54733598e+00,\n",
            "         1.11103022e+00, -9.61104393e-01, -2.17189574e+00,\n",
            "         1.13882864e+00,  1.73423314e+00,  1.02669370e+00,\n",
            "         2.59518456e+00,  1.11587107e+00,  2.92671037e+00,\n",
            "        -3.57787639e-01, -2.44550467e+00, -2.20526171e+00,\n",
            "         2.65387774e+00,  2.28838194e-02, -1.69361591e+00,\n",
            "         3.76423073e+00, -3.20539713e-01,  1.38476938e-01,\n",
            "        -8.15335363e-02,  1.86962628e+00, -3.27440977e+00,\n",
            "        -1.87310791e+00,  3.44440311e-01,  1.49024403e+00,\n",
            "         1.80185542e-01, -6.82098150e-01,  2.92748475e+00,\n",
            "         1.00710464e+00, -1.44331050e+00, -1.00258136e+00,\n",
            "        -9.47347283e-01, -1.85316932e+00,  1.50059581e+00,\n",
            "        -1.05540693e+00, -3.71770486e-02,  2.84909821e+00,\n",
            "         9.24176514e-01,  9.94496465e-01, -9.17991698e-02,\n",
            "        -2.69437766e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.67694326e-06,  3.36479609e-08, -7.39574552e-01,\n",
            "        -5.47181389e-06,  9.65239823e-01, -5.46183169e-01,\n",
            "        -9.49550748e-01, -4.80995823e-07,  9.99476314e-01,\n",
            "         1.54318783e-04,  7.18269169e-01,  2.98400428e-05,\n",
            "         9.71709907e-01, -1.81841403e-06, -1.81864234e-05,\n",
            "        -3.05880640e-05, -3.17613769e-10, -9.18765664e-01,\n",
            "        -5.25189079e-02,  4.05574560e-01, -1.98375870e-04,\n",
            "        -7.15764938e-03,  6.06739998e-01, -1.76956491e-05,\n",
            "        -5.47415624e-08,  7.61342227e-01, -9.09944713e-01,\n",
            "         6.78764867e-09,  3.63721888e-08, -1.30325160e-11,\n",
            "        -3.56269956e-01,  1.04238659e-01,  5.22407618e-07,\n",
            "        -5.09737954e-02, -5.24526477e-05, -9.78216715e-03,\n",
            "        -9.61723345e-05, -1.37510675e-03,  1.51316563e-05,\n",
            "         3.33111188e-07,  9.90498483e-01,  4.18797016e-01,\n",
            "        -1.29166772e-04, -9.20857608e-01, -2.86371360e-05,\n",
            "        -3.47993106e-01,  1.74874617e-06,  1.18467789e-02,\n",
            "         9.99537706e-01,  1.38843097e-05,  7.25390797e-04,\n",
            "         9.85916734e-01,  1.41532632e-06, -9.90111470e-01,\n",
            "         8.61014705e-03,  4.20571351e-03,  2.58003536e-04,\n",
            "        -8.30836594e-04, -9.98863995e-01,  2.24697200e-04,\n",
            "        -4.09819275e-01,  9.97802019e-01, -9.40208972e-01,\n",
            "         6.77676144e-05,  4.22433959e-06,  1.42224773e-04,\n",
            "        -3.51800591e-01,  2.48524384e-06,  2.20877077e-08,\n",
            "        -1.16373472e-01,  2.87277866e-02,  1.56707782e-03,\n",
            "        -7.12456644e-01,  8.82408977e-01, -3.46314870e-02,\n",
            "        -5.86175534e-04,  1.68665179e-06, -3.68173808e-01,\n",
            "        -8.70380104e-01, -1.21207064e-04, -8.47426653e-02,\n",
            "        -2.34563657e-07,  8.36926281e-01,  1.87569801e-02,\n",
            "        -7.44395606e-07,  1.30082284e-07, -1.60734686e-07,\n",
            "         1.72888569e-03,  7.29726851e-01, -7.55930245e-01,\n",
            "         2.94602648e-10, -6.95478857e-01, -2.91896313e-01,\n",
            "        -1.50184533e-07, -8.86285052e-05, -3.40835249e-09,\n",
            "         2.68930449e-07, -8.89245868e-01, -2.22860908e-04,\n",
            "         2.69321928e-04,  9.89791155e-01, -6.76086962e-01,\n",
            "        -1.03121258e-01, -9.90823805e-01, -6.79308796e-05,\n",
            "         4.31816339e-01,  1.57738177e-05,  5.99456672e-03,\n",
            "         9.32172164e-02,  2.49629915e-02,  8.53800711e-12,\n",
            "         5.57340264e-01,  6.64494877e-08, -9.79262710e-01,\n",
            "         5.69742988e-04,  6.05936535e-03,  9.89003599e-01,\n",
            "        -1.76740158e-02,  7.32245040e-04, -4.43168619e-06,\n",
            "        -4.60917654e-05, -2.68165430e-04,  1.48952842e-01,\n",
            "        -7.01261997e-01,  8.17462931e-10,  1.11227477e-04,\n",
            "         1.73281421e-07, -9.43469882e-01,  3.38131725e-03,\n",
            "         2.88165151e-03, -3.59282848e-09, -8.26269031e-01,\n",
            "        -2.93780655e-01,  1.25856886e-05,  9.19928588e-03,\n",
            "         7.91412055e-01, -2.91201315e-04, -2.35537027e-14,\n",
            "        -9.97636855e-01,  1.18190663e-07,  9.62442718e-04,\n",
            "         2.97432065e-01,  1.24500802e-04, -9.47519663e-09,\n",
            "         1.29993916e-01, -3.19515448e-06, -1.43024037e-02,\n",
            "        -5.63614607e-01,  4.80788713e-03,  4.09585178e-01,\n",
            "         6.55042171e-01,  7.25866470e-04, -1.23624258e-01,\n",
            "        -2.95512649e-07, -2.77546775e-02, -8.16040199e-07,\n",
            "         9.27313268e-01,  9.88509834e-01, -4.19910062e-09,\n",
            "        -7.76330022e-09,  3.87080252e-01,  8.85096829e-10,\n",
            "         1.51311517e-01,  9.22919139e-02,  4.07855250e-02,\n",
            "        -2.91426539e-01,  5.05791720e-09, -3.31756860e-01,\n",
            "         4.04395998e-01, -1.87933438e-06, -9.29901123e-01,\n",
            "        -9.91417587e-01,  1.62926295e-09,  1.12367400e-10,\n",
            "         2.20559514e-06,  5.54201845e-03, -3.42606791e-06,\n",
            "         3.02751141e-05, -3.36059579e-03,  8.85464177e-02,\n",
            "         8.09144918e-10,  6.73804343e-01, -9.61921728e-07,\n",
            "        -5.28392047e-05, -4.41651285e-01,  1.72761008e-01,\n",
            "        -3.39999981e-02, -1.78216646e-06, -3.25100871e-07,\n",
            "        -7.60662019e-01, -5.61513048e-07,  1.03867111e-04,\n",
            "         1.30726054e-01, -6.16158009e-01,  9.35503006e-01,\n",
            "        -4.44072396e-01,  4.92659330e-01, -1.48422401e-07,\n",
            "        -3.85355220e-11, -6.92525581e-02,  1.74426809e-01,\n",
            "        -1.00051851e-08,  3.68472457e-01,  8.53629666e-04,\n",
            "        -1.39029115e-04,  7.33985364e-01, -8.32729507e-03,\n",
            "        -9.76754010e-01,  2.68836808e-03, -3.65949399e-03,\n",
            "         7.73688555e-01, -4.94825870e-01, -4.71969048e-04,\n",
            "         1.31301519e-07, -9.91669774e-01,  7.23729372e-01,\n",
            "         8.04356456e-01,  1.18037434e-02, -1.90550454e-05,\n",
            "         8.03577483e-01,  2.43770778e-02,  2.94277124e-04,\n",
            "         1.92443167e-05,  1.65349988e-07,  1.53507658e-11,\n",
            "        -2.81046960e-04, -7.41365850e-01, -8.36437583e-01,\n",
            "         4.77139086e-01, -7.36908019e-01, -2.47156713e-05,\n",
            "         4.37840004e-04, -2.48518273e-01,  3.12090246e-03,\n",
            "        -8.14094245e-02,  2.16911659e-01, -1.36155053e-04,\n",
            "        -2.16325135e-11,  5.33839107e-01,  6.97680533e-01,\n",
            "         2.53905750e-06, -5.25661676e-07,  3.58277052e-09,\n",
            "         4.03905404e-04, -8.45318735e-01, -7.25819349e-01,\n",
            "        -5.61384869e-13, -4.16547875e-04,  6.16861805e-02,\n",
            "        -2.26651582e-06, -4.21866439e-02,  9.89175498e-01,\n",
            "         6.21697832e-11,  7.37721205e-01, -5.20379295e-09,\n",
            "        -2.82994410e-08]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.23003101e+00,  2.60774517e+00, -9.49539483e-01,\n",
            "        -1.76700842e+00,  2.02788401e+00, -2.52828574e+00,\n",
            "        -2.98854780e+00, -4.22979259e+00,  4.12750959e+00,\n",
            "         2.82122731e+00,  9.04787183e-01,  3.91415358e+00,\n",
            "         2.15641737e+00, -1.94433713e+00, -4.32906914e+00,\n",
            "        -3.16500092e+00, -3.10757995e+00, -1.58558476e+00,\n",
            "        -2.04785466e+00,  4.30303246e-01, -2.13397217e+00,\n",
            "        -4.13684273e+00,  7.03745723e-01, -3.97800756e+00,\n",
            "        -3.64596581e+00,  9.99413311e-01, -1.52721620e+00,\n",
            "         2.19103742e+00,  2.21911955e+00, -1.12570441e+00,\n",
            "        -3.73128325e-01,  1.15518522e+00,  2.02572179e+00,\n",
            "        -2.57338190e+00, -1.70083717e-02, -3.43460107e+00,\n",
            "        -2.10261440e+00, -6.67409658e-01,  3.96898484e+00,\n",
            "         3.20390677e+00,  2.75163078e+00,  4.46411401e-01,\n",
            "        -1.12224615e+00, -5.11710691e+00, -2.37592912e+00,\n",
            "        -3.63298476e-01,  2.42156434e+00,  2.02158618e+00,\n",
            "         4.31810808e+00,  3.12632537e+00,  1.20691165e-01,\n",
            "         2.47581863e+00,  1.70868039e+00, -2.65228653e+00,\n",
            "         1.55833697e+00,  4.58809757e+00,  2.06563568e+00,\n",
            "        -3.67405939e+00, -3.73639894e+00,  3.31877089e+00,\n",
            "        -4.35476601e-01,  3.46688342e+00, -2.02574039e+00,\n",
            "         3.26256132e+00,  3.51977849e+00,  4.37106371e+00,\n",
            "        -3.67497265e-01,  1.99532413e+00,  2.76303506e+00,\n",
            "        -7.90685177e-01,  8.51268828e-01,  1.62946784e+00,\n",
            "        -8.92342448e-01,  3.22156954e+00, -3.68469842e-02,\n",
            "        -5.14780581e-01,  1.69827592e+00, -4.51799542e-01,\n",
            "        -1.91950274e+00, -1.13071346e+00, -8.50756019e-02,\n",
            "        -2.12896514e+00,  1.87194371e+00,  4.35157754e-02,\n",
            "        -1.26316893e+00,  2.61588168e+00, -7.63557017e-01,\n",
            "         2.36452770e+00,  1.15802121e+00, -9.86856520e-01,\n",
            "         1.96703136e+00, -8.61854374e-01, -3.00723106e-01,\n",
            "        -1.20082772e+00, -1.19964075e+00, -3.77069116e+00,\n",
            "         2.19140649e+00, -1.90913355e+00, -2.21087146e+00,\n",
            "         1.30788982e+00,  2.64021754e+00, -8.21882248e-01,\n",
            "        -1.72543555e-01, -2.74236321e+00, -2.46872640e+00,\n",
            "         9.63941455e-01,  2.93891430e+00,  2.28542328e+00,\n",
            "         1.96168816e+00,  1.33139551e+00,  1.81256831e+00,\n",
            "         6.28966749e-01,  2.05478501e+00, -2.29173970e+00,\n",
            "         1.20073952e-01,  1.08445369e-01,  2.59892583e+00,\n",
            "        -3.88365793e+00,  2.50549269e+00, -1.63983703e+00,\n",
            "        -3.77895737e+00, -2.80569285e-01,  3.45587802e+00,\n",
            "        -2.51122928e+00,  1.07201660e+00,  2.58585787e+00,\n",
            "         2.73999310e+00, -1.77982211e+00,  3.08841825e+00,\n",
            "         1.69604969e+00, -2.07811284e+00, -1.17626119e+00,\n",
            "        -6.42203450e-01,  7.63670981e-01,  3.27263188e+00,\n",
            "         1.11164534e+00, -1.12803888e+00, -4.30319929e+00,\n",
            "        -3.37234950e+00,  1.09253870e-02,  1.41971457e+00,\n",
            "         2.20620751e+00,  1.93423927e+00, -1.02941418e+00,\n",
            "         1.25550508e+00, -4.30269384e+00, -5.99586964e-01,\n",
            "        -6.38120890e-01,  1.86192834e+00,  4.35166121e-01,\n",
            "         3.83677483e+00,  2.02815557e+00, -1.24506041e-01,\n",
            "        -1.11946893e+00, -2.26463914e+00, -2.25686502e+00,\n",
            "         3.75830913e+00,  2.57856560e+00, -2.38132119e+00,\n",
            "        -3.02321982e+00,  6.83199286e-01,  3.74940896e+00,\n",
            "         1.52903289e-01,  1.52941632e+00,  1.32723367e+00,\n",
            "        -3.00448030e-01,  2.05482864e+00, -3.56403917e-01,\n",
            "         4.28894579e-01, -2.19329882e+00, -2.58347797e+00,\n",
            "        -2.72344470e+00,  8.86117399e-01,  3.51870847e+00,\n",
            "         1.48547506e+00,  1.57784432e-01, -3.82246876e+00,\n",
            "         3.40772581e+00, -1.95875311e+00,  2.07073259e+00,\n",
            "         1.10105395e+00,  2.16144466e+00, -4.35987568e+00,\n",
            "        -2.81160402e+00, -2.11832380e+00,  3.18954515e+00,\n",
            "        -3.45973708e-02, -1.33533585e+00, -1.84155607e+00,\n",
            "        -9.97785866e-01, -9.44391668e-01,  3.37820983e+00,\n",
            "         1.31479546e-01, -7.18824625e-01,  1.86330175e+00,\n",
            "        -4.77309823e-01,  5.42809010e-01, -2.13801884e-03,\n",
            "        -3.46084332e+00, -1.92056906e+00,  2.06555024e-01,\n",
            "        -2.05315828e+00,  2.00292993e+00,  1.85747826e+00,\n",
            "        -1.68018675e+00,  9.37313437e-01, -3.99239324e-02,\n",
            "        -4.04067039e+00,  2.22526622e+00, -2.01428080e+00,\n",
            "         4.04886389e+00, -1.41865242e+00, -2.86438456e-03,\n",
            "         2.53169847e+00, -3.72914743e+00,  2.54691315e+00,\n",
            "         1.11113644e+00,  1.18043255e-02, -3.17183924e+00,\n",
            "         1.10862994e+00,  2.73373508e+00,  2.02646375e+00,\n",
            "         3.05982494e+00,  2.11565638e+00,  3.61932230e+00,\n",
            "        -2.42054194e-01, -2.26214242e+00, -1.20919418e+00,\n",
            "         3.61975741e+00, -9.44934964e-01, -2.69360781e+00,\n",
            "         4.70169449e+00, -2.53832936e-01,  1.13235533e+00,\n",
            "        -8.16274583e-02,  2.86322832e+00, -1.36160641e-04,\n",
            "        -2.83909535e+00,  1.22220087e+00,  9.25517142e-01,\n",
            "         4.89480235e-03, -1.68083656e+00,  3.77971387e+00,\n",
            "         1.73987114e+00, -1.44916308e+00, -9.55610037e-01,\n",
            "        -1.93761766e+00, -2.84620690e+00,  6.18191250e-02,\n",
            "        -2.05200028e+00, -1.03023744e+00,  2.60683274e+00,\n",
            "         1.89798772e+00,  9.94585574e-01, -1.80791661e-01,\n",
            "        -3.68610859e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.49288069e-04,  9.60774050e-05, -8.43385339e-01,\n",
            "        -1.82296628e-06,  5.19793639e-06, -1.18657634e-01,\n",
            "        -8.37398693e-02, -2.27098003e-08,  9.99251723e-01,\n",
            "         6.90523419e-04,  2.15202908e-06,  1.47496612e-10,\n",
            "         1.50027457e-08, -3.06775723e-06, -5.33625894e-07,\n",
            "        -5.57781050e-07, -7.49824449e-06, -5.81478894e-01,\n",
            "        -6.54090345e-02,  7.45522618e-01, -4.10733264e-05,\n",
            "        -1.40736942e-04, -1.58502515e-02, -2.78584616e-06,\n",
            "        -9.18352425e-01,  9.62624907e-01, -6.43396139e-01,\n",
            "         9.95801866e-01,  2.78299285e-06, -3.43550042e-08,\n",
            "         7.34096318e-02,  7.04840582e-04,  8.71412851e-07,\n",
            "        -9.33903694e-01, -5.82564361e-02, -4.58881260e-07,\n",
            "        -8.18748958e-06, -3.67341990e-11,  5.86745404e-02,\n",
            "         9.96332109e-01,  1.79247500e-03,  4.79496066e-07,\n",
            "        -9.25572142e-02, -9.95168507e-01, -1.15059356e-05,\n",
            "        -3.08514416e-01,  2.38118173e-06,  4.17126458e-08,\n",
            "         9.70546365e-01,  1.42668269e-03,  9.65855975e-07,\n",
            "         9.83585954e-01,  3.67407724e-02, -9.59522009e-01,\n",
            "         5.01038642e-07,  4.46999802e-05,  2.88961883e-06,\n",
            "        -6.95368799e-05,  7.55484223e-01,  8.16649581e-10,\n",
            "        -4.19904768e-01,  9.96794820e-01, -3.71873767e-07,\n",
            "         1.46441771e-05,  3.34391334e-11,  1.72424386e-08,\n",
            "        -3.71193528e-01,  9.18149064e-12,  2.76614423e-06,\n",
            "        -1.32956579e-08,  1.10186449e-09,  1.00739894e-03,\n",
            "        -9.45187807e-01,  9.94332552e-01, -1.80175632e-01,\n",
            "        -1.43069556e-04,  8.67309046e-13, -3.84218395e-01,\n",
            "        -5.12225986e-01, -2.82313431e-05, -4.78806011e-02,\n",
            "        -9.73803043e-01,  2.56809779e-03,  1.39736057e-05,\n",
            "        -3.87384453e-08,  9.87276441e-11, -9.18304437e-08,\n",
            "         9.74411070e-01,  8.09830189e-01, -9.55699265e-01,\n",
            "         1.68426996e-05, -9.15531740e-02, -6.62287652e-01,\n",
            "        -1.59923490e-02, -1.27428507e-06, -3.81161844e-05,\n",
            "         4.55305695e-07, -1.44893740e-04, -1.86285183e-06,\n",
            "         8.55928874e-08,  9.79688823e-01, -7.62814403e-01,\n",
            "        -4.56866398e-02, -9.75571930e-01, -2.34644879e-02,\n",
            "         3.87698092e-05,  1.41096315e-10,  2.56239048e-08,\n",
            "         1.02470131e-06,  8.06958452e-02,  6.19807608e-11,\n",
            "        -3.32101494e-01,  3.05757229e-03, -2.65927520e-04,\n",
            "         4.51007509e-06,  2.10691258e-04,  9.87828434e-01,\n",
            "        -1.46689534e-01,  3.53675615e-03, -2.19533611e-02,\n",
            "        -3.21878098e-08, -1.25460938e-01,  9.27749276e-01,\n",
            "        -4.87163424e-01,  7.42197852e-04,  8.81967664e-01,\n",
            "         3.78203389e-08, -2.81334226e-03,  2.22521857e-03,\n",
            "         1.11416343e-03, -3.57104273e-06, -8.06016731e-04,\n",
            "        -6.42560481e-05,  4.65493590e-01,  1.11951585e-05,\n",
            "         1.55634254e-07, -8.08340013e-01, -9.15030178e-05,\n",
            "         7.00014472e-01,  1.44063955e-10,  3.77139151e-01,\n",
            "         2.72883372e-05,  1.24518983e-02, -6.86273580e-08,\n",
            "         2.88094307e-05, -2.16146090e-12,  1.32374585e-01,\n",
            "        -9.25897896e-01,  2.94768765e-10,  3.95513177e-01,\n",
            "         1.76117465e-01,  9.94260967e-01, -1.07778244e-01,\n",
            "        -5.92083903e-04, -4.63450737e-02, -9.37340246e-06,\n",
            "         6.14977926e-02,  7.31319368e-01, -4.44480079e-08,\n",
            "        -2.18443029e-06,  8.84216279e-03,  8.68859686e-08,\n",
            "         1.52091727e-01,  1.57114729e-01,  7.46567501e-03,\n",
            "        -1.90607794e-02,  1.28998767e-09, -6.01511240e-01,\n",
            "         4.01442528e-01, -4.24288871e-08, -9.34894606e-02,\n",
            "        -9.91405427e-01,  1.73239778e-09,  3.40888050e-07,\n",
            "         3.41206469e-05,  4.07992341e-02, -2.68938541e-01,\n",
            "         5.70082307e-01, -9.92589485e-05,  5.36462059e-04,\n",
            "         1.03699382e-10,  9.73088682e-01, -5.40437541e-05,\n",
            "        -9.94219363e-07, -9.51436903e-08,  1.05830587e-01,\n",
            "        -3.98838281e-04, -1.15419037e-11, -2.68966041e-08,\n",
            "        -8.33096385e-01, -1.46167412e-01,  9.95065331e-01,\n",
            "         1.39655964e-02, -9.32375908e-01,  9.37309384e-01,\n",
            "         4.40628499e-01,  9.10296500e-01,  1.57991753e-08,\n",
            "        -9.99635875e-01, -7.91803468e-04, -1.40380040e-01,\n",
            "        -9.78133685e-05,  2.78168529e-01,  5.18982206e-03,\n",
            "        -1.91904928e-05, -7.31177390e-01, -1.85803011e-01,\n",
            "        -4.61516351e-01,  2.78668106e-01, -2.20838422e-03,\n",
            "         1.87892219e-04, -1.19150252e-06,  1.96524933e-01,\n",
            "         2.96725239e-06, -2.37007756e-02,  8.05330038e-01,\n",
            "         8.05119574e-01,  2.76232846e-02, -1.62489556e-07,\n",
            "         8.00684333e-01,  1.61264416e-06,  1.43514967e-06,\n",
            "         7.61998763e-06,  5.27093513e-03,  1.65885419e-03,\n",
            "        -1.52442912e-02, -9.76909518e-01, -6.50620520e-01,\n",
            "         1.88583974e-03, -5.75733781e-01, -1.16406962e-04,\n",
            "         1.37317535e-02, -1.98145494e-01,  2.69395183e-03,\n",
            "        -4.75207806e-01,  5.31188743e-05, -1.54493019e-01,\n",
            "        -5.83938276e-09,  3.12667280e-01, -6.51988238e-02,\n",
            "         7.54908264e-01, -1.42786475e-02,  1.48275185e-05,\n",
            "         6.71346716e-05, -8.87013748e-02, -6.80730820e-01,\n",
            "        -3.29200266e-05, -8.50189567e-01,  5.80902733e-02,\n",
            "        -3.31415540e-05, -3.02888364e-01,  9.81569648e-01,\n",
            "         4.51348403e-11,  6.10652706e-03, -6.15278668e-06,\n",
            "        -8.39217842e-01]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.52365565e+00,  3.47270656e+00, -1.23278725e+00,\n",
            "        -2.32037520e+00,  2.94961762e+00, -3.52583671e+00,\n",
            "        -3.91702127e+00, -5.18486595e+00,  4.05590200e+00,\n",
            "         3.26855206e+00,  9.83822465e-01,  4.80400181e+00,\n",
            "         3.12489128e+00, -2.93474293e+00, -4.91245461e+00,\n",
            "        -4.12983751e+00, -3.10744166e+00, -8.81494284e-01,\n",
            "        -1.13396335e+00,  9.62805510e-01, -2.43504190e+00,\n",
            "        -4.18918705e+00, -1.58515815e-02, -4.74298763e+00,\n",
            "        -4.44279194e+00,  1.98102927e+00, -7.63947248e-01,\n",
            "         3.18908548e+00,  2.26876855e+00, -2.00368881e+00,\n",
            "         7.35497698e-02,  1.16259181e+00,  3.00448084e+00,\n",
            "        -3.55412006e+00, -5.83236516e-02, -3.49711728e+00,\n",
            "        -3.04301691e+00, -8.63898814e-01,  4.00885820e+00,\n",
            "         3.14973831e+00,  3.75090265e+00,  5.12251854e-01,\n",
            "        -1.17544150e+00, -6.08899307e+00, -3.14091754e+00,\n",
            "        -3.20245057e-01,  2.36917496e+00,  2.24556565e+00,\n",
            "         4.53950644e+00,  3.96796870e+00,  3.92000556e-01,\n",
            "         2.40201330e+00,  2.51686621e+00, -1.93986785e+00,\n",
            "         1.44759083e+00,  5.46547842e+00,  2.05281281e+00,\n",
            "        -4.62818480e+00,  9.85610366e-01,  3.96348023e+00,\n",
            "        -4.60357100e-01,  3.44716978e+00, -2.33709669e+00,\n",
            "         4.12502003e+00,  1.49503804e-03,  5.36859465e+00,\n",
            "        -3.89919102e-01,  2.99027348e+00,  3.08792591e+00,\n",
            "        -6.08988762e-01,  1.84183598e+00,  2.54924917e+00,\n",
            "        -1.88318110e+00,  2.94167614e+00, -9.86120045e-01,\n",
            "        -5.15459180e-01,  2.39188766e+00, -5.04126251e-01,\n",
            "        -2.91948843e+00, -2.08939624e+00, -8.98138136e-02,\n",
            "        -3.12733269e+00,  2.85058570e+00,  1.00532532e+00,\n",
            "        -2.26201248e+00,  3.54449558e+00, -1.44280946e+00,\n",
            "         3.33483338e+00,  1.13597822e+00, -1.89379871e+00,\n",
            "         2.94330025e+00, -2.57785827e-01, -7.96882093e-01,\n",
            "        -1.77234685e+00, -1.81993830e+00, -4.38106585e+00,\n",
            "         3.19137621e+00, -2.90585136e+00, -2.19438624e+00,\n",
            "         2.30114818e+00,  2.49214292e+00, -1.00291216e+00,\n",
            "        -4.57222201e-02, -2.19899917e+00, -3.39033222e+00,\n",
            "         1.96392214e+00,  3.86795568e+00,  3.23484945e+00,\n",
            "         2.92914701e+00,  1.46474707e+00,  2.78821945e+00,\n",
            "        -3.45188737e-01,  3.04986596e+00, -3.16321206e+00,\n",
            "         1.49648860e-01,  1.18328966e-01,  2.54788256e+00,\n",
            "        -4.85123920e+00,  2.51462269e+00, -2.63691378e+00,\n",
            "        -4.33069420e+00, -1.27134264e+00,  2.01286197e+00,\n",
            "        -3.47605848e+00,  1.87282407e+00,  3.56728411e+00,\n",
            "         3.24558163e+00, -2.46428752e+00,  3.85631490e+00,\n",
            "         2.14274597e+00, -3.06078649e+00, -1.77705720e-01,\n",
            "        -1.63757396e+00,  8.34481537e-01,  4.27241564e+00,\n",
            "         1.55556464e+00, -2.12251067e+00, -5.23096132e+00,\n",
            "         8.67342412e-01,  2.08513681e-02,  2.36439705e+00,\n",
            "         2.88811374e+00,  2.85675454e+00, -1.99942851e+00,\n",
            "         2.12602162e+00, -2.86109328e+00,  2.61133432e-01,\n",
            "        -1.63042176e+00,  2.63095450e+00,  4.18362707e-01,\n",
            "         4.82818508e+00,  2.96164227e+00, -1.08231880e-01,\n",
            "        -7.60629535e-01, -4.63786460e-02, -3.22206116e+00,\n",
            "         4.72929382e+00,  2.89634109e+00, -3.05890155e+00,\n",
            "        -3.84914875e+00,  6.42226711e-02,  4.24103403e+00,\n",
            "         1.53298050e-01,  2.52933836e+00,  2.28375602e+00,\n",
            "        -9.66630578e-02,  3.05335855e+00, -1.11528206e+00,\n",
            "         4.25407499e-01, -2.52632999e+00, -2.62094522e+00,\n",
            "        -2.72284269e+00,  1.00660276e+00,  4.37799358e+00,\n",
            "         1.53172386e+00,  4.74753156e-02, -4.82233286e+00,\n",
            "         3.86560893e+00, -2.93006992e+00,  3.05854225e+00,\n",
            "         1.88783014e+00,  2.15036750e+00, -5.25554228e+00,\n",
            "        -3.77779841e+00, -3.09651494e+00,  4.16081953e+00,\n",
            "        -8.01211417e-01, -1.28692675e+00, -2.83652997e+00,\n",
            "        -1.43017018e+00, -1.91876352e+00,  4.33147764e+00,\n",
            "         4.88841742e-01, -1.69892156e+00,  1.81756163e+00,\n",
            "         4.73011702e-01,  1.53179538e+00,  3.85648534e-02,\n",
            "        -4.45356941e+00, -2.47319627e+00, -1.70983180e-01,\n",
            "        -2.92834401e+00,  2.67882848e+00,  2.82731748e+00,\n",
            "        -2.67608047e+00, -9.31523561e-01, -2.61529416e-01,\n",
            "        -5.02572632e+00,  3.22410393e+00, -3.01379895e+00,\n",
            "         5.04669523e+00, -2.06757784e+00,  1.99115381e-01,\n",
            "         2.99597144e+00, -3.97308540e+00,  3.54414439e+00,\n",
            "         1.11304951e+00,  2.83188485e-02, -4.01901674e+00,\n",
            "         1.10665476e+00,  2.73395705e+00,  3.02476716e+00,\n",
            "         3.73027706e+00,  3.11542773e+00,  4.14953470e+00,\n",
            "        -1.54893156e-02, -2.22873092e+00, -7.76431561e-01,\n",
            "         3.79626203e+00, -6.56062841e-01, -3.51252031e+00,\n",
            "         4.72089148e+00, -2.00909063e-01,  2.11088228e+00,\n",
            "        -9.98993993e-01,  3.59474540e+00, -1.56528547e-01,\n",
            "        -2.89118242e+00,  2.16273427e+00, -7.35563934e-02,\n",
            "         9.98119056e-01, -1.69067550e+00,  4.73772240e+00,\n",
            "         2.71156621e+00, -7.48137236e-01, -8.36059034e-01,\n",
            "        -2.39144683e+00, -1.25723529e+00,  6.63586259e-02,\n",
            "        -2.75715899e+00, -1.02371526e+00,  2.33921146e+00,\n",
            "         2.33309722e+00,  2.35646680e-01, -9.57921743e-01,\n",
            "        -4.66440105e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.67352813e-01,  7.23997831e-01, -6.93228126e-01,\n",
            "        -7.49770924e-03,  9.73715484e-01, -3.48687987e-03,\n",
            "        -9.62675512e-01, -6.55502372e-04,  9.98955727e-01,\n",
            "         1.09172411e-01,  7.53375934e-03,  1.39826559e-03,\n",
            "         6.55471410e-08, -1.61594618e-02, -5.00492635e-04,\n",
            "        -4.03930535e-05, -5.29824123e-02, -5.80772042e-01,\n",
            "        -6.09524420e-07,  8.11461747e-01, -1.03566032e-02,\n",
            "        -9.98739243e-01, -9.28301811e-02, -2.78746273e-04,\n",
            "        -8.86003733e-01,  5.75502552e-02, -6.42555118e-01,\n",
            "         7.61216797e-05,  2.16687738e-04, -7.25935353e-03,\n",
            "         1.92753702e-01,  1.12803653e-04,  9.90805924e-01,\n",
            "        -6.37954072e-05, -4.20907090e-05, -5.45686198e-05,\n",
            "        -3.79896228e-05, -1.33922741e-01,  9.98770535e-01,\n",
            "         9.82653379e-01,  5.36902808e-03, -3.08338105e-10,\n",
            "        -9.50567544e-01, -2.74301357e-07, -9.53727053e-04,\n",
            "        -2.51147360e-01,  2.76302826e-03,  1.27599856e-06,\n",
            "         5.59441469e-05,  4.15200135e-04,  4.17259205e-09,\n",
            "         9.83644664e-01,  1.80047718e-05, -7.45170891e-01,\n",
            "         2.85194219e-05,  3.91625207e-07,  5.41828058e-06,\n",
            "        -1.26061117e-04,  7.58023739e-01,  2.01865309e-03,\n",
            "        -4.77822847e-04,  9.97937262e-01, -9.97353673e-01,\n",
            "         9.99917150e-01,  1.42017499e-01,  9.09958326e-04,\n",
            "        -4.66110021e-01,  2.51763426e-02,  4.03823465e-01,\n",
            "        -9.09984529e-01,  1.31843153e-05,  4.25431086e-03,\n",
            "        -2.66678154e-01,  8.02787423e-01, -2.02731876e-08,\n",
            "        -3.43384326e-01,  4.05641867e-06, -5.91649771e-01,\n",
            "        -1.91003892e-05, -9.66240000e-03, -2.62912326e-02,\n",
            "        -3.50744594e-05,  2.63274368e-02,  5.18532237e-03,\n",
            "        -4.87712736e-04,  2.12362688e-03, -2.20457162e-03,\n",
            "         1.35966435e-01,  5.21319032e-01,  4.63573486e-01,\n",
            "         5.52985966e-06, -2.54901469e-01, -9.24774185e-02,\n",
            "        -9.32409421e-07, -6.21263310e-03, -9.04502085e-05,\n",
            "         9.14015532e-01, -1.07187929e-03, -1.08493259e-05,\n",
            "         9.82961990e-03,  9.86211717e-01, -9.36182916e-01,\n",
            "         1.04539497e-02, -8.76150489e-01, -6.80893019e-04,\n",
            "         2.20146525e-04,  9.99338925e-01,  9.99032259e-01,\n",
            "         9.68798020e-08,  5.80855762e-04,  4.20515519e-03,\n",
            "        -7.42213130e-01,  4.10588691e-05, -2.14701961e-03,\n",
            "         2.57408010e-06,  1.41976470e-05,  9.60564971e-01,\n",
            "        -6.49255736e-12,  1.70502474e-08,  1.28172403e-02,\n",
            "        -1.96700455e-07, -1.28170929e-03,  9.70897509e-06,\n",
            "        -9.99523163e-01,  1.30262959e-03,  7.48233731e-07,\n",
            "         5.75886630e-02, -1.10058607e-09,  1.97311376e-08,\n",
            "         9.57753778e-01, -1.42591456e-02,  3.06854099e-01,\n",
            "         4.64820623e-01,  5.61493099e-01,  1.04812109e-07,\n",
            "         1.37598246e-01,  7.70169936e-05, -3.04875872e-03,\n",
            "         8.79354596e-01,  2.60359440e-02,  5.36698608e-05,\n",
            "         2.01772968e-06,  8.32270075e-08, -1.93659260e-04,\n",
            "         2.56589472e-01, -5.07575704e-10, -7.74943910e-05,\n",
            "        -7.78411422e-03,  1.42745087e-02,  3.09337676e-01,\n",
            "         2.01446710e-06,  5.95076382e-01,  6.74221575e-01,\n",
            "        -6.18974507e-01, -7.64416635e-01, -6.69580847e-02,\n",
            "         1.18835098e-11,  5.20797491e-01, -1.24077544e-01,\n",
            "        -5.95139514e-04, -2.13258535e-01,  8.15154314e-01,\n",
            "         2.09600821e-01,  1.74289022e-03,  9.77083623e-01,\n",
            "         6.21047914e-01,  7.67763631e-05, -1.36757912e-02,\n",
            "        -1.84733823e-01, -1.14455538e-07, -6.99679833e-04,\n",
            "        -9.90444779e-01,  1.22309735e-04,  3.19929817e-03,\n",
            "         3.17776467e-05,  5.33325455e-08, -9.38878238e-01,\n",
            "         1.40593306e-03, -6.25852823e-01,  1.60236630e-06,\n",
            "         8.99308077e-08,  9.72548902e-01, -6.72938177e-06,\n",
            "        -2.16053854e-06, -1.12339215e-07,  1.42776771e-04,\n",
            "        -6.22086646e-03, -1.74352215e-06, -8.99273217e-01,\n",
            "        -1.23102680e-01, -2.68923526e-04,  1.11761360e-12,\n",
            "         1.08233176e-03, -4.44131319e-06,  8.79406452e-01,\n",
            "         1.99311331e-01,  8.17521513e-01,  4.03853320e-02,\n",
            "        -6.97676966e-04, -3.75070376e-05, -2.90408701e-01,\n",
            "        -1.47291348e-05,  6.84101238e-08,  9.98966634e-01,\n",
            "        -1.04221648e-07, -7.76671827e-01, -5.02027869e-01,\n",
            "        -2.18699977e-01,  9.75116432e-01, -3.00520509e-02,\n",
            "         6.83967664e-05, -3.54417076e-04,  7.65383422e-01,\n",
            "         1.38873816e-01, -2.84292191e-01,  3.77404535e-06,\n",
            "         4.69306469e-01,  7.62117624e-01, -9.97615635e-01,\n",
            "         7.95226872e-01,  3.72077048e-01,  6.97556834e-06,\n",
            "         1.89186423e-04,  1.93623930e-01,  5.30014752e-08,\n",
            "        -7.67583489e-01, -9.76662159e-01, -6.44385874e-01,\n",
            "         1.95314260e-05, -8.91966522e-01, -6.82209502e-04,\n",
            "         9.99821901e-01,  5.88068187e-01,  2.14239776e-01,\n",
            "        -1.44828670e-03,  6.09103180e-02, -1.85175195e-01,\n",
            "        -9.97229517e-01,  2.00238032e-03, -8.49834457e-03,\n",
            "         5.56906198e-05, -3.53948446e-04,  4.29556094e-05,\n",
            "         8.69149881e-06,  6.22120351e-02, -4.60851461e-01,\n",
            "        -4.80641971e-10, -2.04723775e-02,  8.13113227e-02,\n",
            "        -7.93456495e-01, -7.62800395e-01,  9.01886463e-01,\n",
            "         1.00572940e-07,  2.77849231e-02, -2.01851595e-02,\n",
            "        -2.56112940e-03]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.5342202e+00,  3.5156662e+00, -1.2822081e+00, -3.3178596e+00,\n",
            "         2.1622162e+00, -3.5910747e+00, -3.9184129e+00, -5.9863572e+00,\n",
            "         3.7967687e+00,  3.2628531e+00,  1.2406409e+00,  5.7805042e+00,\n",
            "         3.8849194e+00, -2.7853481e-02, -5.6036692e+00, -5.0369873e+00,\n",
            "        -3.1416676e+00, -8.5822999e-01, -1.1472021e+00,  1.8556341e+00,\n",
            "        -2.5153356e+00, -4.2930255e+00, -9.3098238e-02, -5.1188083e+00,\n",
            "        -4.5052428e+00,  1.2169808e+00, -7.6263744e-01,  4.1151714e+00,\n",
            "         2.2703180e+00, -2.8919196e+00,  1.9520067e-01,  1.1844876e+00,\n",
            "         2.6902122e+00, -4.2177587e+00, -6.3580841e-02, -3.6268978e+00,\n",
            "        -3.0452962e+00, -1.7847440e+00,  4.9680200e+00,  4.0098510e+00,\n",
            "         5.3690798e-03, -2.9857397e-01, -2.1746368e+00, -6.6330357e+00,\n",
            "        -3.7064245e+00, -3.1845239e-01,  2.4236138e+00,  1.1450032e+00,\n",
            "         4.5751724e+00,  4.2710733e+00,  1.3207526e+00,  2.3992178e+00,\n",
            "         3.1672196e+00, -9.6201944e-01,  7.6777226e-01,  6.2591581e+00,\n",
            "         1.9471751e+00, -5.3609881e+00,  9.9497634e-01,  4.7287908e+00,\n",
            "        -5.0981367e-01,  3.4382973e+00, -3.3246441e+00,  5.0955405e+00,\n",
            "         9.9271995e-01,  5.4381485e+00, -5.0511760e-01,  3.9608483e+00,\n",
            "         3.9911067e+00, -1.5287048e+00,  1.8220340e+00,  3.3942120e+00,\n",
            "        -2.4275892e+00,  1.9690305e+00, -1.9822109e+00, -3.6814508e-01,\n",
            "         3.1135445e+00, -7.4518704e-01, -2.9256225e+00, -2.1069312e+00,\n",
            "        -7.4663705e-01, -2.1388128e+00,  3.2431130e+00,  1.3927383e+00,\n",
            "        -2.5073357e+00,  4.5267072e+00, -2.0770526e+00,  4.3344269e+00,\n",
            "         5.7842284e-01,  5.0185335e-01,  3.6397128e+00, -4.6532172e-01,\n",
            "        -8.2059449e-01, -9.8692095e-01, -1.7869028e+00, -5.2727151e+00,\n",
            "         4.1912427e+00, -2.9075882e+00, -1.6308984e+00,  3.2598040e+00,\n",
            "         2.4895375e+00, -1.7065849e+00,  1.0455560e-02, -1.3649211e+00,\n",
            "        -6.8089360e-04,  5.6721938e-01,  4.0110173e+00,  4.0195880e+00,\n",
            "         2.9804876e+00,  1.4591893e+00,  2.7270999e+00, -9.7274208e-01,\n",
            "         3.1698961e+00, -3.2418616e+00,  1.3504841e-03,  1.1143945e+00,\n",
            "         1.9535253e+00, -4.8828235e+00,  2.3048065e+00,  7.4250036e-01,\n",
            "        -4.9124708e+00, -1.6805131e+00,  2.9982023e+00, -4.4736242e+00,\n",
            "         2.8589790e+00,  4.4649315e+00,  3.9557030e+00, -2.5703101e+00,\n",
            "         4.7446980e+00,  1.9227412e+00, -3.5853038e+00,  6.8368196e-01,\n",
            "         6.0234737e-01,  8.2116461e-01,  4.7396541e+00,  2.3386464e+00,\n",
            "         7.4041700e-01, -5.4244537e+00,  1.6264912e+00,  4.5450318e-01,\n",
            "         2.7767935e+00,  3.4196463e+00,  3.7060039e+00, -2.6430237e+00,\n",
            "         2.7762480e+00, -3.6173060e+00, -2.6447466e-01, -2.5955534e+00,\n",
            "         3.5539002e+00,  3.1982762e-01,  4.9359770e+00,  3.7427864e+00,\n",
            "         8.1844407e-01, -7.2338611e-01, -1.0067552e+00, -4.1813264e+00,\n",
            "         5.6139975e+00,  3.2517891e+00, -4.0526175e+00, -4.7564688e+00,\n",
            "        -5.6419665e-01,  5.0025716e+00,  2.1275386e-01,  1.7504832e-03,\n",
            "         2.3812792e+00,  7.2682840e-01,  4.0489836e+00, -1.1160634e+00,\n",
            "        -1.8688013e-01, -2.5086443e+00, -2.6095824e+00, -2.7502818e+00,\n",
            "         1.9731139e+00,  5.0968580e+00,  8.4415913e-01,  9.3540460e-01,\n",
            "        -4.8982210e+00,  3.0422631e-01, -3.8864405e+00,  3.1317627e+00,\n",
            "         1.9373384e+00,  2.1373396e+00, -6.0965486e+00, -4.7141919e+00,\n",
            "        -4.0445151e+00,  4.7840447e+00, -1.7936968e+00, -1.9480339e+00,\n",
            "        -3.8355117e+00, -1.2713236e-01, -2.8757927e+00,  4.3317723e+00,\n",
            "         1.4217380e+00, -1.7682569e+00,  1.6932055e+00,  2.0201534e-01,\n",
            "         1.1498878e+00,  9.7460419e-01, -5.4210801e+00, -2.9730036e+00,\n",
            "        -2.9905206e-01, -3.8380291e+00,  2.0605729e+00,  3.7837913e+00,\n",
            "        -2.6462715e+00, -1.1166109e+00, -5.5307281e-01, -4.9552193e+00,\n",
            "         4.1672893e+00, -3.0757089e+00,  6.0362430e+00, -2.1323786e+00,\n",
            "         1.0090857e+00,  3.9587348e+00, -3.9933977e+00,  3.6322265e+00,\n",
            "         1.1128914e+00,  1.0278636e+00, -4.9524503e+00,  1.0854920e+00,\n",
            "         2.7589893e+00,  2.8960876e+00,  3.6921587e+00,  4.1151571e+00,\n",
            "         4.2477574e+00, -1.0149130e+00, -2.2283492e+00, -7.6563889e-01,\n",
            "         4.7085567e+00, -1.5224427e+00, -4.0615525e+00,  4.7212181e+00,\n",
            "         6.7488104e-01,  3.0945473e+00, -1.9967405e+00,  4.0185509e+00,\n",
            "        -1.8750855e-01, -3.8067305e+00,  2.3225048e+00, -1.0653920e+00,\n",
            "         2.3247272e-01, -7.4974453e-01,  5.7149301e+00,  3.5974407e+00,\n",
            "         6.5335035e-02, -6.3205343e-01, -3.3450613e+00, -2.2545896e+00,\n",
            "         9.3046173e-02, -3.4777532e+00, -1.0095189e+00,  1.5441179e+00,\n",
            "         2.9768054e+00,  3.3340748e-02, -1.3924797e+00, -5.6480207e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.91250178e-02,  1.58065596e-08, -1.27524021e-04,\n",
            "        -1.07394328e-11, -5.02104012e-05, -8.05504897e-07,\n",
            "        -2.69037912e-07, -1.37294731e-10,  9.93601918e-01,\n",
            "         5.29664064e-08,  4.08657788e-14,  7.76966382e-03,\n",
            "         4.15257253e-02, -7.50201404e-01, -1.25932764e-10,\n",
            "        -1.27976385e-08, -2.92479656e-16,  1.33339226e-01,\n",
            "        -3.13595374e-12,  3.87991131e-05, -3.73664805e-19,\n",
            "        -1.67212824e-18, -4.50413942e-01, -2.02319370e-05,\n",
            "        -6.84119783e-08,  7.05486238e-01, -6.42271936e-01,\n",
            "         4.88681826e-06,  5.55807527e-12, -9.04144906e-15,\n",
            "         2.55824924e-01,  8.32692022e-05,  4.61998212e-07,\n",
            "        -2.98411906e-01, -2.23803090e-05, -1.84257876e-03,\n",
            "        -7.23370208e-09, -8.98774655e-09,  9.95595217e-01,\n",
            "         2.67469495e-05,  4.09134460e-04, -1.24397362e-03,\n",
            "        -9.96197402e-01, -9.99886572e-01, -6.09643655e-11,\n",
            "        -3.08079123e-01,  2.04105515e-08, -6.00702663e-07,\n",
            "         9.21668834e-06,  5.03561193e-10,  5.00690045e-11,\n",
            "         9.73661423e-01,  1.38634285e-10, -6.91298187e-01,\n",
            "        -9.15337419e-17,  7.05834537e-08,  1.65339150e-02,\n",
            "        -7.87681937e-01,  7.15553641e-01,  2.36952545e-07,\n",
            "        -1.67157222e-02,  9.85154927e-01, -1.50048122e-01,\n",
            "         3.76942116e-05,  2.90708570e-03, -1.32951945e-01,\n",
            "        -8.54961395e-01,  9.28332584e-12, -7.08175662e-12,\n",
            "        -1.07384174e-07,  1.11811517e-14,  1.95878485e-07,\n",
            "        -1.56928785e-04,  9.60599959e-01, -7.61622250e-01,\n",
            "        -3.69253282e-12,  2.76766036e-06, -8.99964333e-01,\n",
            "        -2.07143014e-09, -2.34927415e-06,  7.45189548e-01,\n",
            "        -4.99371531e-08,  5.51628917e-02,  1.48729160e-01,\n",
            "        -9.61060359e-05,  4.32486136e-19, -3.26952243e-10,\n",
            "         9.99944210e-01, -3.53355765e-01,  8.80498767e-01,\n",
            "         6.75211907e-14, -2.53891503e-03, -9.48004007e-01,\n",
            "        -7.19369453e-09, -2.69721767e-12, -1.60167571e-12,\n",
            "         1.59792943e-10, -7.50459833e-07, -7.68108526e-04,\n",
            "         4.79980378e-12,  9.86318529e-01, -9.57216144e-01,\n",
            "         2.15233341e-01, -3.67924452e-01,  6.32660044e-19,\n",
            "        -7.10070891e-11,  6.76904738e-01,  1.61668299e-06,\n",
            "         7.27072620e-05,  4.17256160e-06,  4.55400441e-03,\n",
            "        -9.45437372e-01,  8.06491852e-12, -2.72906419e-07,\n",
            "        -7.61376381e-01,  8.28757510e-02,  9.60573077e-01,\n",
            "        -9.55116237e-04,  1.41110817e-07,  3.90930177e-09,\n",
            "        -4.09248627e-16,  3.80690047e-03,  1.73418655e-07,\n",
            "        -8.04342330e-03,  3.66103486e-04,  3.58300944e-08,\n",
            "         7.37970449e-11, -1.07779371e-04,  2.83924049e-08,\n",
            "         6.68804205e-06, -1.47146260e-12,  9.33326662e-01,\n",
            "         1.14255697e-11,  3.76389695e-14,  9.96029854e-01,\n",
            "         5.06915204e-11, -8.40462690e-06, -9.99125600e-01,\n",
            "         2.36480823e-03, -1.77003486e-12,  3.75305824e-02,\n",
            "         1.87809178e-11,  6.86382428e-02, -4.86449506e-20,\n",
            "         2.47819279e-03, -1.52724594e-13,  6.48456872e-01,\n",
            "        -1.69971108e-01,  6.05929196e-11,  2.85761476e-01,\n",
            "         5.13263765e-15,  2.42938637e-03,  6.81152523e-01,\n",
            "        -5.28909480e-15, -6.53867271e-09, -6.17600415e-12,\n",
            "         4.27668467e-02,  9.80846822e-01, -1.34510073e-17,\n",
            "        -4.34071431e-16, -7.49597013e-01,  6.48329318e-14,\n",
            "         2.10846007e-01,  2.88901674e-07,  8.51772638e-05,\n",
            "         6.58398271e-01,  6.92025196e-07, -4.29665625e-01,\n",
            "        -2.53404617e-01,  5.51770718e-08, -2.36618170e-09,\n",
            "        -9.61082339e-01,  9.82366085e-01,  1.22870446e-11,\n",
            "        -4.13803160e-21,  3.76603326e-09, -4.41994735e-06,\n",
            "        -4.58853549e-07, -1.95010379e-03,  9.98043537e-01,\n",
            "         7.72292629e-18,  3.93948942e-01, -2.59047314e-13,\n",
            "        -6.51853188e-05, -1.56694266e-16,  1.20066204e-06,\n",
            "        -3.90282929e-01, -1.05369495e-22, -8.88388030e-08,\n",
            "        -7.51716435e-01, -2.68482580e-07,  9.31247473e-01,\n",
            "         7.61690915e-01, -6.30009672e-05,  6.51381969e-01,\n",
            "         2.38461971e-01,  5.22893310e-01, -2.84838804e-20,\n",
            "         7.04465574e-03, -8.03865194e-02, -1.67034790e-02,\n",
            "        -2.50709672e-05,  1.07798822e-11,  5.15977616e-09,\n",
            "         4.40469325e-01, -6.47504476e-06, -9.01892841e-01,\n",
            "        -3.39466541e-12,  7.19370952e-10, -9.67987716e-01,\n",
            "         3.70385354e-11, -2.26010433e-09,  1.95742745e-11,\n",
            "         4.70096795e-10, -7.03253299e-02, -7.61336625e-01,\n",
            "         1.96259338e-04,  6.85719609e-01, -1.04523118e-11,\n",
            "         9.68806603e-07,  6.54538735e-06,  4.64294280e-05,\n",
            "         1.84405542e-06,  2.71709094e-14,  5.94800889e-01,\n",
            "        -7.67281890e-01, -9.77059066e-01, -1.87945276e-01,\n",
            "         1.20821950e-10, -1.22078360e-04, -3.02329892e-04,\n",
            "         3.48250793e-20,  2.17732395e-05,  6.05559151e-04,\n",
            "        -1.37191836e-09,  1.38418311e-02, -1.85887888e-02,\n",
            "        -3.72251074e-09,  1.08168026e-08, -9.71349925e-02,\n",
            "         2.28148118e-01,  3.25661720e-12,  3.06352877e-14,\n",
            "         1.85968396e-09,  4.95999247e-01, -5.59065878e-01,\n",
            "        -2.83628406e-14, -3.51336166e-05,  2.62950576e-04,\n",
            "        -4.01181533e-05, -7.65572906e-01,  9.10468400e-01,\n",
            "         1.97334131e-07, -9.60315269e-13,  6.49785477e-07,\n",
            "        -5.53768187e-09]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.8891888e+00,  2.5156078e+00, -1.7104905e+00, -4.3176966e+00,\n",
            "        -9.9999559e-01, -4.5781546e+00, -4.9068117e+00, -6.4358311e+00,\n",
            "         2.8708501e+00,  3.1005175e+00,  1.3059616e+00,  6.1209879e+00,\n",
            "         4.8840547e+00, -1.0277960e+00, -5.4858613e+00, -4.4941177e+00,\n",
            "        -4.0191059e+00,  1.3414960e-01, -1.4720213e-01,  1.8811328e+00,\n",
            "        -1.5153686e+00, -4.2904754e+00, -4.8521942e-01, -5.9295244e+00,\n",
            "        -5.2255268e+00,  9.9999410e-01, -7.6203132e-01,  4.1151099e+00,\n",
            "         2.2618968e+00, -1.8912646e+00,  2.6163596e-01,  2.9359615e-01,\n",
            "         3.6770630e+00, -5.2153244e+00, -6.8937816e-02, -3.1084700e+00,\n",
            "        -9.9999595e-01, -2.7184446e+00,  5.3286576e+00,  3.6836464e+00,\n",
            "         1.0053691e+00, -1.0000243e+00, -3.1746271e+00, -6.3465667e+00,\n",
            "        -4.7043681e+00, -3.1843677e-01,  2.4185872e+00, -9.9989992e-01,\n",
            "         4.8979969e+00,  5.2569442e+00,  2.2894418e+00,  2.1631081e+00,\n",
            "         2.2657242e+00, -8.5051715e-01, -2.3222774e-01,  6.1195149e+00,\n",
            "         1.9471549e+00, -6.3543396e+00,  9.0695578e-01,  3.7235391e+00,\n",
            "        -5.1127923e-01,  2.4514809e+00, -4.3243623e+00,  5.3879480e+00,\n",
            "         9.9092275e-01, -3.1847036e-01, -1.2743115e+00,  2.9609630e+00,\n",
            "        -9.9991101e-01, -5.2859873e-01,  2.8217435e+00,  4.3822560e+00,\n",
            "        -3.3981204e+00,  1.9676815e+00, -1.0000669e+00, -1.3349118e+00,\n",
            "         4.0997338e+00, -1.4763311e+00, -3.9254098e+00, -3.1057734e+00,\n",
            "         9.6216816e-01, -1.3917568e+00,  3.1477561e+00,  3.9273852e-01,\n",
            "        -3.4883423e+00,  5.4394598e+00, -1.1083686e+00,  5.3344254e+00,\n",
            "        -3.6927423e-01,  1.3779829e+00,  4.6273808e+00, -1.4618427e+00,\n",
            "        -1.8182460e+00, -1.5487838e-01, -7.7836675e-04, -6.2471671e+00,\n",
            "         5.1912427e+00, -2.9074631e+00, -6.3099343e-01,  2.2659142e+00,\n",
            "         2.4890015e+00, -1.9115942e+00,  2.1865252e-01, -3.8720033e-01,\n",
            "         6.2494433e-01, -4.3154532e-01,  5.0093107e+00,  5.0195780e+00,\n",
            "         3.8984632e+00,  1.4588813e+00,  3.7270980e+00, -1.8296841e+00,\n",
            "         3.5392857e+00, -4.2385044e+00, -9.9985290e-01,  1.4023883e+00,\n",
            "         1.9532880e+00, -5.8828053e+00,  2.2804587e+00,  1.7424924e+00,\n",
            "        -4.3329501e+00,  7.8626591e-01,  3.9814758e+00, -4.5270739e+00,\n",
            "         3.8582187e+00,  5.2836347e+00,  4.0854187e+00, -3.5699437e+00,\n",
            "         5.7272754e+00,  2.9064243e+00, -2.5889163e+00,  1.6835959e+00,\n",
            "         1.0329812e+00,  1.8036656e+00,  4.8611884e+00,  3.3386452e+00,\n",
            "        -2.6075876e-01, -6.3701568e+00,  9.0952682e-01, -9.9886048e-01,\n",
            "         2.3741319e+00,  4.4194756e+00,  4.7059660e+00, -3.6415331e+00,\n",
            "         2.4782231e+00, -4.5869198e+00,  7.7263123e-01, -3.5921552e+00,\n",
            "         2.5537264e+00,  2.9394475e-01,  4.8822842e+00,  1.3163615e+00,\n",
            "         8.3140844e-01, -7.2244507e-01, -1.0067320e+00, -5.0439377e+00,\n",
            "         6.6021557e+00,  4.2505302e+00, -5.0499959e+00, -5.7284923e+00,\n",
            "        -1.2525457e+00,  5.8327932e+00,  2.1463965e-01,  1.0017505e+00,\n",
            "         3.3408060e+00,  7.9002124e-01,  3.0645020e+00, -1.1110564e+00,\n",
            "        -2.5904900e-01,  9.9984008e-01, -2.4256034e+00, -1.9599099e+00,\n",
            "         2.9731112e+00,  5.0552120e+00, -1.5584469e-01,  1.0561002e+00,\n",
            "        -3.8982229e+00, -9.9997526e-01, -4.8859715e+00,  4.1317325e+00,\n",
            "         2.9371550e+00,  1.1376783e+00, -6.3106856e+00, -5.7033782e+00,\n",
            "        -4.9697027e+00,  5.7830868e+00, -2.7887626e+00, -9.4816411e-01,\n",
            "        -3.8355358e+00, -1.0098698e+00, -3.8750353e+00,  4.3317833e+00,\n",
            "         1.0002304e+00, -2.4464233e+00,  7.8859007e-01,  2.4314296e-01,\n",
            "         2.1486964e+00, -5.4940738e-02,  9.3157345e-01, -2.9698246e+00,\n",
            "        -3.0019799e-01, -2.8379722e+00,  2.0594532e+00,  4.7834840e+00,\n",
            "         9.9454510e-01, -9.9853861e-01, -1.4892832e+00, -3.9584913e+00,\n",
            "         5.1600318e+00, -2.0593235e+00,  7.0283694e+00, -1.6456407e+00,\n",
            "         1.4882666e+00,  4.9341898e+00, -3.0540564e+00, -9.9945652e-01,\n",
            "         1.0620011e+00,  1.0990715e+00, -5.9524431e+00,  2.0853856e+00,\n",
            "         2.4913166e+00,  2.9498119e+00,  4.6680202e+00,  5.0996003e+00,\n",
            "         5.2066941e+00, -1.0136867e+00, -2.2283108e+00, -1.9020727e-01,\n",
            "         4.7075429e+00, -2.5223477e+00, -3.0839124e+00,  4.7212057e+00,\n",
            "         9.7379130e-01,  4.0875440e+00, -2.9899590e+00,  4.9745569e+00,\n",
            "        -6.9547176e-02, -3.0666935e+00,  3.2913086e+00, -2.0399811e+00,\n",
            "         2.3223503e-01,  9.9918050e-01,  4.7149329e+00,  2.5983877e+00,\n",
            "         1.0652671e+00, -6.3148528e-01, -4.3077579e+00, -3.2539604e+00,\n",
            "         1.0830849e+00, -4.4772420e+00, -1.0095433e+00,  1.5302578e+00,\n",
            "         3.9698682e+00, -9.6665931e-01,  9.9754065e-01, -4.6539106e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.15070537e-07,  1.61744026e-06, -5.74015779e-04,\n",
            "        -2.01526345e-05, -9.35572445e-01, -9.90908504e-01,\n",
            "        -3.61353050e-05, -2.94752270e-01,  9.87656415e-01,\n",
            "         3.54158372e-01,  1.12047032e-01,  9.98238146e-01,\n",
            "         4.24310237e-01, -7.76782811e-01, -9.00518731e-04,\n",
            "        -5.20037720e-04, -1.73686232e-04,  3.84637117e-01,\n",
            "        -5.82678914e-01,  5.19095408e-03, -2.95496248e-02,\n",
            "        -2.21775076e-06, -5.25988102e-01, -7.40986361e-05,\n",
            "        -7.98011257e-04,  8.60793807e-04, -6.42141581e-01,\n",
            "         9.10103381e-01,  4.61447636e-09, -3.64424795e-01,\n",
            "         2.55789965e-01,  1.81515170e-05,  2.94644433e-08,\n",
            "        -3.71160954e-02, -5.40347278e-01, -2.47941520e-02,\n",
            "        -3.01431622e-02, -2.23569732e-04,  9.99988258e-01,\n",
            "         2.48870463e-03,  1.31684579e-02, -4.69766371e-02,\n",
            "        -4.40386299e-04, -9.99066889e-01, -5.76124967e-06,\n",
            "         5.90666056e-01,  2.31809927e-09, -2.02627163e-02,\n",
            "         4.23518213e-04,  1.33375579e-03,  7.26585586e-06,\n",
            "         8.37157190e-01,  3.24981251e-08, -3.17120820e-01,\n",
            "        -1.86473846e-01,  4.15369749e-01,  9.54960108e-01,\n",
            "        -9.80400205e-01,  3.32848608e-01,  3.41566396e-04,\n",
            "        -3.73101771e-01,  9.85579491e-01, -2.72238534e-03,\n",
            "         1.23056030e-04,  5.05752027e-01, -7.01409221e-01,\n",
            "        -7.96798944e-01,  7.70188153e-01, -4.30729706e-03,\n",
            "         4.38838750e-01,  6.78510871e-03,  1.04900224e-04,\n",
            "        -9.36388135e-01,  7.53592849e-01, -6.50559412e-03,\n",
            "        -9.40716028e-01,  6.04866706e-02, -5.88274971e-02,\n",
            "        -9.03458614e-03, -1.10568653e-04,  6.93797541e-04,\n",
            "        -1.06479172e-04,  1.73074082e-02,  8.82135212e-01,\n",
            "        -4.83928574e-03,  1.76439155e-02, -9.43132877e-01,\n",
            "         9.98502076e-01, -3.24167222e-01,  8.56298566e-01,\n",
            "         2.54034694e-05, -8.94139349e-01, -9.88022447e-01,\n",
            "        -2.76329531e-03,  2.82565951e-01, -9.99707997e-01,\n",
            "         9.44197834e-01, -4.31213666e-05, -9.48846209e-05,\n",
            "         5.40526258e-03,  9.75371599e-01, -8.38410378e-01,\n",
            "         6.08902931e-01, -1.98696181e-01, -7.28029090e-06,\n",
            "         2.98631992e-02,  9.40873444e-01,  9.86375332e-01,\n",
            "         7.73889769e-05,  1.23272219e-03,  9.99399126e-01,\n",
            "        -2.41678730e-01,  4.35066846e-04, -9.97342646e-01,\n",
            "        -1.42183881e-05,  7.69937217e-01,  8.37882578e-01,\n",
            "        -3.44940662e-01,  9.67395723e-01,  7.51610041e-01,\n",
            "        -9.07865324e-05,  6.01844149e-05,  5.15604825e-06,\n",
            "        -1.40851876e-03,  1.99625894e-01,  5.38685806e-02,\n",
            "         5.61072629e-05, -8.77403596e-04,  2.62898629e-06,\n",
            "         1.26851164e-03, -5.06694056e-03,  9.72633243e-01,\n",
            "         5.27831912e-01,  9.78690028e-01,  9.99875486e-01,\n",
            "         1.38802500e-06, -5.37223876e-01, -6.74329460e-01,\n",
            "         8.49115625e-02, -2.08558273e-02,  9.97649312e-01,\n",
            "         5.85606685e-05,  6.29047900e-02, -1.07049897e-01,\n",
            "         1.98798007e-04, -1.46173658e-02,  9.83302444e-02,\n",
            "        -9.75508153e-01,  9.12381947e-01,  2.85321295e-01,\n",
            "         7.03892531e-03,  9.71937478e-01,  1.21315099e-01,\n",
            "        -3.21392566e-02,  1.86563702e-05, -4.99808799e-08,\n",
            "         2.21229385e-07,  9.93921340e-01, -2.36108355e-11,\n",
            "        -2.09028319e-01, -8.79020512e-01,  3.31487390e-04,\n",
            "         2.33847857e-01,  4.55176132e-06,  1.05399461e-02,\n",
            "         7.62337089e-01,  1.99343771e-01, -6.37996782e-05,\n",
            "        -2.26082981e-01,  3.39344115e-04, -6.24031067e-01,\n",
            "        -9.61073339e-01,  9.17245746e-01,  6.88923194e-08,\n",
            "        -2.42081253e-04,  7.62893498e-01, -4.15454149e-01,\n",
            "        -8.41342270e-01, -1.80743437e-03,  7.60627445e-05,\n",
            "         2.36845540e-06,  1.36996299e-01, -8.79492654e-06,\n",
            "        -5.05987585e-01, -1.39874275e-04,  2.22539599e-03,\n",
            "        -8.43203843e-01,  2.90609449e-02, -9.98782933e-01,\n",
            "        -9.39836264e-01, -9.96047080e-01,  5.22500113e-06,\n",
            "         1.93213345e-03, -6.01986408e-01,  6.19194269e-01,\n",
            "         8.31425428e-01,  6.94280565e-01,  4.41405457e-03,\n",
            "        -9.15154396e-06, -1.68817773e-01, -8.11452985e-01,\n",
            "        -5.02670975e-03,  1.11270947e-06,  5.42649813e-03,\n",
            "        -1.25768585e-02, -2.00546429e-01, -9.43503618e-01,\n",
            "        -2.61788839e-03,  5.79497730e-03, -1.23820559e-03,\n",
            "         2.59282824e-04, -3.46906506e-03,  1.83170645e-09,\n",
            "         2.14124039e-01, -9.75746334e-01, -1.41600981e-01,\n",
            "         9.33580935e-01,  9.63211894e-01,  2.78665870e-03,\n",
            "         9.58643258e-01,  9.96240854e-01, -1.85437173e-01,\n",
            "         8.95584673e-02,  6.66385051e-03,  2.72209812e-02,\n",
            "        -4.72896814e-01, -8.30274820e-01,  5.77266693e-01,\n",
            "         3.24242370e-04, -9.97588396e-01, -1.20704882e-01,\n",
            "         3.98870803e-09,  9.58547950e-01,  1.22510582e-01,\n",
            "        -3.79573845e-04,  9.93884802e-01, -3.17098886e-01,\n",
            "        -6.24882355e-02,  9.78127182e-01, -2.68986493e-01,\n",
            "         1.02031484e-01,  8.76889797e-04,  3.11464746e-03,\n",
            "         8.49857986e-01,  4.52117443e-01, -5.52291870e-01,\n",
            "        -9.70770866e-02, -8.20548394e-06,  9.76496494e-07,\n",
            "        -2.68581092e-01, -9.53390002e-01,  4.86896932e-01,\n",
            "         3.41105842e-05, -1.02200283e-06,  6.68572366e-01,\n",
            "        -9.72022891e-01]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.5518646e+00,  1.5856501e+00, -1.1931067e+00, -3.2524476e+00,\n",
            "        -1.7073047e+00, -4.1265125e+00, -5.5755100e+00, -6.6926012e+00,\n",
            "         2.5419199e+00,  2.2347744e+00,  3.4121630e-01,  6.9871259e+00,\n",
            "         5.7619052e+00, -1.0372152e+00, -5.0229144e+00, -4.2602820e+00,\n",
            "        -1.4027746e+00,  4.0553045e-01, -8.6806887e-01,  1.8458395e+00,\n",
            "        -5.9383142e-01, -5.1329799e+00, -5.8961546e-01, -6.6113682e+00,\n",
            "        -5.4876637e+00,  8.6258678e-04, -7.6217186e-01,  3.5883787e+00,\n",
            "         3.3597419e-01, -9.3728405e-01,  2.6159903e-01,  3.9395538e-01,\n",
            "         4.4547648e+00, -5.4556017e+00, -9.8984951e-01, -2.7708213e+00,\n",
            "        -6.7014772e-01, -3.1145964e+00,  6.1066742e+00,  3.3439274e+00,\n",
            "         1.9659561e+00, -4.9772358e-01, -4.1214509e+00, -6.3012528e+00,\n",
            "        -2.9856343e+00,  6.8115360e-01,  2.3033495e+00, -1.9281559e+00,\n",
            "         5.8414555e+00,  5.6488962e+00,  1.1298614e+00,  1.2116767e+00,\n",
            "         2.0715365e+00, -3.2918465e-01, -1.2305595e+00,  5.6602426e+00,\n",
            "         1.8890213e+00, -6.6167183e+00,  8.9261234e-01,  6.5726411e-01,\n",
            "        -3.9766940e-01,  2.4625843e+00, -5.1819549e+00,  6.3497210e+00,\n",
            "         1.7839122e+00, -1.0013952e+00, -1.0898280e+00,  1.9334642e+00,\n",
            "        -9.0643629e-02,  4.7079378e-01,  2.4973888e+00,  5.1428695e+00,\n",
            "        -2.4778216e+00,  1.0165926e+00, -1.0948471e+00, -2.3345127e+00,\n",
            "         1.1543169e+00, -5.8974512e-02, -1.3507884e+00, -3.7760012e+00,\n",
            "         8.4753042e-01, -6.0205567e-01,  3.4160988e+00,  1.3853513e+00,\n",
            "        -3.9637647e+00,  6.1743894e+00, -1.7663152e+00,  5.9531755e+00,\n",
            "        -3.3670530e-01,  1.2793009e+00,  3.4471738e+00, -2.4333386e+00,\n",
            "        -2.5565002e+00, -4.7662100e-01,  7.8048980e-01, -7.0783801e+00,\n",
            "         6.1719313e+00, -2.9071524e+00, -1.6149672e+00,  3.1412592e+00,\n",
            "         2.1949868e+00, -1.2191939e+00,  7.0719618e-01, -2.0137759e-01,\n",
            "        -3.9722887e-01,  3.8176912e-01,  5.8679252e+00,  5.4497571e+00,\n",
            "         4.1332164e+00,  4.8352760e-01,  4.0586505e+00, -1.0114750e+00,\n",
            "         4.1200857e+00, -5.0549073e+00, -9.1332489e-01,  1.0234448e+00,\n",
            "         1.2140262e+00, -6.5241551e+00,  2.8556962e+00,  2.6317515e+00,\n",
            "        -4.0488262e+00,  2.6316436e-02,  3.8867123e+00, -5.5174561e+00,\n",
            "         1.0297954e+00,  5.0896873e+00,  3.2526801e+00, -3.7180059e+00,\n",
            "         6.4022846e+00,  3.8127148e+00, -1.5306391e+00,  2.1390309e+00,\n",
            "         5.9345937e-01,  2.2758331e+00,  4.9242125e+00,  3.3294067e+00,\n",
            "        -1.2517470e+00, -6.4123297e+00,  1.1689454e-01, -9.6961284e-01,\n",
            "         3.3725836e+00,  4.3191986e+00,  5.3923988e+00, -3.6555202e+00,\n",
            "         1.5921336e-01, -5.3933330e+00,  1.5224515e+00, -3.5166206e+00,\n",
            "         1.5512267e+00,  2.9347011e-01,  4.8772244e+00,  2.1418531e+00,\n",
            "         1.2287090e-01, -7.2138083e-01,  7.1322012e-01, -5.7149591e+00,\n",
            "         6.6339569e+00,  5.2459855e+00, -6.0105019e+00, -6.4321361e+00,\n",
            "        -1.3765039e+00,  6.4146786e+00,  2.3894575e-01,  1.6428313e+00,\n",
            "         4.0632048e+00,  1.0018495e+00,  2.6991301e+00, -6.2885322e-02,\n",
            "        -2.3048292e-01,  1.9478264e+00, -3.1133671e+00, -1.9599546e+00,\n",
            "         2.0385695e+00,  5.0632615e+00, -1.1552432e+00,  1.0035589e+00,\n",
            "        -3.6562154e+00, -1.9533765e+00, -5.6824598e+00,  5.0886631e+00,\n",
            "         3.0232842e+00,  1.3804795e-01, -5.9032693e+00, -5.7289171e+00,\n",
            "        -5.2020373e+00,  2.8923533e+00, -1.3348844e+00,  8.0669761e-02,\n",
            "        -3.7019658e+00, -1.8661832e+00, -3.1158745e+00,  4.0642376e+00,\n",
            "         1.0173501e+00, -2.0831923e+00,  7.2503030e-01,  1.1927522e+00,\n",
            "         2.6571553e+00,  7.3847628e-01, -5.4289442e-01, -3.1130030e+00,\n",
            "        -1.2665081e+00, -2.9182489e+00,  2.4097851e-02,  3.8184116e+00,\n",
            "        -5.0734591e-01, -3.1239194e-01, -1.7691289e+00, -4.7183051e+00,\n",
            "         5.7817688e+00, -1.4609374e+00,  7.9778724e+00, -1.3927336e-02,\n",
            "         1.6691568e+00,  5.6671925e+00, -3.1003234e+00, -1.4255904e-01,\n",
            "         1.9247092e+00,  2.0387313e+00,  8.2230747e-01,  1.9300754e+00,\n",
            "         3.4194510e+00, -3.7913176e-01,  5.5002027e+00,  4.7443218e+00,\n",
            "         5.1145597e+00, -5.3273523e-01, -1.1922861e+00,  6.5899688e-01,\n",
            "         4.5529294e+00, -3.4353943e+00, -1.2155295e-01,  4.5569515e+00,\n",
            "         1.9481683e+00,  3.6199706e+00, -3.9327192e+00,  4.4757457e+00,\n",
            "        -3.4301344e-01, -2.0416379e+00,  2.3081479e+00, -5.6151313e-01,\n",
            "         1.3300566e-01,  1.8159339e+00,  3.7084777e+00,  3.3312247e+00,\n",
            "         1.1442825e+00, -6.2171715e-01, -4.8247852e+00, -4.2225943e+00,\n",
            "         1.3332227e-01, -5.3375406e+00, -1.8905525e+00,  5.3198552e-01,\n",
            "         4.1872644e+00, -1.9578706e+00,  1.6134691e+00, -4.4553709e+00]],\n",
            "      dtype=float32)>)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 25)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.40484849e-04,  2.72222608e-02,  6.66740656e-01,\n",
            "        -9.78220344e-01,  4.93293464e-01, -5.24990959e-03,\n",
            "        -2.49761011e-04, -3.14468384e-01,  1.45271741e-04,\n",
            "         8.39652028e-03,  8.24540475e-05,  9.04880762e-01,\n",
            "         7.81141400e-01,  2.68424228e-02, -7.75071373e-03,\n",
            "        -9.30774689e-01, -2.56176889e-02, -9.89371717e-01,\n",
            "        -6.24879704e-07,  3.69129889e-02, -3.48740876e-01,\n",
            "        -9.97648895e-01,  9.97649133e-01, -7.61024887e-04,\n",
            "        -2.49060214e-01, -9.19270337e-01, -9.12186503e-01,\n",
            "         4.00298923e-05,  4.96230006e-01, -6.77364739e-03,\n",
            "        -3.75705335e-04,  4.68522630e-04,  2.57975701e-03,\n",
            "        -7.68311262e-01, -1.52868647e-02, -3.20827021e-05,\n",
            "        -4.45041619e-02, -1.03513941e-01,  3.69147017e-07,\n",
            "         3.94834615e-02,  8.68027925e-01, -6.34144817e-05,\n",
            "        -9.79027823e-02, -1.19269046e-03, -3.91512923e-03,\n",
            "        -1.77814835e-03,  2.47340932e-01,  1.73596054e-01,\n",
            "         6.51137173e-01,  5.97703271e-02,  8.16815197e-01,\n",
            "         9.87716556e-01,  8.99296701e-01, -4.28885967e-02,\n",
            "         7.00868785e-01,  4.15188028e-04,  2.82144416e-02,\n",
            "        -1.24954497e-02, -9.99332011e-01,  1.76097149e-06,\n",
            "        -4.21002358e-01,  1.37572382e-02, -1.18930254e-03,\n",
            "         1.86199006e-02,  2.04442822e-05,  4.96363100e-06,\n",
            "         4.63702887e-01,  3.93391261e-03,  8.00432861e-01,\n",
            "        -7.29511857e-01,  7.64876723e-01,  1.21880854e-04,\n",
            "         2.39780601e-02,  9.99956727e-01, -1.13812564e-02,\n",
            "        -6.34166226e-03,  2.38404784e-04,  5.17390945e-05,\n",
            "        -2.41481680e-02, -2.11248714e-02, -4.96332765e-01,\n",
            "        -1.90897748e-01,  1.05912261e-01,  2.43588322e-04,\n",
            "        -3.57037614e-04,  1.87351950e-04, -7.03497052e-01,\n",
            "         3.48539208e-03,  3.13207484e-03, -7.85957336e-01,\n",
            "         2.56699286e-02, -1.13712088e-06,  2.16519386e-02,\n",
            "        -1.04488350e-01, -7.70081300e-04, -5.80749154e-01,\n",
            "         1.79721981e-01, -4.36418441e-06, -4.24488717e-05,\n",
            "         7.58461416e-01,  1.21744885e-03,  3.02381790e-03,\n",
            "        -9.71495390e-01, -2.52026482e-04, -2.05917540e-03,\n",
            "         7.50396566e-06,  6.09969854e-01,  2.82867277e-05,\n",
            "         7.15797246e-01,  8.95506978e-01,  5.43797569e-06,\n",
            "         9.92160320e-01,  8.18778515e-01, -6.70410469e-02,\n",
            "         8.53962302e-02,  1.97310284e-01,  3.77434306e-02,\n",
            "        -1.29801729e-05,  7.75701031e-02, -7.35607088e-01,\n",
            "        -4.04145339e-06, -2.02370604e-04,  4.52220172e-01,\n",
            "        -3.48468614e-03,  2.66630054e-02,  6.39347854e-05,\n",
            "         2.73266028e-06, -6.68591820e-05,  1.69711821e-02,\n",
            "         3.14595878e-01, -8.10162961e-01, -1.14957010e-02,\n",
            "        -2.05520630e-01,  8.22876394e-01,  6.75682008e-01,\n",
            "         1.43358042e-03, -2.19117835e-01, -4.95706916e-01,\n",
            "        -3.54167111e-02,  2.86016881e-01,  8.72052187e-05,\n",
            "         4.74927545e-01,  4.81981784e-01, -1.06666736e-01,\n",
            "         1.59936064e-08, -1.17541291e-03, -9.34386909e-01,\n",
            "         2.41439808e-02,  1.33470837e-06,  9.92515683e-01,\n",
            "         1.95467146e-03,  9.02396202e-01, -6.04537353e-02,\n",
            "        -6.33378149e-05, -1.93132367e-02, -3.87721200e-04,\n",
            "         9.94782984e-01,  7.20302463e-02, -3.92641174e-03,\n",
            "        -8.76019478e-01,  4.70201254e-01,  1.91639434e-03,\n",
            "         8.80806148e-01,  6.83612525e-02,  3.72165628e-02,\n",
            "        -4.31498826e-01,  8.97792578e-02, -1.38258547e-01,\n",
            "         9.62901235e-01, -6.12170875e-01, -8.56662973e-06,\n",
            "        -2.38319990e-05,  5.51812202e-02,  1.91829652e-02,\n",
            "         8.78018439e-02,  7.79697418e-01, -4.03104685e-02,\n",
            "         1.56884908e-03, -8.59335614e-07,  5.89497387e-02,\n",
            "         3.26241702e-01,  9.84090194e-03, -1.37508325e-02,\n",
            "        -3.29327434e-01, -6.26088798e-01,  4.59674606e-03,\n",
            "        -7.72216618e-01, -2.19570684e-05, -6.74117939e-04,\n",
            "         2.63533831e-01, -7.50222227e-07,  4.49640676e-03,\n",
            "         7.49937631e-03, -6.93863332e-02,  1.14799971e-02,\n",
            "        -4.41160938e-03,  4.78005052e-01,  4.01861556e-02,\n",
            "        -1.80720654e-05, -4.16733315e-08,  1.36273205e-02,\n",
            "        -9.52988017e-08,  8.28035414e-01, -9.07477371e-10,\n",
            "        -2.90596038e-02,  3.04569956e-04,  6.97875917e-01,\n",
            "        -5.52848796e-05,  1.59684300e-01, -3.89228135e-01,\n",
            "         9.97997284e-01, -5.02536774e-01,  3.41517705e-04,\n",
            "         2.09848372e-06, -2.65608605e-06,  7.67316160e-05,\n",
            "         4.58555281e-01,  8.41577709e-01, -9.38862503e-01,\n",
            "         1.69730801e-02,  8.42936873e-01,  2.52964616e-01,\n",
            "         2.95131896e-02,  2.16091331e-02,  3.82066413e-04,\n",
            "        -1.14394404e-01, -2.76823968e-01, -7.08142528e-04,\n",
            "         1.06350362e-01,  1.77196920e-01, -1.06750894e-03,\n",
            "         3.65137937e-04, -9.52392697e-01,  7.68812478e-01,\n",
            "        -4.63548124e-01,  9.83999014e-01, -3.58920544e-04,\n",
            "        -7.02488124e-01,  3.81652378e-02, -5.39802253e-01,\n",
            "        -1.77653879e-01, -8.39430664e-04,  4.89896443e-03,\n",
            "         9.88429010e-01, -1.36078256e-07, -1.70129873e-02,\n",
            "        -3.64903314e-03, -2.28186705e-04,  5.32297464e-03,\n",
            "        -1.79146219e-03,  6.59917653e-01,  1.17219705e-02,\n",
            "         4.86040342e-04,  3.50476801e-01, -9.77153242e-01,\n",
            "        -1.53272788e-06]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.72971439e-01,  2.96502542e+00,  1.21392393e+00,\n",
            "        -2.27759576e+00,  5.50313234e-01, -3.32916284e+00,\n",
            "        -4.59425497e+00, -7.72357464e+00,  1.04314709e+00,\n",
            "         4.27895737e+00,  1.36303119e-04,  5.97443199e+00,\n",
            "         1.04871285e+00,  2.69130059e-02, -6.95928574e+00,\n",
            "        -2.81257343e+00, -3.70755577e+00, -4.60151434e+00,\n",
            "        -1.83512020e+00,  7.70871818e-01, -4.38436687e-01,\n",
            "        -8.27152061e+00,  3.44453120e+00, -8.50606251e+00,\n",
            "        -6.82637644e+00, -3.73770738e+00, -1.54048300e+00,\n",
            "         1.98369801e+00,  1.34378040e+00, -7.14010186e-03,\n",
            "        -4.87249470e+00,  7.80510998e+00,  2.93328124e-03,\n",
            "        -1.05492818e+00, -1.52880885e-02, -8.02217388e+00,\n",
            "        -1.94505179e+00, -5.04601765e+00,  1.66999769e+00,\n",
            "         2.98557472e+00,  1.54977703e+00, -2.71520704e-01,\n",
            "        -1.17556155e-01, -8.06489754e+00, -4.30417154e-03,\n",
            "        -1.24552369e+00,  2.54062623e-01,  1.75413415e-01,\n",
            "         8.22236776e-01,  2.83922029e+00,  1.14901912e+00,\n",
            "         2.78415489e+00,  1.56490755e+00, -1.34365809e+00,\n",
            "         8.78360569e-01,  3.23796344e+00,  3.06482334e-02,\n",
            "        -8.02240372e+00, -7.64114428e+00,  8.61304379e+00,\n",
            "        -5.29500484e-01,  5.75336361e+00, -1.33264659e-03,\n",
            "         1.58440948e-01,  8.07592392e+00,  7.71407413e+00,\n",
            "         6.22860909e-01,  4.12530918e-03,  1.10143912e+00,\n",
            "        -9.27713454e-01,  1.00797808e+00,  9.99050260e-01,\n",
            "         7.50358164e-01,  5.37338781e+00, -1.01176560e+00,\n",
            "        -6.37353491e-03,  1.22296205e-03,  8.38321000e-02,\n",
            "        -2.44454257e-02, -5.68548298e+00, -5.62781870e-01,\n",
            "        -1.94213435e-01,  1.08309284e-01,  2.72178054e-01,\n",
            "        -3.57259909e-04,  7.66228855e-01, -1.28213692e+00,\n",
            "         9.57841519e-03,  3.05685711e+00, -1.06078696e+00,\n",
            "         2.76155174e-02, -7.14467466e-01,  3.97926664e+00,\n",
            "        -1.13810435e-01, -8.04878616e+00, -1.00863779e+00,\n",
            "         1.81695580e-01, -1.26149422e-02, -8.16092268e-03,\n",
            "         1.38205564e+00,  4.96202803e+00,  2.06554066e-02,\n",
            "        -2.12092876e+00, -4.72955847e+00, -5.94514036e+00,\n",
            "         1.04568124e+00,  7.83069670e-01,  1.20280810e-01,\n",
            "         9.84325647e-01,  1.45029390e+00,  7.47363811e-06,\n",
            "         5.70906878e+00,  1.27531791e+00, -6.71424046e-02,\n",
            "         9.02009979e-02,  1.99964851e-01,  4.49958563e+00,\n",
            "        -3.12119389e+00,  5.86603880e+00, -9.41379964e-01,\n",
            "        -6.81983566e+00, -2.02422758e-04,  5.00692070e-01,\n",
            "        -7.52653837e-01,  1.73963532e-01,  1.64463747e+00,\n",
            "         3.12917900e+00, -1.41298413e+00,  5.88398933e+00,\n",
            "         7.83208609e-01, -1.14051414e+00, -2.48323774e+00,\n",
            "        -2.15789646e-01,  1.16714704e+00,  1.16535807e+00,\n",
            "         1.49057014e-03, -2.45309472e-01, -7.27405369e-01,\n",
            "        -6.43563843e+00,  3.45907301e-01,  8.72447490e-05,\n",
            "         5.41451454e-01,  5.25682628e-01, -1.07480131e-01,\n",
            "         2.44306661e-02, -2.34816360e+00, -1.69432998e+00,\n",
            "         2.09636736e+00,  2.44484112e-01,  2.97712946e+00,\n",
            "         6.69523478e+00,  1.48626125e+00, -2.06648350e+00,\n",
            "        -8.01781845e+00, -8.75317812e-01, -3.70478421e-01,\n",
            "         8.26678848e+00,  7.51675963e-02, -9.57984757e-03,\n",
            "        -1.35900295e+00,  8.61567974e-01,  7.89056826e+00,\n",
            "         1.37969005e+00,  8.69650170e-02,  3.72760408e-02,\n",
            "        -1.51701140e+00,  2.01868773e-01, -1.41731471e-01,\n",
            "         2.41863489e+00, -2.06701064e+00, -3.34629130e+00,\n",
            "        -1.90782559e+00,  5.93539849e-02,  7.53870010e+00,\n",
            "         8.84666890e-02,  1.24992895e+00, -4.03758287e-02,\n",
            "         3.50346112e+00, -8.59833108e-07,  1.73776940e-01,\n",
            "         3.39254200e-01,  2.45410943e+00, -7.56200743e+00,\n",
            "        -3.44856650e-01, -7.35454679e-01,  4.61766263e-03,\n",
            "        -1.02642071e+00, -9.27729130e-01, -5.05830622e+00,\n",
            "         2.51712298e+00, -1.76580930e+00,  4.37732840e+00,\n",
            "         1.06104650e-02, -7.06863999e-02,  6.87483501e+00,\n",
            "        -3.30948710e-01,  5.20638347e-01,  6.89505756e-01,\n",
            "        -5.32054901e+00, -1.82970936e-07,  3.46173692e+00,\n",
            "        -3.65661140e-06,  1.18188608e+00, -9.54697013e-01,\n",
            "        -8.87602985e-01,  8.27551842e+00,  4.03869677e+00,\n",
            "        -4.48407650e+00,  6.82893181e+00, -4.22320098e-01,\n",
            "         6.42017365e+00, -5.52696466e-01,  6.67764200e-03,\n",
            "         3.18345148e-04, -1.58244991e+00,  3.49381864e-01,\n",
            "         5.27075052e-01,  1.22909975e+00, -1.73072672e+00,\n",
            "         4.52674627e-02,  1.23614514e+00,  2.60086268e-01,\n",
            "         6.59390163e+00,  2.16667689e-02,  8.02634048e+00,\n",
            "        -6.17964566e-01, -4.59857702e+00, -4.77021247e-01,\n",
            "         2.38026047e+00,  2.17874259e-01, -1.14993062e-02,\n",
            "         1.92833138e+00, -1.86433375e+00,  1.03053761e+00,\n",
            "        -5.08190870e-01,  2.63583565e+00, -4.42626619e+00,\n",
            "        -1.28891981e+00,  7.23689854e-01, -6.05481863e-01,\n",
            "        -1.79559484e-01, -1.34521129e-03,  4.29554224e+00,\n",
            "         2.57330036e+00, -1.99888492e+00, -1.84718311e+00,\n",
            "        -1.67722583e-01, -3.82995844e+00,  5.99399090e+00,\n",
            "        -1.83083396e-03,  7.92668521e-01,  3.03531909e+00,\n",
            "         4.18467879e-01,  3.66021991e-01, -2.31459641e+00,\n",
            "        -5.19543457e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.46771835e-02,  3.70746702e-02,  4.16899800e-01,\n",
            "        -9.75258291e-01,  7.98195720e-01, -9.96189535e-01,\n",
            "        -9.70535159e-01, -8.59661307e-03,  3.89817566e-01,\n",
            "         6.16690479e-02,  1.51064829e-03,  5.45734016e-04,\n",
            "         9.16966051e-02, -4.94701462e-03, -3.22362967e-02,\n",
            "        -2.82239914e-01, -8.89430940e-01, -4.41712812e-02,\n",
            "        -4.03627045e-02,  6.50469899e-01, -2.82505542e-01,\n",
            "        -8.47551599e-02,  9.94040430e-01, -1.90241507e-03,\n",
            "        -3.25206602e-05, -9.98941064e-01, -4.97232378e-01,\n",
            "         5.39161498e-03,  7.12343395e-01, -1.87991152e-03,\n",
            "        -9.95534658e-01,  6.32709980e-01,  2.77546465e-01,\n",
            "        -5.41161261e-02, -2.00647414e-02, -8.24569404e-01,\n",
            "        -8.86782467e-01, -6.93423390e-01,  3.83208180e-06,\n",
            "         5.46374824e-03,  9.18306112e-01, -2.28852421e-01,\n",
            "        -1.15148979e-03, -3.72483555e-05, -2.53703236e-03,\n",
            "        -6.38190508e-01,  7.49343932e-01,  7.50355184e-01,\n",
            "         4.51272100e-01,  2.75131706e-02,  6.99055731e-01,\n",
            "         4.98615324e-01,  8.02452117e-02, -3.81685525e-01,\n",
            "         7.07008123e-01,  2.05660332e-02,  1.09010682e-01,\n",
            "        -1.63015444e-02, -9.99931037e-01,  2.26218820e-01,\n",
            "        -4.97857243e-01,  3.24472249e-01, -2.53769100e-01,\n",
            "         1.76401969e-04,  2.63008533e-05,  4.13109094e-01,\n",
            "        -3.35602045e-01,  2.72374094e-01,  1.72999457e-01,\n",
            "        -7.24002063e-01,  3.88202339e-01,  3.19401058e-03,\n",
            "        -2.05468878e-01,  9.60473597e-01, -7.53219485e-01,\n",
            "        -1.01219825e-02,  1.91345473e-03, -3.41930985e-03,\n",
            "        -2.41806149e-01, -8.18634510e-01, -5.09634256e-01,\n",
            "        -1.33573888e-02,  1.73783582e-02,  2.36949891e-01,\n",
            "        -1.47044353e-04,  2.02051364e-02, -4.12090123e-03,\n",
            "         1.66638765e-05,  3.24875176e-01, -9.42795932e-01,\n",
            "         1.81459659e-03, -6.13500535e-01,  9.98174846e-01,\n",
            "        -7.19820410e-02, -3.92368473e-02, -1.35417824e-04,\n",
            "         1.05774612e-04, -1.30118178e-02, -2.51682907e-01,\n",
            "         8.62323701e-01,  9.97709632e-01, -2.77270675e-01,\n",
            "        -5.87168671e-02, -1.52924727e-03, -2.17000972e-02,\n",
            "         2.42592379e-01,  9.01738094e-05,  3.49224448e-01,\n",
            "         9.30165231e-01,  9.68753397e-01,  2.95349637e-05,\n",
            "         9.31280792e-01,  2.69240141e-02, -7.57785678e-01,\n",
            "         1.32223237e-02,  1.94149211e-01,  1.28867492e-01,\n",
            "        -4.72553521e-02,  5.41820303e-02, -7.15847779e-03,\n",
            "        -9.48313415e-01, -1.69822991e-01,  7.35093594e-01,\n",
            "        -1.82492748e-01,  1.24802478e-04,  1.13870678e-02,\n",
            "         6.92968190e-01, -9.87089879e-05,  2.18276764e-05,\n",
            "         5.74686229e-01, -2.92627083e-04, -8.98643255e-01,\n",
            "        -2.04875141e-01,  8.44967127e-01,  3.81391495e-01,\n",
            "         2.05505118e-02, -1.60990772e-03, -1.39076292e-07,\n",
            "        -9.98060286e-01,  5.94960392e-01,  1.44655360e-02,\n",
            "         2.49000210e-02,  6.91108048e-01, -1.22885508e-02,\n",
            "         9.36395861e-03, -2.86029863e-05, -9.82577860e-01,\n",
            "         7.99924076e-01,  2.98622817e-01,  9.94318008e-01,\n",
            "         5.55301551e-03,  6.67721212e-01, -7.46417046e-01,\n",
            "        -9.94558871e-01, -5.76941550e-01, -5.35150290e-01,\n",
            "         4.03124699e-03,  1.16012394e-01, -4.08759806e-04,\n",
            "        -2.80156295e-04,  5.94206214e-01,  1.25958628e-04,\n",
            "         8.98319066e-01,  7.85289556e-02,  1.55997172e-01,\n",
            "        -6.04658537e-02,  1.85740890e-03, -6.02053642e-01,\n",
            "         8.92243624e-01, -3.52914387e-04, -8.79876375e-01,\n",
            "        -9.52532589e-01,  1.82645439e-04,  8.29951896e-05,\n",
            "         4.83370483e-01,  9.18706000e-01, -2.66169131e-01,\n",
            "         9.01783034e-02, -3.14039993e-03,  1.09567143e-01,\n",
            "         1.85478391e-04,  9.75636423e-01, -8.78557146e-01,\n",
            "        -7.29548782e-02, -7.19237149e-01,  6.55966103e-02,\n",
            "        -7.74242401e-01, -2.08563749e-02, -2.00926512e-03,\n",
            "         9.13418531e-01, -1.97679666e-03,  1.56389051e-05,\n",
            "         1.94594592e-01, -1.46882132e-01,  1.33242607e-01,\n",
            "         5.01155257e-01,  7.49113560e-01,  5.96059144e-01,\n",
            "        -1.59881911e-05, -1.83184426e-02,  5.12409747e-01,\n",
            "        -1.58560069e-05,  2.40164459e-01,  4.49287742e-02,\n",
            "        -1.13304287e-01,  9.99991000e-01,  4.24621284e-01,\n",
            "        -4.37531888e-01,  1.47849634e-01, -1.19262286e-01,\n",
            "         4.24374491e-02, -5.02490342e-01,  3.74696986e-03,\n",
            "         2.95716221e-03, -6.36160374e-01,  2.91816483e-04,\n",
            "         4.71441478e-01,  9.59267855e-01, -6.38843776e-05,\n",
            "         4.50154915e-02,  2.23852636e-04,  5.67987142e-03,\n",
            "         2.86669344e-01,  1.26756595e-05,  5.11857979e-05,\n",
            "        -1.85336743e-03, -9.90445435e-01, -4.01877165e-01,\n",
            "         6.76368475e-01, -5.80665052e-01, -9.84185026e-04,\n",
            "         5.05715966e-01, -9.51582253e-01,  6.21613920e-01,\n",
            "        -4.46922839e-01,  4.10849750e-01, -9.99555230e-01,\n",
            "        -2.48127417e-05,  1.06493793e-01, -6.62757933e-01,\n",
            "         5.18393591e-02, -5.14416635e-01,  2.55484390e-03,\n",
            "         9.62160170e-01, -9.57788110e-01, -1.21653929e-01,\n",
            "        -4.65082849e-04, -4.43378687e-01,  7.50288963e-01,\n",
            "        -7.82100396e-05,  1.58297434e-03,  9.67023730e-01,\n",
            "         1.03844400e-03,  3.88247341e-01, -1.49292812e-01,\n",
            "        -1.63500209e-03]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.4208546e+00,  3.4053140e+00,  4.4395965e-01, -2.2803209e+00,\n",
            "         1.2558335e+00, -3.2994475e+00, -4.8611927e+00, -8.6971540e+00,\n",
            "         7.4288273e-01,  5.1362543e+00,  1.6365375e-03,  6.9642992e+00,\n",
            "         1.9214671e+00, -9.9020034e-01, -7.9462624e+00, -3.7836432e+00,\n",
            "        -4.6124816e+00, -4.3099608e+00, -2.7551913e+00,  7.7612132e-01,\n",
            "        -4.3851390e-01, -9.2677851e+00,  2.9079142e+00, -9.1392298e+00,\n",
            "        -7.7389126e+00, -3.7717891e+00, -5.4633880e-01,  2.9824839e+00,\n",
            "         2.3316131e+00, -7.8577924e-01, -4.3461332e+00,  7.8998857e+00,\n",
            "         6.0970676e-01, -2.0363846e+00, -5.6391537e-02, -8.2379856e+00,\n",
            "        -2.9410932e+00, -5.0478458e+00,  2.6678200e+00,  2.9807684e+00,\n",
            "         1.5849814e+00, -2.4529137e-01, -1.3569553e-01, -9.0439186e+00,\n",
            "        -9.8796242e-01, -7.6511621e-01,  1.2538776e+00,  1.1577415e+00,\n",
            "         1.8181392e+00,  3.6250536e+00,  1.2010043e+00,  2.4962547e+00,\n",
            "         2.5568948e+00, -4.0505198e-01,  8.8229406e-01,  4.2304721e+00,\n",
            "         3.0690163e-01, -8.9451370e+00, -6.6466613e+00,  9.2570353e+00,\n",
            "        -5.4648721e-01,  5.7438321e+00, -9.8654342e-01,  1.1576612e+00,\n",
            "         8.5865993e+00,  8.6090107e+00, -3.4916738e-01,  1.0016133e+00,\n",
            "         2.0405936e+00, -9.3044519e-01,  1.0389472e+00,  1.8986503e+00,\n",
            "        -2.0843819e-01,  6.1173577e+00, -1.0120521e+00, -1.0127560e-02,\n",
            "         7.8599799e-01, -7.9213285e-01, -4.1587403e-01, -6.1559253e+00,\n",
            "        -5.6282312e-01, -1.1938539e+00,  1.1031331e+00,  2.7217487e-01,\n",
            "        -9.7760862e-01,  1.7604296e+00, -1.8906380e+00,  1.0054312e+00,\n",
            "         2.9558587e+00, -1.7626364e+00,  9.9810374e-01, -7.1451789e-01,\n",
            "         3.6932390e+00, -6.0238075e-01, -8.7002869e+00, -1.9957521e+00,\n",
            "         1.1464350e+00, -8.7185055e-01, -1.0060288e+00,  1.3593991e+00,\n",
            "         4.1271625e+00, -3.3116394e-01, -1.9704837e+00, -5.6994243e+00,\n",
            "        -6.8775578e+00,  1.2528706e+00,  1.7648488e+00,  7.4094898e-01,\n",
            "         1.9259982e+00,  2.1226156e+00,  4.1527903e-01,  4.7288437e+00,\n",
            "         1.3051044e+00, -9.9143082e-01,  1.3084908e-01,  2.0068929e-01,\n",
            "         3.5748069e+00, -3.9051688e+00,  5.8733582e+00, -9.4854075e-01,\n",
            "        -7.0089874e+00, -1.9552661e-01,  1.4282583e+00, -8.5252535e-01,\n",
            "         2.0016228e-01,  2.6355765e+00,  3.4348798e+00, -1.8396871e+00,\n",
            "         6.5209985e+00,  7.9747337e-01, -2.1363246e+00, -1.4654223e+00,\n",
            "        -2.1613105e-01,  1.2671597e+00,  2.0371509e+00,  3.2067545e-02,\n",
            "        -2.5276113e-01, -1.7225870e+00, -7.3303833e+00,  6.9283158e-01,\n",
            "         1.4501248e-02,  1.5334091e+00,  1.5204320e+00, -1.1623003e-01,\n",
            "         3.5696507e-02, -3.1991258e+00, -2.3991711e+00,  1.0984203e+00,\n",
            "         1.2392117e+00,  2.9756978e+00,  7.0597076e+00,  1.8298998e+00,\n",
            "        -1.0927005e+00, -8.0115767e+00, -1.8558946e+00, -1.3695883e+00,\n",
            "         9.2384348e+00,  1.1659121e-01, -6.3676488e-01, -2.3439074e+00,\n",
            "         7.9133630e-01,  7.9726605e+00,  1.4719809e+00,  4.4171295e-01,\n",
            "         2.8336489e-01, -1.5164583e+00,  1.0527316e+00, -6.9660872e-01,\n",
            "         1.4437500e+00, -2.9241726e+00, -3.3474667e+00, -1.9000058e+00,\n",
            "         1.6316262e-01,  8.4778795e+00,  1.0199353e+00,  2.1835961e+00,\n",
            "        -1.0345098e+00,  4.4075489e+00, -9.9859315e-01,  1.1608852e+00,\n",
            "         3.4491360e-01,  2.4541874e+00, -8.4315405e+00, -1.3422832e+00,\n",
            "        -1.7236166e+00,  2.9811186e-01, -1.0311207e+00, -8.5349458e-01,\n",
            "        -6.0537896e+00,  1.5478433e+00, -2.6957963e+00,  5.1799655e+00,\n",
            "         1.9711381e-01, -1.4797571e-01,  6.4739804e+00,  5.5468154e-01,\n",
            "         9.7493476e-01,  6.8808419e-01, -6.2084851e+00, -2.6123083e-01,\n",
            "         2.4982266e+00, -9.9981141e-01,  2.1712201e+00,  4.4959217e-02,\n",
            "        -1.8432373e+00,  6.5162969e+00,  4.5191736e+00, -4.5320702e+00,\n",
            "         6.9903402e+00, -1.4220662e+00,  6.3443298e+00, -5.5279458e-01,\n",
            "         6.7114173e-03,  9.8800659e-01, -1.9101869e+00,  1.3472006e+00,\n",
            "         5.2682382e-01,  2.0931287e+00, -2.6934912e+00,  4.5046765e-02,\n",
            "         2.2343593e+00,  1.2546316e+00,  6.7260818e+00,  1.0116411e+00,\n",
            "         4.7652478e+00, -7.6879275e-01, -4.5642004e+00, -4.3821630e-01,\n",
            "         2.7906055e+00, -6.6352141e-01, -1.0012308e+00,  2.9279499e+00,\n",
            "        -1.8484162e+00,  1.0555074e+00, -4.8090756e-01,  3.6348579e+00,\n",
            "        -4.3223023e+00, -2.2339075e+00,  1.3428240e+00, -8.0086833e-01,\n",
            "         7.8818297e-01, -8.6077887e-01,  5.2056160e+00,  3.5724828e+00,\n",
            "        -2.0030143e+00, -6.5027553e-01, -1.1034070e+00, -3.4567838e+00,\n",
            "         9.7398204e-01, -1.0001097e+00,  5.2761352e-01,  2.0597429e+00,\n",
            "         1.3747239e+00,  4.1026604e-01, -2.1764910e+00, -6.1913772e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 6.70445161e-06,  1.14939382e-06, -5.01660526e-01,\n",
            "        -1.03841699e-03,  8.69012237e-01, -6.09801590e-01,\n",
            "        -9.90862429e-01, -2.87130320e-06,  2.24091232e-01,\n",
            "         5.23462445e-02,  1.60362036e-03,  1.15045717e-04,\n",
            "         1.30461350e-01, -6.02761400e-04, -3.23891938e-02,\n",
            "        -9.14405007e-03, -9.65906838e-06, -3.13182861e-01,\n",
            "        -2.02214607e-04,  6.50736451e-01, -1.55362031e-05,\n",
            "        -2.77155079e-02,  9.94014084e-01, -9.50786925e-05,\n",
            "        -7.97059874e-06,  7.48228729e-01, -4.69023287e-01,\n",
            "         1.29898767e-08,  7.71795385e-05, -8.81829934e-08,\n",
            "        -9.97321427e-01,  9.44913089e-01,  1.38478455e-04,\n",
            "        -9.95386839e-01, -1.87797414e-05, -7.05168903e-01,\n",
            "        -4.16210502e-01, -3.03220283e-02,  4.34617905e-05,\n",
            "         2.73923879e-03,  4.75439012e-01,  6.34212017e-01,\n",
            "        -1.05510560e-06, -7.63863623e-01, -2.28842744e-03,\n",
            "         1.95717558e-01,  1.49594402e-04,  2.96484716e-02,\n",
            "         9.81805265e-01,  1.06837817e-01,  2.01666355e-01,\n",
            "         9.68387127e-01,  3.07689799e-04,  5.30853689e-01,\n",
            "         1.53613180e-01,  8.39455128e-02,  4.06243473e-01,\n",
            "        -6.51099486e-04, -9.99983251e-01,  1.66390417e-03,\n",
            "        -6.37335837e-01,  9.87968683e-01, -3.42551066e-04,\n",
            "         5.05771197e-04,  2.50399607e-04,  8.06265548e-02,\n",
            "        -3.70186925e-01,  2.82604324e-05,  4.11642686e-04,\n",
            "        -2.22096257e-02,  1.69060787e-03,  1.78328560e-06,\n",
            "        -8.36067557e-01,  4.24851120e-01, -7.66561389e-01,\n",
            "        -2.44286563e-02,  1.91143423e-03, -3.63243520e-01,\n",
            "        -7.38260090e-01, -4.55758738e-04, -5.01785159e-01,\n",
            "        -9.45893316e-06,  9.18273091e-01,  2.58526534e-01,\n",
            "        -7.30847096e-05,  8.75098976e-06, -2.27049986e-06,\n",
            "         1.69751456e-05,  8.04527164e-01, -9.88708317e-01,\n",
            "         2.24197609e-03, -6.13269329e-01,  9.89519119e-01,\n",
            "        -2.61186250e-02, -5.79865184e-03, -2.17055390e-06,\n",
            "         8.95520672e-03, -3.37135345e-02, -5.49285432e-05,\n",
            "         2.72555951e-07,  9.95833397e-01, -6.38441861e-01,\n",
            "        -5.07669330e-01, -9.02855575e-01, -1.67437140e-02,\n",
            "         6.58674091e-02,  1.02673343e-03,  9.61354747e-02,\n",
            "         9.59630728e-01,  9.58220601e-01,  6.66385969e-09,\n",
            "         9.98721957e-01,  5.63885587e-05, -9.46418643e-01,\n",
            "         1.26525518e-02,  1.98262215e-01,  9.89688039e-01,\n",
            "        -3.33409846e-01,  1.09865561e-01, -4.78143208e-02,\n",
            "        -2.36336857e-01, -1.30294129e-05,  1.60927922e-01,\n",
            "        -2.07998801e-05,  2.25837266e-05,  2.32603052e-05,\n",
            "         3.18324915e-03, -5.23172855e-01,  9.95075583e-01,\n",
            "         4.95867084e-07, -1.92760254e-07, -5.87586999e-01,\n",
            "        -2.22130731e-01,  8.44565272e-01,  9.93564010e-01,\n",
            "         1.02264946e-03, -2.40125717e-03, -2.58384655e-12,\n",
            "        -9.99994814e-01,  4.77214158e-03,  6.28495887e-02,\n",
            "         2.38816650e-03,  7.80574000e-03, -3.63703316e-06,\n",
            "         9.78054106e-03, -3.84272588e-03, -9.65745389e-01,\n",
            "         1.18810259e-01,  3.17533463e-02,  9.91876721e-01,\n",
            "         3.98002507e-04,  2.93467939e-02, -1.35371894e-01,\n",
            "        -1.03825526e-02, -5.91204204e-02, -1.77325546e-05,\n",
            "         6.56393290e-01,  3.64745796e-01, -8.85874982e-08,\n",
            "        -8.89717849e-05, -1.47274226e-01,  3.94354203e-07,\n",
            "         8.76969337e-01,  9.93501171e-02,  2.04309132e-02,\n",
            "        -6.06038272e-01,  1.76432434e-06, -1.73581645e-01,\n",
            "         4.46987897e-01, -3.37903053e-02, -2.41658106e-01,\n",
            "        -9.53319728e-01,  2.64426140e-04,  1.05729487e-05,\n",
            "         7.32044969e-03,  9.53073442e-01, -1.32926070e-04,\n",
            "         5.33327818e-01, -2.06272257e-03,  5.81710398e-01,\n",
            "         2.01964774e-08,  1.83292832e-02, -1.59501005e-02,\n",
            "        -6.21136785e-01, -6.01090956e-03,  5.53541322e-05,\n",
            "        -7.73214459e-01, -2.58754244e-05, -2.77496292e-03,\n",
            "        -6.99997425e-01, -9.63396549e-01,  7.25442111e-01,\n",
            "         7.31440959e-03, -1.46982044e-01,  9.80672419e-01,\n",
            "         9.14354265e-01,  7.52864540e-01,  5.95780849e-01,\n",
            "        -7.41334588e-07, -4.46881413e-01,  7.71503210e-01,\n",
            "        -8.05804666e-05,  5.71505308e-01,  7.24847913e-01,\n",
            "        -8.40344205e-02,  9.99557078e-01,  6.34768605e-01,\n",
            "        -9.70048189e-01,  8.06765974e-01, -1.54269096e-02,\n",
            "         2.56768689e-02, -6.65728673e-02,  6.60299577e-07,\n",
            "         1.67523623e-07, -4.31623198e-02,  5.35954118e-01,\n",
            "         4.76008266e-01,  9.14999604e-01, -1.50360065e-02,\n",
            "         4.48299423e-02,  1.13703236e-01,  7.66518224e-06,\n",
            "         1.89905961e-07,  3.21261405e-06,  1.61633488e-05,\n",
            "        -8.55692997e-05, -9.74326730e-01, -4.09356207e-01,\n",
            "         9.88699138e-01, -9.29392815e-01, -6.29462302e-04,\n",
            "         9.94303543e-03, -7.95262456e-01,  1.29328342e-03,\n",
            "        -4.47505534e-01,  5.97163737e-01, -4.26366641e-05,\n",
            "        -2.63962967e-08,  4.21729565e-01, -1.61807507e-01,\n",
            "         3.27783127e-05, -5.20718545e-02,  2.95829494e-08,\n",
            "         3.63726586e-01, -5.85440040e-01, -5.51492691e-01,\n",
            "        -7.70491795e-08, -7.63649106e-01,  4.82925475e-01,\n",
            "        -4.60544936e-09, -1.29454672e-01,  7.91621804e-01,\n",
            "         1.82316624e-04,  3.36879655e-03, -6.50139873e-06,\n",
            "        -1.29374923e-04]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.4078140e+00,  4.3893118e+00, -5.5152279e-01, -2.2825005e+00,\n",
            "         1.4361650e+00, -3.3063343e+00, -5.8526077e+00, -9.6828318e+00,\n",
            "         3.1922227e-01,  6.1327772e+00,  2.4317456e-03,  7.9621911e+00,\n",
            "         2.8829477e+00, -1.9901814e+00, -8.9208059e+00, -4.7605829e+00,\n",
            "        -5.5846672e+00, -3.3727899e+00, -3.7551789e+00,  7.7659112e-01,\n",
            "        -4.3854046e-01, -1.0267304e+01,  2.9043293e+00, -1.0095628e+01,\n",
            "        -8.7338295e+00,  9.6892118e-01, -5.0881994e-01,  3.4843171e+00,\n",
            "         3.3295004e+00, -1.7810893e+00, -3.3597872e+00,  8.8772860e+00,\n",
            "         1.5689840e+00, -3.0351515e+00, -2.0755962e-02, -8.2401018e+00,\n",
            "        -3.9380941e+00, -5.0559711e+00,  3.6666424e+00,  2.8154764e+00,\n",
            "         1.8674021e+00,  7.4862188e-01, -9.0318853e-01, -1.0036642e+01,\n",
            "        -1.9852524e+00,  2.0761114e-01,  2.2515168e+00,  2.1431220e+00,\n",
            "         2.7998643e+00,  4.5562201e+00,  1.2029462e+00,  2.0829844e+00,\n",
            "         3.5519984e+00,  5.9133774e-01,  1.8785354e+00,  5.2274561e+00,\n",
            "         1.2758460e+00, -9.9255037e+00, -5.8484912e+00,  1.0206984e+01,\n",
            "        -7.5368160e-01,  4.8771114e+00, -1.9852436e+00,  2.1574309e+00,\n",
            "         8.5419359e+00,  9.5896654e+00, -3.8864791e-01,  2.0012512e+00,\n",
            "         3.0391829e+00, -1.9269745e+00,  2.0354307e+00,  2.8637264e+00,\n",
            "        -1.2080443e+00,  5.1304812e+00, -1.0119385e+00, -4.8441734e-02,\n",
            "         1.6439377e+00, -1.7405223e+00, -1.4067891e+00, -7.1387773e+00,\n",
            "        -5.6839913e-01, -2.1938350e+00,  2.1025400e+00,  2.7220032e-01,\n",
            "        -1.9769661e+00,  2.7517815e+00, -2.4404037e+00,  1.9997518e+00,\n",
            "         2.0054941e+00, -2.5896633e+00,  1.9973791e+00, -7.1598828e-01,\n",
            "         2.7212937e+00, -1.2466494e+00, -9.6639309e+00, -2.9919868e+00,\n",
            "         2.0733762e+00, -1.8717690e+00, -1.9991190e+00,  1.3613375e+00,\n",
            "         3.1298134e+00, -7.5554729e-01, -1.2330583e+00, -5.3482842e+00,\n",
            "        -7.8767600e+00,  2.1894491e+00,  2.7559710e+00,  1.7151262e+00,\n",
            "         2.9248393e+00,  3.0415990e+00,  1.4152253e+00,  3.7304795e+00,\n",
            "         1.3365408e+00, -1.9911107e+00,  4.6680287e-01,  2.0159097e-01,\n",
            "         2.6343184e+00, -4.8976164e+00,  6.3437872e+00, -1.0185177e+00,\n",
            "        -7.8783798e+00, -2.3502675e-01,  2.4278705e+00, -1.5094147e+00,\n",
            "         1.0412328e+00,  3.6291502e+00,  4.3559551e+00, -2.8291092e+00,\n",
            "         7.1281328e+00,  1.7016058e+00, -3.1338327e+00, -6.7397398e-01,\n",
            "        -2.2744255e-01,  1.2670023e+00,  3.0361953e+00,  1.2301415e-01,\n",
            "        -1.2426476e+00, -2.7202542e+00, -6.7625027e+00,  1.6812152e+00,\n",
            "         8.8487977e-01,  2.5154951e+00,  2.5077939e+00, -1.0646621e+00,\n",
            "         6.6479468e-01, -4.0859585e+00, -3.2455523e+00,  1.1937548e-01,\n",
            "         2.2389510e+00,  2.9746742e+00,  8.0168486e+00,  2.7738934e+00,\n",
            "        -1.3661838e-01, -8.0098209e+00, -1.8569528e+00, -2.3680837e+00,\n",
            "         1.0225229e+01,  3.8238245e-01, -1.5886475e+00, -2.6856005e+00,\n",
            "        -2.0241207e-01,  8.7177486e+00,  1.4719563e+00,  1.4058011e+00,\n",
            "         1.2452796e+00, -1.5068089e+00,  2.0332358e+00, -1.0270358e+00,\n",
            "         4.8111331e-01, -3.8441179e+00, -4.1365371e+00, -1.8669820e+00,\n",
            "         1.6971087e-01,  9.4389820e+00,  2.0181892e+00,  2.0496297e+00,\n",
            "        -2.0283203e+00,  5.3589602e+00, -1.9959139e+00,  2.1593747e+00,\n",
            "         3.4716815e-01,  3.4537222e+00, -9.3922138e+00, -2.3421354e+00,\n",
            "        -2.6985269e+00,  1.2948760e+00, -1.0311327e+00, -1.7377795e+00,\n",
            "        -7.0537238e+00, -8.6776692e-01, -2.9520469e+00,  5.7587752e+00,\n",
            "         7.3147267e-03, -1.4805539e-01,  5.5084658e+00,  1.5536731e+00,\n",
            "         1.9703780e+00,  6.9094926e-01, -7.2029052e+00, -1.2580628e+00,\n",
            "         1.5132359e+00, -1.9994045e+00,  3.1699872e+00,  9.1830152e-01,\n",
            "        -2.8369508e+00,  4.2075000e+00,  3.5286303e+00, -5.0597854e+00,\n",
            "         7.0088134e+00, -2.4218388e+00,  7.2851062e+00, -1.5275856e+00,\n",
            "         6.7281807e-03,  1.9757196e+00, -1.9136335e+00,  2.3448591e+00,\n",
            "         5.2202296e-01,  3.0849185e+00, -3.6768036e+00,  4.4932161e-02,\n",
            "         3.2337871e+00,  2.2532759e+00,  6.7275248e+00,  1.9990915e+00,\n",
            "         4.8410921e+00, -5.1403117e-01, -3.5606875e+00, -4.3483785e-01,\n",
            "         3.5526760e+00, -1.6629217e+00, -2.0004709e+00,  3.9278567e+00,\n",
            "        -1.0855898e+00,  2.0414081e+00, -4.8161820e-01,  4.6346140e+00,\n",
            "        -4.2644930e-05, -3.2099228e+00,  1.3807184e+00, -9.6576017e-01,\n",
            "         3.1441443e-02, -1.8589953e+00,  6.1957936e+00,  4.5672946e+00,\n",
            "        -1.8708494e+00, -6.3430572e-01, -2.0906200e+00, -1.0049183e+00,\n",
            "         5.3070074e-01, -1.9999288e+00, -5.3707665e-01,  1.0757657e+00,\n",
            "         2.3509676e+00,  4.1941366e-01, -2.2930279e+00, -7.1902323e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.82232817e-02,  9.84531283e-01, -9.12815750e-01,\n",
            "        -9.29026365e-01,  2.88734231e-02, -9.96970832e-01,\n",
            "        -9.99987781e-01, -8.87113810e-03,  2.89173543e-01,\n",
            "         9.99992192e-01,  4.63459566e-02,  2.18567497e-10,\n",
            "         4.71207659e-06, -1.36183289e-05, -3.00943013e-02,\n",
            "        -2.10409351e-02, -9.90617335e-01, -9.85394239e-01,\n",
            "        -1.76567453e-04,  9.44242120e-01, -2.65107095e-01,\n",
            "        -3.77395132e-04,  9.57605660e-01, -1.27297726e-05,\n",
            "        -4.37047333e-01,  1.31960423e-05,  4.13258672e-01,\n",
            "         7.77042715e-07,  1.32442355e-01, -9.22024131e-01,\n",
            "        -9.82384682e-01,  4.62526351e-01,  9.87952709e-01,\n",
            "        -1.29580221e-05, -1.74870864e-02, -1.80795556e-03,\n",
            "        -9.93887544e-01, -9.99968112e-01,  9.99772012e-01,\n",
            "         9.92987037e-01,  3.34053963e-01,  1.69658114e-03,\n",
            "        -7.87404895e-01, -4.38500820e-06, -1.00157067e-05,\n",
            "         5.94070971e-01,  2.90300610e-04,  2.05222532e-04,\n",
            "         6.44605979e-02,  9.16342318e-01,  1.58614526e-03,\n",
            "         9.65092063e-01,  1.46723399e-02,  9.18500185e-01,\n",
            "         7.28905320e-01,  4.90351113e-07,  5.30471823e-07,\n",
            "        -1.86173851e-03,  7.39316404e-01,  1.16915824e-02,\n",
            "        -9.40749168e-01,  9.98580515e-01, -2.19798443e-04,\n",
            "         7.84671720e-05,  9.26609500e-04,  4.52442964e-06,\n",
            "        -5.08960843e-01,  3.98191645e-07,  2.51477659e-01,\n",
            "        -9.59663093e-01,  8.67187628e-05,  7.08905905e-02,\n",
            "        -9.61582899e-01,  9.56362188e-01, -6.06367450e-07,\n",
            "        -4.69752438e-02,  1.09344234e-09, -9.66459572e-01,\n",
            "        -2.60156376e-04, -1.47714090e-05, -4.20811549e-02,\n",
            "        -6.48215950e-01,  3.09292082e-05,  1.39330155e-06,\n",
            "        -4.81346831e-07,  7.28289545e-01, -2.43824601e-01,\n",
            "         5.28996699e-02,  9.01781499e-01,  7.60597110e-01,\n",
            "         9.42699984e-02, -1.06906649e-02,  3.49719524e-01,\n",
            "        -4.57647070e-02, -4.99970727e-02, -1.83141246e-01,\n",
            "         5.33129632e-01, -3.39486403e-04, -2.48629658e-05,\n",
            "         2.58277007e-03,  9.91890728e-01, -8.37378561e-01,\n",
            "        -8.30838561e-01, -9.98951614e-01, -7.85069048e-01,\n",
            "         6.58386946e-01,  9.66038346e-01,  9.91075754e-01,\n",
            "         1.04183380e-06,  2.50275731e-02,  3.90175046e-06,\n",
            "         9.90563095e-01,  3.93033959e-03, -9.63893116e-01,\n",
            "         7.89390970e-03,  2.45480105e-01,  9.26951587e-01,\n",
            "        -9.33214556e-03,  2.13117063e-01, -7.45280355e-04,\n",
            "        -1.43113612e-05, -1.22000985e-01,  5.34716295e-03,\n",
            "        -3.60756367e-02,  6.90994924e-03,  5.55419829e-04,\n",
            "         3.76621960e-04, -1.10091825e-09,  9.21411411e-05,\n",
            "         9.34403241e-01, -1.29335103e-05,  3.20073962e-01,\n",
            "        -1.11828297e-01,  9.05629158e-01,  9.99335229e-01,\n",
            "         1.17543046e-07, -1.57118007e-03, -4.16457715e-06,\n",
            "         1.97661772e-01,  8.97034347e-01,  1.42438395e-04,\n",
            "         5.70884986e-05,  2.45498930e-04, -5.19635856e-01,\n",
            "         5.02256953e-05, -2.58833388e-05, -9.94068325e-01,\n",
            "        -1.33828167e-02,  1.53383953e-05,  9.64812279e-01,\n",
            "         8.15798273e-07,  8.83344233e-01,  6.96386397e-01,\n",
            "        -9.99648333e-01, -9.31777298e-01, -9.97239590e-01,\n",
            "         2.00183656e-08,  7.89409876e-01, -5.58842748e-06,\n",
            "        -9.66922045e-01, -6.37368679e-01,  8.36681724e-02,\n",
            "         8.99589419e-01,  1.89678848e-01,  9.60610569e-01,\n",
            "        -4.98984337e-01,  1.05482060e-04, -9.63793874e-01,\n",
            "        -2.04844996e-01, -1.26908928e-10, -2.93032695e-02,\n",
            "        -9.53163564e-01,  7.96885431e-01,  7.65455980e-03,\n",
            "         7.48605747e-03,  5.75772836e-04, -9.84824121e-01,\n",
            "         9.71234798e-01, -6.19498547e-03,  9.93225515e-01,\n",
            "         2.71365017e-01,  9.97938275e-01, -3.59751808e-04,\n",
            "        -1.74779235e-03, -6.35471370e-05,  9.77436125e-01,\n",
            "        -2.76955545e-01, -5.92497364e-03, -1.85077035e-04,\n",
            "        -5.09905070e-03, -9.97650981e-01,  4.25725080e-11,\n",
            "         2.65993738e-09, -3.76298800e-02,  9.80333745e-01,\n",
            "         9.21641529e-01,  9.16509509e-01,  6.79308116e-01,\n",
            "        -4.16435185e-04, -4.49857488e-03,  4.56188768e-01,\n",
            "        -7.92751074e-01,  4.87181865e-07,  9.57562149e-01,\n",
            "        -5.77388200e-05, -7.37853408e-01,  9.89176393e-01,\n",
            "        -9.12275791e-01,  9.99814570e-01, -1.13636615e-05,\n",
            "         2.66260412e-02, -9.30304527e-02,  6.36484265e-01,\n",
            "         9.91915226e-01, -9.57440734e-01,  1.36257469e-07,\n",
            "         4.56985027e-01,  9.98769641e-01, -7.86047220e-01,\n",
            "         4.48771305e-02,  2.20057461e-03,  1.95294488e-02,\n",
            "         8.72573128e-06,  2.66034603e-01,  2.90491525e-02,\n",
            "        -1.24911021e-05, -9.93926466e-01, -3.10795754e-01,\n",
            "         2.53319257e-07, -9.85326648e-01, -6.22541791e-07,\n",
            "         9.99853492e-01,  4.90678459e-01,  9.94932413e-01,\n",
            "        -8.85074317e-01,  3.48917544e-01, -6.27054870e-02,\n",
            "        -9.99425650e-01,  1.28957268e-03, -7.23018358e-03,\n",
            "         2.52454010e-05, -2.03979970e-03,  1.79217324e-01,\n",
            "         5.57177543e-07, -7.62995481e-01,  3.05624425e-01,\n",
            "        -1.28206511e-06, -9.61685956e-01,  8.93872857e-01,\n",
            "        -7.49085018e-07, -5.27419479e-06,  1.44615009e-01,\n",
            "         5.11119333e-06,  3.17748599e-02, -9.91668165e-01,\n",
            "        -3.66081744e-01]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.97874904e+00,  5.22691107e+00, -1.54415560e+00,\n",
            "        -2.41073656e+00,  1.40389740e+00, -3.30622721e+00,\n",
            "        -6.65697765e+00, -1.06146202e+01,  2.98596889e-01,\n",
            "         6.23286772e+00,  6.93464577e-01,  8.95587063e+00,\n",
            "         3.74781561e+00, -1.26013588e-02, -9.89933109e+00,\n",
            "        -5.74464464e+00, -6.49613380e+00, -2.47291636e+00,\n",
            "        -4.74301529e+00,  1.77580559e+00, -2.85371274e-01,\n",
            "        -1.12595587e+01,  1.91623259e+00, -1.06113386e+01,\n",
            "        -9.71876907e+00,  2.29117340e-05,  4.39567864e-01,\n",
            "         4.40917063e+00,  3.73576760e+00, -2.78101587e+00,\n",
            "        -2.36448860e+00,  8.80905724e+00,  2.55321574e+00,\n",
            "        -4.00978899e+00, -2.12393720e-02, -8.62620163e+00,\n",
            "        -3.94704556e+00, -6.05323792e+00,  4.66657066e+00,\n",
            "         2.82497668e+00,  7.42622435e-01,  7.48693168e-01,\n",
            "        -1.07275164e+00, -1.09536572e+01, -2.30231667e+00,\n",
            "         8.55023623e-01,  3.20862412e+00,  2.89101768e+00,\n",
            "         2.23585773e+00,  5.40955782e+00,  1.51046252e+00,\n",
            "         2.01538181e+00,  4.52149200e+00,  1.58155894e+00,\n",
            "         2.80095077e+00,  6.20580196e+00,  1.75495553e+00,\n",
            "        -1.08078833e+01,  9.48976099e-01,  1.11229239e+01,\n",
            "        -1.74535644e+00,  4.87707424e+00, -2.97035933e+00,\n",
            "         3.15046048e+00,  9.42604733e+00,  9.25961208e+00,\n",
            "        -5.63269734e-01,  2.92367530e+00,  3.84426403e+00,\n",
            "        -1.94294679e+00,  2.57482052e+00,  3.57152486e+00,\n",
            "        -2.04801941e+00,  4.11268806e+00, -1.01191700e+00,\n",
            "        -4.82232124e-02,  1.72143090e+00, -2.64042425e+00,\n",
            "        -1.69493401e+00, -7.23378563e+00, -5.98752737e-01,\n",
            "        -3.19352603e+00,  2.69414282e+00,  2.70335495e-01,\n",
            "        -2.96561790e+00,  3.71718574e+00, -3.05356240e+00,\n",
            "         2.20835829e+00,  1.95164466e+00,  9.97657359e-01,\n",
            "         2.97816181e+00, -1.06915729e-02,  2.71382236e+00,\n",
            "        -2.23025084e+00, -9.88583755e+00, -3.96465898e+00,\n",
            "         3.06163335e+00, -1.91587138e+00, -2.99379349e+00,\n",
            "         2.31509018e+00,  2.76278257e+00, -1.21241391e+00,\n",
            "        -1.19331706e+00, -4.45159435e+00, -1.05848122e+00,\n",
            "         2.34410954e+00,  3.11873555e+00,  2.70476604e+00,\n",
            "         3.92232037e+00,  1.08713770e+00,  1.13015485e+00,\n",
            "         2.71152282e+00,  7.26719022e-01, -1.99817491e+00,\n",
            "         4.69769210e-01,  2.52365530e-01,  1.63628781e+00,\n",
            "        -5.02088118e+00,  6.61245632e+00, -2.00058660e-03,\n",
            "        -8.37906647e+00, -1.20482993e+00,  3.42096233e+00,\n",
            "        -2.46070695e+00,  1.73192549e+00,  4.60210514e+00,\n",
            "         5.24182177e+00, -3.09246516e+00,  7.25807381e+00,\n",
            "         1.70168984e+00, -4.01978111e+00,  3.32239896e-01,\n",
            "        -2.18374565e-01,  1.50267124e+00,  4.03589916e+00,\n",
            "         1.54939145e-01, -1.09812297e-01, -3.71900749e+00,\n",
            "         2.00299397e-01,  1.68093395e+00,  1.85096908e+00,\n",
            "         3.40708804e+00,  3.46744061e+00, -5.95209837e-01,\n",
            "         1.64877188e+00, -5.07992840e+00, -4.19527626e+00,\n",
            "        -2.65553091e-02,  2.77013230e+00,  2.01138186e+00,\n",
            "         8.02236080e+00,  1.39105833e+00,  8.60339820e-01,\n",
            "        -7.06694174e+00, -2.84977746e+00, -3.36506844e+00,\n",
            "         1.10401220e+01,  1.23729074e+00, -1.84680009e+00,\n",
            "        -3.63312006e+00, -1.16003633e+00,  9.11696815e+00,\n",
            "         1.47008359e+00,  9.64850366e-01,  2.03529787e+00,\n",
            "        -6.41755819e-01,  2.95136070e+00, -2.02458835e+00,\n",
            "        -2.07789958e-01, -4.65277004e+00, -4.13653803e+00,\n",
            "        -1.86698449e+00,  1.09027731e+00,  1.03875866e+01,\n",
            "         3.01537061e+00,  2.05598211e+00, -2.43681693e+00,\n",
            "         5.08752298e+00, -2.99119043e+00,  2.86180353e+00,\n",
            "         3.52112770e-01,  3.43819308e+00, -1.03056259e+01,\n",
            "        -3.34127808e+00, -3.68112063e+00,  2.26731968e+00,\n",
            "        -2.01533747e+00, -1.75050235e+00, -5.21295977e+00,\n",
            "        -5.10451011e-03, -3.38635969e+00,  5.85712481e+00,\n",
            "         1.20894394e-04, -1.14583671e+00,  4.51189041e+00,\n",
            "         1.60120213e+00,  1.56677079e+00,  8.27828169e-01,\n",
            "        -8.20223999e+00, -7.34088898e-01,  5.08763492e-01,\n",
            "        -2.99937105e+00,  2.56683517e+00,  1.91570735e+00,\n",
            "        -3.83693457e+00, -9.45756733e-01,  2.60697174e+00,\n",
            "        -5.28118658e+00,  7.48375368e+00, -2.44002676e+00,\n",
            "         5.70564795e+00, -3.67673129e-01,  7.52521217e-01,\n",
            "         2.97194982e+00, -1.91425073e+00,  3.33810806e+00,\n",
            "         4.93493766e-01,  4.08484268e+00, -3.50450563e+00,\n",
            "         4.49088886e-02,  3.54666114e+00,  2.95684791e+00,\n",
            "         7.15562010e+00,  2.99905491e+00,  4.91948843e+00,\n",
            "        -1.08198166e+00, -2.95599866e+00, -3.21460247e-01,\n",
            "         4.53094864e+00, -2.47165084e+00, -1.05204368e+00,\n",
            "         4.77427435e+00,  5.36969900e-01,  3.02193403e+00,\n",
            "        -1.39880633e+00,  5.45931482e+00, -6.27996698e-02,\n",
            "        -4.19020319e+00,  1.38970244e+00, -1.95679259e+00,\n",
            "         9.98669267e-01, -2.82945013e+00,  7.14927149e+00,\n",
            "         4.58538914e+00, -1.00644708e+00,  7.97419906e-01,\n",
            "        -3.04852843e+00, -1.96787143e+00,  1.47492313e+00,\n",
            "        -2.99058151e+00, -8.05451127e-05,  1.45636231e-01,\n",
            "         3.34031129e+00,  1.39828578e-01, -3.21495128e+00,\n",
            "        -8.18781376e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.61483938e-02,  3.74272946e-10, -8.66207946e-03,\n",
            "        -3.36654510e-10, -1.02721515e-05, -1.04842866e-05,\n",
            "        -1.04141452e-06, -8.26073083e-14, -5.93865335e-01,\n",
            "         4.09048906e-10,  1.57983828e-13,  1.98783775e-04,\n",
            "         3.40602946e-06, -7.58593023e-01, -6.86146086e-14,\n",
            "        -1.40805501e-09, -1.48373878e-18, -8.99123967e-01,\n",
            "        -1.73019571e-10,  6.50347583e-03, -2.47601539e-23,\n",
            "        -5.87337991e-19,  9.56309021e-01, -1.64599314e-05,\n",
            "        -2.86032829e-11,  7.52772450e-01,  4.83971685e-01,\n",
            "         5.51926917e-07,  2.23466722e-14, -1.98217843e-15,\n",
            "        -9.82255101e-01,  2.56380998e-03,  7.47260884e-08,\n",
            "        -9.56516489e-02, -1.38689347e-06, -2.33164224e-06,\n",
            "        -3.28425571e-08, -8.82039828e-08,  9.74524140e-01,\n",
            "         4.15605030e-07,  1.51822373e-04, -1.38633892e-01,\n",
            "        -8.82737339e-02, -9.94455576e-01, -8.11511231e-14,\n",
            "         6.93817377e-01,  3.84770299e-10, -1.44664067e-08,\n",
            "         2.97549665e-08,  4.81880438e-11,  8.28578612e-12,\n",
            "         8.53284121e-01,  1.71032112e-12,  9.84677553e-01,\n",
            "         1.75587217e-16,  1.96576181e-07,  1.17748801e-03,\n",
            "        -1.96361244e-01,  4.66439575e-01,  2.73468402e-07,\n",
            "        -1.20441169e-01,  9.99318361e-01, -1.70779508e-02,\n",
            "         6.65893083e-08,  1.25309848e-03, -4.56895819e-03,\n",
            "        -9.03493822e-01,  9.95876219e-14, -3.98067911e-14,\n",
            "        -1.92280891e-06,  2.05924827e-15,  3.40007951e-08,\n",
            "        -7.51785282e-03,  9.91673052e-01, -7.61504650e-01,\n",
            "        -5.02027753e-10,  1.13461255e-07, -9.96421397e-01,\n",
            "        -1.11370031e-10, -4.62287193e-04, -7.87664294e-01,\n",
            "        -2.42968423e-10,  6.28405323e-05, -1.08771038e-03,\n",
            "        -5.70142689e-09,  4.32293878e-21, -1.89834884e-11,\n",
            "         9.91138577e-01,  8.42039227e-01,  9.63636041e-01,\n",
            "         3.65297880e-13, -5.15761435e-01,  9.33830082e-01,\n",
            "        -9.81518131e-11, -3.33376209e-12, -3.21242306e-15,\n",
            "         3.40547466e-08, -5.76895698e-10, -2.93913551e-08,\n",
            "         7.59148929e-13,  9.91940439e-01, -8.86876166e-01,\n",
            "        -8.28949034e-01, -9.83733773e-01, -4.41600225e-20,\n",
            "         2.64123376e-11,  3.11390281e-01,  1.14361580e-06,\n",
            "         9.92955733e-03,  1.01673754e-06,  3.36739380e-04,\n",
            "         6.06508672e-01,  3.51200536e-12, -9.79094583e-09,\n",
            "        -4.93101567e-01,  7.37459481e-01,  9.26961064e-01,\n",
            "        -1.49961356e-02,  9.61146952e-07,  1.77041215e-10,\n",
            "        -5.47405948e-16,  1.37321483e-02,  5.82451656e-11,\n",
            "        -7.95726373e-05,  7.96383247e-02,  3.52973172e-11,\n",
            "         1.18802359e-14, -1.70669134e-03,  8.93763968e-07,\n",
            "         3.81694406e-07, -2.97729303e-14,  8.69792342e-01,\n",
            "         2.27870101e-11,  1.46773073e-14,  9.99879122e-01,\n",
            "         2.33622610e-13, -1.55273025e-04, -1.39573529e-01,\n",
            "         7.25774348e-01, -2.32750458e-14,  1.07543834e-03,\n",
            "         1.81144216e-12,  2.49222480e-03, -3.64403191e-21,\n",
            "         1.78436236e-03, -2.80061144e-14, -9.96628225e-01,\n",
            "        -1.52922608e-02,  4.23914332e-12,  9.64753568e-01,\n",
            "         1.85546358e-15,  4.12899628e-03,  8.60262811e-01,\n",
            "        -3.57273144e-14, -5.75748560e-10, -1.81892560e-13,\n",
            "         3.08678900e-05,  9.69885945e-01, -2.02450637e-22,\n",
            "        -6.26347632e-22, -8.39527130e-01,  4.88497189e-16,\n",
            "         8.98554742e-01,  5.25923805e-10,  4.81593702e-07,\n",
            "        -5.65978646e-01,  9.19237880e-11, -1.49724670e-04,\n",
            "        -2.29838088e-01,  1.82983317e-08, -2.99039797e-08,\n",
            "        -9.11658883e-01,  1.09042734e-01,  4.28906568e-16,\n",
            "         2.62171543e-21,  6.11939004e-06, -2.15915725e-06,\n",
            "        -1.36514655e-06, -3.19451874e-06,  9.99107659e-01,\n",
            "         9.42755942e-18,  8.87202740e-01, -2.05601027e-15,\n",
            "        -3.27303660e-08, -2.25168971e-15,  5.02592957e-06,\n",
            "        -4.72505987e-02, -4.74310887e-23, -1.96617584e-08,\n",
            "        -7.59018362e-01, -3.44827548e-02,  7.93468021e-03,\n",
            "         7.61594117e-01, -7.18261526e-06,  9.95318115e-01,\n",
            "         9.49722946e-01,  9.09084618e-01,  6.70681711e-19,\n",
            "         5.53758923e-07, -3.60784412e-04,  4.88962829e-02,\n",
            "        -2.40597524e-06,  2.85487736e-12,  1.17500683e-07,\n",
            "        -1.78220764e-01, -1.88809575e-03,  9.24960732e-01,\n",
            "        -1.12016143e-13,  7.73072752e-12, -9.10380423e-01,\n",
            "         7.91527821e-09, -4.59129013e-10,  5.30200623e-12,\n",
            "         8.30721991e-10, -6.64281717e-04,  8.09924901e-01,\n",
            "         7.28786545e-05,  6.81106925e-01, -6.88994082e-14,\n",
            "         6.65412472e-07,  1.54155799e-09,  2.04883272e-05,\n",
            "         1.01591913e-09,  5.37517472e-18,  7.09200231e-03,\n",
            "        -7.93926537e-01, -9.94601071e-01,  5.90499282e-01,\n",
            "         2.36944353e-11, -2.37634358e-05, -5.31858859e-07,\n",
            "         2.46078002e-18,  1.18067059e-04,  1.82675558e-05,\n",
            "        -3.09076817e-08,  6.49899885e-04, -2.09092703e-02,\n",
            "        -6.83202003e-14,  1.98998329e-08, -4.41950047e-03,\n",
            "         7.60882199e-01,  2.47017494e-13,  5.94762014e-15,\n",
            "         3.03558806e-12, -5.93162468e-03,  6.62569642e-01,\n",
            "        -7.69258978e-17, -1.45465392e-03,  5.11559695e-02,\n",
            "        -1.03999455e-05, -8.05459131e-05,  4.72619832e-02,\n",
            "         2.99970027e-09, -1.36186881e-14,  3.23069230e-06,\n",
            "        -1.06550289e-08]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 3.8686678e+00,  4.2267900e+00, -2.5294375e+00, -3.4107339e+00,\n",
            "        -9.9994928e-01, -4.3049946e+00, -7.6529102e+00, -1.1605938e+01,\n",
            "        -6.8361634e-01,  7.2121797e+00,  1.0972707e+00,  9.8210878e+00,\n",
            "         4.7477579e+00, -1.0126004e+00, -1.0228447e+01, -6.6765962e+00,\n",
            "        -7.4784207e+00, -1.4769841e+00, -3.7430153e+00,  1.8902380e+00,\n",
            "        -5.9893680e-01, -1.1139441e+01,  1.9008368e+00, -1.1608883e+01,\n",
            "        -1.0717929e+01,  9.9998486e-01,  5.2815783e-01,  4.4090676e+00,\n",
            "         3.7357128e+00, -1.7810166e+00, -2.3580499e+00,  8.8322601e+00,\n",
            "         3.5485175e+00, -5.0097179e+00, -2.3525510e-02, -7.8272915e+00,\n",
            "        -1.0001353e+00, -6.9474359e+00,  5.5641460e+00,  2.8296123e+00,\n",
            "         1.7426205e+00, -9.9993795e-01, -2.0727460e+00, -1.1940601e+01,\n",
            "        -3.3023138e+00,  8.5528451e-01,  3.2067468e+00, -9.7989178e-01,\n",
            "         2.4515729e+00,  6.4059300e+00,  2.5099077e+00,  1.2681085e+00,\n",
            "         3.5817618e+00,  2.4426608e+00,  1.8009508e+00,  7.1973739e+00,\n",
            "         1.7151610e+00, -1.1807575e+01,  5.5672789e-01,  1.1239855e+01,\n",
            "        -2.2051299e+00,  3.9925339e+00, -3.9703331e+00,  4.1443357e+00,\n",
            "         9.4257946e+00, -4.0924990e-01, -1.4909196e+00,  1.9238409e+00,\n",
            "        -9.3144703e-01, -9.4299012e-01,  3.5748200e+00,  4.5713530e+00,\n",
            "        -2.8051167e+00,  4.1102905e+00, -9.9978697e-01, -1.6310042e-01,\n",
            "         2.7214239e+00, -3.2201607e+00, -2.6947737e+00, -8.2337818e+00,\n",
            "        -1.0663438e+00, -2.1999779e+00,  2.0315747e+00, -7.2962731e-01,\n",
            "        -3.9654238e+00,  4.7165885e+00, -4.0528445e+00,  3.2083580e+00,\n",
            "         1.2281408e+00,  1.9944873e+00,  3.9757307e+00, -1.0106136e+00,\n",
            "         1.7142226e+00, -3.2301261e+00, -5.3749871e-01, -4.9640727e+00,\n",
            "         4.0616331e+00, -1.9159062e+00, -2.0441542e+00,  3.3111312e+00,\n",
            "         2.7550025e+00, -1.4071076e+00, -1.1847676e+00, -3.4522798e+00,\n",
            "        -5.8509469e-02,  1.3458440e+00,  4.1186161e+00,  3.7047658e+00,\n",
            "         4.9216537e+00,  1.2263719e+00,  2.1301548e+00,  1.8873348e+00,\n",
            "         1.0250247e+00, -2.9981732e+00, -5.4015088e-01,  1.2175535e+00,\n",
            "         1.6363533e+00, -6.0208788e+00,  6.6386652e+00,  9.9799836e-01,\n",
            "        -9.3540316e+00,  9.9419540e-01,  4.4207048e+00, -2.5942860e+00,\n",
            "         2.7319081e+00,  5.5984073e+00,  5.9822745e+00, -4.0924358e+00,\n",
            "         8.2576084e+00,  2.7016287e+00, -3.5172980e+00,  1.3322299e+00,\n",
            "         9.9210882e-01,  2.5007761e+00,  4.9660053e+00,  1.1549391e+00,\n",
            "        -1.1096966e+00, -4.7185440e+00,  9.9999303e-01, -9.7980404e-01,\n",
            "         2.8509686e+00,  4.4070859e+00,  4.4674368e+00, -1.5950098e+00,\n",
            "         8.1284636e-01, -6.0798173e+00, -3.1918857e+00, -1.0263044e+00,\n",
            "         1.7701321e+00,  2.0103788e+00,  8.0240593e+00,  1.6415071e+00,\n",
            "         1.2945166e+00, -7.0660305e+00, -2.8497746e+00, -4.3508153e+00,\n",
            "         1.2039992e+01,  2.1384709e+00, -2.8467214e+00, -4.6315269e+00,\n",
            "        -1.8484333e+00,  1.0116509e+01,  1.4700903e+00,  1.9648504e+00,\n",
            "         2.9324868e+00, -6.4159364e-01,  1.9515312e+00, -2.0307913e+00,\n",
            "        -2.3401858e-01,  9.9998719e-01, -4.7073660e+00, -1.5385801e+00,\n",
            "         2.0902767e+00,  1.0981184e+01,  2.0153706e+00,  2.0559883e+00,\n",
            "        -1.4374621e+00, -9.9951267e-01, -3.9911873e+00,  3.8618031e+00,\n",
            "         1.3521066e+00,  2.4387410e+00, -1.1297405e+01, -4.3410616e+00,\n",
            "        -4.6805186e+00,  3.2668657e+00, -3.0096118e+00, -8.8917351e-01,\n",
            "        -5.2134981e+00, -1.0007180e+00, -4.3851810e+00,  5.8576937e+00,\n",
            "         9.9999988e-01, -2.1457772e+00,  3.5222456e+00,  1.8289467e+00,\n",
            "         2.5667019e+00,  1.8250736e+00,  7.4839818e-01, -7.3398638e-01,\n",
            "         4.4293484e-01, -3.9948831e+00,  2.5668290e+00,  2.9156907e+00,\n",
            "        -4.8313222e+00, -9.9996442e-01,  1.6583078e+00, -4.2902904e+00,\n",
            "         8.4103956e+00, -1.5297419e+00,  6.6979165e+00, -1.3398799e+00,\n",
            "         1.2700257e+00,  3.9716604e+00, -2.8591704e+00,  1.1268589e+00,\n",
            "         2.9410881e-01,  5.0248408e+00, -4.5045056e+00,  1.0321805e+00,\n",
            "         3.0321088e+00,  2.9580162e+00,  8.1549931e+00,  3.9989643e+00,\n",
            "         5.9166794e+00, -1.0819654e+00, -2.9559977e+00,  6.7843270e-01,\n",
            "         4.5304823e+00, -3.4716499e+00, -5.6318939e-02,  4.7742753e+00,\n",
            "         5.5304110e-01,  4.0217476e+00, -2.3910661e+00,  6.4561558e+00,\n",
            "        -2.1009669e-02, -5.1543846e+00,  2.3895085e+00, -2.9557199e+00,\n",
            "         9.9830693e-01,  9.8995298e-01,  6.1492767e+00,  3.5876513e+00,\n",
            "        -6.7179799e-03,  7.9738986e-01, -4.0426846e+00, -2.9678607e+00,\n",
            "         2.4748366e+00, -3.9905486e+00, -8.0546066e-05,  4.7297537e-02,\n",
            "         4.3400283e+00, -8.6031264e-01,  9.9789220e-01, -7.1918783e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 1.8500784e-02,  1.5601124e-06, -9.5293361e-01, -2.7260397e-05,\n",
            "        -6.5474868e-01, -1.8533827e-05, -9.9851978e-01, -4.1511390e-05,\n",
            "        -5.9707260e-01,  1.3176021e-01,  3.7996292e-01,  1.0553287e-02,\n",
            "         2.9339374e-03, -6.4052975e-01, -2.3635730e-01, -1.5032318e-02,\n",
            "        -6.1690138e-05, -4.6293989e-01,  2.7497651e-04,  2.1572988e-02,\n",
            "        -3.1057593e-01, -1.9339592e-05,  9.5646882e-01, -2.8357420e-03,\n",
            "        -1.2018727e-06,  3.8294226e-01,  4.4699416e-01,  1.3769971e-07,\n",
            "         9.6962474e-05, -4.6417266e-01, -8.7651223e-01,  5.8276020e-04,\n",
            "        -7.5236136e-01, -1.7817995e-02,  1.3173021e-01, -9.9813515e-01,\n",
            "        -1.1791460e-02, -9.9735010e-01,  9.9998236e-01,  1.5435431e-07,\n",
            "         1.0821729e-04,  3.5014826e-01, -7.2542922e-10, -9.0363598e-01,\n",
            "        -2.7754859e-04,  7.2393602e-01,  4.4306740e-03, -1.2884838e-04,\n",
            "         9.8569387e-01,  9.9894780e-01,  4.0232528e-02,  9.6633077e-01,\n",
            "         1.6512554e-06,  9.8562598e-01,  9.0737134e-01,  3.9641189e-05,\n",
            "         5.1312399e-01, -2.1157578e-02,  9.0499187e-01,  9.3210270e-05,\n",
            "        -7.4187315e-01,  9.9881321e-01, -7.3082340e-01,  7.3958904e-01,\n",
            "         8.6734593e-01, -8.7978035e-01, -7.6194847e-01,  3.2435872e-02,\n",
            "         1.1364187e-04, -8.2783288e-01,  1.2915742e-03,  1.7861418e-02,\n",
            "        -9.9023062e-01,  9.9002218e-01, -1.2428262e-03, -7.7793285e-02,\n",
            "         3.3841982e-06, -9.9854994e-01, -9.2988979e-04, -3.5056395e-03,\n",
            "        -2.1620937e-05, -9.4723998e-04,  5.2771738e-05, -9.2981976e-01,\n",
            "        -1.8109281e-02,  9.0643770e-01, -4.4979450e-01,  1.9631510e-05,\n",
            "         2.4192414e-01,  1.3643804e-01,  1.3112955e-01, -3.3301868e-02,\n",
            "         7.8887379e-01, -3.4323293e-01, -4.4572753e-06, -3.9962069e-06,\n",
            "         9.9933982e-01, -3.2085537e-03, -8.6296102e-05,  1.1837050e-08,\n",
            "         9.3913049e-01, -9.4884145e-01, -9.7083002e-01, -9.9115384e-01,\n",
            "        -3.8053105e-07,  9.2923838e-01,  9.9798214e-01,  9.8098087e-01,\n",
            "         5.4627325e-02,  8.3976023e-02,  9.3738252e-01,  9.5173341e-01,\n",
            "         9.6213525e-06, -8.9253110e-01,  2.2117428e-03,  5.6545206e-05,\n",
            "         5.2966094e-01, -1.9640125e-05,  4.2271730e-04,  6.0099268e-01,\n",
            "        -7.7159735e-03,  1.1982410e-02,  1.1907117e-06, -1.8535661e-06,\n",
            "         5.7858713e-03,  1.3090647e-04,  5.9428823e-04, -6.4536648e-06,\n",
            "         7.9953542e-04,  2.1190350e-05, -3.1934888e-04,  9.7392267e-01,\n",
            "         9.6080786e-01,  2.6444709e-01,  9.9986923e-01,  1.0632550e-03,\n",
            "         5.4932082e-01, -9.7205216e-01, -5.4594990e-02, -1.5364116e-03,\n",
            "         9.4502169e-01,  7.8543329e-01,  8.9065230e-01, -1.1976920e-07,\n",
            "         2.1239617e-04, -7.5654060e-01, -9.6115202e-02, -7.2438166e-02,\n",
            "         1.1459390e-02,  8.1353819e-01,  2.1755615e-02,  3.5389495e-01,\n",
            "         3.8166490e-01, -8.0399960e-03, -2.1140987e-07, -1.7187918e-02,\n",
            "         1.6585801e-09,  8.7688422e-01, -3.0170393e-06, -2.6612461e-04,\n",
            "        -3.4398514e-01,  1.8085550e-05,  8.6278403e-01,  1.7910860e-01,\n",
            "         8.1489140e-01,  1.7692067e-01,  9.3689704e-01,  4.3085005e-02,\n",
            "         3.5041150e-01,  1.9192414e-06, -9.9564886e-01, -9.1293436e-01,\n",
            "         8.2984442e-01,  2.4292623e-01,  6.1372564e-05,  9.6392179e-01,\n",
            "        -9.1888171e-01, -7.1296233e-01, -1.5210960e-02,  1.2203902e-01,\n",
            "         2.8013801e-02,  9.6588111e-01, -2.0337398e-05, -5.8606840e-03,\n",
            "        -3.9292709e-03,  3.7218209e-02, -4.1395709e-01, -4.7155330e-01,\n",
            "        -9.8868918e-01,  6.4923155e-01, -9.9951708e-01,  1.1380039e-06,\n",
            "         1.8368320e-01, -9.9130791e-01,  9.9338919e-01,  9.5199490e-01,\n",
            "         3.4236482e-01,  8.3669871e-01, -4.9600741e-05, -1.9436389e-04,\n",
            "         2.0428447e-01,  7.4347435e-04,  4.9133971e-04,  9.9381304e-01,\n",
            "        -2.9994824e-05, -5.5409914e-01,  7.7790362e-01, -9.9692297e-01,\n",
            "         3.3622783e-01, -5.7539827e-01,  1.7959788e-01,  1.2220162e-01,\n",
            "         3.9813695e-09,  4.7934130e-03, -9.5303601e-01,  1.4502724e-01,\n",
            "         6.0092947e-03,  8.3943868e-01, -7.1867420e-03, -1.5570674e-02,\n",
            "         9.8190588e-01,  9.9431926e-01,  8.6706161e-05,  1.9588051e-06,\n",
            "         3.2291585e-04, -5.2284095e-02, -9.5519310e-01,  9.2210102e-01,\n",
            "         6.3450066e-03, -9.9637961e-01, -2.9547427e-05,  3.7172004e-03,\n",
            "        -3.4197953e-01,  1.0011707e-02, -8.9994496e-01,  1.6351234e-05,\n",
            "        -1.7294513e-02, -3.6682026e-03,  9.2592622e-08, -1.6473451e-01,\n",
            "         2.9169882e-03,  2.3912417e-04,  2.0686073e-06,  1.1608456e-03,\n",
            "         6.5124403e-03,  5.3459245e-01, -5.2886357e-05, -2.2240703e-03,\n",
            "         4.7769044e-03, -1.8422836e-01,  2.3910122e-01, -7.2831571e-01,\n",
            "         8.4696364e-01, -9.5099233e-07, -2.3239067e-01, -1.0173924e-02]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.5220466e+00,  3.8056128e+00, -2.6395621e+00, -3.4615657e+00,\n",
            "        -9.9951404e-01, -4.1885610e+00, -7.7162328e+00, -1.1623789e+01,\n",
            "        -6.8883079e-01,  7.6698685e+00,  2.0115709e+00,  1.0756985e+01,\n",
            "         5.7207499e+00, -7.6090467e-01, -1.0152906e+01, -6.6714883e+00,\n",
            "        -7.4609075e+00, -5.0421590e-01,  7.4551666e-01,  1.8848450e+00,\n",
            "        -3.3936194e-01, -1.1133817e+01,  1.9035897e+00, -1.1074651e+01,\n",
            "        -1.0204305e+01,  8.0816305e-01,  4.8117214e-01,  4.0036197e+00,\n",
            "         1.5208911e+00, -1.9895382e+00, -1.3605477e+00,  9.5014524e+00,\n",
            "        -9.7912872e-01, -5.8249125e+00,  9.8808801e-01, -5.1307726e+00,\n",
            "        -9.9514616e-01, -7.5969629e+00,  6.4055657e+00,  1.4223039e+00,\n",
            "         1.6661317e+00,  9.6115559e-01, -3.2914046e-02, -1.2449796e+01,\n",
            "        -3.9584498e+00,  9.1643548e-01,  4.0657272e+00, -1.2743229e+00,\n",
            "         3.4465916e+00,  6.3863349e+00,  2.7369325e+00,  2.0350697e+00,\n",
            "         3.5624950e+00,  2.4926100e+00,  1.5251433e+00,  7.7650180e+00,\n",
            "         5.8694023e-01, -1.1832294e+01,  1.5039045e+00,  1.1763303e+01,\n",
            "        -2.9563437e+00,  3.9931657e+00, -4.1114602e+00,  5.1398640e+00,\n",
            "         1.0212458e+01, -1.3747953e+00, -1.0008441e+00,  2.2775118e+00,\n",
            "         1.5080370e-01, -1.1812950e+00,  4.1280289e+00,  5.1188211e+00,\n",
            "        -2.7537556e+00,  2.6669221e+00, -2.1439835e-02, -7.8278281e-02,\n",
            "         1.3076370e+00, -3.7915552e+00, -2.6429472e+00, -8.4772158e+00,\n",
            "        -2.0586376e+00, -2.2731504e+00,  2.4541171e+00, -1.6626161e+00,\n",
            "        -4.9280167e+00,  5.6617904e+00, -6.0075676e-01,  2.5169096e+00,\n",
            "         2.6152074e-01,  1.3731636e-01,  3.2051320e+00, -1.9684368e+00,\n",
            "         1.0779572e+00, -3.7940359e+00, -8.3024585e-01, -5.5744996e+00,\n",
            "         5.0588875e+00, -1.0630391e+00, -2.2896981e+00,  1.6100105e+00,\n",
            "         1.7572314e+00, -2.2916274e+00, -2.1097853e+00, -2.9541092e+00,\n",
            "        -7.3588192e-03,  2.0612361e+00,  3.4578624e+00,  4.5712476e+00,\n",
            "         5.8952374e+00,  1.0014511e+00,  1.7160959e+00,  1.8539684e+00,\n",
            "         1.5613714e+00, -1.4426231e+00,  7.5872040e-01,  2.6305511e-03,\n",
            "         5.9426922e-01, -3.7656167e+00,  7.3340387e+00,  7.6761746e-01,\n",
            "        -9.2027540e+00,  1.7797784e+00,  4.3028531e+00, -2.7468641e+00,\n",
            "         1.9781662e+00,  5.4108100e+00,  6.6291099e+00, -2.6246240e+00,\n",
            "         9.0405025e+00,  2.7120461e+00, -3.8384433e+00,  2.1634130e+00,\n",
            "         1.9616495e+00,  2.4995317e+00,  4.8198867e+00,  1.1979632e+00,\n",
            "         8.0332947e-01, -5.6707702e+00, -5.5052910e-02, -1.7359790e+00,\n",
            "         1.7863219e+00,  4.9693208e+00,  4.3342772e+00, -1.0553167e+00,\n",
            "         8.0342555e-01, -6.4737401e+00, -1.7314490e+00, -4.1386923e-01,\n",
            "         1.7795451e+00,  1.1375302e+00,  8.4708576e+00,  3.8174769e-01,\n",
            "         4.0354404e-01, -3.1365657e+00, -2.1220512e+00, -5.1349406e+00,\n",
            "         1.2216958e+01,  2.9892988e+00, -3.6344814e+00, -5.5411649e+00,\n",
            "        -1.5717410e+00,  1.0503646e+01,  1.3939105e+00,  2.9424887e+00,\n",
            "         2.9315784e+00,  1.8117499e-01,  1.9308183e+00,  5.5776492e-02,\n",
            "         3.7717575e-01,  7.9818267e-01, -3.5943244e+00, -1.5448833e+00,\n",
            "         1.2324730e+00,  1.1327351e+01,  5.1871663e-01,  2.0417197e+00,\n",
            "        -1.5821445e+00, -1.9642230e+00, -4.9056201e+00,  3.8422453e+00,\n",
            "         1.7188015e+00,  2.0548487e+00, -1.1328488e+01, -4.6207576e+00,\n",
            "        -5.6062303e+00,  2.4437943e+00, -3.3881078e+00, -1.8841114e+00,\n",
            "        -2.8172793e+00,  7.7600950e-01, -4.3805733e+00,  6.2386761e+00,\n",
            "         5.2669024e-01, -2.7173743e+00,  2.9102509e+00,  1.8529888e+00,\n",
            "         2.9262509e+00,  1.6745712e+00, -7.9957289e-01, -2.0897482e-01,\n",
            "         2.0724681e-01,  5.4714060e-03,  1.9543709e+00,  2.8908691e+00,\n",
            "        -5.8237815e+00, -6.2442136e-01,  1.1778370e+00, -4.3954425e+00,\n",
            "         8.5258856e+00, -6.7113972e-01,  3.6987656e-01,  3.8456076e-01,\n",
            "         6.0230041e-01,  4.8953629e+00, -2.4997990e+00,  2.1259487e+00,\n",
            "         1.3549745e-01,  5.8429141e+00, -4.1103368e+00, -1.5571951e-02,\n",
            "         4.0247087e+00,  2.9331496e+00,  8.1329365e+00,  4.8931503e+00,\n",
            "         5.1911435e+00, -1.8205651e+00, -1.8930210e+00,  1.6036656e+00,\n",
            "         2.9902918e+00, -4.3369904e+00, -1.7857648e-01,  5.7402959e+00,\n",
            "        -3.5792121e-01,  4.8356490e+00, -1.4755689e+00,  6.2987638e+00,\n",
            "        -1.9360788e-02, -5.9218550e+00,  2.2175223e-01, -3.3810350e-01,\n",
            "         2.1567464e-02,  1.8075718e+00,  6.8007531e+00,  4.2260389e+00,\n",
            "         8.0039911e-03,  1.1232253e+00, -4.6412172e+00, -3.9551983e+00,\n",
            "         9.1489756e-01, -6.7023617e-01,  2.8877395e-01, -9.3524629e-01,\n",
            "         4.9591489e+00, -8.5407239e-01, -2.3679145e-01, -6.4171600e+00]],\n",
            "      dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 2.36660471e-05,  1.44381675e-05, -9.98238146e-01,\n",
            "        -2.15698383e-05, -7.60012567e-01, -5.45701084e-08,\n",
            "        -3.38740945e-01, -3.33114556e-04, -5.97045064e-01,\n",
            "         3.66223139e-05,  9.63290334e-01,  3.15155266e-05,\n",
            "         4.11556438e-02, -1.14044951e-05, -5.61945617e-01,\n",
            "        -1.32836357e-01, -1.23075256e-02, -3.13688099e-01,\n",
            "        -5.57692528e-01,  9.54813361e-01, -3.26907307e-01,\n",
            "        -6.81788802e-01,  9.56439734e-01, -2.81846017e-01,\n",
            "        -2.16166313e-06,  6.26857221e-01,  1.45752132e-01,\n",
            "         5.02832409e-04,  2.07923260e-03, -1.08601078e-02,\n",
            "        -4.96365845e-01,  8.45656157e-01,  3.55035445e-05,\n",
            "        -1.46050108e-04, -6.37692750e-01, -9.98675108e-01,\n",
            "        -1.80754487e-05, -9.21647821e-04,  8.64666998e-01,\n",
            "         4.96891700e-03,  6.52153790e-03,  7.39731848e-01,\n",
            "        -2.21988525e-10, -1.01749617e-06, -7.33224452e-01,\n",
            "         9.57213700e-01,  3.41743946e-01, -1.09929548e-04,\n",
            "         9.88883972e-01,  2.42300104e-07,  1.63079530e-03,\n",
            "         9.48582470e-01,  4.83897328e-02,  9.90366578e-01,\n",
            "         9.22448397e-01,  9.78390813e-01,  8.30913842e-01,\n",
            "        -6.00613020e-02,  4.24438000e-01,  1.40790462e-01,\n",
            "        -6.34416752e-03,  9.98620331e-01, -7.50411488e-03,\n",
            "         2.34196905e-05,  1.84905448e-03, -3.19471993e-02,\n",
            "        -7.63750494e-01,  4.38093469e-02,  6.32561641e-05,\n",
            "        -4.64453275e-04,  1.49684661e-06,  2.67107282e-02,\n",
            "        -9.19166148e-01,  9.28093612e-01, -2.34079749e-07,\n",
            "        -4.80031520e-02,  1.38267642e-03, -9.98752534e-01,\n",
            "        -9.34977412e-01, -9.99990761e-01, -3.76489535e-02,\n",
            "        -4.87900041e-02,  3.98006946e-01, -3.70721519e-03,\n",
            "        -1.20829127e-03,  1.53838471e-02, -2.44860048e-03,\n",
            "         8.58313963e-02,  9.86328870e-02, -1.88233793e-01,\n",
            "         7.41715892e-04, -8.38628829e-01,  3.26648319e-06,\n",
            "        -6.79482333e-03, -3.17711470e-04, -8.81863380e-05,\n",
            "         8.13785434e-01, -8.53136897e-01, -4.18931365e-01,\n",
            "         1.30293818e-04,  9.41326976e-01, -9.88414884e-01,\n",
            "        -9.71363008e-01, -9.90447044e-01, -1.10804820e-02,\n",
            "         6.21194541e-01,  1.61178086e-05,  5.54551661e-01,\n",
            "         1.84244066e-01,  1.87580381e-02,  2.26057018e-03,\n",
            "         5.34660071e-02,  1.04375809e-01, -4.11844552e-01,\n",
            "         5.10783434e-01,  5.17364359e-04,  5.32501459e-01,\n",
            "        -2.09418372e-09,  9.74399678e-04,  4.48248498e-02,\n",
            "        -2.20419109e-01,  3.94888548e-03,  1.79776608e-03,\n",
            "        -8.35734129e-01,  6.62129896e-05,  6.82395417e-04,\n",
            "         6.42355822e-04, -6.53079003e-02,  1.42358156e-04,\n",
            "         4.44177873e-02, -4.62752907e-03,  4.26895730e-03,\n",
            "         1.08100509e-03,  1.03449296e-04,  8.86817098e-01,\n",
            "         9.09695208e-01,  6.64016366e-01, -1.13866314e-07,\n",
            "        -7.61541069e-01, -1.79335713e-01,  1.45510957e-03,\n",
            "         6.24328554e-01,  2.41185007e-05, -3.82607715e-04,\n",
            "         1.14410743e-03, -7.10741505e-02, -6.02125704e-01,\n",
            "        -1.31614890e-03,  9.71036911e-01,  8.10029030e-01,\n",
            "         9.96397495e-01,  2.06251498e-02,  2.03624114e-01,\n",
            "        -7.72671103e-01, -6.95401609e-01, -7.40299225e-01,\n",
            "         1.18293849e-06,  9.99153316e-01, -4.81395982e-02,\n",
            "        -4.77012836e-05, -6.95938945e-01,  1.07844287e-04,\n",
            "         8.83998871e-01,  6.75931369e-06,  3.60650563e-04,\n",
            "         1.83666945e-01,  5.69939438e-08, -4.26931269e-02,\n",
            "         1.25444487e-01, -1.98285021e-02, -9.98454154e-01,\n",
            "        -9.12898123e-01,  5.37311006e-03,  2.71943072e-03,\n",
            "         4.90123630e-01,  9.93945062e-01, -1.03948150e-04,\n",
            "        -8.67754877e-01, -3.74881737e-02,  2.15250812e-02,\n",
            "         1.25086299e-05,  9.64409471e-01, -9.30683985e-02,\n",
            "        -1.05701620e-03, -9.99989927e-01,  7.33166218e-01,\n",
            "        -6.91398233e-03, -9.86784339e-01, -8.35332867e-06,\n",
            "        -6.85751811e-02, -9.99684811e-01,  1.63418704e-07,\n",
            "         4.29281965e-03, -9.91326571e-01,  9.49661016e-01,\n",
            "         8.43209982e-01,  4.68855083e-01,  8.83925021e-01,\n",
            "        -3.52223676e-13, -4.01496945e-05, -6.59908772e-01,\n",
            "        -1.12977441e-05,  1.01300869e-02,  3.74985248e-01,\n",
            "        -7.18658953e-07, -9.16107774e-01,  1.84986457e-01,\n",
            "        -1.20833991e-02,  9.84654248e-01, -4.65377525e-06,\n",
            "         4.77970481e-08, -4.66553159e-02,  6.85646772e-01,\n",
            "         1.95717681e-02, -9.85866964e-01,  6.13478232e-06,\n",
            "         1.34581238e-01,  5.58463931e-01, -2.94064812e-05,\n",
            "        -1.57810748e-02,  4.66305863e-07,  2.09443515e-05,\n",
            "         3.71312535e-06,  7.00114429e-01,  5.18341192e-09,\n",
            "        -2.49786541e-01, -9.55477297e-01,  9.35901940e-01,\n",
            "         1.18879683e-07, -9.94094312e-01, -1.71320841e-01,\n",
            "         2.20164090e-01,  4.89291772e-02,  1.21062901e-02,\n",
            "        -9.15948629e-01,  8.74291217e-09, -1.96094289e-02,\n",
            "        -3.75325021e-10,  1.08832335e-02, -2.36443598e-02,\n",
            "         6.49366304e-02,  4.15768009e-03,  2.37510234e-01,\n",
            "         9.84017253e-01,  7.75245670e-03,  8.31032544e-02,\n",
            "        -1.38770724e-06, -1.07603293e-04,  3.19751911e-02,\n",
            "        -3.72419381e-05, -3.53100896e-03, -8.30407202e-01,\n",
            "         1.91102095e-06, -6.37283981e-01, -7.04074025e-01,\n",
            "        -5.06410913e-08]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.84707880e+00,  4.76242876e+00, -3.51683068e+00,\n",
            "        -3.53864193e+00, -9.99494910e-01, -4.88111973e+00,\n",
            "        -7.72435284e+00, -1.25732412e+01, -6.88543260e-01,\n",
            "         7.66640854e+00,  2.01121783e+00,  1.17561331e+01,\n",
            "         6.71713114e+00, -9.74561088e-03, -1.10845613e+01,\n",
            "        -7.58533812e+00, -7.95615435e+00, -3.24784160e-01,\n",
            "        -7.05523551e-01,  1.88491488e+00, -3.39361608e-01,\n",
            "        -3.24354577e+00,  1.90242171e+00, -1.14886894e+01,\n",
            "        -1.11927595e+01,  7.36349642e-01,  1.46957546e-01,\n",
            "         4.91185570e+00,  2.51945043e+00, -2.96354938e+00,\n",
            "        -5.44472396e-01,  9.50141907e+00,  2.05079317e-02,\n",
            "        -6.78301859e+00, -8.29830110e-01, -5.13077497e+00,\n",
            "        -1.02126789e+00, -7.59583855e+00,  7.40457106e+00,\n",
            "         2.39595604e+00,  6.52172696e-03,  9.61404920e-01,\n",
            "        -8.02955702e-02, -1.33495140e+01, -4.89908886e+00,\n",
            "         1.91154027e+00,  5.06246376e+00, -2.78209597e-01,\n",
            "         3.36953688e+00,  7.22382116e+00,  3.70624995e+00,\n",
            "         1.81902635e+00,  4.36396313e+00,  2.75462937e+00,\n",
            "         1.65442348e+00,  8.70668697e+00,  1.56063259e+00,\n",
            "        -1.19347839e+01,  4.53095585e-01,  1.27071152e+01,\n",
            "        -2.97541261e+00,  3.99310994e+00, -4.37829638e+00,\n",
            "         6.13953400e+00,  1.02054491e+01, -3.74779254e-01,\n",
            "        -1.00522923e+00,  2.86997080e+00,  1.15032709e+00,\n",
            "        -1.18129528e+00,  3.99948192e+00,  5.83827972e+00,\n",
            "        -2.75731659e+00,  1.64448333e+00, -1.73580706e-01,\n",
            "        -4.80444729e-02,  2.20305467e+00, -3.79113555e+00,\n",
            "        -3.63441539e+00, -8.47872543e+00, -1.95296216e+00,\n",
            "        -3.27314162e+00,  3.45393085e+00, -6.71872139e-01,\n",
            "        -5.88895273e+00,  6.64990377e+00, -5.30677028e-02,\n",
            "         3.50361872e+00,  9.89556313e-02, -1.90505445e-01,\n",
            "         4.17954493e+00, -1.87573481e+00,  8.76811206e-01,\n",
            "        -4.79048300e+00, -1.81181324e+00, -6.55403948e+00,\n",
            "         6.05874825e+00, -1.72720206e+00, -3.28803253e+00,\n",
            "         1.67862928e+00,  1.74957764e+00, -2.62964153e+00,\n",
            "        -2.11593986e+00, -2.69700456e+00, -1.00634456e+00,\n",
            "         1.29377782e+00,  4.45767117e+00,  5.24977827e+00,\n",
            "         6.72900200e+00,  1.46308410e+00,  2.69071269e+00,\n",
            "         8.54113519e-01,  1.11621189e+00, -4.37830985e-01,\n",
            "         9.20544088e-01,  8.40691328e-01,  5.93633413e-01,\n",
            "        -3.66390491e+00,  8.19675922e+00,  7.51862228e-01,\n",
            "        -1.00001917e+01,  1.31722927e+00,  5.16283274e+00,\n",
            "        -2.75226617e+00,  2.79454160e+00,  6.38838291e+00,\n",
            "         7.51659966e+00, -2.62473083e+00,  9.92315960e+00,\n",
            "         2.71233964e+00, -4.33694172e+00,  1.16375554e+00,\n",
            "         1.94140954e-03,  2.41587877e+00,  5.81930685e+00,\n",
            "         1.52576184e+00,  8.00432265e-01, -6.66586637e+00,\n",
            "        -1.00011611e+00, -1.56510019e+00,  2.74702001e+00,\n",
            "         5.96918583e+00,  4.58628893e+00, -1.98825574e+00,\n",
            "         1.28197600e-03, -7.47308540e+00, -2.59122539e+00,\n",
            "        -4.26984161e-01,  2.11015487e+00,  1.12712204e+00,\n",
            "         9.46918106e+00,  3.17392528e-01,  6.59806013e-01,\n",
            "        -2.08934617e+00, -8.58386397e-01, -6.12555838e+00,\n",
            "         1.31443071e+01,  3.98415661e+00, -1.87060380e+00,\n",
            "        -6.53932142e+00, -1.60555136e+00,  1.11152201e+01,\n",
            "         1.39378762e+00,  1.20474055e-01,  3.29316378e+00,\n",
            "         1.85775489e-01,  4.35285896e-01, -9.39185500e-01,\n",
            "         3.75057101e-01, -2.79431548e-02, -3.58278155e+00,\n",
            "        -1.54495752e+00,  1.34206891e+00,  1.22458849e+01,\n",
            "         5.36224008e-01,  2.89995098e+00, -1.81723034e+00,\n",
            "        -1.34395647e+00, -5.88139105e+00,  3.89403558e+00,\n",
            "         2.14021015e+00,  2.00544786e+00, -1.22588558e+01,\n",
            "        -5.60770273e+00, -6.60600090e+00,  2.56898189e+00,\n",
            "        -3.38809347e+00, -2.82511306e+00, -2.79689550e+00,\n",
            "        -6.86831921e-02, -4.38067818e+00,  7.22488117e+00,\n",
            "         8.79917920e-01, -2.71815252e+00,  2.06886911e+00,\n",
            "         1.23226845e+00,  2.53401208e+00,  2.67450762e+00,\n",
            "        -1.69887817e+00, -9.57625270e-01, -7.92668581e-01,\n",
            "        -9.94260669e-01,  1.95416915e+00,  2.91804123e+00,\n",
            "        -5.82401323e+00, -1.62349510e+00,  1.87144324e-01,\n",
            "        -5.10408115e+00,  8.65641022e+00, -1.67082429e+00,\n",
            "         4.81875269e-08, -4.69512828e-02,  8.40483069e-01,\n",
            "         5.80147839e+00, -2.47567630e+00,  3.12429953e+00,\n",
            "         1.35493919e-01,  6.27612114e+00, -5.05575705e+00,\n",
            "        -1.57835726e-02,  4.99629831e+00,  2.93586564e+00,\n",
            "         8.25643253e+00,  5.89059973e+00,  6.01809835e+00,\n",
            "        -1.42240644e+00, -1.89268613e+00,  1.70433855e+00,\n",
            "         1.32245874e+00, -4.97198582e+00, -1.73029974e-01,\n",
            "         6.74024343e+00,  4.89817634e-02,  5.83345127e+00,\n",
            "        -2.47495270e+00,  7.26345825e+00, -1.96157880e-02,\n",
            "        -6.71645498e+00,  1.04437256e+00, -1.06238234e+00,\n",
            "         9.99685943e-01,  8.18344355e-01,  7.77555752e+00,\n",
            "         5.22507668e+00,  7.75270350e-03,  1.10167193e+00,\n",
            "        -5.55684137e+00, -4.70915270e+00,  3.19886878e-02,\n",
            "        -9.59470987e-01, -5.72266221e-01, -1.18957233e+00,\n",
            "         5.65202188e+00, -8.53928328e-01, -1.10558641e+00,\n",
            "        -7.41570568e+00]], dtype=float32)>)\n",
            "DECODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 4.79880095e-01,  9.45255697e-01, -6.73047230e-02,\n",
            "        -1.58536073e-04, -3.15101027e-01, -9.99687612e-01,\n",
            "        -9.97262716e-01, -7.80705377e-05, -8.76936793e-01,\n",
            "         3.94054726e-02,  2.38959615e-06,  3.95783246e-07,\n",
            "         1.22246129e-04, -4.40235381e-05, -1.58540986e-03,\n",
            "        -2.57870508e-03, -4.10803268e-03,  4.93591189e-01,\n",
            "        -2.38070720e-06,  4.00641441e-01, -6.75326010e-05,\n",
            "        -7.86533952e-01,  7.22584724e-01, -4.52442646e-01,\n",
            "        -4.23972905e-02,  2.90618241e-01,  7.42299378e-01,\n",
            "         9.99420345e-01,  2.22447678e-04, -9.51923966e-01,\n",
            "        -4.43570971e-01,  2.26706881e-02,  5.88756166e-06,\n",
            "        -3.56969977e-04, -3.17529957e-05, -9.63396206e-03,\n",
            "        -1.32089178e-06, -3.07169762e-02,  9.99963164e-01,\n",
            "         2.05164328e-01,  9.15817246e-02,  6.14665507e-04,\n",
            "        -2.81070564e-02, -1.32897583e-06, -3.02870684e-09,\n",
            "         9.77685094e-01,  2.00266214e-07, -6.73919357e-03,\n",
            "         2.40558762e-07,  9.23195981e-13,  2.17563468e-07,\n",
            "         6.92548335e-01,  5.56103669e-06,  2.89941072e-01,\n",
            "         4.38514771e-03,  2.37848936e-03,  4.88716841e-01,\n",
            "        -1.21037783e-02,  7.75646508e-01,  1.19458110e-10,\n",
            "        -3.81853789e-01,  9.99310613e-01, -1.49254383e-05,\n",
            "         4.67710424e-06,  9.84412491e-01, -1.02214599e-05,\n",
            "        -7.57348537e-01,  1.50735425e-02,  2.84258986e-05,\n",
            "        -1.53375128e-02,  3.02705025e-08,  7.55947411e-01,\n",
            "        -9.24062058e-02,  6.00619256e-01, -5.33269383e-02,\n",
            "         3.22354212e-02,  7.17981718e-04, -9.99072254e-01,\n",
            "        -3.56675650e-06, -4.30627279e-02, -5.20884283e-02,\n",
            "        -1.04873412e-04,  9.95616019e-01,  6.34135213e-04,\n",
            "        -2.70793976e-07,  1.00168016e-07, -7.78531730e-01,\n",
            "         8.15594375e-01,  7.96156675e-02,  7.56689787e-01,\n",
            "         9.20634925e-01, -7.89330065e-01, -1.02018923e-01,\n",
            "        -1.90524297e-04, -2.31402548e-04, -5.80456078e-01,\n",
            "         1.53580368e-01, -7.93627990e-08, -2.88906358e-06,\n",
            "         3.85195017e-04,  5.84725559e-01, -9.95720685e-01,\n",
            "        -8.22288632e-01, -9.82269108e-01, -7.83906281e-01,\n",
            "         5.38029475e-04,  9.99944448e-01,  9.99775767e-01,\n",
            "         6.90537217e-06,  2.74894742e-11,  1.70356724e-02,\n",
            "        -3.24107483e-02,  6.80260314e-07, -1.28473213e-04,\n",
            "         4.06431228e-01,  9.42871645e-02, -2.08013833e-01,\n",
            "        -2.69735938e-05,  3.86976438e-07, -1.01727331e-02,\n",
            "        -1.55184225e-07,  1.41120972e-02,  9.68242064e-04,\n",
            "        -8.53257179e-01,  4.93442029e-01,  4.31936525e-04,\n",
            "         2.32935527e-05, -1.90639748e-05,  6.59567240e-06,\n",
            "         4.98680572e-04, -4.74591076e-01,  9.34971094e-01,\n",
            "         1.87185943e-01,  9.97519255e-01,  8.55677307e-01,\n",
            "         5.20515742e-10, -1.96835175e-01, -4.31957915e-07,\n",
            "        -5.44428647e-01, -2.02905359e-09,  8.09631228e-01,\n",
            "         6.09258264e-02,  2.66834279e-04, -4.96342331e-01,\n",
            "         7.60991825e-04, -1.42852514e-06, -9.71184969e-01,\n",
            "        -7.52696097e-01,  6.69419169e-01,  6.56911969e-01,\n",
            "         8.68552718e-07,  8.66130292e-01,  5.65955877e-01,\n",
            "        -3.46842103e-06,  6.52417541e-03, -2.97220820e-03,\n",
            "         3.82691678e-06,  9.98661578e-01, -1.46206639e-05,\n",
            "        -4.78604048e-01, -9.88614261e-01,  6.38921862e-04,\n",
            "         9.06421721e-01,  4.43969412e-08,  4.16342914e-01,\n",
            "         1.86039940e-01,  4.91467763e-05, -9.56658304e-01,\n",
            "         1.48032397e-01,  4.03006698e-06, -3.92945902e-03,\n",
            "        -2.43884698e-02,  2.94170439e-01,  5.95631322e-09,\n",
            "         4.68617039e-08,  1.97423510e-02, -9.82613385e-01,\n",
            "        -8.35348070e-01, -6.79707637e-06,  5.34255952e-02,\n",
            "         3.95980533e-06,  9.63834047e-01, -2.09438676e-05,\n",
            "        -5.23373246e-01, -8.34865688e-08,  9.60591137e-01,\n",
            "        -1.01721004e-01, -4.13499457e-09, -9.98315334e-01,\n",
            "        -1.13760987e-02, -9.99947608e-01,  1.37805046e-07,\n",
            "         3.72642921e-06, -5.71305145e-06,  8.39560509e-01,\n",
            "         8.41946602e-01,  9.79022264e-01,  9.98140395e-01,\n",
            "        -8.12761858e-03, -8.38238280e-04, -9.42499518e-01,\n",
            "        -1.97193012e-01,  4.90487537e-06,  9.94820535e-01,\n",
            "        -1.26527585e-02, -9.42601621e-01, -7.53289580e-01,\n",
            "        -1.87884808e-07,  1.00000000e+00, -1.41365781e-01,\n",
            "         5.49565868e-07, -4.24144442e-10,  9.50620532e-01,\n",
            "         3.66483152e-01, -4.22247112e-01,  1.25571126e-02,\n",
            "         1.59536198e-01,  9.83718872e-01, -1.54149870e-03,\n",
            "        -1.57449534e-03,  2.82310275e-03,  2.31450535e-02,\n",
            "         3.49072570e-06,  3.87938023e-02,  1.42173434e-04,\n",
            "        -4.84945066e-03, -9.03712571e-01,  7.90369213e-01,\n",
            "         2.10805592e-06, -9.99510705e-01, -1.98778156e-02,\n",
            "         3.22563597e-03,  2.58916318e-02,  2.92486906e-01,\n",
            "        -9.95017052e-01,  6.31848820e-07, -1.07778441e-02,\n",
            "        -3.59215178e-02,  9.54158425e-01, -1.32308132e-03,\n",
            "         1.19824171e-01,  2.12891027e-01,  8.03582244e-13,\n",
            "         8.75882979e-04,  5.34999371e-02,  1.67792910e-04,\n",
            "        -1.07880157e-06, -9.90442216e-01,  3.88327683e-03,\n",
            "        -1.61576500e-05, -1.97491114e-04, -9.70810235e-01,\n",
            "         4.10658629e-07, -1.86648467e-05, -4.35473521e-06,\n",
            "        -9.99970078e-01]], dtype=float32)>, <tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
            "array([[ 5.4563231e+00,  5.4679651e+00, -1.0523995e+00, -4.5164056e+00,\n",
            "        -3.3249059e-01, -5.8802881e+00, -8.4178982e+00, -1.3551203e+01,\n",
            "        -1.3643578e+00,  8.5303869e+00,  3.0108058e+00,  1.2754618e+01,\n",
            "         7.6976638e+00, -1.0044140e+00, -1.2030682e+01, -8.5155840e+00,\n",
            "        -8.9208078e+00,  5.4350448e-01, -1.0735993e+00,  2.3072026e+00,\n",
            "        -1.3317562e+00, -4.1491928e+00,  9.1303277e-01, -1.2463189e+01,\n",
            "        -1.2185151e+01,  3.1467295e-01,  9.5558137e-01,  5.8872375e+00,\n",
            "         2.5184331e+00, -3.9287076e+00, -4.7667384e-01,  9.4992790e+00,\n",
            "         1.0204993e+00, -7.7475219e+00, -8.0862537e-02, -6.1122351e+00,\n",
            "        -1.9576401e+00, -8.5622883e+00,  8.3932238e+00,  2.0817225e-01,\n",
            "         9.1939107e-02,  9.9299717e-01, -1.6698354e-01, -1.4278998e+01,\n",
            "        -5.8695612e+00,  2.2422357e+00,  5.0682507e+00, -1.2254534e+00,\n",
            "         3.5193024e+00,  8.0165997e+00,  4.6678176e+00,  8.5284048e-01,\n",
            "         5.3278093e+00,  3.7337842e+00,  2.5460224e+00,  9.6159430e+00,\n",
            "         5.7296628e-01, -1.2834835e+01,  1.0355421e+00,  1.3643598e+01,\n",
            "        -3.9233844e+00,  3.9928803e+00, -5.3782458e+00,  6.2975378e+00,\n",
            "         9.9160538e+00, -1.3175792e+00, -1.0098965e+00,  3.8645689e+00,\n",
            "         1.7749878e+00, -2.1279283e+00,  4.9993596e+00,  6.8023777e+00,\n",
            "        -3.2398536e+00,  6.9412452e-01, -5.5336233e-02,  3.2480348e-02,\n",
            "         3.1515229e+00, -3.8436792e+00, -4.5959344e+00, -9.4787245e+00,\n",
            "        -2.8991723e+00, -4.2260098e+00,  4.4496889e+00,  3.2816356e-01,\n",
            "        -6.8884797e+00,  7.6365361e+00, -1.0424360e+00,  4.5035458e+00,\n",
            "         7.9785839e-02,  9.8842782e-01,  5.1342516e+00, -1.0698310e+00,\n",
            "        -1.0237599e-01, -5.7877369e+00, -2.0235443e+00, -7.5372357e+00,\n",
            "         7.0575457e+00, -1.7879382e+00, -4.2836280e+00,  2.6774464e+00,\n",
            "         7.6056975e-01, -3.0748868e+00, -1.1638622e+00, -2.3924260e+00,\n",
            "        -1.0756283e+00,  1.7846895e+00,  5.3172998e+00,  6.2468162e+00,\n",
            "         7.7236552e+00,  2.4623470e+00,  3.6685114e+00, -7.5577086e-01,\n",
            "         1.1197391e+00, -9.1098344e-01,  1.5937337e+00,  1.4280049e+00,\n",
            "        -2.1725780e-01, -4.0416269e+00,  9.1682434e+00, -2.4807186e-01,\n",
            "        -1.0936074e+01,  1.6178483e-01,  6.1565108e+00, -3.7344158e+00,\n",
            "         3.7779160e+00,  7.3468933e+00,  8.4922276e+00, -2.6372902e+00,\n",
            "         1.0870431e+01,  3.7033534e+00, -5.3336587e+00,  2.1631033e+00,\n",
            "         4.1096228e-01,  3.3867178e+00,  6.8193059e+00,  2.5243084e+00,\n",
            "        -1.9943899e-01, -7.0114956e+00, -6.1334854e-01, -7.0585477e-01,\n",
            "         3.7470150e+00,  5.9861679e+00,  5.5832529e+00, -2.7979496e+00,\n",
            "         9.9775785e-01, -8.4618902e+00, -2.3993881e+00, -1.3958473e+00,\n",
            "         2.6227121e+00,  7.8737485e-01,  9.5407715e+00,  1.3173879e+00,\n",
            "         6.4167792e-01, -2.0768998e+00,  3.4583140e-02, -7.1018949e+00,\n",
            "         1.4077190e+01,  4.0223203e+00, -2.8697588e+00, -7.4872084e+00,\n",
            "        -2.5918121e+00,  1.2104897e+01,  1.5071204e+00,  1.1064764e+00,\n",
            "         4.2720466e+00,  1.8835522e-01,  1.4352825e+00, -1.9327152e+00,\n",
            "         1.5195909e-01,  8.4019309e-01, -3.6259253e+00, -1.5445614e+00,\n",
            "         2.3351791e+00,  1.3163753e+01,  1.5205091e+00,  2.9908779e+00,\n",
            "        -2.8153834e+00, -1.3417685e+00, -6.8687530e+00,  4.8882875e+00,\n",
            "         2.8573086e+00,  1.9973459e+00, -1.3242561e+01, -6.5721989e+00,\n",
            "        -7.6054640e+00,  3.5598261e+00, -4.3828735e+00, -2.5152190e+00,\n",
            "        -3.7959645e+00, -2.3812063e-02, -5.3806424e+00,  7.4626646e+00,\n",
            "         2.1100278e-01, -3.7164598e+00,  1.2219653e+00,  1.2311270e+00,\n",
            "         3.3112078e+00,  3.6744368e+00, -2.6924136e+00, -1.9200430e+00,\n",
            "        -1.7604817e+00, -1.9942604e+00,  1.9752994e+00,  2.9768980e+00,\n",
            "        -6.8240075e+00, -2.6223640e+00, -9.8392415e-01, -4.9398847e+00,\n",
            "         9.6062880e+00, -2.6604905e+00,  2.2568913e-01, -1.0004097e+00,\n",
            "         1.8382051e+00,  6.7874036e+00, -3.4731758e+00,  4.1239753e+00,\n",
            "         1.6151863e-01,  6.6987524e+00, -5.8705392e+00, -1.7055336e-02,\n",
            "         5.0038567e+00,  3.6465838e+00,  9.2215385e+00,  6.8902950e+00,\n",
            "         6.9893284e+00, -8.9992231e-01, -1.4921381e+00,  1.7079769e+00,\n",
            "         2.3002141e+00, -5.9674239e+00, -2.3875813e-01,  7.5831547e+00,\n",
            "         9.8975545e-01,  6.7827625e+00, -3.4744980e+00,  8.1358910e+00,\n",
            "        -1.5484691e-02, -7.6775017e+00,  2.0279105e+00, -1.4680594e+00,\n",
            "         9.9718940e-01,  9.8506403e-01,  8.7694569e+00,  6.2250533e+00,\n",
            "         5.3554654e-02,  1.0227498e-01, -6.3284016e+00, -2.6693792e+00,\n",
            "         1.0110164e+00, -1.9589424e+00, -2.0084203e-04, -2.1062491e+00,\n",
            "         6.6245251e+00, -1.7162929e+00, -2.1055539e+00, -8.4136553e+00]],\n",
            "      dtype=float32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "996pFO8BLOfG"
      },
      "outputs": [],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "print('Mean BLEU score for Vanilla encoder decoder model is :',statistics.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTJ30oaQ5NhG",
        "outputId": "3c1b06e0-439f-434e-d8b1-dd74e0dd65d9"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean BLEU score for Vanilla encoder decoder model is : 0.9100080943583135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWFDxZXLOfJ"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Lx_5NA24KzRp"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.inp_vocab_size=inp_vocab_size\n",
        "        self.embedding_size=embedding_size\n",
        "        self.input_length=input_length\n",
        "        self.lstm_size=lstm_size\n",
        "        self.encoder_output = 0\n",
        "        self.encoder_state_h=0\n",
        "        self.encoder_state_c=0\n",
        "        self.embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True,return_sequences=True, name=\"Encoder_LSTM\")\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        # print(\"ENCODER ==> INPUT SQUENCES SHAPE :\",input_sequence.shape)\n",
        "        input_embedd                           = self.embedding(input_sequence)\n",
        "\n",
        "        self.encoder_output, self.encoder_state_h,self.encoder_state_c = self.lstm(input_embedd,states)\n",
        "        return self.encoder_output, self.encoder_state_h,self.encoder_state_c\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      self.initial_hidden_state=tf.zeros(shape=(batch_size,self.lstm_size))\n",
        "      self.initial_cell_state=tf.zeros(shape=(batch_size,self.lstm_size))\n",
        "      return [self.initial_hidden_state,self.initial_cell_state]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRoe65b9LB0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b80bda5-b91a-4225-f750-b29e557fa44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ab5SNdPZLlur"
      },
      "outputs": [],
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super().__init__()\n",
        "    self.scoring_function=scoring_function\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "    self.softmax=tf.keras.activations.softmax\n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      pass\n",
        "    if scoring_function == 'general':\n",
        "      # Intialize variables needed for General score function here\n",
        "      self.w=Dense(att_units)\n",
        "      pass\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "      self.w1=Dense(att_units,activation='tanh')\n",
        "      self.v=Dense(1)\n",
        "      pass\n",
        "  \n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "    #print(decoder_hidden_state.shape,encoder_output.shape)\n",
        "    decoder_hidden_state=tf.expand_dims(decoder_hidden_state,axis=1)\n",
        "    # print('Decoder hidden state',decoder_hidden_state.shape)\n",
        "    # print('Encoder output',encoder_output.shape)\n",
        "    if self.scoring_function == 'dot':\n",
        "        # Implement Dot score function here\n",
        "        score=tf.matmul(decoder_hidden_state,encoder_output,transpose_b=True)\n",
        "        #print('Dot Score',score.shape)\n",
        "        pass\n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        score=tf.matmul(decoder_hidden_state,self.w(encoder_output),transpose_b=True)\n",
        "        #print('general score',score.shape)\n",
        "        pass\n",
        "    elif self.scoring_function == 'concat':\n",
        "        # Implement General score function here\n",
        "        decoder_hidden_state=tf.tile(decoder_hidden_state, [1, tf.shape(encoder_output)[1], 1])\n",
        "        score=self.v(self.w1(tf.concat((decoder_hidden_state,encoder_output),axis=-1)))\n",
        "        #print('v*w[hei,hd',score.shape)\n",
        "        score=tf.transpose(score,[0,2,1])\n",
        "        #print('after transpose shape',score.shape)\n",
        "        pass\n",
        "    #print('score',score.shape)\n",
        "    final_scores=self.softmax(score)\n",
        "    #print('final score shape',final_scores.shape)\n",
        "    #print('encoder_output',encoder_output.shape)\n",
        "    context_vec=tf.matmul(final_scores,encoder_output)\n",
        "    #print('context_vec',context_vec.shape)\n",
        "    context_vec=tf.squeeze(context_vec,axis=1)\n",
        "    #print(context_vec.shape)\n",
        "    final_scores=tf.transpose(final_scores,[0,2,1])\n",
        "    #print('context vector shape',context_vec.shape)\n",
        "    return context_vec,final_scores\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "51x50h_TLrl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b62654-9f05-408e-e202-0294321d8883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Kc8m7lmOL097"
      },
      "outputs": [],
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      super().__init__()\n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "      self.embedding=Embedding(input_dim=tar_vocab_size,output_dim=embedding_dim,input_length=input_length,mask_zero=True)\n",
        "      self.lstm=LSTM(dec_units,return_state=True,return_sequences=True)\n",
        "      self.attention=Attention(score_fun,att_units)\n",
        "      self.dense=Dense(tar_vocab_size)\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "      '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "      # print('encoder_output',encoder_output.shape)\n",
        "      # print('state_c',state_c.shape)\n",
        "      # print('state_h',state_h.shape)\n",
        "      # print('decoder inp',input_to_decoder.shape)\n",
        "      input_embed=self.embedding(input_to_decoder)\n",
        "      #print('input_embedding',input_embed.shape)\n",
        "      context,attention_weights=self.attention(state_h,encoder_output)\n",
        "      #print('context',context.shape)\n",
        "      context=tf.expand_dims(context,axis=1)\n",
        "      #print('context after expanding',context.shape)\n",
        "      concat=tf.concat((context,input_embed),axis=-1)\n",
        "      #print('concat',concat.shape)\n",
        "      decoder_output,state_h,state_c=self.lstm(concat)\n",
        "      output=self.dense(decoder_output)\n",
        "      #print('output',output.shape)\n",
        "      #print('atlast context',context.shape)\n",
        "      return tf.squeeze(output,axis=1),state_h,state_c,attention_weights,tf.squeeze(context,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "uLEXhChnMC1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ebaaf4-cbf0-42bf-ac80-21f5657902c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=14\n",
        "    onestepdecoder=One_Step_Decoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "NV-x31rj6Hc4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      super().__init__()\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      self.osd=One_Step_Decoder(out_vocab_size,embedding_dim,input_length,dec_units,score_fun,att_units)\n",
        "    @tf.function     \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        all_outputs=tf.TensorArray(tf.float32,size=tf.shape(input_to_decoder)[1],name='output_arrays')\n",
        "        #Iterate till the length of the decoder input\n",
        "        \n",
        "        for timestep in range(tf.shape(input_to_decoder)[1]):\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # print('input passed to osd',input_to_decoder[:,timestep:timestep+1].shape)\n",
        "            output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector=self.osd(input_to_decoder[:,timestep:timestep+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n",
        "            # Store the output in tensorarray\n",
        "            all_outputs=all_outputs.write(timestep,output)\n",
        "        # Return the tensor array\n",
        "        all_outputs=tf.transpose(all_outputs.stack(),[1,0,2])\n",
        "        return all_outputs\n",
        "        \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "rtbx6onFMJXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbaf7597-c698-4faa-8494-9a3368dbf44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Decoder.call at 0x7f42d878c290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Decoder.call at 0x7f42d878c290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Decoder.call at 0x7f42d87e3050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Decoder.call at 0x7f42d87e3050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "FfqBIe20MT3D"
      },
      "outputs": [],
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self,encoder_inputs_length,decoder_inputs_length,batch_size,score_fun,att_units,encoder_size,decoder_size):\n",
        "    #Intialize objects from encoder decoder\n",
        "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
        "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita,embedding_size=100,input_length=encoder_inputs_length,lstm_size=encoder_size)\n",
        "        self.decoder = Decoder(out_vocab_size=vocab_size_eng,embedding_dim=100,input_length=decoder_inputs_length,dec_units=decoder_size,score_fun=score_fun,att_units=att_units)\n",
        "        self.td=TimeDistributed(Dense(vocab_size_eng, activation='softmax'))\n",
        "        self.batch_size=batch_size\n",
        "        self.initial_states = self.encoder.initialize_states(self.batch_size)\n",
        "  \n",
        "  def call(self,data):\n",
        "        encoder_inp=data[0]\n",
        "        decoder_inp=data[1]\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "        encoder_output,encoder_state_h,encoder_state_c=self.encoder(encoder_inp,self.initial_states)\n",
        "        output=self.decoder(decoder_inp,encoder_output,encoder_state_h,encoder_state_c)\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    # return the decoder output\n",
        "        return output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QY_3izrXMs8y"
      },
      "outputs": [],
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QlbWAqNNlqe"
      },
      "source": [
        "<font color='blue'>**Training**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dot_model = encoder_decoder(encoder_inputs_length=25,decoder_inputs_length=25,batch_size=1024,score_fun='dot',att_units=64,encoder_size=256,decoder_size=256)"
      ],
      "metadata": {
        "id": "7CQyOKByrkIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler"
      ],
      "metadata": {
        "id": "cTzIkEnQXY-x"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch,lr):\n",
        "  if epoch%2==1:\n",
        "    lr=0.9*lr\n",
        "  return lr\n",
        "callbacks=[ModelCheckpoint(filepath='best_dot_model.h5',save_best_only=True,mode='min',save_weights_only=True),\n",
        "           LearningRateScheduler(scheduler)]"
      ],
      "metadata": {
        "id": "s5_eO--qXs97"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "dot_model.compile(optimizer=optimizer,loss=loss_function)\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "dot_model.fit(train_dataloader, batch_size=1024,steps_per_epoch=train_steps, epochs=50, validation_data=test_dataloader, validation_steps=valid_steps,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I1zAVNnmtksT",
        "outputId": "dd44e040-620b-425a-fad5-78144d4a5458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (1024, 25)\n",
            "Epoch 1/50\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "276/276 [==============================] - ETA: 0s - loss: 1.2782ENCODER ==> INPUT SQUENCES SHAPE : (None, None)\n",
            "276/276 [==============================] - 140s 417ms/step - loss: 1.2782 - val_loss: 1.0591 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "276/276 [==============================] - 113s 410ms/step - loss: 0.9666 - val_loss: 0.8837 - lr: 0.0090\n",
            "Epoch 3/50\n",
            "276/276 [==============================] - 113s 408ms/step - loss: 0.7668 - val_loss: 0.6558 - lr: 0.0090\n",
            "Epoch 4/50\n",
            "276/276 [==============================] - 113s 411ms/step - loss: 0.5124 - val_loss: 0.4537 - lr: 0.0081\n",
            "Epoch 5/50\n",
            "276/276 [==============================] - 114s 413ms/step - loss: 0.3571 - val_loss: 0.3667 - lr: 0.0081\n",
            "Epoch 6/50\n",
            "276/276 [==============================] - 114s 411ms/step - loss: 0.2713 - val_loss: 0.3102 - lr: 0.0073\n",
            "Epoch 7/50\n",
            "276/276 [==============================] - 113s 408ms/step - loss: 0.2194 - val_loss: 0.2849 - lr: 0.0073\n",
            "Epoch 8/50\n",
            "276/276 [==============================] - 113s 408ms/step - loss: 0.1822 - val_loss: 0.2657 - lr: 0.0066\n",
            "Epoch 9/50\n",
            "276/276 [==============================] - 113s 408ms/step - loss: 0.1625 - val_loss: 0.2576 - lr: 0.0066\n",
            "Epoch 10/50\n",
            "276/276 [==============================] - 114s 411ms/step - loss: 0.1430 - val_loss: 0.2446 - lr: 0.0059\n",
            "Epoch 11/50\n",
            "276/276 [==============================] - 115s 416ms/step - loss: 0.1288 - val_loss: 0.2423 - lr: 0.0059\n",
            "Epoch 12/50\n",
            "276/276 [==============================] - 120s 435ms/step - loss: 0.1139 - val_loss: 0.2374 - lr: 0.0053\n",
            "Epoch 13/50\n",
            "276/276 [==============================] - 114s 413ms/step - loss: 0.1041 - val_loss: 0.2339 - lr: 0.0053\n",
            "Epoch 14/50\n",
            "276/276 [==============================] - 114s 411ms/step - loss: 0.0950 - val_loss: 0.2297 - lr: 0.0048\n",
            "Epoch 15/50\n",
            "276/276 [==============================] - 113s 411ms/step - loss: 0.0876 - val_loss: 0.2285 - lr: 0.0048\n",
            "Epoch 16/50\n",
            "276/276 [==============================] - 111s 403ms/step - loss: 0.0807 - val_loss: 0.2292 - lr: 0.0043\n",
            "Epoch 17/50\n",
            "276/276 [==============================] - 112s 406ms/step - loss: 0.0753 - val_loss: 0.2269 - lr: 0.0043\n",
            "Epoch 18/50\n",
            "276/276 [==============================] - 112s 405ms/step - loss: 0.0713 - val_loss: 0.2266 - lr: 0.0039\n",
            "Epoch 19/50\n",
            "276/276 [==============================] - 112s 406ms/step - loss: 0.0669 - val_loss: 0.2263 - lr: 0.0039\n",
            "Epoch 20/50\n",
            "276/276 [==============================] - 112s 406ms/step - loss: 0.0620 - val_loss: 0.2290 - lr: 0.0035\n",
            "Epoch 21/50\n",
            "276/276 [==============================] - 112s 406ms/step - loss: 0.0636 - val_loss: 0.2287 - lr: 0.0035\n",
            "Epoch 22/50\n",
            "276/276 [==============================] - 114s 411ms/step - loss: 0.0563 - val_loss: 0.2252 - lr: 0.0031\n",
            "Epoch 23/50\n",
            "276/276 [==============================] - 113s 411ms/step - loss: 0.0530 - val_loss: 0.2289 - lr: 0.0031\n",
            "Epoch 24/50\n",
            "276/276 [==============================] - 113s 410ms/step - loss: 0.0502 - val_loss: 0.2305 - lr: 0.0028\n",
            "Epoch 25/50\n",
            " 24/276 [=>............................] - ETA: 1:29 - loss: 0.0447"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-c80c4bd3b0ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdot_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dot_model.load_weights('/content/best_dot_model.h5')"
      ],
      "metadata": {
        "id": "gpyyPBlIXhnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_model.evaluate(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJhoCGiNP-6u",
        "outputId": "4931cb48-22fb-4fc1-bd6b-a9159f314706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 15s 213ms/step - loss: 0.2252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22516530752182007"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtZUQF2NuZE"
      },
      "source": [
        "Implement dot function here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZGp6qEzQo6pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgyWwZWeMxGQ"
      },
      "outputs": [],
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "# decoder output should be\n",
        "# Hi How are you <end>\n",
        "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
        "\n",
        "# or\n",
        " \n",
        "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
        "# Note: If you follow this approach some grader functions might return false and this is fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "## <font color='blue'>**Inference**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "<font color='blue'>**Plot attention weights**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pkEY7SsBMtrC"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "def plot_attention(input,prediction,attention):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "  attention=np.squeeze(np.array(attention))\n",
        "  ax = sns.heatmap(attention, linewidth=0.5,xticklabels=input.split(),yticklabels=prediction.split())\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MP3kLZoPMvSu"
      },
      "outputs": [],
      "source": [
        "def attention_predict(input_sentence,model):\n",
        "  \n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  final_sentence =[]\n",
        "  attention = []\n",
        "  enc_ita_data = np.array(tknizer_ita.texts_to_sequences(np.array([input_sentence])))\n",
        "  # print(enc_ita_data)\n",
        "  # print(enc_ita_data.shape)\n",
        "  initial_state = model.encoder.initialize_states(batch_size = 1)\n",
        "  #print(enc_ita_data)\n",
        "  #print(type(enc_ita_data))\n",
        "  encoder_output, encoder_h, encoder_c = model.layers[0](enc_ita_data,initial_state)\n",
        "  # print('Encoder Output',encoder_output.shape)\n",
        "  # print('Encoder Hidden',encoder_h.shape)\n",
        "  # print('Encoder cell',encoder_c.shape)\n",
        "  decoder_input = np.array(tknizer_eng.texts_to_sequences(np.array(['<start>'])))\n",
        "  #print('decoder_input',decoder_input.shape)\n",
        "  #print(decoder_input)\n",
        "  max_length = 25 # in data preprocessing we have remove all datapoints which are greater then 20\n",
        "  for i in range(max_length):\n",
        "\n",
        "    predicted_out,state_h,state_c,attn_weights,context =   model.layers[1].osd(decoder_input,encoder_output,encoder_h,encoder_c)\n",
        "\n",
        "    encoder_h = state_h\n",
        "    encoder_c = state_c\n",
        "    attention.extend(attn_weights)\n",
        "\n",
        "    #print(output.shape)\n",
        "    #print(np.argmax(output))\n",
        "    #print(output)\n",
        "    vec = np.argmax(predicted_out)\n",
        "    word = tknizer_eng.index_word[vec]\n",
        "    decoder_input = np.array([np.array([vec])])\n",
        "    #print(decoder_input)\n",
        "    #break\n",
        "    final_sentence.append(word)\n",
        "    if vec == tknizer_eng.word_index['<end>']:\n",
        "      return ' '.join(final_sentence),attention\n",
        "      \n",
        "\n",
        "  return ' '.join(final_sentence),attention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=10009\n",
        "sent,attention=attention_predict(data['italian'][i],dot_model)\n",
        "plot_attention(data['italian'][i],sent,attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "oswiwDfnnJMt",
        "outputId": "d0aee4fc-193f-4a2f-a7b2-98a7777d9d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=data.sample(1000)\n",
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lcP5yaiXCV3G",
        "outputId": "d9fae626-5fc6-42a7-9870-05c14fce1df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   italian  \\\n",
              "134846      lui mi ha salvata dal pericolo   \n",
              "276574  dovresti andare a messa più spesso   \n",
              "84557                 tu ne vorresti un po   \n",
              "229877      attualmente abito in australia   \n",
              "21707                           non ero io   \n",
              "\n",
              "                                     english_inp  \\\n",
              "134846           <start> he saved me from danger   \n",
              "276574  <start> you should go to mass more often   \n",
              "84557                <start> would you like some   \n",
              "229877     <start> i currently live in australia   \n",
              "21707                    <start> that was not me   \n",
              "\n",
              "                                   english_out  \n",
              "134846           he saved me from danger <end>  \n",
              "276574  you should go to mass more often <end>  \n",
              "84557                would you like some <end>  \n",
              "229877     i currently live in australia <end>  \n",
              "21707                    that was not me <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-270b2ce7-4461-4809-9ba6-3bc38489ce61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134846</th>\n",
              "      <td>lui mi ha salvata dal pericolo</td>\n",
              "      <td>&lt;start&gt; he saved me from danger</td>\n",
              "      <td>he saved me from danger &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276574</th>\n",
              "      <td>dovresti andare a messa più spesso</td>\n",
              "      <td>&lt;start&gt; you should go to mass more often</td>\n",
              "      <td>you should go to mass more often &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84557</th>\n",
              "      <td>tu ne vorresti un po</td>\n",
              "      <td>&lt;start&gt; would you like some</td>\n",
              "      <td>would you like some &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229877</th>\n",
              "      <td>attualmente abito in australia</td>\n",
              "      <td>&lt;start&gt; i currently live in australia</td>\n",
              "      <td>i currently live in australia &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21707</th>\n",
              "      <td>non ero io</td>\n",
              "      <td>&lt;start&gt; that was not me</td>\n",
              "      <td>that was not me &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-270b2ce7-4461-4809-9ba6-3bc38489ce61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-270b2ce7-4461-4809-9ba6-3bc38489ce61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-270b2ce7-4461-4809-9ba6-3bc38489ce61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iHiLdROM23l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffff9c05-6aa7-4def-d036-f1062fd4d02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 12)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 14)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 15)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 20)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 16)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 12)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 12)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 12)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 12)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 12)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 13)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 13)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 13)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 13)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 14)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 20)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 1)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 11)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 10)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 9)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 8)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 7)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 12)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 5)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 4)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 3)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 2)\n",
            "ENCODER ==> INPUT SQUENCES SHAPE : (1, 6)\n"
          ]
        }
      ],
      "source": [
        "#Create an object of your custom model.\n",
        "#Compile and train your model on dot scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "#Sample example\n",
        "scores=[]\n",
        "import statistics\n",
        "import nltk.translate.bleu_score as bleu\n",
        "for i in range(len(test)):\n",
        "  prediction,weights=attention_predict(test['italian'].values[i],dot_model)\n",
        "  reference = [test['english_out'].values[i].split()] # the original\n",
        "  translation = prediction.split() # trasilated using model\n",
        "  scores.append(bleu.sentence_bleu(reference, translation,weights=(1,0,0,0)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Average BLEU score :',statistics.mean(scores))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzqvMv34FZE_",
        "outputId": "d67bf2a6-1456-4286-b441-872dedb1e241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU score : 0.8012174915429399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWg2ferDQvT3"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Rh9_w79M5JO"
      },
      "outputs": [],
      "source": [
        "#Compile and train your model on general scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "general_model = encoder_decoder(encoder_inputs_length=25,decoder_inputs_length=25,batch_size=1024,score_fun='general',att_units=256,encoder_size=256,decoder_size=256)"
      ],
      "metadata": {
        "id": "QhfqtSJSF91j"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler2(epoch,lr):\n",
        "  if epoch%2==1:\n",
        "    lr=0.9*lr\n",
        "  return lr\n",
        "callbacks=[ModelCheckpoint(filepath='best_general_model.h5',save_best_only=True,mode='min',save_weights_only=True),\n",
        "           LearningRateScheduler(scheduler2)]#LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "XaVhwimyLcrE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "general_model.compile(optimizer=optimizer,loss=loss_function)\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "general_model.fit(train_dataloader, batch_size=1024,steps_per_epoch=train_steps, epochs=50, validation_data=test_dataloader, validation_steps=valid_steps,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "osbhUwk7Lp4R",
        "outputId": "2214d7ec-e719-4e21-f3f2-21f8d44745b3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "276/276 [==============================] - 118s 407ms/step - loss: 1.5119 - val_loss: 1.3561 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "276/276 [==============================] - 112s 405ms/step - loss: 1.2336 - val_loss: 1.1029 - lr: 0.0090\n",
            "Epoch 3/50\n",
            "276/276 [==============================] - 112s 406ms/step - loss: 0.9633 - val_loss: 0.7942 - lr: 0.0090\n",
            "Epoch 4/50\n",
            "276/276 [==============================] - 112s 404ms/step - loss: 0.6649 - val_loss: 0.5628 - lr: 0.0081\n",
            "Epoch 5/50\n",
            "276/276 [==============================] - 112s 407ms/step - loss: 0.4781 - val_loss: 0.4413 - lr: 0.0081\n",
            "Epoch 6/50\n",
            "276/276 [==============================] - 111s 402ms/step - loss: 0.3698 - val_loss: 0.3706 - lr: 0.0073\n",
            "Epoch 7/50\n",
            "276/276 [==============================] - 112s 405ms/step - loss: 0.3027 - val_loss: 0.3264 - lr: 0.0073\n",
            "Epoch 8/50\n",
            "276/276 [==============================] - 113s 409ms/step - loss: 0.2557 - val_loss: 0.2940 - lr: 0.0066\n",
            "Epoch 9/50\n",
            "276/276 [==============================] - 111s 403ms/step - loss: 0.2231 - val_loss: 0.2766 - lr: 0.0066\n",
            "Epoch 10/50\n",
            "276/276 [==============================] - 111s 403ms/step - loss: 0.1925 - val_loss: 0.2574 - lr: 0.0059\n",
            "Epoch 11/50\n",
            "276/276 [==============================] - 111s 403ms/step - loss: 0.1729 - val_loss: 0.2505 - lr: 0.0059\n",
            "Epoch 12/50\n",
            "276/276 [==============================] - 111s 402ms/step - loss: 0.1550 - val_loss: 0.2378 - lr: 0.0053\n",
            "Epoch 13/50\n",
            "276/276 [==============================] - 111s 401ms/step - loss: 0.1413 - val_loss: 0.2314 - lr: 0.0053\n",
            "Epoch 14/50\n",
            "276/276 [==============================] - 112s 407ms/step - loss: 0.1293 - val_loss: 0.2288 - lr: 0.0048\n",
            "Epoch 15/50\n",
            "276/276 [==============================] - 111s 402ms/step - loss: 0.1222 - val_loss: 0.2222 - lr: 0.0048\n",
            "Epoch 16/50\n",
            "276/276 [==============================] - 111s 402ms/step - loss: 0.1189 - val_loss: 0.2238 - lr: 0.0043\n",
            "Epoch 17/50\n",
            "276/276 [==============================] - 113s 410ms/step - loss: 0.1105 - val_loss: 0.2169 - lr: 0.0043\n",
            "Epoch 18/50\n",
            "276/276 [==============================] - 111s 403ms/step - loss: 0.0983 - val_loss: 0.2128 - lr: 0.0039\n",
            "Epoch 19/50\n",
            "276/276 [==============================] - 110s 399ms/step - loss: 0.0912 - val_loss: 0.2110 - lr: 0.0039\n",
            "Epoch 20/50\n",
            "276/276 [==============================] - 111s 403ms/step - loss: 0.0867 - val_loss: 0.2131 - lr: 0.0035\n",
            "Epoch 21/50\n",
            "276/276 [==============================] - 112s 407ms/step - loss: 0.0822 - val_loss: 0.2093 - lr: 0.0035\n",
            "Epoch 22/50\n",
            "276/276 [==============================] - 112s 406ms/step - loss: 0.0770 - val_loss: 0.2092 - lr: 0.0031\n",
            "Epoch 23/50\n",
            "276/276 [==============================] - 111s 402ms/step - loss: 0.0732 - val_loss: 0.2086 - lr: 0.0031\n",
            "Epoch 24/50\n",
            "276/276 [==============================] - 112s 406ms/step - loss: 0.0691 - val_loss: 0.2076 - lr: 0.0028\n",
            "Epoch 25/50\n",
            "276/276 [==============================] - 111s 403ms/step - loss: 0.0667 - val_loss: 0.2081 - lr: 0.0028\n",
            "Epoch 26/50\n",
            "276/276 [==============================] - 111s 402ms/step - loss: 0.0628 - val_loss: 0.2071 - lr: 0.0025\n",
            "Epoch 27/50\n",
            "276/276 [==============================] - 112s 404ms/step - loss: 0.0613 - val_loss: 0.2089 - lr: 0.0025\n",
            "Epoch 28/50\n",
            "276/276 [==============================] - 112s 404ms/step - loss: 0.0592 - val_loss: 0.2091 - lr: 0.0023\n",
            "Epoch 29/50\n",
            " 21/276 [=>............................] - ETA: 1:35 - loss: 0.0537"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-93db1de87973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgeneral_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "general_model.load_weights('best_general_model.h5')"
      ],
      "metadata": {
        "id": "8dj6a1o_wJAT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "general_model.evaluate(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAq2-Q8Ew0v5",
        "outputId": "d7503663-0ae5-4129-b765-f94ff8757324"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 10s 143ms/step - loss: 0.2071\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20712852478027344"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=10009\n",
        "sent,attention=attention_predict(data['italian'][i],general_model)\n",
        "plot_attention(data['italian'][i],sent,attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "aPW80t5SxDit",
        "outputId": "9a215e7a-13ec-4451-e1a8-8267d1695e7b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=data.sample(1000)\n",
        "scores=[]\n",
        "import statistics\n",
        "import nltk.translate.bleu_score as bleu\n",
        "for i in range(len(test)):\n",
        "  prediction,weights=attention_predict(test['italian'].values[i],general_model)\n",
        "  reference = [test['english_out'].values[i].split()] # the original\n",
        "  translation = prediction.split() # trasilated using model\n",
        "  scores.append(bleu.sentence_bleu(reference, translation,weights=(1,0,0,0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG3T-UK3xzu_",
        "outputId": "b4cbc5a7-579d-4f9e-e409-62ce378c11a9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "print('Average BLEU score for Model with General score function is :',statistics.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLyPiSLtyO8o",
        "outputId": "f70eb485-9f2b-4040-9321-8fa698125a00"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU score for Model with General score function is : 0.8888081117757333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kN9ZWViQNMB"
      },
      "outputs": [],
      "source": [
        "#Compile and train your model on concat scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concat_model = encoder_decoder(encoder_inputs_length=25,decoder_inputs_length=25,batch_size=1024,score_fun='concat',att_units=64,encoder_size=256,decoder_size=256)"
      ],
      "metadata": {
        "id": "dJVEfpdtyp0q"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler2(epoch,lr):\n",
        "  if epoch%2==1:\n",
        "    lr=0.9*lr\n",
        "  return lr\n",
        "callbacks=[ModelCheckpoint(filepath='best_concat_model.h5',save_best_only=True,mode='min',save_weights_only=True),\n",
        "           LearningRateScheduler(scheduler2)]"
      ],
      "metadata": {
        "id": "moRSHxu1y0tC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "concat_model.compile(optimizer=optimizer,loss=loss_function)\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "concat_model.fit(train_dataloader, batch_size=1024,steps_per_epoch=train_steps, epochs=50, validation_data=test_dataloader, validation_steps=valid_steps,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8Yda5_m3y4w6",
        "outputId": "4c0cfc3b-8c22-4704-c9c1-308dd9833efb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "276/276 [==============================] - 130s 454ms/step - loss: 1.5095 - val_loss: 1.3742 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "276/276 [==============================] - 124s 450ms/step - loss: 1.2085 - val_loss: 1.0538 - lr: 0.0090\n",
            "Epoch 3/50\n",
            "276/276 [==============================] - 124s 449ms/step - loss: 0.9075 - val_loss: 0.8924 - lr: 0.0090\n",
            "Epoch 4/50\n",
            "276/276 [==============================] - 126s 456ms/step - loss: 0.6944 - val_loss: 0.7545 - lr: 0.0081\n",
            "Epoch 5/50\n",
            "276/276 [==============================] - 124s 449ms/step - loss: 0.5235 - val_loss: 0.6163 - lr: 0.0081\n",
            "Epoch 6/50\n",
            "276/276 [==============================] - 124s 448ms/step - loss: 0.3947 - val_loss: 0.5470 - lr: 0.0073\n",
            "Epoch 7/50\n",
            "276/276 [==============================] - 125s 453ms/step - loss: 0.3179 - val_loss: 0.5038 - lr: 0.0073\n",
            "Epoch 8/50\n",
            "276/276 [==============================] - 125s 452ms/step - loss: 0.2603 - val_loss: 0.4751 - lr: 0.0066\n",
            "Epoch 9/50\n",
            "276/276 [==============================] - 134s 485ms/step - loss: 0.2238 - val_loss: 0.4740 - lr: 0.0066\n",
            "Epoch 10/50\n",
            "276/276 [==============================] - 125s 452ms/step - loss: 0.1937 - val_loss: 0.4438 - lr: 0.0059\n",
            "Epoch 11/50\n",
            "276/276 [==============================] - 125s 453ms/step - loss: 0.1733 - val_loss: 0.4413 - lr: 0.0059\n",
            "Epoch 12/50\n",
            "276/276 [==============================] - 124s 450ms/step - loss: 0.1535 - val_loss: 0.4336 - lr: 0.0053\n",
            "Epoch 13/50\n",
            "276/276 [==============================] - 125s 454ms/step - loss: 0.1397 - val_loss: 0.4399 - lr: 0.0053\n",
            "Epoch 14/50\n",
            "276/276 [==============================] - 126s 455ms/step - loss: 0.1264 - val_loss: 0.4114 - lr: 0.0048\n",
            "Epoch 15/50\n",
            "276/276 [==============================] - 124s 450ms/step - loss: 0.1193 - val_loss: 0.4158 - lr: 0.0048\n",
            "Epoch 16/50\n",
            "276/276 [==============================] - 125s 453ms/step - loss: 0.1107 - val_loss: 0.3953 - lr: 0.0043\n",
            "Epoch 17/50\n",
            "276/276 [==============================] - 124s 451ms/step - loss: 0.1043 - val_loss: 0.4136 - lr: 0.0043\n",
            "Epoch 18/50\n",
            "276/276 [==============================] - 124s 450ms/step - loss: 0.0962 - val_loss: 0.4005 - lr: 0.0039\n",
            "Epoch 19/50\n",
            "276/276 [==============================] - 126s 455ms/step - loss: 0.0890 - val_loss: 0.4035 - lr: 0.0039\n",
            "Epoch 20/50\n",
            "276/276 [==============================] - 124s 450ms/step - loss: 0.0827 - val_loss: 0.3969 - lr: 0.0035\n",
            "Epoch 21/50\n",
            "276/276 [==============================] - 125s 452ms/step - loss: 0.0791 - val_loss: 0.4093 - lr: 0.0035\n",
            "Epoch 22/50\n",
            "276/276 [==============================] - 126s 456ms/step - loss: 0.0743 - val_loss: 0.3987 - lr: 0.0031\n",
            "Epoch 23/50\n",
            "276/276 [==============================] - 124s 450ms/step - loss: 0.0707 - val_loss: 0.4011 - lr: 0.0031\n",
            "Epoch 24/50\n",
            "276/276 [==============================] - 124s 451ms/step - loss: 0.0671 - val_loss: 0.4027 - lr: 0.0028\n",
            "Epoch 25/50\n",
            "276/276 [==============================] - 125s 454ms/step - loss: 0.0644 - val_loss: 0.4014 - lr: 0.0028\n",
            "Epoch 26/50\n",
            "276/276 [==============================] - 125s 451ms/step - loss: 0.0614 - val_loss: 0.4232 - lr: 0.0025\n",
            "Epoch 27/50\n",
            "276/276 [==============================] - 134s 487ms/step - loss: 0.0589 - val_loss: 0.4274 - lr: 0.0025\n",
            "Epoch 28/50\n",
            " 25/276 [=>............................] - ETA: 1:42 - loss: 0.0542"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-676763287755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concat_model.load_weights('/content/best_concat_model.h5')"
      ],
      "metadata": {
        "id": "-h2zrhEHc0Fz"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concat_model.evaluate(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOqZr1rjc7DG",
        "outputId": "8304eff3-6daf-4a63-d9bd-88ade4b33d91"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 15s 217ms/step - loss: 0.3953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3953363597393036"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=10009\n",
        "sent,attention=attention_predict(data['italian'][i],concat_model)\n",
        "plot_attention(data['italian'][i],sent,attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_S8cPfSrdFbU",
        "outputId": "1b320a00-0c1a-420c-a1a8-fa1bf41b0236"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=data.sample(1000)\n",
        "scores=[]\n",
        "import statistics\n",
        "import nltk.translate.bleu_score as bleu\n",
        "for i in range(len(test)):\n",
        "  prediction,weights=attention_predict(test['italian'].values[i],concat_model)\n",
        "  reference = [test['english_out'].values[i].split()] # the original\n",
        "  translation = prediction.split() # trasilated using model\n",
        "  scores.append(bleu.sentence_bleu(reference, translation,weights=(1,0,0,0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MEy86ltdaq6",
        "outputId": "a41e048e-f915-437b-9184-e4100b157339"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "print('Average BLEU score for Model with Concat score function is :',statistics.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwvSBl-kdkGO",
        "outputId": "222afdb3-0222-4887-daa6-c6468532751e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU score for Model with Concat score function is : 0.7295647526276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff1lV0ITM6_p"
      },
      "outputs": [],
      "source": [
        "# Write your observations on each of the scoring function"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Seq2SeqImplementation__Assignment.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}