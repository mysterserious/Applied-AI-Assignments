{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wVIx_KIigxPV"
      },
      "outputs": [],
      "source": [
        "# import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UNHw6luQg3gc"
      },
      "outputs": [],
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dsO_yGxcg5D8"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB7o3zu1g6eT",
        "outputId": "b276e99d-27d9-4ab5-e404-57b6c499f783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lAk_Mw_5-rn",
        "outputId": "1dd2f17f-c81c-4798-ce50-b24d31e250e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVkpgHsc5-rp",
        "outputId": "3094eb25-49eb-45a1-bf50-6eedd7c5d5a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPU0oAjzIoY_",
        "outputId": "9b1f2465-9d96-4d29-d841-f709107e6c4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wJ1Zi8OmIu1Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x_tr=X_train.astype('float')/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y29ZHDcI7l3",
        "outputId": "2ed6e0d7-8670-4282-e47e-e6f85301a165"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.23137255, 0.24313725, 0.24705882],\n",
              "        [0.16862745, 0.18039216, 0.17647059],\n",
              "        [0.19607843, 0.18823529, 0.16862745],\n",
              "        ...,\n",
              "        [0.61960784, 0.51764706, 0.42352941],\n",
              "        [0.59607843, 0.49019608, 0.4       ],\n",
              "        [0.58039216, 0.48627451, 0.40392157]],\n",
              "\n",
              "       [[0.0627451 , 0.07843137, 0.07843137],\n",
              "        [0.        , 0.        , 0.        ],\n",
              "        [0.07058824, 0.03137255, 0.        ],\n",
              "        ...,\n",
              "        [0.48235294, 0.34509804, 0.21568627],\n",
              "        [0.46666667, 0.3254902 , 0.19607843],\n",
              "        [0.47843137, 0.34117647, 0.22352941]],\n",
              "\n",
              "       [[0.09803922, 0.09411765, 0.08235294],\n",
              "        [0.0627451 , 0.02745098, 0.        ],\n",
              "        [0.19215686, 0.10588235, 0.03137255],\n",
              "        ...,\n",
              "        [0.4627451 , 0.32941176, 0.19607843],\n",
              "        [0.47058824, 0.32941176, 0.19607843],\n",
              "        [0.42745098, 0.28627451, 0.16470588]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.81568627, 0.66666667, 0.37647059],\n",
              "        [0.78823529, 0.6       , 0.13333333],\n",
              "        [0.77647059, 0.63137255, 0.10196078],\n",
              "        ...,\n",
              "        [0.62745098, 0.52156863, 0.2745098 ],\n",
              "        [0.21960784, 0.12156863, 0.02745098],\n",
              "        [0.20784314, 0.13333333, 0.07843137]],\n",
              "\n",
              "       [[0.70588235, 0.54509804, 0.37647059],\n",
              "        [0.67843137, 0.48235294, 0.16470588],\n",
              "        [0.72941176, 0.56470588, 0.11764706],\n",
              "        ...,\n",
              "        [0.72156863, 0.58039216, 0.36862745],\n",
              "        [0.38039216, 0.24313725, 0.13333333],\n",
              "        [0.3254902 , 0.20784314, 0.13333333]],\n",
              "\n",
              "       [[0.69411765, 0.56470588, 0.45490196],\n",
              "        [0.65882353, 0.50588235, 0.36862745],\n",
              "        [0.70196078, 0.55686275, 0.34117647],\n",
              "        ...,\n",
              "        [0.84705882, 0.72156863, 0.54901961],\n",
              "        [0.59215686, 0.4627451 , 0.32941176],\n",
              "        [0.48235294, 0.36078431, 0.28235294]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x_tr[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3vqCNeBC_ZzS"
      },
      "outputs": [],
      "source": [
        "x_te=X_test.astype('float')/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esLF0O9f_w9G",
        "outputId": "f341f509-8714-4de3-9e01-6334ff80d8c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.61960784, 0.43921569, 0.19215686],\n",
              "        [0.62352941, 0.43529412, 0.18431373],\n",
              "        [0.64705882, 0.45490196, 0.2       ],\n",
              "        ...,\n",
              "        [0.5372549 , 0.37254902, 0.14117647],\n",
              "        [0.49411765, 0.35686275, 0.14117647],\n",
              "        [0.45490196, 0.33333333, 0.12941176]],\n",
              "\n",
              "       [[0.59607843, 0.43921569, 0.2       ],\n",
              "        [0.59215686, 0.43137255, 0.15686275],\n",
              "        [0.62352941, 0.44705882, 0.17647059],\n",
              "        ...,\n",
              "        [0.53333333, 0.37254902, 0.12156863],\n",
              "        [0.49019608, 0.35686275, 0.1254902 ],\n",
              "        [0.46666667, 0.34509804, 0.13333333]],\n",
              "\n",
              "       [[0.59215686, 0.43137255, 0.18431373],\n",
              "        [0.59215686, 0.42745098, 0.12941176],\n",
              "        [0.61960784, 0.43529412, 0.14117647],\n",
              "        ...,\n",
              "        [0.54509804, 0.38431373, 0.13333333],\n",
              "        [0.50980392, 0.37254902, 0.13333333],\n",
              "        [0.47058824, 0.34901961, 0.12941176]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.26666667, 0.48627451, 0.69411765],\n",
              "        [0.16470588, 0.39215686, 0.58039216],\n",
              "        [0.12156863, 0.34509804, 0.5372549 ],\n",
              "        ...,\n",
              "        [0.14901961, 0.38039216, 0.57254902],\n",
              "        [0.05098039, 0.25098039, 0.42352941],\n",
              "        [0.15686275, 0.33333333, 0.49803922]],\n",
              "\n",
              "       [[0.23921569, 0.45490196, 0.65882353],\n",
              "        [0.19215686, 0.4       , 0.58039216],\n",
              "        [0.1372549 , 0.33333333, 0.51764706],\n",
              "        ...,\n",
              "        [0.10196078, 0.32156863, 0.50980392],\n",
              "        [0.11372549, 0.32156863, 0.49411765],\n",
              "        [0.07843137, 0.25098039, 0.41960784]],\n",
              "\n",
              "       [[0.21176471, 0.41960784, 0.62745098],\n",
              "        [0.21960784, 0.41176471, 0.58431373],\n",
              "        [0.17647059, 0.34901961, 0.51764706],\n",
              "        ...,\n",
              "        [0.09411765, 0.30196078, 0.48627451],\n",
              "        [0.13333333, 0.32941176, 0.50588235],\n",
              "        [0.08235294, 0.2627451 , 0.43137255]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x_te[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qNRKAdoVKYth"
      },
      "outputs": [],
      "source": [
        "datagen=ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LrJGr-X-Vohl"
      },
      "outputs": [],
      "source": [
        "#datagen.fit(x_tr_16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ee-sge5Kg7vr"
      },
      "outputs": [],
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate,name='Dropout'+str(block)+str(_))(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False,kernel_regularizer=regularizers.l2(0.0003) ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "anPCpQWhhGb7"
      },
      "outputs": [],
      "source": [
        "num_filter = 36\n",
        "dropout_rate = 0\n",
        "l = 12\n",
        "input = layers.Input(shape=(img_height, img_width, channel,),name='input_layer')\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same',name='first_conv',kernel_regularizer=regularizers.l2(0.0003))(input)\n",
        "block=1\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "block=2\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "block=3\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "block=4\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "c5Wksy8z5-rw",
        "outputId": "66006fd8-a07e-4d6f-bf30-94bb1f18c49e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f99db0ed110>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/-W6y8xnd--U\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#https://arxiv.org/pdf/1608.06993.pdf\n",
        "from IPython.display import IFrame, YouTubeVideo\n",
        "YouTubeVideo(id='-W6y8xnd--U', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kFh7pdxhNtT",
        "outputId": "ea3702fa-7f39-4ba4-dfea-a312ecf0bc1f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_layer (InputLayer)       [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " first_conv (Conv2D)            (None, 32, 32, 36)   972         ['input_layer[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 36)  144         ['first_conv[0][0]']             \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 32, 32, 36)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 18)   5832        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 54)   0           ['first_conv[0][0]',             \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 54)  216         ['concatenate[0][0]']            \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 32, 32, 54)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 18)   8748        ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 32, 32, 72)   0           ['concatenate[0][0]',            \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 72)  288         ['concatenate_1[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 72)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 18)   11664       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 32, 32, 90)   0           ['concatenate_1[0][0]',          \n",
            "                                                                  'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 90)  360         ['concatenate_2[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 90)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 18)   14580       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 32, 32, 108)  0           ['concatenate_2[0][0]',          \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 108)  432        ['concatenate_3[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 108)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 18)   17496       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 32, 32, 126)  0           ['concatenate_3[0][0]',          \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 126)  504        ['concatenate_4[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 126)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 18)   20412       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 32, 32, 144)  0           ['concatenate_4[0][0]',          \n",
            "                                                                  'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 144)  576        ['concatenate_5[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 18)   23328       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 32, 32, 162)  0           ['concatenate_5[0][0]',          \n",
            "                                                                  'conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 162)  648        ['concatenate_6[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 162)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 18)   26244       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 32, 32, 180)  0           ['concatenate_6[0][0]',          \n",
            "                                                                  'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 180)  720        ['concatenate_7[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 32, 32, 180)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 18)   29160       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 32, 32, 198)  0           ['concatenate_7[0][0]',          \n",
            "                                                                  'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 198)  792        ['concatenate_8[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 32, 198)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 18)   32076       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 32, 32, 216)  0           ['concatenate_8[0][0]',          \n",
            "                                                                  'conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 216)  864        ['concatenate_9[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 216)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 18)   34992       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 32, 32, 234)  0           ['concatenate_9[0][0]',          \n",
            "                                                                  'conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 234)  936        ['concatenate_10[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 234)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 18)   37908       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 32, 32, 252)  0           ['concatenate_10[0][0]',         \n",
            "                                                                  'conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 32, 32, 252)  1008       ['concatenate_11[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 32, 32, 252)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 18)   4536        ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 18)  0           ['conv2d_12[0][0]']              \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 18)  72          ['average_pooling2d[0][0]']      \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 18)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 18)   2916        ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 16, 16, 36)   0           ['average_pooling2d[0][0]',      \n",
            "                                                                  'conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 36)  144         ['concatenate_12[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 36)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 18)   5832        ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 16, 16, 54)   0           ['concatenate_12[0][0]',         \n",
            "                                                                  'conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 54)  216         ['concatenate_13[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 54)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 18)   8748        ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 16, 16, 72)   0           ['concatenate_13[0][0]',         \n",
            "                                                                  'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 72)  288         ['concatenate_14[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 72)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 18)   11664       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 16, 16, 90)   0           ['concatenate_14[0][0]',         \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 90)  360         ['concatenate_15[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 90)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 18)   14580       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 16, 16, 108)  0           ['concatenate_15[0][0]',         \n",
            "                                                                  'conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 108)  432        ['concatenate_16[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 108)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 18)   17496       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenate)   (None, 16, 16, 126)  0           ['concatenate_16[0][0]',         \n",
            "                                                                  'conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 126)  504        ['concatenate_17[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 126)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 18)   20412       ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenate)   (None, 16, 16, 144)  0           ['concatenate_17[0][0]',         \n",
            "                                                                  'conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 144)  576        ['concatenate_18[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 144)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 18)   23328       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 16, 16, 162)  0           ['concatenate_18[0][0]',         \n",
            "                                                                  'conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 162)  648        ['concatenate_19[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 162)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 18)   26244       ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 16, 16, 180)  0           ['concatenate_19[0][0]',         \n",
            "                                                                  'conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 180)  720        ['concatenate_20[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 180)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 18)   29160       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 16, 16, 198)  0           ['concatenate_20[0][0]',         \n",
            "                                                                  'conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 198)  792        ['concatenate_21[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 198)  0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 18)   32076       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 16, 16, 216)  0           ['concatenate_21[0][0]',         \n",
            "                                                                  'conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 216)  864        ['concatenate_22[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 216)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 18)   34992       ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 16, 16, 234)  0           ['concatenate_22[0][0]',         \n",
            "                                                                  'conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 234)  936        ['concatenate_23[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 234)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 18)   4212        ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 8, 8, 18)    0           ['conv2d_25[0][0]']              \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 8, 8, 18)    72          ['average_pooling2d_1[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 8, 8, 18)     0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 8, 8, 18)     2916        ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 8, 8, 36)     0           ['average_pooling2d_1[0][0]',    \n",
            "                                                                  'conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 8, 8, 36)    144         ['concatenate_24[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 8, 8, 36)     0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 8, 8, 18)     5832        ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenate)   (None, 8, 8, 54)     0           ['concatenate_24[0][0]',         \n",
            "                                                                  'conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 8, 8, 54)    216         ['concatenate_25[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 8, 8, 54)     0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 8, 8, 18)     8748        ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_26 (Concatenate)   (None, 8, 8, 72)     0           ['concatenate_25[0][0]',         \n",
            "                                                                  'conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 8, 8, 72)    288         ['concatenate_26[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 8, 8, 72)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 8, 8, 18)     11664       ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_27 (Concatenate)   (None, 8, 8, 90)     0           ['concatenate_26[0][0]',         \n",
            "                                                                  'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 8, 8, 90)    360         ['concatenate_27[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 8, 8, 90)     0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 8, 8, 18)     14580       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (None, 8, 8, 108)    0           ['concatenate_27[0][0]',         \n",
            "                                                                  'conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 8, 8, 108)   432         ['concatenate_28[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 8, 8, 108)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 8, 8, 18)     17496       ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenate)   (None, 8, 8, 126)    0           ['concatenate_28[0][0]',         \n",
            "                                                                  'conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 8, 8, 126)   504         ['concatenate_29[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 8, 8, 126)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 8, 8, 18)     20412       ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenate)   (None, 8, 8, 144)    0           ['concatenate_29[0][0]',         \n",
            "                                                                  'conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 8, 8, 144)   576         ['concatenate_30[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 8, 8, 144)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 8, 8, 18)     23328       ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (None, 8, 8, 162)    0           ['concatenate_30[0][0]',         \n",
            "                                                                  'conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 8, 8, 162)   648         ['concatenate_31[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 8, 8, 162)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 8, 8, 18)     26244       ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 8, 8, 180)    0           ['concatenate_31[0][0]',         \n",
            "                                                                  'conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 8, 8, 180)   720         ['concatenate_32[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 8, 8, 180)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 8, 8, 18)     29160       ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 8, 8, 198)    0           ['concatenate_32[0][0]',         \n",
            "                                                                  'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 8, 8, 198)   792         ['concatenate_33[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 8, 8, 198)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 8, 8, 18)     32076       ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 8, 8, 216)    0           ['concatenate_33[0][0]',         \n",
            "                                                                  'conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 8, 8, 216)   864         ['concatenate_34[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 8, 8, 216)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 8, 8, 18)     34992       ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 8, 8, 234)    0           ['concatenate_34[0][0]',         \n",
            "                                                                  'conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 8, 8, 234)   936         ['concatenate_35[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 8, 8, 234)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 8, 8, 18)     4212        ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 4, 4, 18)    0           ['conv2d_38[0][0]']              \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 4, 4, 18)    72          ['average_pooling2d_2[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 4, 4, 18)     0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 4, 4, 18)     2916        ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, 4, 4, 36)     0           ['average_pooling2d_2[0][0]',    \n",
            "                                                                  'conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 4, 4, 36)    144         ['concatenate_36[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 4, 4, 36)     0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 4, 4, 18)     5832        ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenate)   (None, 4, 4, 54)     0           ['concatenate_36[0][0]',         \n",
            "                                                                  'conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 4, 4, 54)    216         ['concatenate_37[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 4, 4, 54)     0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 4, 4, 18)     8748        ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenate)   (None, 4, 4, 72)     0           ['concatenate_37[0][0]',         \n",
            "                                                                  'conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 4, 4, 72)    288         ['concatenate_38[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 4, 4, 72)     0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 4, 4, 18)     11664       ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenate)   (None, 4, 4, 90)     0           ['concatenate_38[0][0]',         \n",
            "                                                                  'conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 4, 4, 90)    360         ['concatenate_39[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 4, 4, 90)     0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 4, 4, 18)     14580       ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenate)   (None, 4, 4, 108)    0           ['concatenate_39[0][0]',         \n",
            "                                                                  'conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 4, 4, 108)   432         ['concatenate_40[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 4, 4, 108)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 4, 4, 18)     17496       ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenate)   (None, 4, 4, 126)    0           ['concatenate_40[0][0]',         \n",
            "                                                                  'conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 4, 4, 126)   504         ['concatenate_41[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 4, 4, 126)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 4, 4, 18)     20412       ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_42 (Concatenate)   (None, 4, 4, 144)    0           ['concatenate_41[0][0]',         \n",
            "                                                                  'conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 4, 4, 144)   576         ['concatenate_42[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 4, 4, 144)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 4, 4, 18)     23328       ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenate)   (None, 4, 4, 162)    0           ['concatenate_42[0][0]',         \n",
            "                                                                  'conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 4, 4, 162)   648         ['concatenate_43[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 4, 4, 162)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 4, 4, 18)     26244       ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenate)   (None, 4, 4, 180)    0           ['concatenate_43[0][0]',         \n",
            "                                                                  'conv2d_47[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 4, 4, 180)   720         ['concatenate_44[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 4, 4, 180)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 4, 4, 18)     29160       ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenate)   (None, 4, 4, 198)    0           ['concatenate_44[0][0]',         \n",
            "                                                                  'conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 4, 4, 198)   792         ['concatenate_45[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 4, 4, 198)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 4, 4, 18)     32076       ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenate)   (None, 4, 4, 216)    0           ['concatenate_45[0][0]',         \n",
            "                                                                  'conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 4, 4, 216)   864         ['concatenate_46[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 4, 4, 216)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 4, 4, 18)     34992       ['activation_50[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenate)   (None, 4, 4, 234)    0           ['concatenate_46[0][0]',         \n",
            "                                                                  'conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 4, 4, 234)   936         ['concatenate_47[0][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 4, 4, 234)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 2, 2, 234)   0           ['activation_51[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 936)          0           ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           9370        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 995,230\n",
            "Trainable params: 981,658\n",
            "Non-trainable params: 13,572\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model= Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Aqzk9AFXb1y",
        "outputId": "d2341329-ee39-429c-8d15-bfe67daf994e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211\n"
          ]
        }
      ],
      "source": [
        "print(len(model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(x_tr)"
      ],
      "metadata": {
        "id": "DtXOL4QZzbx6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b4XOsW3ahSkL"
      },
      "outputs": [],
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.01),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KEz4C6zPbbV8"
      },
      "outputs": [],
      "source": [
        "filepath=\"model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor='val_accuracy',\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto')\n",
        "tensorboard=tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs/DenseNet',\n",
        "    histogram_freq=0,\n",
        "    write_graph=True,\n",
        "    write_images=False,\n",
        "    write_steps_per_second=False,\n",
        "    update_freq='epoch')\n",
        "def lr_update(epoch):\n",
        "  lr=0.01\n",
        "  if epoch>=25 and epoch<50 :\n",
        "    lr=0.005\n",
        "  elif epoch>=50:\n",
        "    lr=0.001  \n",
        "  return lr  \n",
        "lr_scheduler=tf.keras.callbacks.LearningRateScheduler(lr_update)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KyBLEL_0nXjy"
      },
      "outputs": [],
      "source": [
        "!rm -rf logs\n",
        "!rm -rf model_save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFQz7PzsJ1zW",
        "outputId": "a6e762c9-1bf0-438c-8ded-68bca2a2469f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "390"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(x_tr)//128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ymT_WGiRWfmQ",
        "outputId": "83cfb469-f444-4cc3-be87-c5fa30f3a15e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "390/390 [==============================] - 121s 259ms/step - loss: 1.9557 - accuracy: 0.3195 - val_loss: 1.8309 - val_accuracy: 0.3568 - lr: 0.0100\n",
            "Epoch 2/75\n",
            "390/390 [==============================] - 96s 245ms/step - loss: 1.5054 - accuracy: 0.4641 - val_loss: 1.5265 - val_accuracy: 0.4800 - lr: 0.0100\n",
            "Epoch 3/75\n",
            "390/390 [==============================] - 96s 245ms/step - loss: 1.2712 - accuracy: 0.5581 - val_loss: 1.4437 - val_accuracy: 0.5198 - lr: 0.0100\n",
            "Epoch 4/75\n",
            "390/390 [==============================] - 95s 244ms/step - loss: 1.1275 - accuracy: 0.6110 - val_loss: 1.8800 - val_accuracy: 0.4484 - lr: 0.0100\n",
            "Epoch 5/75\n",
            "390/390 [==============================] - 96s 245ms/step - loss: 1.0189 - accuracy: 0.6571 - val_loss: 1.5745 - val_accuracy: 0.5377 - lr: 0.0100\n",
            "Epoch 6/75\n",
            "390/390 [==============================] - 95s 244ms/step - loss: 0.9298 - accuracy: 0.6919 - val_loss: 1.3092 - val_accuracy: 0.5975 - lr: 0.0100\n",
            "Epoch 7/75\n",
            "390/390 [==============================] - 96s 245ms/step - loss: 0.8622 - accuracy: 0.7194 - val_loss: 1.1628 - val_accuracy: 0.6358 - lr: 0.0100\n",
            "Epoch 8/75\n",
            "390/390 [==============================] - 96s 245ms/step - loss: 0.8081 - accuracy: 0.7369 - val_loss: 0.9944 - val_accuracy: 0.6979 - lr: 0.0100\n",
            "Epoch 9/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.7688 - accuracy: 0.7506 - val_loss: 0.9826 - val_accuracy: 0.6847 - lr: 0.0100\n",
            "Epoch 10/75\n",
            "390/390 [==============================] - 95s 244ms/step - loss: 0.7225 - accuracy: 0.7666 - val_loss: 1.0411 - val_accuracy: 0.6913 - lr: 0.0100\n",
            "Epoch 11/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.7012 - accuracy: 0.7753 - val_loss: 0.8933 - val_accuracy: 0.7205 - lr: 0.0100\n",
            "Epoch 12/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.6658 - accuracy: 0.7893 - val_loss: 1.4600 - val_accuracy: 0.6113 - lr: 0.0100\n",
            "Epoch 13/75\n",
            "390/390 [==============================] - 95s 244ms/step - loss: 0.6461 - accuracy: 0.7970 - val_loss: 0.7450 - val_accuracy: 0.7731 - lr: 0.0100\n",
            "Epoch 14/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.6193 - accuracy: 0.8036 - val_loss: 0.8361 - val_accuracy: 0.7525 - lr: 0.0100\n",
            "Epoch 15/75\n",
            "390/390 [==============================] - 95s 242ms/step - loss: 0.5970 - accuracy: 0.8133 - val_loss: 0.8275 - val_accuracy: 0.7663 - lr: 0.0100\n",
            "Epoch 16/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.5833 - accuracy: 0.8180 - val_loss: 0.7953 - val_accuracy: 0.7706 - lr: 0.0100\n",
            "Epoch 17/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.5654 - accuracy: 0.8232 - val_loss: 0.9653 - val_accuracy: 0.7317 - lr: 0.0100\n",
            "Epoch 18/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.5605 - accuracy: 0.8249 - val_loss: 0.9290 - val_accuracy: 0.7609 - lr: 0.0100\n",
            "Epoch 19/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.5369 - accuracy: 0.8328 - val_loss: 0.7141 - val_accuracy: 0.7925 - lr: 0.0100\n",
            "Epoch 20/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.5229 - accuracy: 0.8371 - val_loss: 0.9057 - val_accuracy: 0.7397 - lr: 0.0100\n",
            "Epoch 21/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.5128 - accuracy: 0.8415 - val_loss: 0.6952 - val_accuracy: 0.7869 - lr: 0.0100\n",
            "Epoch 22/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.5057 - accuracy: 0.8413 - val_loss: 0.7283 - val_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 23/75\n",
            "390/390 [==============================] - 95s 242ms/step - loss: 0.4915 - accuracy: 0.8474 - val_loss: 0.7090 - val_accuracy: 0.8054 - lr: 0.0100\n",
            "Epoch 24/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.4862 - accuracy: 0.8483 - val_loss: 0.7402 - val_accuracy: 0.7890 - lr: 0.0100\n",
            "Epoch 25/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.4757 - accuracy: 0.8514 - val_loss: 0.9056 - val_accuracy: 0.7549 - lr: 0.0100\n",
            "Epoch 26/75\n",
            "390/390 [==============================] - 95s 242ms/step - loss: 0.3975 - accuracy: 0.8778 - val_loss: 0.4167 - val_accuracy: 0.8745 - lr: 0.0050\n",
            "Epoch 27/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.3729 - accuracy: 0.8844 - val_loss: 0.4796 - val_accuracy: 0.8584 - lr: 0.0050\n",
            "Epoch 28/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.3651 - accuracy: 0.8870 - val_loss: 0.4466 - val_accuracy: 0.8662 - lr: 0.0050\n",
            "Epoch 29/75\n",
            "390/390 [==============================] - 95s 244ms/step - loss: 0.3549 - accuracy: 0.8902 - val_loss: 0.4295 - val_accuracy: 0.8750 - lr: 0.0050\n",
            "Epoch 30/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.3488 - accuracy: 0.8910 - val_loss: 0.5585 - val_accuracy: 0.8378 - lr: 0.0050\n",
            "Epoch 31/75\n",
            "390/390 [==============================] - 95s 242ms/step - loss: 0.3448 - accuracy: 0.8926 - val_loss: 0.5554 - val_accuracy: 0.8410 - lr: 0.0050\n",
            "Epoch 32/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.3381 - accuracy: 0.8942 - val_loss: 0.5864 - val_accuracy: 0.8300 - lr: 0.0050\n",
            "Epoch 33/75\n",
            "390/390 [==============================] - 95s 242ms/step - loss: 0.3340 - accuracy: 0.8960 - val_loss: 0.3991 - val_accuracy: 0.8855 - lr: 0.0050\n",
            "Epoch 34/75\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.3280 - accuracy: 0.8985 - val_loss: 0.4991 - val_accuracy: 0.8555 - lr: 0.0050\n",
            "Epoch 35/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.3272 - accuracy: 0.8974 - val_loss: 0.3972 - val_accuracy: 0.8836 - lr: 0.0050\n",
            "Epoch 36/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.3143 - accuracy: 0.9018 - val_loss: 0.4883 - val_accuracy: 0.8622 - lr: 0.0050\n",
            "Epoch 37/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.3117 - accuracy: 0.9014 - val_loss: 0.3952 - val_accuracy: 0.8819 - lr: 0.0050\n",
            "Epoch 38/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.3098 - accuracy: 0.9027 - val_loss: 0.4724 - val_accuracy: 0.8649 - lr: 0.0050\n",
            "Epoch 39/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.3040 - accuracy: 0.9031 - val_loss: 0.4409 - val_accuracy: 0.8706 - lr: 0.0050\n",
            "Epoch 40/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.3034 - accuracy: 0.9045 - val_loss: 0.6310 - val_accuracy: 0.8269 - lr: 0.0050\n",
            "Epoch 41/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.2990 - accuracy: 0.9067 - val_loss: 0.6040 - val_accuracy: 0.8322 - lr: 0.0050\n",
            "Epoch 42/75\n",
            "390/390 [==============================] - 94s 241ms/step - loss: 0.2915 - accuracy: 0.9089 - val_loss: 0.5135 - val_accuracy: 0.8564 - lr: 0.0050\n",
            "Epoch 43/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.2901 - accuracy: 0.9113 - val_loss: 0.4557 - val_accuracy: 0.8694 - lr: 0.0050\n",
            "Epoch 44/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.2907 - accuracy: 0.9106 - val_loss: 0.4704 - val_accuracy: 0.8635 - lr: 0.0050\n",
            "Epoch 45/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.2855 - accuracy: 0.9128 - val_loss: 0.4882 - val_accuracy: 0.8659 - lr: 0.0050\n",
            "Epoch 46/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.2800 - accuracy: 0.9127 - val_loss: 0.8506 - val_accuracy: 0.7907 - lr: 0.0050\n",
            "Epoch 47/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.2785 - accuracy: 0.9138 - val_loss: 0.4300 - val_accuracy: 0.8790 - lr: 0.0050\n",
            "Epoch 48/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.2753 - accuracy: 0.9151 - val_loss: 0.4064 - val_accuracy: 0.8831 - lr: 0.0050\n",
            "Epoch 49/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.2726 - accuracy: 0.9152 - val_loss: 0.4854 - val_accuracy: 0.8692 - lr: 0.0050\n",
            "Epoch 50/75\n",
            "390/390 [==============================] - 95s 242ms/step - loss: 0.2667 - accuracy: 0.9187 - val_loss: 0.4109 - val_accuracy: 0.8803 - lr: 0.0050\n",
            "Epoch 51/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.2175 - accuracy: 0.9345 - val_loss: 0.3375 - val_accuracy: 0.9031 - lr: 0.0010\n",
            "Epoch 52/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.1977 - accuracy: 0.9409 - val_loss: 0.3316 - val_accuracy: 0.9055 - lr: 0.0010\n",
            "Epoch 53/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.1924 - accuracy: 0.9428 - val_loss: 0.3615 - val_accuracy: 0.8995 - lr: 0.0010\n",
            "Epoch 54/75\n",
            "390/390 [==============================] - 95s 243ms/step - loss: 0.1918 - accuracy: 0.9426 - val_loss: 0.3150 - val_accuracy: 0.9120 - lr: 0.0010\n",
            "Epoch 55/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.1868 - accuracy: 0.9439 - val_loss: 0.3249 - val_accuracy: 0.9108 - lr: 0.0010\n",
            "Epoch 56/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.1836 - accuracy: 0.9448 - val_loss: 0.3539 - val_accuracy: 0.8995 - lr: 0.0010\n",
            "Epoch 57/75\n",
            "390/390 [==============================] - 94s 242ms/step - loss: 0.1788 - accuracy: 0.9463 - val_loss: 0.3419 - val_accuracy: 0.9043 - lr: 0.0010\n",
            "Epoch 58/75\n",
            "390/390 [==============================] - 95s 244ms/step - loss: 0.1758 - accuracy: 0.9470 - val_loss: 0.3144 - val_accuracy: 0.9126 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-691a471d3458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(datagen.flow(x_tr,y_train,batch_size=128),\n\u001b[1;32m      2\u001b[0m          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          steps_per_epoch=len(x_tr)//128, epochs=75,callbacks=[checkpoint,tensorboard,lr_scheduler])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(datagen.flow(x_tr,y_train,batch_size=128),\n",
        "         validation_data=(x_te,y_test),verbose=1,\n",
        "         steps_per_epoch=len(x_tr)//128, epochs=75,callbacks=[checkpoint,tensorboard,lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcWydmIVhZGr",
        "outputId": "6dc452d9-6619-401f-8884-570d8425d769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3144 - accuracy: 0.9126\n",
            "Test loss: 0.314426064491272\n",
            "Test accuracy: 0.9125999808311462\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_te, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE3lF6EH1r_L",
        "outputId": "9eb83aae-5499-4927-ae0f-7d491c74f679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"/content/drive/MyDrive/Kaggle/DNST_model58.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtorwMzAaO6u",
        "outputId": "f1fdee62-73f6-44b0-d3fd-7594206073fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of DenseNet - cifar10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}